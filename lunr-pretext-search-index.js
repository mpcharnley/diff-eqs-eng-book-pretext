var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "front-colophon",
  "level": "1",
  "url": "front-colophon.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": "  "
},
{
  "id": "attributions",
  "level": "1",
  "url": "attributions.html",
  "type": "Subsection",
  "number": "1.1",
  "title": "Attributions",
  "body": " Attributions  The main inspiration for this book, as well as the vast majority of the source material, is Notes on Diffy Qs by Jiří Lebl . The fact that the book is freely available and open-source provided the main motivation for creating this current text. It allowed this book to be put together in a timely manner to be useful. It significantly reduced the work needed to put together a free textbook that fit the course exactly.  "
},
{
  "id": "introduction-to-this-version",
  "level": "1",
  "url": "introduction-to-this-version.html",
  "type": "Subsection",
  "number": "1.2",
  "title": "Introduction to this Version",
  "body": " Introduction to this Version  This text was originally designed for the Math 244 class at Rutgers University. This class is a first course in Differential Equations for Engineering majors. This class is taken immediately after Multivariable Calculus and does not assume any knowledge of linear algebra. Prior to the design of this book, the course used Boyce and DiPrima’s Elementary Differential Equations and Boundary Value Problems   . The course provided a very brief introduction to matrices in order to get to the information necessary to handle first order systems of differential equations. With the course being redesigned to include more linear algebra, I was pointed in the direction of Jiří Lebl’s Notes on Diffy Qs   , which was meant to be a drop-in replacement for the Boyce and DiPrima text, and as of a more recent version of the text, contained an appendix on Linear Algebra.  In creating this book, I wanted to retain the style of Notes on Diffy Qs  but shape the text into something that directly fit the course that we wanted to run. This included reorganizing some of the topics, extra contextualization of the concept of differential equations, sections devoted to modeling principles and how these equations can be derived, and guidance in using MATLAB to solve differential equations numerically. Specifically, the content added to this book is    that gives an introduction or review to coding in MATLAB, as well as references to sample MATLAB files that can be used to easily sketch slope fields and solution curves to differential equations.    Section on the accumulation equation and its use in mathematical models, and which contains a discussion of parameter estimation, with inspiration taken from SIMIODE .    The work on the eigenvalue method was split into three sections to account for real, complex, and repeated eigenvalues.    A discussion of the trace-determinant plane and applications to analysis of linear (and non-linear) systems was added in .    on prerequisite material to be referred to when needed. Some of the material here was pulled from Stitz and Zeager’s book Precalculus  .    Exercises and answers were added at the end of most sections of the text.    "
},
{
  "id": "acknowledgements",
  "level": "1",
  "url": "acknowledgements.html",
  "type": "Subsection",
  "number": "1.3",
  "title": "Acknowledgements",
  "body": " Acknowledgements  I would like to acknowledge David Molnar, who initially referred me to the Notes on Diffy Qs text , as well as the Precalculus text , and provided inspiration and motivation to work on designing this text. For feedback during the development of the text, I want to acknowledge David Herrera, Yi-Zhi Huang, and many others who have helped over the development and refinement of this text. Finally, I want to acknowledge the Rutgers Open and Affordable Textbook Program for supporting the development and implementation of this text.  "
},
{
  "id": "introduction-to-notes-on-diffy-qs",
  "level": "1",
  "url": "introduction-to-notes-on-diffy-qs.html",
  "type": "Subsection",
  "number": "1.4",
  "title": "Introduction to <em class=\"emphasis\">Notes on Diffy Qs<\/em>",
  "body": " Introduction to Notes on Diffy Qs   This book originated from my class notes for Math 286 at the University of Illinois at Urbana-Champaign (UIUC) in Fall 2008 and Spring 2009. It is a first course on differential equations for engineers. Using this book, I also taught Math 285 at UIUC, Math 20D at University of California, San Diego (UCSD), and Math 4233 at Oklahoma State University (OSU). Normally these courses are taught with Edwards and Penney, Differential Equations and Boundary Value Problems: Computing and Modeling   , or Boyce and DiPrima’s Elementary Differential Equations and Boundary Value Problems   , and this book aims to be more or less a drop-in replacement. Other books I used as sources of information and inspiration are E.L. Ince’s classic (and inexpensive) Ordinary Differential Equations   , Stanley Farlow’s Differential Equations and Their Applications   , now available from Dover, Berg and McGregor’s Elementary Partial Differential Equations   , and William Trench’s free book Elementary Differential Equations with Boundary Value Problems   . See the chapter at the end of the book.    Computer resources  The book’s website https:\/\/www.jirka.org\/diffyqs\/ contains the following resources:    Interactive SAGE demos.    Online WeBWorK homeworks (using either your own WeBWorK installation or Edfinity) for most sections, customized for this book.    The PDFs of the figures used in this book.    I taught the UIUC courses using IODE ( https:\/\/faculty.math.illinois.edu\/iode\/ ). IODE is a free software package that works with Matlab (proprietary) or Octave (free software). The graphs in the book were made with the Genius software (see https:\/\/www.jirka.org\/genius.html ). I use Genius in class to show these (and other) graphs.    Acknowledgments  Firstly, I would like to acknowledge Rick Laugesen. I used his handwritten class notes the first time I taught Math 286. My organization of this book through chapter 5, and the choice of material covered, is heavily influenced by his notes. Many examples and computations are taken from his notes. I am also heavily indebted to Rick for all the advice he has given me, not just on teaching Math 286. For spotting errors and other suggestions, I would also like to acknowledge (in no particular order): John P. D’Angelo, Sean Raleigh, Jessica Robinson, Michael Angelini, Leonardo Gomes, Jeff Winegar, Ian Simon, Thomas Wicklund, Eliot Brenner, Sean Robinson, Jannett Susberry, Dana Al-Quadi, Cesar Alvarez, Cem Bagdatlioglu, Nathan Wong, Alison Shive, Shawn White, Wing Yip Ho, Joanne Shin, Gladys Cruz, Jonathan Gomez, Janelle Louie, Navid Froutan, Grace Victorine, Paul Pearson, Jared Teague, Ziad Adwan, Martin Weilandt, Sönmez Şahutoğlu, Pete Peterson, Thomas Gresham, Prentiss Hyde, Jai Welch, Simon Tse, Andrew Browning, James Choi, Dusty Grundmeier, John Marriott, Jim Kruidenier, Barry Conrad, Wesley Snider, Colton Koop, Sarah Morse, Erik Boczko, Asif Shakeel, Chris Peterson, Nicholas Hu, Paul Seeburger, Jonathan McCormick, David Leep, William Meisel, Shishir Agrawal, Tom Wan, Andres Valloud, and probably others I have forgotten. Finally, I would like to acknowledge NSF grants DMS-0900885 and DMS-1362337.   "
},
{
  "id": "integralsols-section",
  "level": "1",
  "url": "integralsols-section.html",
  "type": "Section",
  "number": "1.1",
  "title": "Integrals as solutions",
  "body": " Integrals as solutions  A first order ODE is an equation of the form or just Some examples that fit this form are and Looking back at the last section, the first of these is linear and the second is not. In general, there is no simple formula or procedure one can follow to find solutions. In the next few sections we will look at special cases where solutions are not difficult to obtain. In this section, let us assume that is a function of alone, that is, the equation is We could just integrate (antidifferentiate) both sides with respect to . that is This is actually the general solution. So to solve , we find some antiderivative of and then we add an arbitrary constant to get the general solution.  Now is a good time to discuss a point about calculus notation and terminology. One of the final keystone concepts in Calculus 1 is that of the fundamental theorem of calculus, which ties together two mathematical ideas: (defined as the area under a curve) and or (undoing the operation of differentiation). This theorem says that these two ideas are in some sense the same; in order to compute a definite integral, one can first find an antiderivative and plug in the endpoints (the most common use of the theorem), and that the derivative of a definite integral gives back the function inside (something that will be useful in this course).  The main distinction between these two is the type of object that they are. Definite integrals evaluate to numbers, so they are functions, which means they are the object we want to deal with in this course. Indefinite integrals are families of functions, and while they have their uses (motivating the idea of a general solution), their main use is the process of antidifferentiation which leads us to solutions in the form of definite integrals. Provided that you can evaluate the antiderivative in question, these two processes will end up at exactly the same solution. If you end up confused about the terminology, the goal for this class is always a definite integral, but we can use antiderivatives to get there. Hence the terminology to when we may really mean to . Integration is just one way to compute the antiderivative (and it is a way that always works, see the following examples). Integration is defined as the area under the graph and it also happens to also compute antiderivatives. For sake of consistency, we will keep using the indefinite integral notation when we want an antiderivative, and you should always think of the definite integral as a way to write it.      Find the general solution of .    Elementary calculus tells us that the general solution must be . Let us check by differentiating: . We got precisely our equation back.    Normally, we will also have an such as for some two numbers and ( is often 0, but not always). If we do, the combination of a differential equation and an initial condition is called an . We can then write the solution as a definite integral in a nice way. Suppose our problem is , . Then the solution is Let us check! We compute Since is a constant, it’s derivative is zero, and by the fundamental theorem of calculus Therefore , and by Jupiter, is a solution. Is it the one satisfying the initial condition? Well, and since is a nice function, we know that the integral of with matching endpoints is . Therefore . It is!  Do note that the definite integral and the indefinite integral (antidifferentiation) are completely different beasts. The definite integral always evaluates to a number. Therefore, is a formula we can plug into the calculator or a computer, and it will be happy to calculate specific values for us. We will easily be able to plot the solution and work with it just like with any other function. It is not so crucial to always find a closed form for the antiderivative.      Solve     By the preceding discussion, the solution must be Here is a good way to make fun of your friends taking second semester calculus. Tell them to find the closed form solution. Ha ha ha (bad math joke). It is not possible (in closed form). There is absolutely nothing wrong with writing the solution as a definite integral. This particular integral is in fact very important in statistics.    While there is nothing wrong with writing solutions as a definite integral, they should be simplified and evaluated if possible. Given the differential equation the solution can be written as However, it is much more convenient, both for human reasoning and computers, to write this solution as So, if integrals can be evaluated and simplified to explicit functions, then they should be worked out. If it is not possible, then answers in integral form are completely fine.  Classical problems leading to differential equations solvable by integration are problems dealing with , and . You have surely seen these problems before in your calculus class.      Suppose a car drives at a speed meters per second, where is time in seconds. How far did the car get in 2 seconds (starting at )? How far in 10 seconds?    Let denote the distance the car traveled. The equation is We just integrate this equation to get that We still need to figure out . We know that when , then . That is, . So Thus and Now we just plug in to get where the car is at 2 and at 10 seconds. We obtain         Suppose that the car accelerates at a rate of . At time the car is at the 1 meter mark and is traveling at . Where is the car at time ?    Well this is actually a second order problem. If is the distance traveled, then is the velocity, and is the acceleration. The initial value problem for this situation is What if we say . Then we have the problem Once we solve for , we can integrate and find .      Solve for , and then solve for . Find to answer the question.     Exercises    Solve with .           Solve with .           Solve with .      Solve with .           Solve with .           Solve with .           Solve for . (This requires partial fractions or hyperbolic trigonometric functions.)           Solve for , .           A spaceship is traveling at the speed ( is time in seconds). It is pointing directly away from earth and at time it is 1000 kilometers from earth. How far from earth is it at one minute from time ?           Sid is in a car traveling at speed miles per hour away from Las Vegas, where is in hours. At , Sid is 10 miles away from Vegas. How far from Vegas is Sid 2 hours later?      Solve , . It is OK to leave your answer as a definite integral.           Solve , . The answer can be left as a definite integral.           A dropped ball accelerates downwards at a constant rate meters per second squared. Set up the differential equation for the height above ground in meters. Then supposing meters, how long does it take for the ball to hit the ground.           The rate of change of the volume of a snowball that is melting is proportional to the surface area of the snowball. Suppose the snowball is perfectly spherical. The volume (in centimeters cubed) of a ball of radius centimeters is . The surface area is . Set up the differential equation for how the radius is changing. Then, suppose that at time minutes, the radius is 10 centimeters. After 5 minutes, the radius is 8 centimeters. At what time will the snowball be completely melted?      Find the general solution to . How many distinct constants do you need?     "
},
{
  "id": "integralsols-section-5",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-5",
  "type": "Example",
  "number": "1.1.1",
  "title": ".",
  "body": "    Find the general solution of .    Elementary calculus tells us that the general solution must be . Let us check by differentiating: . We got precisely our equation back.   "
},
{
  "id": "integralsols-section-8",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-8",
  "type": "Example",
  "number": "1.1.2",
  "title": ".",
  "body": "    Solve     By the preceding discussion, the solution must be Here is a good way to make fun of your friends taking second semester calculus. Tell them to find the closed form solution. Ha ha ha (bad math joke). It is not possible (in closed form). There is absolutely nothing wrong with writing the solution as a definite integral. This particular integral is in fact very important in statistics.   "
},
{
  "id": "integralsols-section-11",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-11",
  "type": "Example",
  "number": "1.1.3",
  "title": ".",
  "body": "    Suppose a car drives at a speed meters per second, where is time in seconds. How far did the car get in 2 seconds (starting at )? How far in 10 seconds?    Let denote the distance the car traveled. The equation is We just integrate this equation to get that We still need to figure out . We know that when , then . That is, . So Thus and Now we just plug in to get where the car is at 2 and at 10 seconds. We obtain    "
},
{
  "id": "integralsols-section-12",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-12",
  "type": "Example",
  "number": "1.1.4",
  "title": ".",
  "body": "    Suppose that the car accelerates at a rate of . At time the car is at the 1 meter mark and is traveling at . Where is the car at time ?    Well this is actually a second order problem. If is the distance traveled, then is the velocity, and is the acceleration. The initial value problem for this situation is What if we say . Then we have the problem Once we solve for , we can integrate and find .   "
},
{
  "id": "integralsols-section-13",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-13",
  "type": "Checkpoint",
  "number": "1.1.5",
  "title": "",
  "body": "  Solve for , and then solve for . Find to answer the question.   "
},
{
  "id": "integralsols-section-14-2",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-2",
  "type": "Exercise",
  "number": "1.1.1",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "integralsols-section-14-3",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-3",
  "type": "Exercise",
  "number": "1.1.2",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "integralsols-section-14-4",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-4",
  "type": "Exercise",
  "number": "1.1.3",
  "title": "",
  "body": "  Solve with .   "
},
{
  "id": "integralsols-section-14-5",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-5",
  "type": "Exercise",
  "number": "1.1.4",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "integralsols-section-14-6",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-6",
  "type": "Exercise",
  "number": "1.1.5",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "integralsols-section-14-7",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-7",
  "type": "Exercise",
  "number": "1.1.6",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "integralsols-section-14-8",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-8",
  "type": "Exercise",
  "number": "1.1.7",
  "title": "",
  "body": "  Solve for . (This requires partial fractions or hyperbolic trigonometric functions.)        "
},
{
  "id": "integralsols-section-14-9",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-9",
  "type": "Exercise",
  "number": "1.1.8",
  "title": "",
  "body": "  Solve for , .        "
},
{
  "id": "integralsols-section-14-10",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-10",
  "type": "Exercise",
  "number": "1.1.9",
  "title": "",
  "body": "  A spaceship is traveling at the speed ( is time in seconds). It is pointing directly away from earth and at time it is 1000 kilometers from earth. How far from earth is it at one minute from time ?        "
},
{
  "id": "integralsols-section-14-11",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-11",
  "type": "Exercise",
  "number": "1.1.10",
  "title": "",
  "body": "  Sid is in a car traveling at speed miles per hour away from Las Vegas, where is in hours. At , Sid is 10 miles away from Vegas. How far from Vegas is Sid 2 hours later?   "
},
{
  "id": "integralsols-section-14-12",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-12",
  "type": "Exercise",
  "number": "1.1.11",
  "title": "",
  "body": "  Solve , . It is OK to leave your answer as a definite integral.        "
},
{
  "id": "integralsols-section-14-13",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-13",
  "type": "Exercise",
  "number": "1.1.12",
  "title": "",
  "body": "  Solve , . The answer can be left as a definite integral.        "
},
{
  "id": "integralsols-section-14-14",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-14",
  "type": "Exercise",
  "number": "1.1.13",
  "title": "",
  "body": "  A dropped ball accelerates downwards at a constant rate meters per second squared. Set up the differential equation for the height above ground in meters. Then supposing meters, how long does it take for the ball to hit the ground.        "
},
{
  "id": "integralsols-section-14-15",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-15",
  "type": "Exercise",
  "number": "1.1.14",
  "title": "",
  "body": "  The rate of change of the volume of a snowball that is melting is proportional to the surface area of the snowball. Suppose the snowball is perfectly spherical. The volume (in centimeters cubed) of a ball of radius centimeters is . The surface area is . Set up the differential equation for how the radius is changing. Then, suppose that at time minutes, the radius is 10 centimeters. After 5 minutes, the radius is 8 centimeters. At what time will the snowball be completely melted?   "
},
{
  "id": "integralsols-section-14-16",
  "level": "2",
  "url": "integralsols-section.html#integralsols-section-14-16",
  "type": "Exercise",
  "number": "1.1.15",
  "title": "",
  "body": "  Find the general solution to . How many distinct constants do you need?   "
},
{
  "id": "slopefields-section",
  "level": "1",
  "url": "slopefields-section.html",
  "type": "Section",
  "number": "1.2",
  "title": "Slope fields",
  "body": " Slope fields   As we said, the general first order equation we are studying looks like A lot of the time, we cannot simply solve these kinds of equations explicitly, because our direct integration method only works when the equation is of the form which we could integrate directly. In these more complicated cases, it would be nice if we could at least figure out the shape and behavior of the solutions, or find approximate solutions.    Slope fields   2.75in  Suppose that we have a solution to the equation with . What does the fact that this solves the differential equation tell us about the solution? It tells us that the derivative of the solution at this point will be . Graphically, the derivative gives the slope of the solution, so it means that the solution will pass through the point and will have slope . For example, if , then at point we draw a short line of slope . So, if is a solution and , then the equation mandates that . See .  To get an idea of how solutions behave, we draw such lines at lots of points in the plane, not just the point . We would ideally want to see the slope at every point, but that is just not possible. Usually we pick a grid of points fine enough so that it shows the behavior, but not too fine so that we can still recognize the individual lines. We call this picture the of the equation. See for the slope field of the equation . Usually in practice, one does not do this by hand, but has a computer do the drawing.  The idea of a slope field is that it tells us how the graph of the solution should be sloped, or should curve, if it passed through a given point. Having a wide variety of slopes plotted in our slope field gives an idea of how all of the solutions behave for a bunch of different initial conditions. Which curve we want in particular, and where we should start the curve, depends on the initial condition.  Suppose we are given a specific initial condition . A solution, that is, the graph of the solution, would be a curve that follows the slopes we drew, starting from the point . For a few sample solutions, see . It is easy to roughly sketch (or at least imagine) possible solutions in the slope field, just from looking at the slope field itself. You simply sketch a line that roughly fits the little line segments and goes through your initial condition. The graph should flow along the little slopes that are on the slope field.    By looking at the slope field we get a lot of information about the behavior of solutions without having to solve the equation. For example, in we see what the solutions do when the initial conditions are , and . A small change in the initial condition causes quite different behavior. We see this behavior just from the slope field and imagining what solutions ought to do.  We see a different behavior for the equation . The slope field and a few solutions is in see . If we think of moving from left to right (perhaps is time and time is usually increasing), then we see that no matter what is, all solutions tend to zero as tends to infinity. Again that behavior is clear from simply looking at the slope field itself.      Exercises    Sketch slope field for . How do the solutions behave as grows? Can you guess a particular solution by looking at the slope field?      image    is a solution.    Sketch the slope field of . Can you visually find the solution that satisfies ?      Sketch slope field for .           Sketch slope field for .           For each of the following differential equations, sketch out a slope field on and and determine the overall behavior of the solutions to the equation as . If this fact depends on the value of the solution at , explain how it changes.   (4)        a)       image   b)     image   c)     image   d)     image   a) Solutions tend to . b) Solutions go to if , goes to is . Constant if . c) Solutions go to if , goes to is . Constant if . d) Solutions tend to .    Which of the following slope fields corresponds to the differential equation . Explain your reasoning.   (3)    image     image     image     b)      Which of the following slope fields corresponds to the differential equation . Explain your reasoning.   (3)    image     image     image     c)      Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)        Match equations , , to slope fields. Justify.   (3)    image     image     image       Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)        Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)        The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Tends to 3      The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Tends to -4      The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Goes to . Will not exist for all positive values.       image      image      image     Take , , where for all and . If the solution exists for all , can you say what happens to as goes to positive infinity? Explain.    Yes, it will go to .      Suppose . What will the slope field look like, explain and sketch an example, if you know the following about :   (2) does not depend on . does not depend on . for any number . and for all .    a) Slopes are independent of . On a vertical line, the slopes are all the same. b) Slopes are independent of . Horizontal invariance. c) Horizontal tangents along the line . d) Horizontal tangents along the -axis, so is a solution. Slope along .      Describe what each of the following facts about the function tells you about the slope field for the differential equation .    for all  for all  for all  for all     a) Horizontal tangents along . b) Horizontal tangents along the line . c) Slope one along the line . Also is a solution. d) Horizontal tangents along the line .     "
},
{
  "id": "slopefields-section-4-2",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-2",
  "type": "Exercise",
  "number": "1.2.2.1",
  "title": "",
  "body": "  Sketch slope field for . How do the solutions behave as grows? Can you guess a particular solution by looking at the slope field?   "
},
{
  "id": "slopefields-section-4-3",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-3",
  "type": "Figure",
  "number": "1.2.1",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-5",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-5",
  "type": "Exercise",
  "number": "1.2.2.2",
  "title": "",
  "body": "  Sketch the slope field of . Can you visually find the solution that satisfies ?   "
},
{
  "id": "slopefields-section-4-6",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-6",
  "type": "Exercise",
  "number": "1.2.2.3",
  "title": "",
  "body": "  Sketch slope field for .        "
},
{
  "id": "slopefields-section-4-7",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-7",
  "type": "Exercise",
  "number": "1.2.2.4",
  "title": "",
  "body": "  Sketch slope field for .        "
},
{
  "id": "slopefields-section-4-8",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-8",
  "type": "Exercise",
  "number": "1.2.2.5",
  "title": "",
  "body": "  For each of the following differential equations, sketch out a slope field on and and determine the overall behavior of the solutions to the equation as . If this fact depends on the value of the solution at , explain how it changes.   (4)        a)    "
},
{
  "id": "slopefields-section-4-9",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-9",
  "type": "Figure",
  "number": "1.2.2",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-11",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-11",
  "type": "Figure",
  "number": "1.2.3",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-13",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-13",
  "type": "Figure",
  "number": "1.2.4",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-15",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-15",
  "type": "Figure",
  "number": "1.2.5",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-17",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-17",
  "type": "Exercise",
  "number": "1.2.2.6",
  "title": "",
  "body": "  Which of the following slope fields corresponds to the differential equation . Explain your reasoning.   (3)    image     image     image     b)   "
},
{
  "id": "slopefields-section-4-18",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-18",
  "type": "Exercise",
  "number": "1.2.2.7",
  "title": "",
  "body": "  Which of the following slope fields corresponds to the differential equation . Explain your reasoning.   (3)    image     image     image     c)   "
},
{
  "id": "slopefields-section-4-19",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-19",
  "type": "Exercise",
  "number": "1.2.2.8",
  "title": "",
  "body": "  Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)     "
},
{
  "id": "slopefields-section-4-20",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-20",
  "type": "Exercise",
  "number": "1.2.2.9",
  "title": "",
  "body": "  Match equations , , to slope fields. Justify.   (3)    image     image     image    "
},
{
  "id": "slopefields-section-4-21",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-21",
  "type": "Exercise",
  "number": "1.2.2.10",
  "title": "",
  "body": "  Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)     "
},
{
  "id": "slopefields-section-4-22",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-22",
  "type": "Exercise",
  "number": "1.2.2.11",
  "title": "",
  "body": "  Match equations , , to slope fields. Justify.   (3)    image     image     image     a)  b)  c)     "
},
{
  "id": "slopefields-section-4-23",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-23",
  "type": "Exercise",
  "number": "1.2.2.12",
  "title": "",
  "body": "  The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Tends to 3   "
},
{
  "id": "slopefields-section-4-24",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-24",
  "type": "Exercise",
  "number": "1.2.2.13",
  "title": "",
  "body": "  The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Tends to -4   "
},
{
  "id": "slopefields-section-4-25",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-25",
  "type": "Exercise",
  "number": "1.2.2.14",
  "title": "",
  "body": "  The slope field for the differential equation is below. If we find the solution to this differential equation with initial condition, , what will happen to the solution as ? Use the slope field and your knowledge of the equation to determine the long-time behavior of this solution.    Goes to . Will not exist for all positive values.   "
},
{
  "id": "slopefields-section-4-26",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-26",
  "type": "Figure",
  "number": "1.2.24",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-27",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-27",
  "type": "Figure",
  "number": "1.2.25",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-28",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-28",
  "type": "Figure",
  "number": "1.2.26",
  "title": "",
  "body": "  image  "
},
{
  "id": "slopefields-section-4-29",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-29",
  "type": "Exercise",
  "number": "1.2.2.15",
  "title": "",
  "body": "  Take , , where for all and . If the solution exists for all , can you say what happens to as goes to positive infinity? Explain.    Yes, it will go to .   "
},
{
  "id": "slopefields-section-4-30",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-30",
  "type": "Exercise",
  "number": "1.2.2.16",
  "title": "",
  "body": "  Suppose . What will the slope field look like, explain and sketch an example, if you know the following about :   (2) does not depend on . does not depend on . for any number . and for all .    a) Slopes are independent of . On a vertical line, the slopes are all the same. b) Slopes are independent of . Horizontal invariance. c) Horizontal tangents along the line . d) Horizontal tangents along the -axis, so is a solution. Slope along .   "
},
{
  "id": "slopefields-section-4-31",
  "level": "2",
  "url": "slopefields-section.html#slopefields-section-4-31",
  "type": "Exercise",
  "number": "1.2.2.17",
  "title": "",
  "body": "  Describe what each of the following facts about the function tells you about the slope field for the differential equation .    for all  for all  for all  for all     a) Horizontal tangents along . b) Horizontal tangents along the line . c) Slope one along the line . Also is a solution. d) Horizontal tangents along the line .   "
},
{
  "id": "separable-section",
  "level": "1",
  "url": "separable-section.html",
  "type": "Section",
  "number": "1.3",
  "title": "Separable equations",
  "body": " Separable equations    After this section, you will be able to:     Identify when a differential equation is separable.    Find the general solution of a separable differential equation, and    Solve initial value problems for separable differential equations.      As mentioned in , when a differential equation is of the form , we can just integrate: . Unfortunately this method no longer works for the general form of the equation . Integrating both sides yields . Notice the dependence on in the integral. Since is a function of , this expression is really of the form and without knowing what is in advance (which we don't, because that's what we are trying to solve for) we can't compute this integral. Note that while you may have seen integrals of the form in Calculus 3, this is not the same situation. In that class, and were both independent variables, so we could integrate this expression in , treating as a constant. However, here is a function of , so they are not both independent variables and can not be treated like a constant. If is a function of and any shows up in the integral, you can not compute it.    Separable equations  One particular type of differential equation that we can evaluate using a technique very similar to direct integration is separable equations.    We say a differential equation is separable if we can write it as , for some functions and .    Let us write the equation in the . Then we rewrite the equation as . It looks like we just separated the derivative as a fraction. The actual reasoning here is the differential from Calculus 1. This is the fact that for a function of , we know that . This means that we can take the equation , rearrange it as and then multiply both sides by to get which leads to the rewritten equation above. Both sides look like something we can integrate. We obtain . If we can find closed form expressions for these two integrals, we can, perhaps, solve for .    Solve the equation .    Note that is a solution. We will remember that fact and assume from now on, so that we can divide by . Write the equation as . Then . We compute the antiderivatives to get , or , where is some constant. Because is also a solution and because of the absolute value we can write: , for any number (including zero or negative).  We check: . Yay!    One particular case in which this method works very well is if the function is only a function of . With this, we can explicitly complete the solution to equations like . reaching the solution .  We should be a little bit more careful with this method. You may be worried that we integrated in two different variables. We seemingly did a different operation to each side. Let us work through this method more rigorously. Take . We rewrite the equation as follows. Note that is a function of and so is ! . We integrate both sides with respect to : . We use the change of variables formula (substitution) on the left hand side: . And we are done.  However, in some cases there are some special solutions to these problems as well that don't fit the same formula. Assume we have and we have a value such that . Then, the function is a solution, provided is defined everywhere. (Plug this in and check!) This fills in the issue for having in our integral expression, which is not defined when . These are called singular solutions , and the next example will showcase one of them.    Implicit solutions  We sometimes get stuck even if we can do the integration. Consider the separable equation We separate variables, . We integrate to get , or perhaps the easier looking expression (where ) . It is not easy to find the solution explicitly as it is hard to solve for . We, therefore, leave the solution in this form and call it an implicit solution . It is still easy to check that an implicit solution satisfies the differential equation. In this case, we differentiate with respect to , and remember that is a function of , to get . Multiply both sides by and divide by and you will get exactly the differential equation. We leave this computation to the reader.  If you have an implicit solution, and you want to compute values for , you might have to be tricky. You might get multiple solutions for each , so you have to pick one. Sometimes you can graph as a function of , and then flip your paper. Sometimes you have to do more.  Computers are also good at some of these tricks. More advanced mathematical software usually has some way of plotting solutions to implicit equations, which makes these solutions just as good for visualizing or graphing as explicit solutions. For example, for if you plot all the points that are solutions to , you find the two curves in . This is not quite a graph of a function. For each there are two choices of . To find a function you would have to pick one of these two curves. You pick the one that satisfies your initial condition if you have one. For example, the top curve satisfies the condition . So for each we really got two solutions. As you can see, computing values from an implicit solution can be somewhat tricky, but sometimes, an implicit solution is the best we can do.   The implicit solution to .   A graph showing two curves, both representing the same implicit solution. The graph is somewhat parabolic, one pointing up and one pointing down.  The graph shows two different curves, both composing the implicit solution . One comes in from the top left, coming to a minimum at and then leaving to the top right. The second curve comes in from the bottom left, hits a maximum at and then leaves to the bottom right.    The equation above also has the solution . Since our function is zero at , and gives an additional solution to the problem. The function satisfies and for all , which is the right-hand side of the equation. So the general solution is These outlying solutions such as are sometimes called singular solutions , as mentioned previously.    Examples of separable equations    Solve , .    Factor the right-hand side . Separate variables, integrate, and solve for : Solve for the initial condition, to get (or , or , etc.). The particular solution we seek is, therefore, .     A first modeling problem   Bob made a cup of coffee, and Bob likes to drink coffee only once reaches 60 degrees Celsius and will not burn him. Initially at time minutes, Bob measured the temperature and the coffee was 89 degrees Celsius. One minute later, Bob measured the coffee again and it had 85 degrees. The temperature of the room (the ambient temperature) is 22 degrees. When should Bob start drinking?    Let be the temperature of the coffee in degrees Celsius, and let be the ambient (room) temperature, also in degrees Celsius. states that the rate at which the temperature of the coffee is changing is proportional to the difference between the ambient temperature and the temperature of the coffee. That is, for some constant . For our setup , , . We separate variables and integrate (let and denote arbitrary constants): . That is, . We plug in the first condition: , and hence . So . The second condition says . Solving for we get . Now we solve for the time that gives us a temperature of 60 degrees. Namely, we solve to get minutes. So Bob can begin to drink the coffee at just over 9 minutes from the time Bob made it. That is probably about the amount of time it took us to calculate how long it would take. See .   Graphs of the coffee temperature function . On the left, horizontal lines are drawn at temperatures 60, 85, and 89. Vertical lines are drawn at and . Notice that the temperature of the coffee hits 85 at , and 60 at . On the right, the graph is over a longer period of time, with a horizontal line at the ambient temperature 22.   The left graph shows the decaying temperature of the coffee over the time range of 0 to 12.5 minutes, with markings for 89, 85, and 60 degrees as described in the caption. The plot on the right shows the same curve over the range of 0 to 90 minutes to show the long-time behavior approaching 22.       Example with singular solutions   Find the general solution to (including singular solutions).    First note that is a solution (a singular solution). Now assume that . . So the general solution is, .      Find the general solution to     Using the methods of separable equations, we can rewrite this differential equation as and we can integrate both sides to solve. This leads to The right-hand side of this can be integrated normally to give and the left-hand side requires partial fractions in order to integrate correctly. If you are not familiar with this technique of partial fractions, it is reviewed in .  Using the method of partial fractions, we want to rewrite and solve for and , which gives Therefore, we can compute the integral .  Therefore, we can write the general solution as We could solve this out for as an explicit function, but that is not necessary for a problem like this.  There are also two singular solutions here at and . Notice that the implicit solution that we found previously is not defined at either of these values, because they involve taking the natural log of , which is not defined.      Exercises    Solve for .           Solve , .      Solve for . (Note: Requires partial fractions)           Solve , .      Solve for .           Solve .           Solve .           Consider the differential equation      Find the general solution as an implicit function.           Find the solution to this differential equation as an explicit function with .           Find the solution to this differential equation as an explicit function with .            Solve , , where is a positive integer. Hint: You have to consider different cases.      Solve , for . (Note: Requires partial fractions)           Solve , for .           Solve .      Solve with .           Solve . Hint: Factor the right-hand side.           Solve , .      Find the general solution of , and then .     ,       Solve , where .           Find an implicit solution for , .      Solve , for .           Find an implicit solution for , for .           Find an implicit solution to .      Find an implicit solution for with .           Find an explicit solution for , .           Find an explicit solution to , .      Find an explicit solution for , for .           Find an explicit solution for with .           Find an explicit solution for with .           Find an explicit solution for , . It is alright to leave a definite integral in your answer.           Is the equation separable? If so, find the general solution, if not, explain why.    No      Is the equation separable? If so, find the general solution, if not, explain why.    Yes.       Is the equation separable? If so, find the general solution, if not, explain why. (Note: Requires partial fractions)    Yes.       Suppose a cup of coffee is at 100 degrees Celsius at time , it is at 70 degrees at minutes, and it is at 50 degrees at minutes. Compute the ambient temperature.    10 C      Take with the same numbers: 89 degrees at , 85 degrees at , and ambient temperature of 22 degrees. Suppose these temperatures were measured with precision of degrees. Given this imprecision, the time it takes the coffee to cool to (exactly) 60 degrees is also only known in a certain range. Find this range. Hint: Think about what kind of error makes the cooling time longer and what shorter.      A population of rabbits on an island is modeled by , where the independent variable is time in months. At time , there are 40 rabbits on the island.     Find the solution to the equation with the initial condition.           How many rabbits are on the island in 1 month, 5 months, 10 months, 15 months (round to the nearest integer).    102 rabbits after one month, 861 after 5 months, 999 after 10 months, 1000 after 15 months.      "
},
{
  "id": "separable-section-2",
  "level": "2",
  "url": "separable-section.html#separable-section-2",
  "type": "Objectives",
  "number": "1.3",
  "title": "",
  "body": "  After this section, you will be able to:     Identify when a differential equation is separable.    Find the general solution of a separable differential equation, and    Solve initial value problems for separable differential equations.    "
},
{
  "id": "def-separableeqn",
  "level": "2",
  "url": "separable-section.html#def-separableeqn",
  "type": "Definition",
  "number": "1.3.1",
  "title": "",
  "body": "  We say a differential equation is separable if we can write it as , for some functions and .   "
},
{
  "id": "separable-equations-5",
  "level": "2",
  "url": "separable-section.html#separable-equations-5",
  "type": "Example",
  "number": "1.3.2",
  "title": "",
  "body": "  Solve the equation .    Note that is a solution. We will remember that fact and assume from now on, so that we can divide by . Write the equation as . Then . We compute the antiderivatives to get , or , where is some constant. Because is also a solution and because of the absolute value we can write: , for any number (including zero or negative).  We check: . Yay!   "
},
{
  "id": "separable-equations-8",
  "level": "2",
  "url": "separable-section.html#separable-equations-8",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "singular solutions "
},
{
  "id": "implicit-solutions-2",
  "level": "2",
  "url": "separable-section.html#implicit-solutions-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "implicit solution "
},
{
  "id": "implicitsols-fig",
  "level": "2",
  "url": "separable-section.html#implicitsols-fig",
  "type": "Figure",
  "number": "1.3.3",
  "title": "",
  "body": " The implicit solution to .   A graph showing two curves, both representing the same implicit solution. The graph is somewhat parabolic, one pointing up and one pointing down.  The graph shows two different curves, both composing the implicit solution . One comes in from the top left, coming to a minimum at and then leaving to the top right. The second curve comes in from the bottom left, hits a maximum at and then leaves to the bottom right.   "
},
{
  "id": "examples-of-separable-equations-2",
  "level": "2",
  "url": "separable-section.html#examples-of-separable-equations-2",
  "type": "Example",
  "number": "1.3.4",
  "title": "",
  "body": "  Solve , .    Factor the right-hand side . Separate variables, integrate, and solve for : Solve for the initial condition, to get (or , or , etc.). The particular solution we seek is, therefore, .   "
},
{
  "id": "examples-of-separable-equations-3",
  "level": "2",
  "url": "separable-section.html#examples-of-separable-equations-3",
  "type": "Example",
  "number": "1.3.5",
  "title": "A first modeling problem.",
  "body": " A first modeling problem   Bob made a cup of coffee, and Bob likes to drink coffee only once reaches 60 degrees Celsius and will not burn him. Initially at time minutes, Bob measured the temperature and the coffee was 89 degrees Celsius. One minute later, Bob measured the coffee again and it had 85 degrees. The temperature of the room (the ambient temperature) is 22 degrees. When should Bob start drinking?    Let be the temperature of the coffee in degrees Celsius, and let be the ambient (room) temperature, also in degrees Celsius. states that the rate at which the temperature of the coffee is changing is proportional to the difference between the ambient temperature and the temperature of the coffee. That is, for some constant . For our setup , , . We separate variables and integrate (let and denote arbitrary constants): . That is, . We plug in the first condition: , and hence . So . The second condition says . Solving for we get . Now we solve for the time that gives us a temperature of 60 degrees. Namely, we solve to get minutes. So Bob can begin to drink the coffee at just over 9 minutes from the time Bob made it. That is probably about the amount of time it took us to calculate how long it would take. See .   Graphs of the coffee temperature function . On the left, horizontal lines are drawn at temperatures 60, 85, and 89. Vertical lines are drawn at and . Notice that the temperature of the coffee hits 85 at , and 60 at . On the right, the graph is over a longer period of time, with a horizontal line at the ambient temperature 22.   The left graph shows the decaying temperature of the coffee over the time range of 0 to 12.5 minutes, with markings for 89, 85, and 60 degrees as described in the caption. The plot on the right shows the same curve over the range of 0 to 90 minutes to show the long-time behavior approaching 22.     "
},
{
  "id": "examples-of-separable-equations-4",
  "level": "2",
  "url": "separable-section.html#examples-of-separable-equations-4",
  "type": "Example",
  "number": "1.3.7",
  "title": "Example with singular solutions.",
  "body": " Example with singular solutions   Find the general solution to (including singular solutions).    First note that is a solution (a singular solution). Now assume that . . So the general solution is, .   "
},
{
  "id": "examples-of-separable-equations-5",
  "level": "2",
  "url": "separable-section.html#examples-of-separable-equations-5",
  "type": "Example",
  "number": "1.3.8",
  "title": "",
  "body": "  Find the general solution to     Using the methods of separable equations, we can rewrite this differential equation as and we can integrate both sides to solve. This leads to The right-hand side of this can be integrated normally to give and the left-hand side requires partial fractions in order to integrate correctly. If you are not familiar with this technique of partial fractions, it is reviewed in .  Using the method of partial fractions, we want to rewrite and solve for and , which gives Therefore, we can compute the integral .  Therefore, we can write the general solution as We could solve this out for as an explicit function, but that is not necessary for a problem like this.  There are also two singular solutions here at and . Notice that the implicit solution that we found previously is not defined at either of these values, because they involve taking the natural log of , which is not defined.   "
},
{
  "id": "separable-section-7-2",
  "level": "2",
  "url": "separable-section.html#separable-section-7-2",
  "type": "Exercise",
  "number": "1.3.4.1",
  "title": "",
  "body": "  Solve for .        "
},
{
  "id": "separable-section-7-3",
  "level": "2",
  "url": "separable-section.html#separable-section-7-3",
  "type": "Exercise",
  "number": "1.3.4.2",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "separable-section-7-4",
  "level": "2",
  "url": "separable-section.html#separable-section-7-4",
  "type": "Exercise",
  "number": "1.3.4.3",
  "title": "",
  "body": "  Solve for . (Note: Requires partial fractions)        "
},
{
  "id": "separable-section-7-5",
  "level": "2",
  "url": "separable-section.html#separable-section-7-5",
  "type": "Exercise",
  "number": "1.3.4.4",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "separable-section-7-6",
  "level": "2",
  "url": "separable-section.html#separable-section-7-6",
  "type": "Exercise",
  "number": "1.3.4.5",
  "title": "",
  "body": "  Solve for .        "
},
{
  "id": "separable-section-7-7",
  "level": "2",
  "url": "separable-section.html#separable-section-7-7",
  "type": "Exercise",
  "number": "1.3.4.6",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "separable-section-7-8",
  "level": "2",
  "url": "separable-section.html#separable-section-7-8",
  "type": "Exercise",
  "number": "1.3.4.7",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "separable-section-7-9",
  "level": "2",
  "url": "separable-section.html#separable-section-7-9",
  "type": "Exercise",
  "number": "1.3.4.8",
  "title": "",
  "body": "  Consider the differential equation      Find the general solution as an implicit function.           Find the solution to this differential equation as an explicit function with .           Find the solution to this differential equation as an explicit function with .         "
},
{
  "id": "separable-section-7-10",
  "level": "2",
  "url": "separable-section.html#separable-section-7-10",
  "type": "Exercise",
  "number": "1.3.4.9",
  "title": "",
  "body": "  Solve , , where is a positive integer. Hint: You have to consider different cases.   "
},
{
  "id": "separable-section-7-11",
  "level": "2",
  "url": "separable-section.html#separable-section-7-11",
  "type": "Exercise",
  "number": "1.3.4.10",
  "title": "",
  "body": "  Solve , for . (Note: Requires partial fractions)        "
},
{
  "id": "separable-section-7-12",
  "level": "2",
  "url": "separable-section.html#separable-section-7-12",
  "type": "Exercise",
  "number": "1.3.4.11",
  "title": "",
  "body": "  Solve , for .        "
},
{
  "id": "separable-section-7-13",
  "level": "2",
  "url": "separable-section.html#separable-section-7-13",
  "type": "Exercise",
  "number": "1.3.4.12",
  "title": "",
  "body": "  Solve .   "
},
{
  "id": "separable-section-7-14",
  "level": "2",
  "url": "separable-section.html#separable-section-7-14",
  "type": "Exercise",
  "number": "1.3.4.13",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "separable-section-7-15",
  "level": "2",
  "url": "separable-section.html#separable-section-7-15",
  "type": "Exercise",
  "number": "1.3.4.14",
  "title": "",
  "body": "  Solve . Hint: Factor the right-hand side.        "
},
{
  "id": "separable-section-7-16",
  "level": "2",
  "url": "separable-section.html#separable-section-7-16",
  "type": "Exercise",
  "number": "1.3.4.15",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "separable-section-7-17",
  "level": "2",
  "url": "separable-section.html#separable-section-7-17",
  "type": "Exercise",
  "number": "1.3.4.16",
  "title": "",
  "body": "  Find the general solution of , and then .     ,    "
},
{
  "id": "separable-section-7-18",
  "level": "2",
  "url": "separable-section.html#separable-section-7-18",
  "type": "Exercise",
  "number": "1.3.4.17",
  "title": "",
  "body": "  Solve , where .        "
},
{
  "id": "separable-section-7-19",
  "level": "2",
  "url": "separable-section.html#separable-section-7-19",
  "type": "Exercise",
  "number": "1.3.4.18",
  "title": "",
  "body": "  Find an implicit solution for , .   "
},
{
  "id": "separable-section-7-20",
  "level": "2",
  "url": "separable-section.html#separable-section-7-20",
  "type": "Exercise",
  "number": "1.3.4.19",
  "title": "",
  "body": "  Solve , for .        "
},
{
  "id": "separable-section-7-21",
  "level": "2",
  "url": "separable-section.html#separable-section-7-21",
  "type": "Exercise",
  "number": "1.3.4.20",
  "title": "",
  "body": "  Find an implicit solution for , for .        "
},
{
  "id": "separable-section-7-22",
  "level": "2",
  "url": "separable-section.html#separable-section-7-22",
  "type": "Exercise",
  "number": "1.3.4.21",
  "title": "",
  "body": "  Find an implicit solution to .   "
},
{
  "id": "separable-section-7-23",
  "level": "2",
  "url": "separable-section.html#separable-section-7-23",
  "type": "Exercise",
  "number": "1.3.4.22",
  "title": "",
  "body": "  Find an implicit solution for with .        "
},
{
  "id": "separable-section-7-24",
  "level": "2",
  "url": "separable-section.html#separable-section-7-24",
  "type": "Exercise",
  "number": "1.3.4.23",
  "title": "",
  "body": "  Find an explicit solution for , .        "
},
{
  "id": "separable-section-7-25",
  "level": "2",
  "url": "separable-section.html#separable-section-7-25",
  "type": "Exercise",
  "number": "1.3.4.24",
  "title": "",
  "body": "  Find an explicit solution to , .   "
},
{
  "id": "separable-section-7-26",
  "level": "2",
  "url": "separable-section.html#separable-section-7-26",
  "type": "Exercise",
  "number": "1.3.4.25",
  "title": "",
  "body": "  Find an explicit solution for , for .        "
},
{
  "id": "separable-section-7-27",
  "level": "2",
  "url": "separable-section.html#separable-section-7-27",
  "type": "Exercise",
  "number": "1.3.4.26",
  "title": "",
  "body": "  Find an explicit solution for with .        "
},
{
  "id": "separable-section-7-28",
  "level": "2",
  "url": "separable-section.html#separable-section-7-28",
  "type": "Exercise",
  "number": "1.3.4.27",
  "title": "",
  "body": "  Find an explicit solution for with .        "
},
{
  "id": "separable-section-7-29",
  "level": "2",
  "url": "separable-section.html#separable-section-7-29",
  "type": "Exercise",
  "number": "1.3.4.28",
  "title": "",
  "body": "  Find an explicit solution for , . It is alright to leave a definite integral in your answer.        "
},
{
  "id": "separable-section-7-30",
  "level": "2",
  "url": "separable-section.html#separable-section-7-30",
  "type": "Exercise",
  "number": "1.3.4.29",
  "title": "",
  "body": "  Is the equation separable? If so, find the general solution, if not, explain why.    No   "
},
{
  "id": "separable-section-7-31",
  "level": "2",
  "url": "separable-section.html#separable-section-7-31",
  "type": "Exercise",
  "number": "1.3.4.30",
  "title": "",
  "body": "  Is the equation separable? If so, find the general solution, if not, explain why.    Yes.    "
},
{
  "id": "separable-section-7-32",
  "level": "2",
  "url": "separable-section.html#separable-section-7-32",
  "type": "Exercise",
  "number": "1.3.4.31",
  "title": "",
  "body": "  Is the equation separable? If so, find the general solution, if not, explain why. (Note: Requires partial fractions)    Yes.    "
},
{
  "id": "separable-section-7-33",
  "level": "2",
  "url": "separable-section.html#separable-section-7-33",
  "type": "Exercise",
  "number": "1.3.4.32",
  "title": "",
  "body": "  Suppose a cup of coffee is at 100 degrees Celsius at time , it is at 70 degrees at minutes, and it is at 50 degrees at minutes. Compute the ambient temperature.    10 C   "
},
{
  "id": "separable-section-7-34",
  "level": "2",
  "url": "separable-section.html#separable-section-7-34",
  "type": "Exercise",
  "number": "1.3.4.33",
  "title": "",
  "body": "  Take with the same numbers: 89 degrees at , 85 degrees at , and ambient temperature of 22 degrees. Suppose these temperatures were measured with precision of degrees. Given this imprecision, the time it takes the coffee to cool to (exactly) 60 degrees is also only known in a certain range. Find this range. Hint: Think about what kind of error makes the cooling time longer and what shorter.   "
},
{
  "id": "separable-section-7-35",
  "level": "2",
  "url": "separable-section.html#separable-section-7-35",
  "type": "Exercise",
  "number": "1.3.4.34",
  "title": "",
  "body": "  A population of rabbits on an island is modeled by , where the independent variable is time in months. At time , there are 40 rabbits on the island.     Find the solution to the equation with the initial condition.           How many rabbits are on the island in 1 month, 5 months, 10 months, 15 months (round to the nearest integer).    102 rabbits after one month, 861 after 5 months, 999 after 10 months, 1000 after 15 months.    "
},
{
  "id": "intfactor-section",
  "level": "1",
  "url": "intfactor-section.html",
  "type": "Section",
  "number": "1.4",
  "title": "Linear equations and the integrating factor",
  "body": " Linear equations and the integrating factor  One of the most important types of equations we will learn how to solve are the so-called linear equations . In fact, the majority of the course is about linear equations. In this section we focus on the .   A first order equation is linear if we can put it into the form:   The word means linear in and ; no higher powers nor functions of or appear. The dependence on can be more complicated.  Solutions of linear equations have nice properties. For example, the solution exists wherever and are defined, and has the same regularity (read: it is just as nice). We’ll see this in detail in . But most importantly for us right now, there is a method for solving linear first order equations. In , we saw that we could easily solve equations of the form because we could directly integrate both sides of the equation, since the left hand side was the derivative of something (in this case, ) and the right side was only a function of . We want to do the same here, but the something on the left will not be the derivative of just .  The trick is to rewrite the left-hand side of as a derivative of a product of with another function. Let be this other function, and we can compute, by the product rule, that Now, if we multiply by the function on both sides, we get and the first term on the left here matches the first term from our product rule derivative. To make the second terms match up as well, we need that This equation is separable! We can solve for the here by separating variables to get that so that or   With this choice of , we get that so that if we multiply by , we obtain on the left-hand side, which we can simplify using our product rule derivative above to obtain Now we integrate both sides. The right-hand side does not depend on and the left-hand side is written as a derivative of a function. Afterwards, we solve for . The function is called the and the method is called the .  This method works for any first order linear equation, no matter what and are. In general, we can compute:   Advice: Do not try to remember the formula itself, that is way too hard. It is easier to remember the process and repeat it.  Of course, to get a closed form formula for , we need to be able to find a closed form formula for the integrals appearing above.      Solve     First note that and . The integrating factor is . We multiply both sides of the equation by to get We integrate Next, we solve for the initial condition , so . The solution is     Note that we do not care which antiderivative we take when computing . You can always add a constant of integration, but those constants will not matter in the end.    Try it! Add a constant of integration to the integral in the integrating factor and show that the solution you get in the end is the same as what we got above.    Since we cannot always evaluate the integrals in closed form, it is useful to know how to write the solution in definite integral form. A definite integral is something that you can plug into a computer or a calculator. Suppose we are given Look at the solution and write the integrals as definite integrals. You should be careful to properly use dummy variables here. If you now plug such a formula into a computer or a calculator, it will be happy to give you numerical answers.      Check that in formula .        Solve the initial value problem     In order to solve this equation, we want to put the equation in standard form, which is In this form, the coefficient of is , so that the integrating factor is Since , we have that . Multiplying both sides of the equation by gives where the left hand side is . Therefore, we can integrate both sides of the equation in to give and we can solve out for as To solve for using the initial condition, we plug in to get that we need Therefore, the solution to the initial value problem is         Solve the initial value problem     This equation is already in standard form. Since the coefficient of is , we know that the integrating factor is We can multiply both sides of the equation by this integrating factor to give and then want to integrate both sides. The left-hand side of the equation is , so the antiderivative of that side is just . For the right-hand side, we would need to compute which does not have a closed-form expression. Therefore, we need to represent this as a definite integral. Since our initial condition gives the value of at zero, we want to use zero as the bottom limit of the integral. Therefore, we can write the solution as and so can solve for as Plugging in the initial condition gives that Therefore, the solution to the initial value problem is       Write the solution of the following problem as a definite integral, but try to simplify as far as you can. You will not be able to find the solution in closed form.           Exercises   In the exercises, feel free to leave answer as a definite integral if a closed form solution cannot be found. If you can find a closed form solution, you should give that.     Solve .           Solve .           Solve .           Solve .           Solve with .           Solve .           Solve .           Solve with .           Solve .           Solve .      Solve , with .           Solve .           Solve the IVP            Solve the IVP .           Solve , with .           Solve , .      Consider the initial value problem for an undetermined value . Solve the problem and determine the dependence on the value of . How does the value of the solution as depend on the value of ?     . If , the solution goes to , if , the solution goes to 0, if , the solution goes to .      Find an expression for the general solution to with . Simplfy your answer as much as possible.          "
},
{
  "id": "intfactor-section-11",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-11",
  "type": "Example",
  "number": "1.4.1",
  "title": ".",
  "body": "    Solve     First note that and . The integrating factor is . We multiply both sides of the equation by to get We integrate Next, we solve for the initial condition , so . The solution is    "
},
{
  "id": "intfactor-section-13",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-13",
  "type": "Checkpoint",
  "number": "1.4.2",
  "title": "",
  "body": "  Try it! Add a constant of integration to the integral in the integrating factor and show that the solution you get in the end is the same as what we got above.    Since we cannot always evaluate the integrals in closed form, it is useful to know how to write the solution in definite integral form. A definite integral is something that you can plug into a computer or a calculator. Suppose we are given Look at the solution and write the integrals as definite integrals. You should be careful to properly use dummy variables here. If you now plug such a formula into a computer or a calculator, it will be happy to give you numerical answers.   "
},
{
  "id": "intfactor-section-14",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-14",
  "type": "Checkpoint",
  "number": "1.4.3",
  "title": "",
  "body": "  Check that in formula .   "
},
{
  "id": "intfactor-section-15",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-15",
  "type": "Example",
  "number": "1.4.4",
  "title": ".",
  "body": "    Solve the initial value problem     In order to solve this equation, we want to put the equation in standard form, which is In this form, the coefficient of is , so that the integrating factor is Since , we have that . Multiplying both sides of the equation by gives where the left hand side is . Therefore, we can integrate both sides of the equation in to give and we can solve out for as To solve for using the initial condition, we plug in to get that we need Therefore, the solution to the initial value problem is    "
},
{
  "id": "intfactor-section-16",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-16",
  "type": "Example",
  "number": "1.4.5",
  "title": ".",
  "body": "    Solve the initial value problem     This equation is already in standard form. Since the coefficient of is , we know that the integrating factor is We can multiply both sides of the equation by this integrating factor to give and then want to integrate both sides. The left-hand side of the equation is , so the antiderivative of that side is just . For the right-hand side, we would need to compute which does not have a closed-form expression. Therefore, we need to represent this as a definite integral. Since our initial condition gives the value of at zero, we want to use zero as the bottom limit of the integral. Therefore, we can write the solution as and so can solve for as Plugging in the initial condition gives that Therefore, the solution to the initial value problem is    "
},
{
  "id": "intfactor-section-17",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-17",
  "type": "Checkpoint",
  "number": "1.4.6",
  "title": "",
  "body": "  Write the solution of the following problem as a definite integral, but try to simplify as far as you can. You will not be able to find the solution in closed form.         "
},
{
  "id": "intfactor-section-18-3",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-3",
  "type": "Exercise",
  "number": "1.4.1",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-4",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-4",
  "type": "Exercise",
  "number": "1.4.2",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-5",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-5",
  "type": "Exercise",
  "number": "1.4.3",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-6",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-6",
  "type": "Exercise",
  "number": "1.4.4",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-7",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-7",
  "type": "Exercise",
  "number": "1.4.5",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "intfactor-section-18-8",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-8",
  "type": "Exercise",
  "number": "1.4.6",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-9",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-9",
  "type": "Exercise",
  "number": "1.4.7",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-10",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-10",
  "type": "Exercise",
  "number": "1.4.8",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "intfactor-section-18-11",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-11",
  "type": "Exercise",
  "number": "1.4.9",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-12",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-12",
  "type": "Exercise",
  "number": "1.4.10",
  "title": "",
  "body": "  Solve .   "
},
{
  "id": "intfactor-section-18-13",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-13",
  "type": "Exercise",
  "number": "1.4.11",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "intfactor-section-18-14",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-14",
  "type": "Exercise",
  "number": "1.4.12",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "intfactor-section-18-15",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-15",
  "type": "Exercise",
  "number": "1.4.13",
  "title": "",
  "body": "  Solve the IVP         "
},
{
  "id": "intfactor-section-18-16",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-16",
  "type": "Exercise",
  "number": "1.4.14",
  "title": "",
  "body": "  Solve the IVP .        "
},
{
  "id": "intfactor-section-18-17",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-17",
  "type": "Exercise",
  "number": "1.4.15",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "intfactor-section-18-18",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-18",
  "type": "Exercise",
  "number": "1.4.16",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "intfactor-section-18-19",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-19",
  "type": "Exercise",
  "number": "1.4.17",
  "title": "",
  "body": "  Consider the initial value problem for an undetermined value . Solve the problem and determine the dependence on the value of . How does the value of the solution as depend on the value of ?     . If , the solution goes to , if , the solution goes to 0, if , the solution goes to .   "
},
{
  "id": "intfactor-section-18-20",
  "level": "2",
  "url": "intfactor-section.html#intfactor-section-18-20",
  "type": "Exercise",
  "number": "1.4.18",
  "title": "",
  "body": "  Find an expression for the general solution to with . Simplfy your answer as much as possible.        "
},
{
  "id": "existunique-section",
  "level": "1",
  "url": "existunique-section.html",
  "type": "Section",
  "number": "1.5",
  "title": "Existence and Uniqueness of Solutions",
  "body": " Existence and Uniqueness of Solutions  If we take the differential equation there are two main questions we want to answer about this equation.    Does a solution exist to the differential equation?    Is there only one solution to the differential equation?    These are more commonly referred to as (a) of the solution and (b) of the solution. These are especially crucial for equations that we are using to model a physical situation. For physical situations, the solution definitely exists (because the system does something and continues to exist) and the solution is unique, because a given system will always do the same thing given the same setup. Since we know that physical systems obey these properties, the equations we use to model them should have these properties as well. These properties do not necessarily hold for all differential equations, as shown in the examples below.      Attempt to solve:   Integrate to find the general solution . The solution does not exist at . See . The equation may have been written as the seemingly harmless .          Solve:   See . Note that is a solution. But another solution is the function     What we see here is a significant problem for trying to represent physical situations. In the first there is no solution at , so if our physical scenario had wanted one, that would be an issue. Similarly, for the second, we do have solutions, but we have two of them, so we can’t use this to predict what is going to happen to a physical situation modeled by this equation over time. So, we need both existence and uniqueness to hold for our modeling equation in order to use differential equations to accurately model situations. Thankfully, these properties do apply to most equations, and we have fairly straight-forward criteria that can be used to determine if these properties are true for a given differential equation. For a first-order linear differential equation, the theorem is fairly straight-forward.   Assume that we have the first-order linear differential equation given by If and are continuous functions on an interval that contains a point , then for any -value , the initial value problem has a unique solution. This solution exists and is unique on the entire interval .  The idea and proof of this theorem comes from the fact that we have an explicit method for solving these equations no matter what and are. We can always find an integrating factor for the equation, convert the left-hand side into a product rule term, take a definite integral of both sides, and then solve for . Since we have this explicit formula, the solution will exist and be defined on the entire interval where the functions and are continuous. This also means that we can answer questions about where and for what values of the solution to a differential equation exists.      Consider the differential equation What do the existence and uniqueness theorems say about the solution to this differential equation with the initial condition ? What about the solution with initial condition ?    To apply the existence and uniqueness theorem, we need to get the term by itself. This results in the differential equation In order to figure out where this solution exists and is unique, we need to determine where the coefficient functions and are continuous. The only two points that we have discontinuities are at and . Therefore, if we have the initial condition , we start at the value of . Because this equation is linear, it will exist everywhere that these two functions are both continuous containing the point , and since the only discontinuities are at and , we know that they are both continuous on . This means that we can take as the interval in the theorem, and know that this solution will exist and be unique on the interval .  For the other initial condition, , we now want an interval where these functions are continuous that contains . Again, we only have to avoid and , so we can take the interval as the interval in the theorem, and so we know the solution with this initial condition will exist and be unique on .  A convenient way to represent this situation is with a number line like that presented in . On this number line, we mark the places where the functions or are discontinuous.    To interpret this image, we can mark the initial point on the number line, where the point that we mark is the x coordinate of the initial condition. All of the intervals are in terms of . Then, the existence and uniqueness theorem says that the solution will exist on the entire interval between any marked points on this number line. From that, we can see that the interval of existence for the initial condition is , and the interval for is .    For non-linear equations, we don’t have an explicit method of getting a solution that works for all equations. This means that we can’t fall back on this formula to guarantee existence or uniqueness of solutions. For this reason, we expect to get a result that is not as strong for non-linear equations. Thankfully, we do still get a result, which is known as Picard’s theorem  Named after the French mathematician Charles Émile Picard (1856–1941) .   Picard’s theorem on existence and uniqueness If is continuous (as a function of two variables) and exists and is continuous near some , then a solution to exists (at least for some small interval of ’s) and is unique.  The main fact that is not as strong about this result is the interval that we get from the theorem. For the linear theorem, we got existence and uniqueness on the entire interval where and are continuous. For the non-linear theorem, we only get existence on some interval around the point . Even if and are really nice functions that are continuous everywhere, we can still only guarantee existence on a small interval (that can depend on the initial condition) around the point .      For some constant , solve:     We know how to solve this equation. First assume that , so is not equal to zero at least for some near 0. So , so , so . If , then so If , then is a solution.  For example, when the solution is which goes to infinity, and so , at . This solution here exists only on the interval , and hence, the solution does not exist for all even if the equation is nice everywhere. The equation certainly looks nice.  However, this fact does not contradict our existence and uniqueness theorem for non-linear equations. The theorem only guarantees that the solution to exists and is unique on some interval containing 0. It does not guarantee that the solution exists everywhere that and its derivative are continuous, only that at each point where this happens, the solution will exist for some interval around that point. The interval is , so the theorem still applies and holds here. See the exercises for more detail on how this process works and how we can illustrate the fact that the interval of existence ise .    The other main conclusion that we can draw from these theorems is the fact that two different solution curves to a first-order differential equation can not cross, provided the existence and uniqueness theorems hold. If and are two different solutions to and the solution curves for and cross, then this means that for some particular value of and , we have that If we pick as a starting point, then the fact that the existence and uniqueness theorems hold imply that, at least for some interval around , there is exactly one solution to However, both and satisfy these two properties. Therefore, and must be the same, which doesn’t make sense because we assumed they were different. So it is impossible for two different solution curves to cross, provided the existence and uniqueness theorem holds. For a comparison, refer back to earlier to see what non-uniqueness looks like, where we do have two solution curves that cross at the point .  This fact is useful for analyzing differential equations in general, but will be particularly useful in in dealing with autonomous equations, where we can use simple solutions to provide boundaries over which other solutions can not cross. This fact will come up again in Chapters and in sketching trajectories for these solutions as well.      Consider the differential equation     Verify that is a solution to this differential equation.    Assume that we solve this problem with initial condition . Is it possible for this solution to ever reach ? Why or why not?        If we take the function , then , and plugging this into the right hand side also gives . Therefore, this function solves the differential equation.    If the solutions starts with , this means that it starts below the line . In order to get up to , the solution would need to cross over the line , which would mean that we have solution curves that cross. However, the function is continuous everywhere, as is the first derivative Therefore, the existence and uniqueness theorem applies everywhere, and so solution curves can not cross. So, it is not possible for the solution to reach , because this would force solution curves to cross, which we know can not happen.       Exercises    Is it possible to solve the equation for ? Justify.    Yes.      Is it possible to solve the equation for ? Is the solution unique? Justify.    Yes      Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ?    a) Linear b)  c)        Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ? What happens if we want to start with ?    a) Linear b)  c)  d) Nothing is guaranteed.      Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ? What happens if we want to start with ?    a) Linear b)  c)  d)        Consider the differential equation .   Is this equation linear or non-linear? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist? Find the solution to this differential equation with . Over what values of does this solution exist? Find the solution to this differential equation with . Over what values of does this solution exist? Do any of these contradict your answer in (b)?    a) Non-linear b) It will exist on some interval around . c)  , d)  , e)  , f)  No. All of these are intervals containing zero.      Consider the differential equation .   Is this equation linear or non-linear? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist?    a) Non-linear b) Some interval around zero. c)  , Exists on       Consider the differential equation .   Is this equation linear or non-linear? If we set , for what values of and are and continuous? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist?    a) Non-linear b) Some interval around c)  , Exists on       Take , .   Find two distinct solutions. Explain why this does not violate Picard’s theorem.    a)  and b)  is discontinuous when , and is one such point.      Find a solution to , . Does Picard’s theorem apply?     or . No.      Consider the IVP .   The Existence and Uniqueness Theorem guarantees a unique solution to this IVP on what interval? Find this solution explicitly.    a)  b)        Take an equation for some function . Can you solve the problem for the initial condition , and if so what is the solution?           Consider the differential equation .   Verify that is a solution to this differential equation. Assume that we look for the solution with . Is it possible that for some later time ? Why or why not? Based on this, what do we know about the solution with ?    a) Yes b) No c) Must stay above for all . Approaches 2.      Suppose is such that for every , is continuous and exists and is continuous for every and .   Guess a solution given the initial condition . Can graphs of two solutions of the equation for different initial conditions ever intersect? Given , what can you say about the solution. In particular, can for any ? Can for any ? Why or why not?    a)  b) No c) Must stay below       Consider the differential equation .   Verify that and are both solutions to this differential equation. Verify that the hypotheses of Picard’s theorem are satisfies for this equation. Assume that we solve this differential equation with . Is it possible for the solution to reach at any point? Why or why not? Assume that we solve this differential equation with . Is it possible for the solution to reach at any point? Why or why not?    a) Yes b) Yes c) No d) No      Is it possible to solve for ? Is the solution unique?      Is it possible to solve for ?      Suppose Does , have a continuously differentiable solution? Does Picard apply? Why, or why not?      Consider an equation of the form for some continuous function , and an initial condition . Does a solution exist for all ? Why or why not?    "
},
{
  "id": "existunique-section-5",
  "level": "2",
  "url": "existunique-section.html#existunique-section-5",
  "type": "Example",
  "number": "1.5.1",
  "title": ".",
  "body": "    Attempt to solve:   Integrate to find the general solution . The solution does not exist at . See . The equation may have been written as the seemingly harmless .     "
},
{
  "id": "existunique-section-6",
  "level": "2",
  "url": "existunique-section.html#existunique-section-6",
  "type": "Example",
  "number": "1.5.2",
  "title": ".",
  "body": "    Solve:   See . Note that is a solution. But another solution is the function    "
},
{
  "id": "existunique-section-10",
  "level": "2",
  "url": "existunique-section.html#existunique-section-10",
  "type": "Example",
  "number": "1.5.3",
  "title": ".",
  "body": "    Consider the differential equation What do the existence and uniqueness theorems say about the solution to this differential equation with the initial condition ? What about the solution with initial condition ?    To apply the existence and uniqueness theorem, we need to get the term by itself. This results in the differential equation In order to figure out where this solution exists and is unique, we need to determine where the coefficient functions and are continuous. The only two points that we have discontinuities are at and . Therefore, if we have the initial condition , we start at the value of . Because this equation is linear, it will exist everywhere that these two functions are both continuous containing the point , and since the only discontinuities are at and , we know that they are both continuous on . This means that we can take as the interval in the theorem, and know that this solution will exist and be unique on the interval .  For the other initial condition, , we now want an interval where these functions are continuous that contains . Again, we only have to avoid and , so we can take the interval as the interval in the theorem, and so we know the solution with this initial condition will exist and be unique on .  A convenient way to represent this situation is with a number line like that presented in . On this number line, we mark the places where the functions or are discontinuous.    To interpret this image, we can mark the initial point on the number line, where the point that we mark is the x coordinate of the initial condition. All of the intervals are in terms of . Then, the existence and uniqueness theorem says that the solution will exist on the entire interval between any marked points on this number line. From that, we can see that the interval of existence for the initial condition is , and the interval for is .   "
},
{
  "id": "existunique-section-14",
  "level": "2",
  "url": "existunique-section.html#existunique-section-14",
  "type": "Example",
  "number": "1.5.4",
  "title": ".",
  "body": "    For some constant , solve:     We know how to solve this equation. First assume that , so is not equal to zero at least for some near 0. So , so , so . If , then so If , then is a solution.  For example, when the solution is which goes to infinity, and so , at . This solution here exists only on the interval , and hence, the solution does not exist for all even if the equation is nice everywhere. The equation certainly looks nice.  However, this fact does not contradict our existence and uniqueness theorem for non-linear equations. The theorem only guarantees that the solution to exists and is unique on some interval containing 0. It does not guarantee that the solution exists everywhere that and its derivative are continuous, only that at each point where this happens, the solution will exist for some interval around that point. The interval is , so the theorem still applies and holds here. See the exercises for more detail on how this process works and how we can illustrate the fact that the interval of existence ise .   "
},
{
  "id": "existunique-section-17",
  "level": "2",
  "url": "existunique-section.html#existunique-section-17",
  "type": "Example",
  "number": "1.5.5",
  "title": ".",
  "body": "    Consider the differential equation     Verify that is a solution to this differential equation.    Assume that we solve this problem with initial condition . Is it possible for this solution to ever reach ? Why or why not?        If we take the function , then , and plugging this into the right hand side also gives . Therefore, this function solves the differential equation.    If the solutions starts with , this means that it starts below the line . In order to get up to , the solution would need to cross over the line , which would mean that we have solution curves that cross. However, the function is continuous everywhere, as is the first derivative Therefore, the existence and uniqueness theorem applies everywhere, and so solution curves can not cross. So, it is not possible for the solution to reach , because this would force solution curves to cross, which we know can not happen.     "
},
{
  "id": "existunique-section-18-2",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-2",
  "type": "Exercise",
  "number": "1.5.1",
  "title": "",
  "body": "  Is it possible to solve the equation for ? Justify.    Yes.   "
},
{
  "id": "existunique-section-18-3",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-3",
  "type": "Exercise",
  "number": "1.5.2",
  "title": "",
  "body": "  Is it possible to solve the equation for ? Is the solution unique? Justify.    Yes   "
},
{
  "id": "existunique-section-18-4",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-4",
  "type": "Exercise",
  "number": "1.5.3",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ?    a) Linear b)  c)     "
},
{
  "id": "existunique-section-18-5",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-5",
  "type": "Exercise",
  "number": "1.5.4",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ? What happens if we want to start with ?    a) Linear b)  c)  d) Nothing is guaranteed.   "
},
{
  "id": "existunique-section-18-6",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-6",
  "type": "Exercise",
  "number": "1.5.5",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? What is the maximum guaranteed interval of existence for the solution to this equation with initial condition ? What if we start with the initial condition ? What happens if we want to start with ?    a) Linear b)  c)  d)     "
},
{
  "id": "existunique-section-18-7",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-7",
  "type": "Exercise",
  "number": "1.5.6",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist? Find the solution to this differential equation with . Over what values of does this solution exist? Find the solution to this differential equation with . Over what values of does this solution exist? Do any of these contradict your answer in (b)?    a) Non-linear b) It will exist on some interval around . c)  , d)  , e)  , f)  No. All of these are intervals containing zero.   "
},
{
  "id": "existunique-section-18-8",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-8",
  "type": "Exercise",
  "number": "1.5.7",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist?    a) Non-linear b) Some interval around zero. c)  , Exists on    "
},
{
  "id": "existunique-section-18-9",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-9",
  "type": "Exercise",
  "number": "1.5.8",
  "title": "",
  "body": "  Consider the differential equation .   Is this equation linear or non-linear? If we set , for what values of and are and continuous? What is the most we can say about the interval of existence for the solution to this equation with initial condition ? Find the solution to this differential equation with . Over what values of does this solution exist?    a) Non-linear b) Some interval around c)  , Exists on    "
},
{
  "id": "existunique-section-18-10",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-10",
  "type": "Exercise",
  "number": "1.5.9",
  "title": "",
  "body": "  Take , .   Find two distinct solutions. Explain why this does not violate Picard’s theorem.    a)  and b)  is discontinuous when , and is one such point.   "
},
{
  "id": "existunique-section-18-11",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-11",
  "type": "Exercise",
  "number": "1.5.10",
  "title": "",
  "body": "  Find a solution to , . Does Picard’s theorem apply?     or . No.   "
},
{
  "id": "existunique-section-18-12",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-12",
  "type": "Exercise",
  "number": "1.5.11",
  "title": "",
  "body": "  Consider the IVP .   The Existence and Uniqueness Theorem guarantees a unique solution to this IVP on what interval? Find this solution explicitly.    a)  b)     "
},
{
  "id": "existunique-section-18-13",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-13",
  "type": "Exercise",
  "number": "1.5.12",
  "title": "",
  "body": "  Take an equation for some function . Can you solve the problem for the initial condition , and if so what is the solution?        "
},
{
  "id": "existunique-section-18-14",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-14",
  "type": "Exercise",
  "number": "1.5.13",
  "title": "",
  "body": "  Consider the differential equation .   Verify that is a solution to this differential equation. Assume that we look for the solution with . Is it possible that for some later time ? Why or why not? Based on this, what do we know about the solution with ?    a) Yes b) No c) Must stay above for all . Approaches 2.   "
},
{
  "id": "existunique-section-18-15",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-15",
  "type": "Exercise",
  "number": "1.5.14",
  "title": "",
  "body": "  Suppose is such that for every , is continuous and exists and is continuous for every and .   Guess a solution given the initial condition . Can graphs of two solutions of the equation for different initial conditions ever intersect? Given , what can you say about the solution. In particular, can for any ? Can for any ? Why or why not?    a)  b) No c) Must stay below    "
},
{
  "id": "existunique-section-18-16",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-16",
  "type": "Exercise",
  "number": "1.5.15",
  "title": "",
  "body": "  Consider the differential equation .   Verify that and are both solutions to this differential equation. Verify that the hypotheses of Picard’s theorem are satisfies for this equation. Assume that we solve this differential equation with . Is it possible for the solution to reach at any point? Why or why not? Assume that we solve this differential equation with . Is it possible for the solution to reach at any point? Why or why not?    a) Yes b) Yes c) No d) No   "
},
{
  "id": "existunique-section-18-17",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-17",
  "type": "Exercise",
  "number": "1.5.16",
  "title": "",
  "body": "  Is it possible to solve for ? Is the solution unique?   "
},
{
  "id": "existunique-section-18-18",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-18",
  "type": "Exercise",
  "number": "1.5.17",
  "title": "",
  "body": "  Is it possible to solve for ?   "
},
{
  "id": "existunique-section-18-19",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-19",
  "type": "Exercise",
  "number": "1.5.18",
  "title": "",
  "body": "  Suppose Does , have a continuously differentiable solution? Does Picard apply? Why, or why not?   "
},
{
  "id": "existunique-section-18-20",
  "level": "2",
  "url": "existunique-section.html#existunique-section-18-20",
  "type": "Exercise",
  "number": "1.5.19",
  "title": "",
  "body": "  Consider an equation of the form for some continuous function , and an initial condition . Does a solution exist for all ? Why or why not?   "
},
{
  "id": "numer-section",
  "level": "1",
  "url": "numer-section.html",
  "type": "Section",
  "number": "1.6",
  "title": "Numerical methods: Euler’s method",
  "body": " Numerical methods: Euler’s method  Unless is of a special form, it is generally very hard if not impossible to get a nice formula for the solution of the problem   If the equation can be solved in closed form, we should do that. But what if we have an equation that cannot be solved in closed form? What if we want to find the value of the solution at some particular ? Or perhaps we want to produce a graph of the solution to inspect the behavior. In this section we will learn about the basics of numerical approximation of solutions.  The simplest method for approximating a solution is  Named after the Swiss mathematician Leonhard Paul Euler (1707–1783). The correct pronunciation of the name sounds more like . It works as follows: Take and compute the slope . The slope is the change in per unit change in . Follow the line for an interval of length on the -axis. Hence if at , then we say that (the approximate value of at ) is . Rinse, repeat! Let , and then compute , and . Now compute and using and , etc. Consider the equation , , and . Then and . We compute We then draw an approximate graph of the solution by connecting the points , , ,…. For the first two steps of the method see .    More abstractly, for any , we compute This can be worked out by hand for a few steps, but the formulas here lend themselves very well to being coded into a looping structure for more involved processes. The line segments we get are an approximate graph of the solution. Generally it is not exactly the solution. See for the plot of the real solution and the approximation.    We continue with the equation , . Let us try to approximate using Euler’s method. In Figures  and  we have graphically approximated with step size 1. With step size 1, we have . The real answer is 3. We are approximately 1.074 off. Let us halve the step size. Computing with , we find that , so an error of about 0.791. gives the values computed for various parameters.    Solve this equation exactly and show that .    The difference between the actual solution and the approximate solution is called the error. We usually talk about just the size of the error and we do not care much about its sign. The point is, we usually do not know the real solution, so we only have a vague understanding of the error. If we knew the error exactly …what is the point of doing the approximation?       Euler’s method approximation of where of , .     Approximate  Error     1  1.92593  1.07407     0.5  2.20861  0.79139  0.73681    0.25  2.47250  0.52751  0.66656    0.125  2.68034  0.31966  0.60599    0.0625  2.82040  0.17960  0.56184    0.03125  2.90412  0.09588  0.53385    0.015625  2.95035  0.04965  0.51779    0.0078125  2.97472  0.02528  0.50913     Notice that except for the first few times, every time we halved the step size the error approximately halved. This halving of the error is a general feature of Euler’s method as it is a . There exists an improved Euler method, see the exercises, which is a . A second order method reduces the error to approximately one quarter every time we halve the interval. The meaning of order is the squaring in .  To get the error to be within 0.1 of the answer we had to already do 64 steps. To get it to within 0.01 we would have to halve another three or four times, meaning doing 512 to 1024 steps. That is quite a bit to do by hand. The improved Euler method from the exercises should quarter the error every time we halve the interval, so we would have to approximately do half as many to get the same error. This reduction can be a big deal. With 10 halvings (starting at ) we have 1024 steps, whereas with 5 halvings we only have to do 32 steps, assuming that the error was comparable to start with. A computer may not care about this difference for a problem this simple, but suppose each step would take a second to compute (the function may be substantially more difficult to compute than ). Then the difference is 32 seconds versus about 17 minutes. We are not being altogether fair, a second order method would probably double the time to do each step. Even so, it is 1 minute versus 17 minutes. Next, suppose that we have to repeat such a calculation for different parameters a thousand times. You get the idea.  Note that in practice we do not know how large the error is! How do we know what is the right step size? Well, essentially we keep halving the interval, and if we are lucky, we can estimate the error from a few of these calculations and the assumption that the error goes down by a factor of one half each time (if we are using standard Euler).    In the table above, suppose you do not know the error. Take the approximate values of the function in the last two lines, assume that the error goes down by a factor of 2. Can you estimate the error in the last time from this? Does it (approximately) agree with the table? Now do it for the first two rows. Does this agree with the table?    Let us talk a little bit more about the example , . Suppose that instead of the value we wish to find . The results of this effort are listed in for successive halvings of . What is going on here? Well, you should solve the equation exactly and you will notice that the solution does not exist at . In fact, the solution goes to infinity when you approach .       Attempts to use Euler’s to approximate where of , .     Approximate    1  3.16232    0.5  4.54329    0.25  6.86079    0.125  10.80321    0.0625  17.59893    0.03125  29.46004    0.015625  50.40121    0.0078125  87.75769     Another case where things go bad is if the solution oscillates wildly near some point. The solution may exist at all points, but even a much better numerical method than Euler would need an insanely small step size to approximate the solution with reasonable precision. And computers might not be able to easily handle such a small step size.  In real applications we would not use a simple method such as Euler's. The simplest method that would probably be used in a real application is the standard Runge–Kutta method (see exercises). That is a , meaning that if we halve the interval, the error generally goes down by a factor of 16 (it is fourth order as ).  Choosing the right method to use and the right step size can be very tricky. There are several competing factors to consider.    Computational time: Each step takes computer time. Even if the function is simple to compute, we do it many times over. Large step size means faster computation, but perhaps not the right precision.    Roundoff errors: Computers only compute with a certain number of significant digits. Errors introduced by rounding numbers off during our computations become noticeable when the step size becomes too small relative to the quantities we are working with. So reducing step size may in fact make errors worse. There is a certain optimum step size such that the precision increases as we approach it, but then starts getting worse as we make our step size smaller still. Trouble is: this optimum may be hard to find.    Stability: Certain equations may be numerically unstable. What may happen is that the numbers never seem to stabilize no matter how many times we halve the interval. We may need a ridiculously small interval size, which may not be practical due to roundoff errors or computational time considerations. Such problems are sometimes called stiff . In the worst case, the numerical computations might be giving us bogus numbers that look like a correct answer. Just because the numbers seem to have stabilized after successive halving, does not mean that we must have the right answer.    We have seen just the beginnings of the challenges that appear in real applications. Numerical approximation of solutions to differential equations is an active research area for engineers and mathematicians. For example, the general purpose method used for the ODE solver in Matlab and Octave (as of this writing) is a method that appeared in the literature only in the 1980s.  The method used in Matlab and Octave is a fair bit different from the methods discussed previously. We don’t need to go too much in detail about it, but some information will be helpful. The main difference that will be visible when running these methods is that they are adaptive method. This means that they adjust the step-size based on what the differential equation looks like at a given point. Euler’s method, along with the improved Euler and Runge-Kutta methods, is a fixed step-size method, where the steps are always the same no matter what. Adaptive methods are harder to write and optimize, but can solve many problems faster because the adaptive nature of the method allows them to get similar accuracy to fixed step methods, but at many fewer steps. In the example below, the initial value problem is solved with an Euler’s method and Matlab’s built-in ode45 method. Both of the solutions are plotted along with the actual solution     The Euler’s method takes 60 steps in this computation, but is still not as accurate as the ode45 method, which only takes 45 steps. In addition, the black diamonds, representing the different values computed by ode45 are not evenly spaced, illustrating the adaptive nature of this solver, while the red stars are all evenly spaced in the -direction, as is expected from Euler’s method.   Exercises    Consider , . Use Euler’s method with step size to approximate .    17\/2      Consider the differential equation with . Approximate the solution at using Euler’s method with a step size of and . Compare these values with the actual solution at .     : 17, : 85\/32, Actual:       Consider the differential equation with . Approximate the solution at using Euler’s method with a step size of and .     : 10, :        Consider , .   Use Euler’s method with step sizes to approximate . Solve the equation exactly. Describe what happens to the errors for each you used. That is, find the factor by which the error changed each time you halved the interval.    a)  , 0. , 0.5. , .  . b)  c) Error decreases by factors of 0.32, 0.4365, 0.4723.      Let , and . Approximate using Euler’s method with step sizes 1, 0.5, 0.25. Use a calculator and compute up to 4 decimal digits.      Approximate the value of by looking at the initial value problem with and approximating using Euler’s method with a step size of .    2.4883      Let , and .   Approximate using Euler’s method with step sizes 4, 2, and 1. Solve exactly, and compute the errors. Compute the factor by which the errors changed.       Let , and .   Approximate using Euler’s method with step sizes 4, 2, and 1. Guess an exact solution based on part a) and compute the errors.      Example of numerical instability: Take , . We know that the solution should decay to zero as grows. Using Euler’s method, start with and compute to try to approximate . What happened? Now halve the interval. Keep halving the interval and approximating until the numbers you are getting start to stabilize (that is, until they start going towards zero). Note: You might want to use a calculator.    For , . , , goes to zero, but oscillates. just goes to zero.      There is a simple way to improve Euler’s method to make it a second order method by doing just one extra step. Consider , , and a step size . What we do is to pretend we compute the next step as in Euler, that is, we start with , we compute a slope , and then look at the point . Instead of letting our new point be , we compute the slope at that point, call it , and then take the average of and , hoping that the average is going to be closer to the actual slope on the interval from to . And we are correct, if we halve the step, the error should go down by a factor of . To summarize, the setup is the same as for regular Euler, except the computation of and .   Consider , .   Use the improved Euler’s method (see above) with step sizes and to approximate . Use Euler’s method with and . Solve exactly, find the exact value of . Compute the errors, and the factors by which the errors changed.    The simplest method used in practice is the . Consider , , and a step size . Everything is the same as in Euler’s method, except the computation of and .       Consider , .   Use Runge–Kutta (see above) with step sizes and to approximate . Use Euler’s method with and . Solve exactly, find the exact value of , and compare.    a)  gives 1.3906. gives 1.3953. b)  gives 1. gives 1.125. c)  Exact: 1.3956. Runge–Kutta matches three decimal places at . Euler needs to go to to get the first two decimals right.     "
},
{
  "id": "numer-section-7",
  "level": "2",
  "url": "numer-section.html#numer-section-7",
  "type": "Checkpoint",
  "number": "1.6.1",
  "title": "",
  "body": "  Solve this equation exactly and show that .    The difference between the actual solution and the approximate solution is called the error. We usually talk about just the size of the error and we do not care much about its sign. The point is, we usually do not know the real solution, so we only have a vague understanding of the error. If we knew the error exactly …what is the point of doing the approximation?   "
},
{
  "id": "numer-section-8",
  "level": "2",
  "url": "numer-section.html#numer-section-8",
  "type": "Table",
  "number": "1.6.2",
  "title": "Euler’s method approximation of <span class=\"process-math\">\\(y(2)\\)<\/span> where of <span class=\"process-math\">\\(y'=\\nicefrac{y^2}{3}\\text{,}\\)<\/span> <span class=\"process-math\">\\(y(0)=1\\text{.}\\)<\/span>",
  "body": " Euler’s method approximation of where of , .     Approximate  Error     1  1.92593  1.07407     0.5  2.20861  0.79139  0.73681    0.25  2.47250  0.52751  0.66656    0.125  2.68034  0.31966  0.60599    0.0625  2.82040  0.17960  0.56184    0.03125  2.90412  0.09588  0.53385    0.015625  2.95035  0.04965  0.51779    0.0078125  2.97472  0.02528  0.50913    "
},
{
  "id": "numer-section-12",
  "level": "2",
  "url": "numer-section.html#numer-section-12",
  "type": "Checkpoint",
  "number": "1.6.3",
  "title": "",
  "body": "  In the table above, suppose you do not know the error. Take the approximate values of the function in the last two lines, assume that the error goes down by a factor of 2. Can you estimate the error in the last time from this? Does it (approximately) agree with the table? Now do it for the first two rows. Does this agree with the table?    Let us talk a little bit more about the example , . Suppose that instead of the value we wish to find . The results of this effort are listed in for successive halvings of . What is going on here? Well, you should solve the equation exactly and you will notice that the solution does not exist at . In fact, the solution goes to infinity when you approach .   "
},
{
  "id": "numer-section-13",
  "level": "2",
  "url": "numer-section.html#numer-section-13",
  "type": "Table",
  "number": "1.6.4",
  "title": "Attempts to use Euler’s to approximate <span class=\"process-math\">\\(y(3)\\)<\/span> where of <span class=\"process-math\">\\(y'=\\nicefrac{y^2}{3}\\text{,}\\)<\/span> <span class=\"process-math\">\\(y(0)=1\\text{.}\\)<\/span>",
  "body": " Attempts to use Euler’s to approximate where of , .     Approximate    1  3.16232    0.5  4.54329    0.25  6.86079    0.125  10.80321    0.0625  17.59893    0.03125  29.46004    0.015625  50.40121    0.0078125  87.75769    "
},
{
  "id": "numer-section-21-2",
  "level": "2",
  "url": "numer-section.html#numer-section-21-2",
  "type": "Exercise",
  "number": "1.6.1",
  "title": "",
  "body": "  Consider , . Use Euler’s method with step size to approximate .    17\/2   "
},
{
  "id": "numer-section-21-3",
  "level": "2",
  "url": "numer-section.html#numer-section-21-3",
  "type": "Exercise",
  "number": "1.6.2",
  "title": "",
  "body": "  Consider the differential equation with . Approximate the solution at using Euler’s method with a step size of and . Compare these values with the actual solution at .     : 17, : 85\/32, Actual:    "
},
{
  "id": "numer-section-21-4",
  "level": "2",
  "url": "numer-section.html#numer-section-21-4",
  "type": "Exercise",
  "number": "1.6.3",
  "title": "",
  "body": "  Consider the differential equation with . Approximate the solution at using Euler’s method with a step size of and .     : 10, :    "
},
{
  "id": "numer-section-21-5",
  "level": "2",
  "url": "numer-section.html#numer-section-21-5",
  "type": "Exercise",
  "number": "1.6.4",
  "title": "",
  "body": "  Consider , .   Use Euler’s method with step sizes to approximate . Solve the equation exactly. Describe what happens to the errors for each you used. That is, find the factor by which the error changed each time you halved the interval.    a)  , 0. , 0.5. , .  . b)  c) Error decreases by factors of 0.32, 0.4365, 0.4723.   "
},
{
  "id": "numer-section-21-6",
  "level": "2",
  "url": "numer-section.html#numer-section-21-6",
  "type": "Exercise",
  "number": "1.6.5",
  "title": "",
  "body": "  Let , and . Approximate using Euler’s method with step sizes 1, 0.5, 0.25. Use a calculator and compute up to 4 decimal digits.   "
},
{
  "id": "numer-section-21-7",
  "level": "2",
  "url": "numer-section.html#numer-section-21-7",
  "type": "Exercise",
  "number": "1.6.6",
  "title": "",
  "body": "  Approximate the value of by looking at the initial value problem with and approximating using Euler’s method with a step size of .    2.4883   "
},
{
  "id": "numer-section-21-8",
  "level": "2",
  "url": "numer-section.html#numer-section-21-8",
  "type": "Exercise",
  "number": "1.6.7",
  "title": "",
  "body": "  Let , and .   Approximate using Euler’s method with step sizes 4, 2, and 1. Solve exactly, and compute the errors. Compute the factor by which the errors changed.   "
},
{
  "id": "numer-section-21-9",
  "level": "2",
  "url": "numer-section.html#numer-section-21-9",
  "type": "Exercise",
  "number": "1.6.8",
  "title": "",
  "body": "  Let , and .   Approximate using Euler’s method with step sizes 4, 2, and 1. Guess an exact solution based on part a) and compute the errors.   "
},
{
  "id": "numer-section-21-10",
  "level": "2",
  "url": "numer-section.html#numer-section-21-10",
  "type": "Exercise",
  "number": "1.6.9",
  "title": "",
  "body": "  Example of numerical instability: Take , . We know that the solution should decay to zero as grows. Using Euler’s method, start with and compute to try to approximate . What happened? Now halve the interval. Keep halving the interval and approximating until the numbers you are getting start to stabilize (that is, until they start going towards zero). Note: You might want to use a calculator.    For , . , , goes to zero, but oscillates. just goes to zero.   "
},
{
  "id": "numer-section-21-11",
  "level": "2",
  "url": "numer-section.html#numer-section-21-11",
  "type": "Exercise",
  "number": "1.6.10",
  "title": "",
  "body": "  There is a simple way to improve Euler’s method to make it a second order method by doing just one extra step. Consider , , and a step size . What we do is to pretend we compute the next step as in Euler, that is, we start with , we compute a slope , and then look at the point . Instead of letting our new point be , we compute the slope at that point, call it , and then take the average of and , hoping that the average is going to be closer to the actual slope on the interval from to . And we are correct, if we halve the step, the error should go down by a factor of . To summarize, the setup is the same as for regular Euler, except the computation of and .   Consider , .   Use the improved Euler’s method (see above) with step sizes and to approximate . Use Euler’s method with and . Solve exactly, find the exact value of . Compute the errors, and the factors by which the errors changed.    The simplest method used in practice is the . Consider , , and a step size . Everything is the same as in Euler’s method, except the computation of and .    "
},
{
  "id": "numer-section-21-12",
  "level": "2",
  "url": "numer-section.html#numer-section-21-12",
  "type": "Exercise",
  "number": "1.6.11",
  "title": "",
  "body": "  Consider , .   Use Runge–Kutta (see above) with step sizes and to approximate . Use Euler’s method with and . Solve exactly, find the exact value of , and compare.    a)  gives 1.3906. gives 1.3953. b)  gives 1. gives 1.125. c)  Exact: 1.3956. Runge–Kutta matches three decimal places at . Euler needs to go to to get the first two decimals right.   "
},
{
  "id": "auteq-section",
  "level": "1",
  "url": "auteq-section.html",
  "type": "Section",
  "number": "1.7",
  "title": "Autonomous equations",
  "body": " Autonomous equations   autoIntro   An equation of the form where the derivative of solutions depends only on (the dependent variable) is called an autonomous equation . If we think of as time, the naming comes from the fact that the equation is independent of time.  We return to the cooling coffee problem (). says where is the temperature, is time, is some positive constant, and is the ambient temperature. See for an example with and .  Note the solution (in the figure ). We call these constant solutions the equilibrium solutions . The points on the -axis where are called critical points of the differential equation . The point is a critical point. In fact, each critical point corresponds to an equilibrium solution.  Now, we want to determine what happens for other values of that are not . Based on the existence and uniqueness theorem in for first order differential equations, the fact that and its partial derivative in , , are continuous everywhere gives that solution curves can not cross. This means that since we know is a solution, if a solution starts below , it must always stay there, and solutions that start above will also stay there. For more information about what the solutions do, we’ll need to look back at the equation and some sample solution curves.  Note also, by looking at the graph, that the solution is in that small perturbations in do not lead to substantially different solutions as grows. If we change the initial condition a little bit, then as we get . We call such a critical point asymptotically stable . In this simple example, it turns out that all solutions in fact go to as . If there is a critical point where all nearby solutions move away from the critical point, we say it is unstable . If some nearby solutions go towards the critical point, and some others move away, then we say it is semistable . The final option is that solutions nearby neither move towards nor away from the critical point, and these critical points are called stable .  The last of these options may seem strange at first, and that is because stable critical points are not possible for autonomous equations with one unknown function. If a solution does not move towards or away from a critical point, that means it doesn’t move anywhere, and so is a critical point on its own. However, when we get to autonomous systems in and , we will see that in two dimensions, this is possible (think of a circle that does not spiral into or away from the center point).    Consider now the  for some positive and . This equation is commonly used to model population if we know the limiting population , that is the maximum sustainable population. The logistic equation leads to less catastrophic predictions on world population than . In the real world there is no such thing as negative population, but we will still consider negative for the purposes of the math.  See for an example, . There are two critical points, and . The critical point at is asymptotically stable, while the critical point at is unstable.  It is not necessary to find the exact solutions to talk about the long term behavior of the solutions. From the slope field above of , we see that Here DNE means From just looking at the slope field we cannot quite decide what happens if . It could be that the solution does not exist for all the way to . Think of the equation ; we have seen that solutions only exist for some finite period of time. Same can happen here. In our example equation above it turns out that the solution does not exist for all time, but to see that we would have to solve the equation. In any case, the solution does go to , but it may get there rather quickly.  If we are interested only in the long term behavior of the solution, we would be doing unnecessary work if we solved the equation exactly. We could draw the slope field, but it is easier to just look at the or , which is a simple way to visualize the behavior of autonomous equations. The phase line for this equation is visible in . In this case there is one dependent variable . We draw the -axis, we mark all the critical points, and then we draw arrows in between. Since is the dependent variable we draw the axis vertically, as it appears in the slope field diagrams above. If , we draw an up arrow. If , we draw a down arrow. To figure this out, we could just plug in some between the critical points, will have the same sign at all between two critical points as long is continuous. For example, , so for , and the arrow above is a down arrow. Next, , so whenever , and the arrow points up. Finally, so when , and the arrow points down.    Armed with the phase diagram, it is easy to sketch the solutions approximately: As time moves from left to right, the graph of a solution goes up if the arrow is up, and it goes down if the arrow is down.    Try sketching a few solutions simply from looking at the phase diagram. Check with the preceding graphs to see if you are getting the types of curves that match the solutions.    Once we draw the phase diagram, we can use it to classify critical points as asymptotically stable, semistable, or unstable based on whether the arrows point into or away from the critical point on each side. Two arrows in means that the critical point is asymptotically stable, two arrows away means unstable, and one in one out means semistable.        Consider the autonomous differential equation Find all equilibrium solutions for this equation, and determine their stability. Draw a phase line and use this information to sketch some approximate solution curves.    This equation is already in factored form. This makes it simple to determine the equilibrium solutions as , , and . In order to determine the stability of each critical point and draw the phase line, we need to plug in values surrounding these points to . We can see that This lets us draw the phase line and determine the stability of each critical point. Thus, we see that is an unstable critical point, is asymptotically stable, is semistable, and is unstable. A set of sample solution curves also validates these conclusions.        Concavity of Solutions  We can tell from the phase line for an autonomous equation when the solution will be increasing or decreasing. Is there any more we can learn about the shape of these graphs? There is, and it comes from looking for the concavity, which is determined by the second derivative.  We can compute the second derivative of our solution by noticing that . This function can be differentiated by the chain rule So, the solution is concave up if is positive, and concave down if that is negative. Phrased another way, the solution is concave up if and have the same sign, and it is concave down if and have opposite signs.  Let’s see what this looks like in action. Take the logistic equation , whose solutions are plotted in . shows the graph of as a function of for this scenario. When do and have the same sign? Well, this happens when is both positive and increasing, or negative and decreasing. This happens between and the vertex, as well as for . The vertex here is at , and so we conlude that the solution should be concave up when is on the intervals and , and be concave down otherwise. Looking back at , this is exactly what we observe. All of the solutions between and seem to flip over to be concave down when crosses .    The same can be seen for solutions to , even though we can’t compute the extreme values explicitly. shows the graph of vs. for this situation. Between each pair of equilibrium solutions there is a critical point of (in the Calculus 1 sense) where the derivative is zero, and at this point, the derivative changes sign, and since the function value does not change sign, the concavity of the solution to the differential equation flips at this point. Comparing this graph and these points where concavity shifts with the solutions drawn in again validates these results.    Exercises     Consider .   Draw the phase diagram, find the critical points, and mark them asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  0 is semistable c)  0      Consider .   Draw the phase diagram for . On this interval mark the critical points asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  are critical points. odd is asymptotically stable, even is unstable. c)        Let .   Sketch the phase diagram and find critical points. Classify the critical points. If , then find .      Let . Sketch a phase diagram for this differential equation. Find and classify all critical points. If , what will happen to the solution as ?     is unstable, is asymptotically stable. Tends towards .      Find and classify all equilibrium solutions for the differential equation .     is semistable, is unstable, is asymptotically stable, is unstable.      Let . Sketch a phase diagram for this differential equation. Find and classify all critical points. If , what will happen to the solution as ?     is unstable, is semistable. Tends towards .      Consider the DE . Find and classify all equilibrium solutions of this DE. Then sketch a representative selection of solution curves.     is unstable, is semistable.      Let .   (2) Find and classify all critical points. Find given any initial condition.      Suppose is positive for , it is zero when and , and it is negative for all other .   Draw the phase diagram for , find the critical points, and mark them asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  is asymptotically stable, is unstable. c)  Tends to 1.      Suppose for two numbers .   Find the critical points, and classify them.  For b), c), d), find based on the phase diagram.   (3) , , .      A disease is spreading through the country. Let be the number of people infected. Let the constant be the number of people susceptible to infection. The infection rate is proportional to the product of already infected people, , and the number of susceptible but uninfected people, .   Write down the differential equation. Supposing , that is, some people are infected at time , what is . Does the solution to part b) agree with your intuition? Why or why not?    a)  b)  S c)  Yes, everyone gets it.     "
},
{
  "id": "subsec-autoIntro-13",
  "level": "2",
  "url": "auteq-section.html#subsec-autoIntro-13",
  "type": "Checkpoint",
  "number": "1.7.1",
  "title": "",
  "body": "  Try sketching a few solutions simply from looking at the phase diagram. Check with the preceding graphs to see if you are getting the types of curves that match the solutions.    Once we draw the phase diagram, we can use it to classify critical points as asymptotically stable, semistable, or unstable based on whether the arrows point into or away from the critical point on each side. Two arrows in means that the critical point is asymptotically stable, two arrows away means unstable, and one in one out means semistable.   "
},
{
  "id": "subsec-autoIntro-14",
  "level": "2",
  "url": "auteq-section.html#subsec-autoIntro-14",
  "type": "Example",
  "number": "1.7.2",
  "title": ".",
  "body": "    Consider the autonomous differential equation Find all equilibrium solutions for this equation, and determine their stability. Draw a phase line and use this information to sketch some approximate solution curves.    This equation is already in factored form. This makes it simple to determine the equilibrium solutions as , , and . In order to determine the stability of each critical point and draw the phase line, we need to plug in values surrounding these points to . We can see that This lets us draw the phase line and determine the stability of each critical point. Thus, we see that is an unstable critical point, is asymptotically stable, is semistable, and is unstable. A set of sample solution curves also validates these conclusions.     "
},
{
  "id": "auteq-section-4-2",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-2",
  "type": "Exercise",
  "number": "1.7.3.1",
  "title": "",
  "body": "  Consider .   Draw the phase diagram, find the critical points, and mark them asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  0 is semistable c)  0   "
},
{
  "id": "auteq-section-4-3",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-3",
  "type": "Exercise",
  "number": "1.7.3.2",
  "title": "",
  "body": "  Consider .   Draw the phase diagram for . On this interval mark the critical points asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  are critical points. odd is asymptotically stable, even is unstable. c)     "
},
{
  "id": "auteq-section-4-4",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-4",
  "type": "Exercise",
  "number": "1.7.3.3",
  "title": "",
  "body": "  Let .   Sketch the phase diagram and find critical points. Classify the critical points. If , then find .   "
},
{
  "id": "auteq-section-4-5",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-5",
  "type": "Exercise",
  "number": "1.7.3.4",
  "title": "",
  "body": "  Let . Sketch a phase diagram for this differential equation. Find and classify all critical points. If , what will happen to the solution as ?     is unstable, is asymptotically stable. Tends towards .   "
},
{
  "id": "auteq-section-4-6",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-6",
  "type": "Exercise",
  "number": "1.7.3.5",
  "title": "",
  "body": "  Find and classify all equilibrium solutions for the differential equation .     is semistable, is unstable, is asymptotically stable, is unstable.   "
},
{
  "id": "auteq-section-4-7",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-7",
  "type": "Exercise",
  "number": "1.7.3.6",
  "title": "",
  "body": "  Let . Sketch a phase diagram for this differential equation. Find and classify all critical points. If , what will happen to the solution as ?     is unstable, is semistable. Tends towards .   "
},
{
  "id": "auteq-section-4-8",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-8",
  "type": "Exercise",
  "number": "1.7.3.7",
  "title": "",
  "body": "  Consider the DE . Find and classify all equilibrium solutions of this DE. Then sketch a representative selection of solution curves.     is unstable, is semistable.   "
},
{
  "id": "auteq-section-4-9",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-9",
  "type": "Exercise",
  "number": "1.7.3.8",
  "title": "",
  "body": "  Let .   (2) Find and classify all critical points. Find given any initial condition.   "
},
{
  "id": "auteq-section-4-10",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-10",
  "type": "Exercise",
  "number": "1.7.3.9",
  "title": "",
  "body": "  Suppose is positive for , it is zero when and , and it is negative for all other .   Draw the phase diagram for , find the critical points, and mark them asymptotically stable, semistable, or unstable. Sketch typical solutions of the equation. Find for the solution with the initial condition .    a)  is asymptotically stable, is unstable. c)  Tends to 1.   "
},
{
  "id": "auteq-section-4-11",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-11",
  "type": "Exercise",
  "number": "1.7.3.10",
  "title": "",
  "body": "  Suppose for two numbers .   Find the critical points, and classify them.  For b), c), d), find based on the phase diagram.   (3) , , .   "
},
{
  "id": "auteq-section-4-12",
  "level": "2",
  "url": "auteq-section.html#auteq-section-4-12",
  "type": "Exercise",
  "number": "1.7.3.11",
  "title": "",
  "body": "  A disease is spreading through the country. Let be the number of people infected. Let the constant be the number of people susceptible to infection. The infection rate is proportional to the product of already infected people, , and the number of susceptible but uninfected people, .   Write down the differential equation. Supposing , that is, some people are infected at time , what is . Does the solution to part b) agree with your intuition? Why or why not?    a)  b)  S c)  Yes, everyone gets it.   "
},
{
  "id": "bifDiag-section",
  "level": "1",
  "url": "bifDiag-section.html",
  "type": "Section",
  "number": "1.8",
  "title": "Bifurcation diagrams",
  "body": " Bifurcation diagrams  An extension of the topic of autonomous equation is autonomous equations with parameter . The idea is that we have a differential equation that has no explicit dependence on time, but does have a dependence on an outside parameter, which is a constant set by the physical situation. In terms of physical problems, this parameter will tend to be something that we can adjust to change how the differential equation behaves. For example, in a logistic differential equation either the or the (or both) could be adjustable parameters. For a given value of the parameter, the differential equation behaves like a standard autonomous differential equation, but we can get different properties of this equation for different values of the parameter.   An autonomous equation with parameter  is a differential equation of the form where, for every value of , is a function of the single variable .  Later, we will want to view as a two-variable function of and , but for now, we want to think about it as a function of just for a fixed value of . We want to be able to analyze what happens to this equation for different values of . Since it is an autonomous equation, we can do this using phase lines. This will be easiest to see through an example.      Consider the differential equation which fits the description of an autonomous equation with parameter . Describe what happens in this differential equation for , , and .    We can draw a phase line for , and .    It is clear that something happens with this equation between and . We go from having only one equilibrium solution at to having three equilibrium solutions at . In addition, the solution at is unstable for , while it is asymptotically stable for . If we want to figure out when this change happens, we’ll need a better way to analyze this problem.    How can we better approach this problem? The idea is to think about when the solution to the differential equation will be increasing or decreasing as a function of the two variables and . Based on the structure of the differential equation, the solution will be increasing when the function is positive and will be decreasing when is negative. Since a phase line is a plot of this information for a given value of , we essentially want to plot all of these phase lines on a two-dimensional graph. This graph is called a bifurcation diagram . shows a bifurcation diagram for the example .    Within this picture, we can see all of our phase lines from before, because at any value of , taking the vertical slice of this graph at that value, we get the phase line. If we want to consider , then we can look above the horizontal coordinate , and that will give us the phase line for . The same goes for any other value of we want to consider. For instance, we can also see that for any , there will be one equilibrium solution, and for there are three equilibrium solutions, indicated by the three black curves above each of those values.  From this, we can see that the point at which the behavior changes is . Thus, for this problem is called the . This is defined to be the value of the parameter for which the overall behavior of the equation changes. This can be a change in the number of equilibrium solutions, the stability of these equilibrium solutions, or both. For this particular example, we have both of these. We go from 1 equilibrium solution to 3, and the solution at changes in stability. This type of bifurcation is called a pitchfork bifurcation based on the shape of the equilibrium solutions near the bifurcation point.  Another example of a bifurcation of a different form can be seen in the example of the logistic equation with harvesting. Suppose an alien race really likes to eat humans. They keep a planet with humans on it and harvest the humans at a rate of million humans per year. Suppose is the number of humans in millions on the planet and is time in years. Let be the limiting population when no harvesting is done. The number is a constant depending on how fast humans multiply. Our equation becomes In this setup, M and k are fixed values, and the parameter that is being adjusted for this equation is . We expand the right-hand side and set it to zero. Solving for the critical points using the quadratic formula, let us call them and , we get     Sketch a phase diagram for different possibilities. Note that these possibilities are , or , or and both complex (i.e. no real solutions). Hint: Fix some simple and and then vary .        For example, let and . What happens for different values of in this situation?    When , then and are distinct and positive. The slope field we get is in . As long as the population starts above , which is approximately 1.55 million, then the population will not die out. It will in fact tend towards million. If ever some catastrophe happens and the population drops below , humans will die out, and the fast food restaurant serving them will go out of business.    When , then . There is only one critical point and it is semistable. When the population starts above 4 million it will tend towards 4 million. If it ever drops below 4 million, humans will die out on the planet. This scenario is not one that we (as the human fast food proprietor) want to be in. A small perturbation of the equilibrium state and we are out of business. There is no room for error. See .  Finally if we are harvesting at 2 million humans per year, there are no critical points. The population will always plummet towards zero, no matter how well stocked the planet starts. See .    All of these can also be seen from the bifurcation diagram, which is drawn in . The values and discussed above represent the upper and lower branches of the parabola in the figure. For any , there are no equilibrium solutions and the phase line is entirely decreasing, meaning the solution will converge to zero no matter what. For , there are two equilibrium solutions, with the top one asymptotically stable and the bottom one unstable. At is where the bifurcation point occurs for this example. This is an example of a saddle-node bifurcation, as the two equilibrium solutions collide with each other at the bifurcation point and disappear.    Another way to visualize this situation is by plotting the function for the different values of . The places where this function is zero give the equilibrium solutions, and we can determine by looking for where the zeros of this function change behavior. For this particular example, the graphs of are drawn in .      The values of we are looking for are those where the number and types of zeros change for the function . In this figure, we see that for , the parabola crosses the axis twice, resulting in two zeros and two equilibrium solutions. For , there is one (double) root, and for , there are no equilibrium solutions, and the function is always negative. Since the number of roots\/zeros changes at , that means that is the bifurcation point for this equation. We can also see this from the equation, since the equilibrium solutions are determined by the values of where which can be found by the quadratic formula Roots to this equation do not exist (because they are complex) if , or .   Exercises    Start with the logistic equation . Suppose we modify our harvesting. That is we will only harvest an amount proportional to current population. In other words, we harvest per unit of time for some (Similar to earlier example with replaced with ).   Construct the differential equation. Show that if , then the equation is still logistic. What happens when ?    a)  b) It changes the effective M c) Population always decreases.      Assume that a population of fish in a lake satisfies . Now suppose that fish are continually added at fish per unit of time.   (2) Find the differential equation for . What is the new limiting population?      Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  . The solution at changes stability.      Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  . Two new equilibrium solutions are created.      Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  , and both change stability.     "
},
{
  "id": "bifDiag-section-5",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-5",
  "type": "Example",
  "number": "1.8.1",
  "title": ".",
  "body": "    Consider the differential equation which fits the description of an autonomous equation with parameter . Describe what happens in this differential equation for , , and .    We can draw a phase line for , and .    It is clear that something happens with this equation between and . We go from having only one equilibrium solution at to having three equilibrium solutions at . In addition, the solution at is unstable for , while it is asymptotically stable for . If we want to figure out when this change happens, we’ll need a better way to analyze this problem.   "
},
{
  "id": "bifDiag-section-10",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-10",
  "type": "Checkpoint",
  "number": "1.8.2",
  "title": "",
  "body": "  Sketch a phase diagram for different possibilities. Note that these possibilities are , or , or and both complex (i.e. no real solutions). Hint: Fix some simple and and then vary .   "
},
{
  "id": "bifDiag-section-11",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-11",
  "type": "Example",
  "number": "1.8.3",
  "title": ".",
  "body": "    For example, let and . What happens for different values of in this situation?    When , then and are distinct and positive. The slope field we get is in . As long as the population starts above , which is approximately 1.55 million, then the population will not die out. It will in fact tend towards million. If ever some catastrophe happens and the population drops below , humans will die out, and the fast food restaurant serving them will go out of business.    When , then . There is only one critical point and it is semistable. When the population starts above 4 million it will tend towards 4 million. If it ever drops below 4 million, humans will die out on the planet. This scenario is not one that we (as the human fast food proprietor) want to be in. A small perturbation of the equilibrium state and we are out of business. There is no room for error. See .  Finally if we are harvesting at 2 million humans per year, there are no critical points. The population will always plummet towards zero, no matter how well stocked the planet starts. See .    All of these can also be seen from the bifurcation diagram, which is drawn in . The values and discussed above represent the upper and lower branches of the parabola in the figure. For any , there are no equilibrium solutions and the phase line is entirely decreasing, meaning the solution will converge to zero no matter what. For , there are two equilibrium solutions, with the top one asymptotically stable and the bottom one unstable. At is where the bifurcation point occurs for this example. This is an example of a saddle-node bifurcation, as the two equilibrium solutions collide with each other at the bifurcation point and disappear.    Another way to visualize this situation is by plotting the function for the different values of . The places where this function is zero give the equilibrium solutions, and we can determine by looking for where the zeros of this function change behavior. For this particular example, the graphs of are drawn in .     "
},
{
  "id": "bifDiag-section-13-2",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-13-2",
  "type": "Exercise",
  "number": "1.8.1",
  "title": "",
  "body": "  Start with the logistic equation . Suppose we modify our harvesting. That is we will only harvest an amount proportional to current population. In other words, we harvest per unit of time for some (Similar to earlier example with replaced with ).   Construct the differential equation. Show that if , then the equation is still logistic. What happens when ?    a)  b) It changes the effective M c) Population always decreases.   "
},
{
  "id": "bifDiag-section-13-3",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-13-3",
  "type": "Exercise",
  "number": "1.8.2",
  "title": "",
  "body": "  Assume that a population of fish in a lake satisfies . Now suppose that fish are continually added at fish per unit of time.   (2) Find the differential equation for . What is the new limiting population?   "
},
{
  "id": "bifDiag-section-13-4",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-13-4",
  "type": "Exercise",
  "number": "1.8.3",
  "title": "",
  "body": "  Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  . The solution at changes stability.   "
},
{
  "id": "bifDiag-section-13-5",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-13-5",
  "type": "Exercise",
  "number": "1.8.4",
  "title": "",
  "body": "  Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  . Two new equilibrium solutions are created.   "
},
{
  "id": "bifDiag-section-13-6",
  "level": "2",
  "url": "bifDiag-section.html#bifDiag-section-13-6",
  "type": "Exercise",
  "number": "1.8.5",
  "title": "",
  "body": "  Consider the differential equation with parameter given by .   Sketch a phase diagram for this differential equation with , , and . Draw a bifurcation diagram for this differential equation with parameter. What is the bifurcation point for this equation? What changes when passes over the bifurcation point?    c)  , and both change stability.   "
},
{
  "id": "exact-section",
  "level": "1",
  "url": "exact-section.html",
  "type": "Section",
  "number": "1.9",
  "title": "Exact equations",
  "body": " Exact equations   exactIntro  Another type of equation that comes up quite often in physics and engineering is an . Suppose is a function of two variables, which we call the . The naming should suggest potential energy, or electric potential. Exact equations and potential functions appear when there is a conservation law at play, such as conservation of energy. Let us make up a simple example. Let    3.25in  We are interested in the lines of constant energy, that is lines where the energy is conserved; we want curves where , for some constant , since represents the energy of the system. In our example, the curves are circles. See .  We take the of : For convenience, we will make use of the notation of and . In our example, We apply the total derivative to , to find the differential equation . The differential equation we obtain in such a way has the form    An equation of the form is called exact if it was obtained as for some potential function .  In our simple example, we obtain the equation Since we obtained this equation by differentiating , the equation is exact. We often wish to solve for in terms of . In our example,   An interpretation of the setup is that at each point in the plane is a vector, that is, a direction and a magnitude. As and are functions of , we have a . The particular vector field that comes from an exact equation is a so-called , that is, a vector field that comes with a potential function , such that This is something that you may have seen in your Calculus 3 course, and if so, the process for solving exact equations is basically identical to the process of finding a potential function for a conservative vector field. The physical interpretation of conservative vector fields is as follows. Let be a path in the plane starting at and ending at . If we think of as force, then the work required to move along is That is, the work done only depends on endpoints, that is where we start and where we end. For example, suppose is gravitational potential. The derivative of given by is the gravitational force. What we are saying is that the work required to move a heavy box from the ground floor to the roof only depends on the change in potential energy. That is, the work done is the same no matter what path we took; if we took the stairs or the elevator. Although if we took the elevator, the elevator is doing the work for us. The curves are those where no work need be done, such as the heavy box sliding along without accelerating or breaking on a perfectly flat roof, on a cart with incredibly well oiled wheels. Effectively, an exact equation is a conservative vector field, and the implicit solution of this equation is the potential function.    Solving exact equations  Now you, the reader, should ask: Where did we solve a differential equation? Well, in applications we generally know and , but we do not know . That is, we may have just started with , or perhaps even It is up to us to find some potential that works. Many different will work; adding a constant to does not change the equation. Once we have a potential function , the equation gives an implicit solution of the ODE.      Let us find the general solution to . Forget we knew what was.    If we know that this is an exact equation, we start looking for a potential function . We have and . If exists, it must be such that . Integrate in the variable to find for some function . The function is the , though it is only constant as far as is concerned, and may still depend on . Now differentiate in and set it equal to , which is what is supposed to be: Integrating, we find . We could add a constant of integration if we wanted to, but there is no need. We found . Next for a constant , we solve for in terms of . In this case, we obtain as we did before.      Why did we not need to add a constant of integration when integrating ? Add a constant of integration, say , and see what you get. What is the difference from what we got above, and why does it not matter?    In the previous example, you may have also noticed that the equation is separable, and we could have solved it via that method as well. This is not a coincidence, as every separable equation is exact (see for the details) but there are many exact equations that are not separable, which we will see throughout the examples here.    The procedure, once we know that the equation is exact, is:    Integrate in resulting in .    Differentiate this in , and set that equal to , so that we may find by integration.    The procedure can also be done by first integrating in and then differentiating in . Pretty easy huh? Let’s try this again.      Consider now .    OK, so and . We try to proceed as before. Suppose exists. Then . We integrate: for some function . Differentiate in and set equal to : But there is no way to satisfy this requirement! The function cannot be written as plus a function of . The equation is not exact; no potential function exists.    Is there an easier way to check for the existence of , other than failing in trying to find it? Turns out there is. Suppose and . Then as long as the second derivatives are continuous, Let us state it as a theorem. Usually this is called the Poincaré Lemma  Named for the French polymath Jules Henri Poincaré (1854–1912). .   Poincaré If and are continuously differentiable functions of , and , then near any point there is a function such that and .  The theorem doesn’t give us a global defined everywhere. In general, we can only find the potential locally, near some initial point. By this time, we have come to expect this from differential equations.  Let us return to the example above where and . Notice and , which are clearly not equal. The equation is not exact.      Solve     We write the equation as so and . Then The equation is exact. Integrating in , we find Differentiating in and setting to , we find So , and will work. Take . We wish to solve . First let us find . As then . Therefore , so . Now we solve for to get         Solve     We leave to the reader to check that .  This vector field is not conservative if considered as a vector field of the entire plane minus the origin. The problem is that if the curve is a circle around the origin, say starting at and ending at going counterclockwise, then if existed we would expect That is nonsense! We leave the computation of the path integral to the interested reader, or you can consult your multivariable calculus textbook. So there is no potential function defined everywhere outside the origin .  If we think back to the theorem, it does not guarantee such a function anyway. It only guarantees a potential function locally, that is only in some region near the initial point. As we start at the point . Considering and integrating in or in , we find The implicit solution is . Solving, . That is, the solution is a straight line. Solving gives us that , and so is the desired solution. See , and note that the solution only exists for .          Solve     The reader should check that this equation is exact. Let and . We follow the procedure for exact equations and Therefore or and . We try to solve . We easily solve for and then just take the square root: When , the term in front of vanishes. You can also see that our solution is not valid in that case. However, one could in that case try to solve for in terms of starting from the implicit solution . The solution is somewhat messy and we leave it as implicit.      Integrating factors  Sometimes an equation is not exact, but it can be made exact by multiplying with a function . That is, perhaps for some nonzero function , is exact. Any solution to this new equation is also a solution to .  In fact, a linear equation is always such an equation. Let be the integrating factor for a linear equation. Multiply the equation by and write it in the form of . Then , so , while , so . In other words, we have an exact equation. Integrating factors for linear functions are just a special case of integrating factors for exact equations.  But how do we find the integrating factor ? Well, given an equation  should be a function such that Therefore, At first it may seem we replaced one differential equation by another. True, but all hope is not lost.  A strategy that often works is to look for a that is a function of alone, or a function of alone. If is a function of alone, that is , then we write instead of , and is just zero. Then In particular, ought to be a function of alone (not depend on ). If so, then we have a linear equation Letting , we solve using the standard integrating factor method, to find . The constant in the solution is not relevant, we need any nonzero solution, so we take . Then is the integrating factor.  Similarly we could try a function of the form . Then In particular, ought to be a function of alone. If so, then we have a linear equation Letting , we find . We take . So is the integrating factor.      Solve     Let and . Compute As this is not zero, the equation is not exact. We notice is a function of alone. We compute the integrating factor Assuming that we want to look at , we multiply our given equation by to obtain which is an exact equation that we solved in . The solution was If, instead, we had wanted a solution with , we would have needed to multiply by , which would have given a very similar result.        Solve     First compute As this is not zero, the equation is not exact. We observe is a function of alone. We compute the integrating factor Therefore we look at the exact equation The reader should double check that this equation is exact. We follow the procedure for exact equations and Consequently or . Thus . It is not possible to solve for in terms of elementary functions, so let us be content with the implicit solution: We are looking for the general solution and we divided by above. We should check what happens when , as the equation itself makes perfect sense in that case. We plug in to find the equation is satisfied. So is also a solution.      Exercises    Solve the following exact equations, implicit general solutions will suffice:   (2)        a)  b)  c)  d)        Solve the following exact equations, implicit general solutions will suffice:   (2)          Solve the differential equation            Solve the differential equation            Solve the differential equation with .           Solve the differential equation with . Write this as an explicit function and determine the interval of values where the solution is valid.     , valid on       Solve the differential equation with . Write this as an explicit function and determine the interval of values where the solution is valid.     , valid on       Find the integrating factor for the following equations making them into exact equations. You can either use the formulas in this section or guess what the integrating factor should be.   (2)        a)  b)  c)  d)         Find the integrating factor for the following equations making them into exact equations:   (2)          Suppose you have an equation of the form: .   Show it is exact. Find the form of the potential function in terms of and .    a) Yes. b)        Suppose that we have the equation .   Is this equation exact? Find the general solution using a definite integral.    a)  Yes. b)        Find the potential function of the exact equation in two different ways.   Integrate in terms of and then differentiate in and set to . Integrate in terms of and then differentiate in and set to .            A function is said to be a if .   Show if is harmonic, is an exact equation. So there exists (at least locally) the so-called function such that and .  Verify that the following are harmonic and find the corresponding harmonic conjugates :   (3)       a)  and , and the difference is zero, so they are equal. b)  (i)  (ii)  (iii)           Show that every separable equation can be written as an exact equation, and verify that it is indeed exact. Using this rewrite as an exact equation, solve it and verify that the solution is the same as it was in .    "
},
{
  "id": "solving-exact-equations-3",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-3",
  "type": "Example",
  "number": "1.9.1",
  "title": ".",
  "body": "    Let us find the general solution to . Forget we knew what was.    If we know that this is an exact equation, we start looking for a potential function . We have and . If exists, it must be such that . Integrate in the variable to find for some function . The function is the , though it is only constant as far as is concerned, and may still depend on . Now differentiate in and set it equal to , which is what is supposed to be: Integrating, we find . We could add a constant of integration if we wanted to, but there is no need. We found . Next for a constant , we solve for in terms of . In this case, we obtain as we did before.   "
},
{
  "id": "solving-exact-equations-4",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-4",
  "type": "Checkpoint",
  "number": "1.9.2",
  "title": "",
  "body": "  Why did we not need to add a constant of integration when integrating ? Add a constant of integration, say , and see what you get. What is the difference from what we got above, and why does it not matter?    In the previous example, you may have also noticed that the equation is separable, and we could have solved it via that method as well. This is not a coincidence, as every separable equation is exact (see for the details) but there are many exact equations that are not separable, which we will see throughout the examples here.   "
},
{
  "id": "solving-exact-equations-8",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-8",
  "type": "Example",
  "number": "1.9.3",
  "title": ".",
  "body": "    Consider now .    OK, so and . We try to proceed as before. Suppose exists. Then . We integrate: for some function . Differentiate in and set equal to : But there is no way to satisfy this requirement! The function cannot be written as plus a function of . The equation is not exact; no potential function exists.   "
},
{
  "id": "solving-exact-equations-13",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-13",
  "type": "Example",
  "number": "1.9.4",
  "title": ".",
  "body": "    Solve     We write the equation as so and . Then The equation is exact. Integrating in , we find Differentiating in and setting to , we find So , and will work. Take . We wish to solve . First let us find . As then . Therefore , so . Now we solve for to get    "
},
{
  "id": "solving-exact-equations-14",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-14",
  "type": "Example",
  "number": "1.9.5",
  "title": ".",
  "body": "    Solve     We leave to the reader to check that .  This vector field is not conservative if considered as a vector field of the entire plane minus the origin. The problem is that if the curve is a circle around the origin, say starting at and ending at going counterclockwise, then if existed we would expect That is nonsense! We leave the computation of the path integral to the interested reader, or you can consult your multivariable calculus textbook. So there is no potential function defined everywhere outside the origin .  If we think back to the theorem, it does not guarantee such a function anyway. It only guarantees a potential function locally, that is only in some region near the initial point. As we start at the point . Considering and integrating in or in , we find The implicit solution is . Solving, . That is, the solution is a straight line. Solving gives us that , and so is the desired solution. See , and note that the solution only exists for .     "
},
{
  "id": "solving-exact-equations-15",
  "level": "2",
  "url": "exact-section.html#solving-exact-equations-15",
  "type": "Example",
  "number": "1.9.6",
  "title": ".",
  "body": "    Solve     The reader should check that this equation is exact. Let and . We follow the procedure for exact equations and Therefore or and . We try to solve . We easily solve for and then just take the square root: When , the term in front of vanishes. You can also see that our solution is not valid in that case. However, one could in that case try to solve for in terms of starting from the implicit solution . The solution is somewhat messy and we leave it as implicit.   "
},
{
  "id": "integrating-factors-7",
  "level": "2",
  "url": "exact-section.html#integrating-factors-7",
  "type": "Example",
  "number": "1.9.7",
  "title": ".",
  "body": "    Solve     Let and . Compute As this is not zero, the equation is not exact. We notice is a function of alone. We compute the integrating factor Assuming that we want to look at , we multiply our given equation by to obtain which is an exact equation that we solved in . The solution was If, instead, we had wanted a solution with , we would have needed to multiply by , which would have given a very similar result.   "
},
{
  "id": "integrating-factors-8",
  "level": "2",
  "url": "exact-section.html#integrating-factors-8",
  "type": "Example",
  "number": "1.9.8",
  "title": ".",
  "body": "    Solve     First compute As this is not zero, the equation is not exact. We observe is a function of alone. We compute the integrating factor Therefore we look at the exact equation The reader should double check that this equation is exact. We follow the procedure for exact equations and Consequently or . Thus . It is not possible to solve for in terms of elementary functions, so let us be content with the implicit solution: We are looking for the general solution and we divided by above. We should check what happens when , as the equation itself makes perfect sense in that case. We plug in to find the equation is satisfied. So is also a solution.   "
},
{
  "id": "exact-section-5-2",
  "level": "2",
  "url": "exact-section.html#exact-section-5-2",
  "type": "Exercise",
  "number": "1.9.4.1",
  "title": "",
  "body": "  Solve the following exact equations, implicit general solutions will suffice:   (2)        a)  b)  c)  d)     "
},
{
  "id": "exact-section-5-3",
  "level": "2",
  "url": "exact-section.html#exact-section-5-3",
  "type": "Exercise",
  "number": "1.9.4.2",
  "title": "",
  "body": "  Solve the following exact equations, implicit general solutions will suffice:   (2)       "
},
{
  "id": "exact-section-5-4",
  "level": "2",
  "url": "exact-section.html#exact-section-5-4",
  "type": "Exercise",
  "number": "1.9.4.3",
  "title": "",
  "body": "  Solve the differential equation         "
},
{
  "id": "exact-section-5-5",
  "level": "2",
  "url": "exact-section.html#exact-section-5-5",
  "type": "Exercise",
  "number": "1.9.4.4",
  "title": "",
  "body": "  Solve the differential equation         "
},
{
  "id": "exact-section-5-6",
  "level": "2",
  "url": "exact-section.html#exact-section-5-6",
  "type": "Exercise",
  "number": "1.9.4.5",
  "title": "",
  "body": "  Solve the differential equation with .        "
},
{
  "id": "exact-section-5-7",
  "level": "2",
  "url": "exact-section.html#exact-section-5-7",
  "type": "Exercise",
  "number": "1.9.4.6",
  "title": "",
  "body": "  Solve the differential equation with . Write this as an explicit function and determine the interval of values where the solution is valid.     , valid on    "
},
{
  "id": "exact-section-5-8",
  "level": "2",
  "url": "exact-section.html#exact-section-5-8",
  "type": "Exercise",
  "number": "1.9.4.7",
  "title": "",
  "body": "  Solve the differential equation with . Write this as an explicit function and determine the interval of values where the solution is valid.     , valid on    "
},
{
  "id": "exact-section-5-9",
  "level": "2",
  "url": "exact-section.html#exact-section-5-9",
  "type": "Exercise",
  "number": "1.9.4.8",
  "title": "",
  "body": "  Find the integrating factor for the following equations making them into exact equations. You can either use the formulas in this section or guess what the integrating factor should be.   (2)        a)  b)  c)  d)     "
},
{
  "id": "exact-section-5-10",
  "level": "2",
  "url": "exact-section.html#exact-section-5-10",
  "type": "Exercise",
  "number": "1.9.4.9",
  "title": "",
  "body": "  Find the integrating factor for the following equations making them into exact equations:   (2)       "
},
{
  "id": "exact-section-5-11",
  "level": "2",
  "url": "exact-section.html#exact-section-5-11",
  "type": "Exercise",
  "number": "1.9.4.10",
  "title": "",
  "body": "  Suppose you have an equation of the form: .   Show it is exact. Find the form of the potential function in terms of and .    a) Yes. b)     "
},
{
  "id": "exact-section-5-12",
  "level": "2",
  "url": "exact-section.html#exact-section-5-12",
  "type": "Exercise",
  "number": "1.9.4.11",
  "title": "",
  "body": "  Suppose that we have the equation .   Is this equation exact? Find the general solution using a definite integral.    a)  Yes. b)     "
},
{
  "id": "exact-section-5-13",
  "level": "2",
  "url": "exact-section.html#exact-section-5-13",
  "type": "Exercise",
  "number": "1.9.4.12",
  "title": "",
  "body": "  Find the potential function of the exact equation in two different ways.   Integrate in terms of and then differentiate in and set to . Integrate in terms of and then differentiate in and set to .        "
},
{
  "id": "exact-section-5-14",
  "level": "2",
  "url": "exact-section.html#exact-section-5-14",
  "type": "Exercise",
  "number": "1.9.4.13",
  "title": "",
  "body": "  A function is said to be a if .   Show if is harmonic, is an exact equation. So there exists (at least locally) the so-called function such that and .  Verify that the following are harmonic and find the corresponding harmonic conjugates :   (3)       a)  and , and the difference is zero, so they are equal. b)  (i)  (ii)  (iii)     "
},
{
  "id": "exact-section-5-15",
  "level": "2",
  "url": "exact-section.html#exact-section-5-15",
  "type": "Exercise",
  "number": "1.9.4.14",
  "title": "",
  "body": "     Show that every separable equation can be written as an exact equation, and verify that it is indeed exact. Using this rewrite as an exact equation, solve it and verify that the solution is the same as it was in .   "
},
{
  "id": "modelfirst-section",
  "level": "1",
  "url": "modelfirst-section.html",
  "type": "Section",
  "number": "1.10",
  "title": "Modeling with First Order Equations",
  "body": " Modeling with First Order Equations   One of the main reasons to study and learn about differential equations, particularly for scientists and engineers, is their application and use in mathematical modeling. Since the derivative of a function represents the rate of change of that quantity, if we can use physical or scientific principles to develop an equation for the rate of change of some quantity in terms of the quantity and time, there’s a chance that we can write a differential equation for this quantity and solve it to determine how the quantity will change.    Principles of Mathematical Modeling  The process of mathematical modeling involves three main steps. The first of these is to write the model. This part comes from basic science or engineering principles and involves writing a differential equation that fits the given situation. If we can determine the rate at which a quantity will change based on the surrounding factors, we have a good shot of getting to such an equation. One main principle that can be used to write these equations is the accumuilation equation, which will be discussed in the next subsection.  The second step of this process is to solve the differential equation. This can mean either an analytic solution or a numeric one, and this is where the work of this class comes into play. We are going through a bunch of different techniques for solving differential equations and analyzing the overall behavior of such equations so that we can use them in this way. The end goal is to get an equation or a graph for how the quantity that we made a model for is going to change in time.  The final step of the process is to validate the model by comparing with experimental data. Once we have written the model and solved the corresponding differential equation, we want to make sure that the model works. To do this, we can take a new version of the original scenario, run the model as well as the physical experiment and see how the results compare. If the results are close (in whatever sense makes logical sense for the problem), then we have a good model and can keep it. However, if our results differ significantly, then the model we used probably doesn’t apply to this problem. We need to go back to step 1 to try to figure out a better model for the physical situation in order to get more accurate results.  Why do we care about mathematical modeling? The biggest thing that it does from an engineering point of view is reduce the need for repeated testing. If we have a mathematical model that works for a given physical system, we can see how the system will be have under slightly different conditions and with different initial conditions without needing to run the physical experiment over and over again. We can do all of this testing on the model, and since we have validated the model, we can assume that the actual results will be similar. This also allows us to change some aspects of the physical situation to try to optimize it, but do so just by modifying the mathematical model, not the physical setup. This can significantly cut down on costs and allow for more optimal system design at the same time.    The Accumulation Equation  The accumulation equation is one of the simplest general mathematical formulations that can be used to develop mathematical models. This equation comes down to the fact that the rate of change of some quantity should be equal to the rate at which it is being added minus the rate at which it is being removed. If we let be the quantity in question, this can be written as This may seem fairly simple. However, it shows up in many places in science and engineering. Any mass or energy balance equations are examples of accumulation equations. These types of equations can also be written for the accumulation of momentum, and doing so for fluids gives rise to the Navier-Stokes equations, providing the basis for several fields of engineering. The examples that we see here will be simpler than that, but the idea is still the same.      A tank initially contains 70 gallons of water and 5 lbs of salt. A solution with salt concentration 0.2 lbs per gallon flows into the tank at a rate of gal\/min. The tank is well stirred, and water is removed from the tank at a rate of gal\/min. Find the amount of salt in the tank at any time ? What happens as ? Does this make sense?    To solve this problem, we use the accumulation equation on the amount of salt in the tank. In order to compute with this, we recognize that in terms of mass of salt moving into the tank and similarly for the mass of salt leaving the tank.  If we let represent the amount of salt in the tank at any time (which is the goal of the problem), we can write a differential equation for this using the accumulation equation . This gives us that For this problem, we have that The last of these lines comes from the fact that the tank is well stirred or well-mixed. This implies that the concentration of salt in the water leaving the tank is the same as the concentration in the tank, which we can compute as . In this case, since the flow rate in and out are both 3 gal\/min, the volume of water in the tank is fixed at gallons, so we can put this in the equation.  Therefore, our equation becomes We can rewrite this equation as which we recognize as a first order linear equation. We can then solve this using the method of integrating factors. Our factor is which we can multiply on both sides of the equation to obtain The left side of this is a product rule derivative, so we can integrate both sides to obtain We can then isolate to get our general solution as Our initial condition tells us that . Plugging this in gives that so the solution to the initial value problem, and thus our calculation for the amount of salt in the tank at any time , is   As , we see that the exponential term goes to zero. This leaves us with 14 lbs of salt in the tank after a long time. This makes some sense because this would give us a concentration of lb\/gal, and that was exactly the concentration of the in-flow stream. It makes sense that after a long time of mixing and removing water from the tank, the concentration of the tank would match that of the incoming stream.    The same principle works for other types of examples, including those where the volume of the tank is not constant in time.   1.55in1.60in      A 100 liter tank contains 10 kilograms of salt dissolved in 60 liters of water. Solution of water and salt (brine) with concentration of 0.1 kilograms per liter is flowing in at the rate of 5 liters a minute. The solution in the tank is well stirred and flows out at a rate of 3 liters a minute. How much salt is in the tank when the tank is full?    We can again use the accumulation equation to write In this example, we have Our equation is, therefore, Or in the form    Let us solve. The integrating factor is   We multiply both sides of the equation to get    3.25in  We need to find . We know that at , . So or   We are interested in when the tank is full. The tank is full when , or when . So See for the graph of over .  The concentration when the tank is full is approximately , and we started with or .    For the previous example, we obtained the solution which is valid and well defined for all positive values of (it has an issue at , but we aren’t concerned about that here). However, as a differential equation that represents a physical situation, it is not valid for all positive values of . The issue here is that the tank is full at . Therefore, beyond this point, while the function still exists, it is not a valid model for this physical system. Once the tank fills, you can’t keep adding and removing water at the same rates that you have been up until this point, because something is going to break with the system. The same goes for if you are removing water from the tank at a faster rate than you are adding it, because then the tank will empty at some point in time and beyond that, the model equation no longer represents the system.  The same ideas apply to problems involving interest compounded continuously. For an interest rate of , the rate in, or the rate at which the money in the account is increasing, is where is the amount of money in the account. Taking this along with other factors that may affect the balance of the account allows us to write a differential equation, which we can solve to determine what the balance will be over time.      A bank account with an interest rate of per year, compounded continuously, starts with a balance of $30000. The owner of the account withdraws $50 from the account each month. Find and solve a differential equation for the account balance over time. What is the largest amount that the owner could withdraw each month without the account eventually reaching $0?    We will use the function to model the balance of the account over time, where is in years . Since the owner withdraws $50 per month, this means that they withdraw $600 over the course of the year. This means that the differential equation we want is We can solve this equation by the integrating factor method. For , we need to take . Thus, the solution to the initial value problem is Since the coefficient in front of is positive, this means that the account balance here will grow in time.  For the second part, we need to adjust the withdrawal amount to see how the solution changes. If we let be the monthly withdrawal amount, then we have the differential equation The same solution method gives us   If , then the account balance will eventually go to zero. Therefore, we need , and since , we have that For this to be equal to zero, we need Thus, the owner can withdraw $150 per month and keep the account balance positive.    To end this section, we will analyze the example that was presented at the very beginning of the book.      An object falling through the air has its velocity affected by two factors: gravity and a drag force. The velocity downward is increased at a rate of due to gravity, and it is decreased by a rate equation to times the current velocity of the object. If the ball is initially thrown downwards at a speed of , what will the velocity be 10 seconds later?    As described in that first section, we know that the differential equation that we can write for this situation is and that the initial condition for the velocity if . Since we have gravity as a positive 9.8, this means that the downward direction is positive, so the object being thrown downward at means that it is positive. We then need to solve this initial value problem, which we can do using first order linear methods. The equation can be written as which has integrating factor . After multiplying this to both sides and integrating, we get that or that   Using the initial condition, we get that so that and the solution to the initial value problem is Then, to determine the velocity at , we can plug into this formula to get that     All of these examples are based around the same idea of the accumulation equation. We need to determine the quantity that is changing as well as all of the factors that cause it to increase and decrease. These get combined into a differential equation which we can solve in order to analyze the situation and answer whatever questions you want about that physical problem. Keeping these ideas in mind will help you approach a wide variety of problems both in this class as well as future applications in engineering classes and beyond.    Exercises    Suppose there are two lakes located on a stream. Clean water flows into the first lake, then the water from the first lake flows into the second lake, and then water from the second lake flows further downstream. The in and out flow from each lake is 500 liters per hour. The first lake contains 100 thousand liters of water and the second lake contains 200 thousand liters of water. A truck with kg of toxic substance crashes into the first lake. Assume that the water is being continually mixed perfectly by the stream.   Find the concentration of toxic substance as a function of time in both lakes. When will the concentration in the first lake be below [ 0 001 ] kg per liter ?  When will the concentration in the second lake be maximal ?    a)    b) 321.89 hours c) 277.26 hours      states that where is the temperature, is time, is the ambient temperature, and is a constant. Suppose that for some constants and . That is, the ambient temperature oscillates (for example night and day temperatures).   Find the general solution. In the long term, will the initial conditions make much of a difference? Why or why not?    a)  b) No. Only in .      Initially 5 grams of salt are dissolved in 20 liters of water. Brine with concentration of salt 2 grams of salt per liter is added at a rate of 3 liters per minute. The tank is mixed well and is drained at 3 liters per minute. How long does the process have to continue until there are 20 grams of salt in the tank?     min      Initially a tank contains 10 liters of pure water. Brine of unknown (but constant) concentration of salt is flowing in at 1 liter per minute. The water is mixed well and drained at 1 liter per minute. In 20 minutes there are 15 grams of salt in the tank. What is the concentration of salt in the incoming brine?     g\/L      Suppose a water tank is being pumped out at . The water tank starts at L of clean water. Water with toxic substance is flowing into the tank at , with concentration at time . When the tank is half empty, how many grams of toxic substance are in the tank (assuming perfect mixing)?      A 300 gallon well-mixed water tank initially starts with 200 gallons of water and 15 lbs of salt. One stream with salt concentration one pound per gallon flows into the tank at a rate of 3 gallons per minute and water is removed from the well-mixed tank at a rate of 2 gallons per minute.   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , . c) No. Overflows at . d)  This function is defined for all positive .      A 500 gallon well-mixed water tank initially starts with 300 gallons of water and 200 lbs of salt. One stream with salt concentration of flows into the tank at a rate of and water is removed from the well-mixed tank at a rate of .   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , c) No, tank empties at . d)  . is negative for .      A 200 gallon well-mixed water tank initially starts with 150 gallons of water and 50 lbs of salt. One stream with salt concentration of flows into the tank at a rate of and water is removed from the well-mixed tank at a rate of .   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , . c) Yes. Solution tends towards 30. d)  . Matches.      Suppose we have bacteria on a plate and suppose that we are slowly adding a toxic substance such that the rate of growth is slowing down. That is, suppose that . If , find the population at .      A cylindrical water tank has water flowing in at cubic meters per second. Let be the area of the cross section of the tank in meters. Suppose water is flowing from the bottom of the tank at a rate proportional to the height of the water level. Set up the differential equation for , the height of the water, introducing and naming constants that you need. You should also give the units for your constants.      An object in free fall has a velocity that increases at a rate of 32 . Due to drag, the velocity decreases at a rate of 0.1 times the velocity of the object squared, when written in feet per second.   Write a differential equation to model the velocity of this object over time. This equation is autonomous, so draw a phase diagram for this equation and classify all critical points. What will happen to the velocity if the object is dropped at ? What about if the object is thrown downwards at a rate of ?    a)  b)  is asymptotically stable, is unstable. c)  Always tends towards       The number of people in a town that support a given measure decays at a constant rate of people per day. However, the support for the measure can be increased by individuals discussing the issue. This results in an increase of the support at a rate of people per day, where is the number of people who support the measure, and is a constant depending on the way in which the issue is being discussed. Write a differential equation to model this situation, and determine the amount of people who will support the measure long-term if is set to .     , .      Newton’s Law of Procrastination states that the rate at which one accomplishes a chore is proportional to the amount of the chore not yet done . Unbeknownst to Newton, this applies to robots too. A Roomba is attempting to vacuum a house measuring 1000 square feet. When none of the house is clean, the roomba can clean 200 square feet per hour. What makes this problem fun is that there is also a dog. It’s whatever kind of dog you like, take your pick. The dog dirties the house at a constant rate of 50 square feet per hour.   Assume that none of the house is clean at . Write a DE for the number of square feet that are clean as a function of time, and solve for that quantity. How long will it take before the house is half clean? Will it ever be entirely clean? (Explain briefly.)    a)  . b)  for half clean. Never fully clean.      A student has a loan for $50000 with 5% interest. The student makes $300 payments on the loan each month. The rate here is an annual rate, compounded continuously, and the differential equation you write should be in years.   With this setup, how long does it take the student to pay off the loan? How much money does the student pay over this period of time? What is the minimal amount the student should pay each month if they want to pay off the loan within 5 years? How much does the student pay over this period?    a)  years or 285 months. Pays approximately $85,500 b)        A factory pumps 6 tons of sludge per day into a nearby pond. The pond initially contains 100,000 gallons of water, and no sludge. Each day, 3,000 gallons of rain water falls into the pond, and 1,000 gallons per day leave the pond via a river. Assume, for no good reason, that the water leaving the pond has the same concentration of sludge as the pond as a whole. How much sludge will there be in the pond after 150 days?    700 gallons      In this exercise, we compare two different young people and their investment strategies. Both of these people are investing in an account with 7.5% annual rate of return. Person 1 invests $50 a month starting at age 20, and Person 2 invests $100 per month starting at age 30. Write differential equations to model each of these account balances over time, and compute the amount of money in each account at age 50. Who has more money in the account? Who has invested more money? What would person 2 have to invest each month in order for the two balances to be equal at age 50?    Person 1 has more money ( compared to ). Person 2 has invested more ( compared to ). Person 2 needs to invest .      Radioactive decay follows similar rules to interest, where a certain portion of the material decays over time, resulting in an equation of the form for some constant . The half-life of a material is the amount of time that it takes for half of the material to have decayed away. Assume that the half-life of a given substance is minutes. Find a formula for , the coefficient in the decay equation, in terms of .          "
},
{
  "id": "the-accumulation-equation-3",
  "level": "2",
  "url": "modelfirst-section.html#the-accumulation-equation-3",
  "type": "Example",
  "number": "1.10.1",
  "title": ".",
  "body": "    A tank initially contains 70 gallons of water and 5 lbs of salt. A solution with salt concentration 0.2 lbs per gallon flows into the tank at a rate of gal\/min. The tank is well stirred, and water is removed from the tank at a rate of gal\/min. Find the amount of salt in the tank at any time ? What happens as ? Does this make sense?    To solve this problem, we use the accumulation equation on the amount of salt in the tank. In order to compute with this, we recognize that in terms of mass of salt moving into the tank and similarly for the mass of salt leaving the tank.  If we let represent the amount of salt in the tank at any time (which is the goal of the problem), we can write a differential equation for this using the accumulation equation . This gives us that For this problem, we have that The last of these lines comes from the fact that the tank is well stirred or well-mixed. This implies that the concentration of salt in the water leaving the tank is the same as the concentration in the tank, which we can compute as . In this case, since the flow rate in and out are both 3 gal\/min, the volume of water in the tank is fixed at gallons, so we can put this in the equation.  Therefore, our equation becomes We can rewrite this equation as which we recognize as a first order linear equation. We can then solve this using the method of integrating factors. Our factor is which we can multiply on both sides of the equation to obtain The left side of this is a product rule derivative, so we can integrate both sides to obtain We can then isolate to get our general solution as Our initial condition tells us that . Plugging this in gives that so the solution to the initial value problem, and thus our calculation for the amount of salt in the tank at any time , is   As , we see that the exponential term goes to zero. This leaves us with 14 lbs of salt in the tank after a long time. This makes some sense because this would give us a concentration of lb\/gal, and that was exactly the concentration of the in-flow stream. It makes sense that after a long time of mixing and removing water from the tank, the concentration of the tank would match that of the incoming stream.   "
},
{
  "id": "the-accumulation-equation-6",
  "level": "2",
  "url": "modelfirst-section.html#the-accumulation-equation-6",
  "type": "Example",
  "number": "1.10.2",
  "title": ".",
  "body": "    A 100 liter tank contains 10 kilograms of salt dissolved in 60 liters of water. Solution of water and salt (brine) with concentration of 0.1 kilograms per liter is flowing in at the rate of 5 liters a minute. The solution in the tank is well stirred and flows out at a rate of 3 liters a minute. How much salt is in the tank when the tank is full?    We can again use the accumulation equation to write In this example, we have Our equation is, therefore, Or in the form    Let us solve. The integrating factor is   We multiply both sides of the equation to get    3.25in  We need to find . We know that at , . So or   We are interested in when the tank is full. The tank is full when , or when . So See for the graph of over .  The concentration when the tank is full is approximately , and we started with or .   "
},
{
  "id": "the-accumulation-equation-9",
  "level": "2",
  "url": "modelfirst-section.html#the-accumulation-equation-9",
  "type": "Example",
  "number": "1.10.3",
  "title": ".",
  "body": "    A bank account with an interest rate of per year, compounded continuously, starts with a balance of $30000. The owner of the account withdraws $50 from the account each month. Find and solve a differential equation for the account balance over time. What is the largest amount that the owner could withdraw each month without the account eventually reaching $0?    We will use the function to model the balance of the account over time, where is in years . Since the owner withdraws $50 per month, this means that they withdraw $600 over the course of the year. This means that the differential equation we want is We can solve this equation by the integrating factor method. For , we need to take . Thus, the solution to the initial value problem is Since the coefficient in front of is positive, this means that the account balance here will grow in time.  For the second part, we need to adjust the withdrawal amount to see how the solution changes. If we let be the monthly withdrawal amount, then we have the differential equation The same solution method gives us   If , then the account balance will eventually go to zero. Therefore, we need , and since , we have that For this to be equal to zero, we need Thus, the owner can withdraw $150 per month and keep the account balance positive.   "
},
{
  "id": "the-accumulation-equation-11",
  "level": "2",
  "url": "modelfirst-section.html#the-accumulation-equation-11",
  "type": "Example",
  "number": "1.10.4",
  "title": ".",
  "body": "    An object falling through the air has its velocity affected by two factors: gravity and a drag force. The velocity downward is increased at a rate of due to gravity, and it is decreased by a rate equation to times the current velocity of the object. If the ball is initially thrown downwards at a speed of , what will the velocity be 10 seconds later?    As described in that first section, we know that the differential equation that we can write for this situation is and that the initial condition for the velocity if . Since we have gravity as a positive 9.8, this means that the downward direction is positive, so the object being thrown downward at means that it is positive. We then need to solve this initial value problem, which we can do using first order linear methods. The equation can be written as which has integrating factor . After multiplying this to both sides and integrating, we get that or that   Using the initial condition, we get that so that and the solution to the initial value problem is Then, to determine the velocity at , we can plug into this formula to get that    "
},
{
  "id": "modelfirst-section-5-2",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-2",
  "type": "Exercise",
  "number": "1.10.3.1",
  "title": "",
  "body": "  Suppose there are two lakes located on a stream. Clean water flows into the first lake, then the water from the first lake flows into the second lake, and then water from the second lake flows further downstream. The in and out flow from each lake is 500 liters per hour. The first lake contains 100 thousand liters of water and the second lake contains 200 thousand liters of water. A truck with kg of toxic substance crashes into the first lake. Assume that the water is being continually mixed perfectly by the stream.   Find the concentration of toxic substance as a function of time in both lakes. When will the concentration in the first lake be below [ 0 001 ] kg per liter ?  When will the concentration in the second lake be maximal ?    a)    b) 321.89 hours c) 277.26 hours   "
},
{
  "id": "modelfirst-section-5-3",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-3",
  "type": "Exercise",
  "number": "1.10.3.2",
  "title": "",
  "body": "  states that where is the temperature, is time, is the ambient temperature, and is a constant. Suppose that for some constants and . That is, the ambient temperature oscillates (for example night and day temperatures).   Find the general solution. In the long term, will the initial conditions make much of a difference? Why or why not?    a)  b) No. Only in .   "
},
{
  "id": "modelfirst-section-5-4",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-4",
  "type": "Exercise",
  "number": "1.10.3.3",
  "title": "",
  "body": "  Initially 5 grams of salt are dissolved in 20 liters of water. Brine with concentration of salt 2 grams of salt per liter is added at a rate of 3 liters per minute. The tank is mixed well and is drained at 3 liters per minute. How long does the process have to continue until there are 20 grams of salt in the tank?     min   "
},
{
  "id": "modelfirst-section-5-5",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-5",
  "type": "Exercise",
  "number": "1.10.3.4",
  "title": "",
  "body": "  Initially a tank contains 10 liters of pure water. Brine of unknown (but constant) concentration of salt is flowing in at 1 liter per minute. The water is mixed well and drained at 1 liter per minute. In 20 minutes there are 15 grams of salt in the tank. What is the concentration of salt in the incoming brine?     g\/L   "
},
{
  "id": "modelfirst-section-5-6",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-6",
  "type": "Exercise",
  "number": "1.10.3.5",
  "title": "",
  "body": "  Suppose a water tank is being pumped out at . The water tank starts at L of clean water. Water with toxic substance is flowing into the tank at , with concentration at time . When the tank is half empty, how many grams of toxic substance are in the tank (assuming perfect mixing)?   "
},
{
  "id": "modelfirst-section-5-7",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-7",
  "type": "Exercise",
  "number": "1.10.3.6",
  "title": "",
  "body": "  A 300 gallon well-mixed water tank initially starts with 200 gallons of water and 15 lbs of salt. One stream with salt concentration one pound per gallon flows into the tank at a rate of 3 gallons per minute and water is removed from the well-mixed tank at a rate of 2 gallons per minute.   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , . c) No. Overflows at . d)  This function is defined for all positive .   "
},
{
  "id": "modelfirst-section-5-8",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-8",
  "type": "Exercise",
  "number": "1.10.3.7",
  "title": "",
  "body": "  A 500 gallon well-mixed water tank initially starts with 300 gallons of water and 200 lbs of salt. One stream with salt concentration of flows into the tank at a rate of and water is removed from the well-mixed tank at a rate of .   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , c) No, tank empties at . d)  . is negative for .   "
},
{
  "id": "modelfirst-section-5-9",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-9",
  "type": "Exercise",
  "number": "1.10.3.8",
  "title": "",
  "body": "  A 200 gallon well-mixed water tank initially starts with 150 gallons of water and 50 lbs of salt. One stream with salt concentration of flows into the tank at a rate of and water is removed from the well-mixed tank at a rate of .   Write and solve an initial value problem for the volume of water in the tank at any time . Set up an initial value problem for the amount of salt in the tank at any time . You do not need to solve it (yet), but should make sure to state it fully. Is the solution to this initial value problem a valid representation of the physical model for all times ? If so, use the information in the equation to determine the long-time behavior of the solution. If not, explain why, determine the time when the representation breaks down, and what happens at that point in time. Solve the initial value problem above and compare this to your answer to the previous part.    a)  , . . b)  , . c) Yes. Solution tends towards 30. d)  . Matches.   "
},
{
  "id": "modelfirst-section-5-10",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-10",
  "type": "Exercise",
  "number": "1.10.3.9",
  "title": "",
  "body": "  Suppose we have bacteria on a plate and suppose that we are slowly adding a toxic substance such that the rate of growth is slowing down. That is, suppose that . If , find the population at .   "
},
{
  "id": "modelfirst-section-5-11",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-11",
  "type": "Exercise",
  "number": "1.10.3.10",
  "title": "",
  "body": "  A cylindrical water tank has water flowing in at cubic meters per second. Let be the area of the cross section of the tank in meters. Suppose water is flowing from the bottom of the tank at a rate proportional to the height of the water level. Set up the differential equation for , the height of the water, introducing and naming constants that you need. You should also give the units for your constants.   "
},
{
  "id": "modelfirst-section-5-12",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-12",
  "type": "Exercise",
  "number": "1.10.3.11",
  "title": "",
  "body": "  An object in free fall has a velocity that increases at a rate of 32 . Due to drag, the velocity decreases at a rate of 0.1 times the velocity of the object squared, when written in feet per second.   Write a differential equation to model the velocity of this object over time. This equation is autonomous, so draw a phase diagram for this equation and classify all critical points. What will happen to the velocity if the object is dropped at ? What about if the object is thrown downwards at a rate of ?    a)  b)  is asymptotically stable, is unstable. c)  Always tends towards    "
},
{
  "id": "modelfirst-section-5-13",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-13",
  "type": "Exercise",
  "number": "1.10.3.12",
  "title": "",
  "body": "  The number of people in a town that support a given measure decays at a constant rate of people per day. However, the support for the measure can be increased by individuals discussing the issue. This results in an increase of the support at a rate of people per day, where is the number of people who support the measure, and is a constant depending on the way in which the issue is being discussed. Write a differential equation to model this situation, and determine the amount of people who will support the measure long-term if is set to .     , .   "
},
{
  "id": "modelfirst-section-5-14",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-14",
  "type": "Exercise",
  "number": "1.10.3.13",
  "title": "",
  "body": "  Newton’s Law of Procrastination states that the rate at which one accomplishes a chore is proportional to the amount of the chore not yet done . Unbeknownst to Newton, this applies to robots too. A Roomba is attempting to vacuum a house measuring 1000 square feet. When none of the house is clean, the roomba can clean 200 square feet per hour. What makes this problem fun is that there is also a dog. It’s whatever kind of dog you like, take your pick. The dog dirties the house at a constant rate of 50 square feet per hour.   Assume that none of the house is clean at . Write a DE for the number of square feet that are clean as a function of time, and solve for that quantity. How long will it take before the house is half clean? Will it ever be entirely clean? (Explain briefly.)    a)  . b)  for half clean. Never fully clean.   "
},
{
  "id": "modelfirst-section-5-15",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-15",
  "type": "Exercise",
  "number": "1.10.3.14",
  "title": "",
  "body": "  A student has a loan for $50000 with 5% interest. The student makes $300 payments on the loan each month. The rate here is an annual rate, compounded continuously, and the differential equation you write should be in years.   With this setup, how long does it take the student to pay off the loan? How much money does the student pay over this period of time? What is the minimal amount the student should pay each month if they want to pay off the loan within 5 years? How much does the student pay over this period?    a)  years or 285 months. Pays approximately $85,500 b)     "
},
{
  "id": "modelfirst-section-5-16",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-16",
  "type": "Exercise",
  "number": "1.10.3.15",
  "title": "",
  "body": "  A factory pumps 6 tons of sludge per day into a nearby pond. The pond initially contains 100,000 gallons of water, and no sludge. Each day, 3,000 gallons of rain water falls into the pond, and 1,000 gallons per day leave the pond via a river. Assume, for no good reason, that the water leaving the pond has the same concentration of sludge as the pond as a whole. How much sludge will there be in the pond after 150 days?    700 gallons   "
},
{
  "id": "modelfirst-section-5-17",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-17",
  "type": "Exercise",
  "number": "1.10.3.16",
  "title": "",
  "body": "  In this exercise, we compare two different young people and their investment strategies. Both of these people are investing in an account with 7.5% annual rate of return. Person 1 invests $50 a month starting at age 20, and Person 2 invests $100 per month starting at age 30. Write differential equations to model each of these account balances over time, and compute the amount of money in each account at age 50. Who has more money in the account? Who has invested more money? What would person 2 have to invest each month in order for the two balances to be equal at age 50?    Person 1 has more money ( compared to ). Person 2 has invested more ( compared to ). Person 2 needs to invest .   "
},
{
  "id": "modelfirst-section-5-18",
  "level": "2",
  "url": "modelfirst-section.html#modelfirst-section-5-18",
  "type": "Exercise",
  "number": "1.10.3.17",
  "title": "",
  "body": "  Radioactive decay follows similar rules to interest, where a certain portion of the material decays over time, resulting in an equation of the form for some constant . The half-life of a material is the amount of time that it takes for half of the material to have decayed away. Assume that the half-life of a given substance is minutes. Find a formula for , the coefficient in the decay equation, in terms of .        "
},
{
  "id": "modelfirstestim-section",
  "level": "1",
  "url": "modelfirstestim-section.html",
  "type": "Section",
  "number": "1.11",
  "title": "Modeling and Parameter Estimation",
  "body": " Modeling and Parameter Estimation  One of the most common ways that the mathematical modeling structure can be used to analyze physical problems is the idea of parameter estimation. The situation is that we have physical principles that give rise to a differential equation that defines how a physical system should behave, but there are one or more constants in the problem that we do not know. Two simpler examples of this are Newton’s Law of Cooling which models the temperature of an object in an environment of temperature over time, and velocity affected by drag modeling the velocity of a falling object where the drag force is proportional to the square of the velocity. In both of these cases, the models are well established, but for a given object, we likely do not know the or values in the problem. These are these of the problem, and would be determined by the shape and structure of the objects, the material that it is made of, and many other factors, so it could be hard to figure out what they are in advance. How can we find these values? We can use data from the actual physical problem to try to estimate these parameters.  The easier version of this is to use a single value at a later time to calculate the constant.      An object that obeys Newton’s Law of Cooling is placed in an environment at a constant temperature of C. The object starts at C, and after 10 minutes, it has reached a temperature of C. Find a function for the temperature as a function of time.    Based on Newton’s Law of Cooling, we know that the temperature satisfies the differential equation with initial condition , but we do not know the value of . In order to work this out, we should solve the differential equation with unknown constant , then figure out which value of gives us the appropriate temperature after 10 minutes. This is a first order linear equation, which can be rewritten as   The integrating factor we need is , which turns the equation into Integrating both sides and solving for gives   To satisfy the initial condition, we need that , or . Thus, our solution, still with an unknown constant , is   To determine the value of , we need to utilize the other given piece of information: that . Plugging this in gives that which we can solve for using logarithms. This will give that   Finally, we can plug that constant into our equation to get the solution for the temperature at any time value,     This method works great if we have the exact measurement from the object at one point in time. However, if the measurements at multiple points in time are known, and if the data is not likely to be exact, then a different method is more applicable. The idea is that we want to minimize the error between our predicted result and the physical data that we gather. The method used to minimize the error is the Least Squared Error method.  Assume that we want to do this for the drag coefficient problem, where we do not know, and want to estimate, the value of . For this method, the data that we gather is a set of velocity values that are obtained at times . For any given value of , we can solve, either numerically or analytically, the solution to the given differential equation with that value of . From this solution, we can compute , the value of this solution at each of the times that we gathered data originally. Now, we want to compute the error that we made in choosing this parameter . This is computed by which is the sum of the squares of the differences between the gathered data and the predicted solution. In order to find the best possible value of , we want to minimze this error by choosing different values of  and whatever value of gives us this minimum is the optimal choice for that parameter.  The function that we want to minimize here is usually a very complicated function, and we may not even be able to solve the differential equation analytically for any . Thus, computers are used most often here to solve these types of problems.      An object is falling under the force of gravity, and has a drag component that is proportional to the square of the velocity. Data is gathered on the falling object, and the velocity at a variety of times are given in .    Data for estimating drag coefficient using least squared errors.    t (s)  v (m\/s)    0  0    0.1  0.9797    0.3  2.8625    0.5  4.4750    0.8  6.3828    0.9  6.8360    1.0  7.0334    1.5  8.1612     Use this data to estimate the coefficient of proportionality on the drag term in the equation     To solve this problem, we will use the least squared error method implemented in MATLAB. The code we need for this is the following, which makes use of the Optimization Toolbox.   global tVals global vVals  tVals = [0, 0.1, 0.3, 0.5, 0.8, 0.9, 1.0, 1.5]; vVals = [0,0.9797,2.8625,4.4750,6.3828,6.8360,7.0334,8.1612];  [aVal, errVal] = fminbnd(@(a) EstSqError(a), 0, 4)  This bit of code inputs the necessary values and uses the fminbnd function to find the minimum of the error function on a defined interval. These problems need to be done on a bounded interval, but in most physical situations there is some reasonable window for where the parameter could be. The rest of the code is the definition of the EstSqError function.   function err = EstSqError(al)  global tVals global vVals  fun = @(t,v) 9.8 - al.*v.^2; sol = ode45(fun, [0,3], 0); vTest = deval(sol, tVals);  err = sum((vVals - vTest).^2) end  The main point of this code is that it takes in a value of , over which we are trying to minimize, it numerically solves the differential equation with that value of over a desired range of values, and then compares the inputted vVals with the generated vTest array, computing the sum of squared errors, and returning the error value.  Running this code results in an value of , with an error of . That means that, based on this data, the best approximation to is .    Note that in the above example, the total error was not zero, and doesn’t actually match the coefficient used to generate the data, which was . This is because noise was added to the data before trying to compute the drag coefficient. In a real world problem, noise would not be added, but a similar effect would arise from slightly inaccurate measurements or round-off errors in the data. While we may not have found the constant exactly, we got really close to it, and could use this as a starting point for further experiments and data validation.   Exercises    Bob is getting coffee from a restaurant and knows that the temperature of the coffee will follow Newton’s Law of Cooling, which says that where is the ambient temperature and is a constant depending on the object and geometry. His car is held at a constant 20 C, and when he receives the coffee, he measures the temperature to be 90 C. Two minutes later, the temperature is 81 C.   Use these two points of data to determine the value of for this coffee. Bob only wants to drink his coffee once it reaches 65 C. How long does he have to wait for this to happen? If the coffee is too cold for Bob’s taste once it reaches 35 C, how long is the acceptable window for Bob to drink his coffee?    a)  0.06681 b)  6.42 min c)  16 min.      Assume that a falling object has a velocity (in meters per second) that obeys the differential equation where represents the drag coefficient of the object.   Solve this differential equation with initial condition to get a solution that depends on . Assume that you drop an object from a height of 10 meters and it hits the ground after seconds. What is the value of here? (Note: You solved for in the previous part, and now you need to get to position. What does that require?) Assume that a second object hits the ground in 6 seconds. How does this change the value of ?    a)  b) 2.94 c) 5.88      A restaurant is trying to analyze the to-go coffee cups that it uses in order to best serve their customers. They assume that the coffee follows Newton’s Law of Cooling and place it in a room with ambient temperature 22 C. They record the following data for the temperature of the coffee as a function of time.      t (min)  T ( C)    0  80    0.5  74    1.1  67    1.7  61    2.3  56      Use code to determine the best-fit value of for this data. The restaurant determines that to avoid any potential legal issues, the coffee can be no warmer than 60 C when it is served. If the coffee comes out of the machine at 90 , how long do they have to wait before they can serve the coffee?    a)  b)  min      Assume that an object falling has a velocity that follows the differential equation where the velocity is in and represents the drag coefficient. During a physics experiment, a student measures data for the velocity of a falling object over time given in the table below.  Use this data (and code) to estimate the value of for this object.         t (s)  v (m\/s)    0  0    0.1  1.0    0.2  1.9    0.4  3.6    0.6  5.2    0.9  6.8    1.1  7.4    1.3  7.9    1.5  8.2    1.8  8.5    2.1  8.8          t (d)  P (thousands)    0  50    7  60    14  70    28  97    37  117    50  148    78  220    100  268       Assume that a species of fish in a lake has a population that is modeled by the differential equation where , , and are parameters, representing the growth rate, the carrying capacity, and the harvesting rate, and the population is in thousands., with given in years. From previous studies, you know that the best value of is . After studying the population over a period of time, you get the data given above.   Your friend tells you that in a previous study, he found that the value of for this particular lake is . Use code to determine the best value of for this situation. Note that the equation expects in years, but the data is given in days. Search for in the range . That answer doesn’t look great. Plot the solution with these parameters along with the data and compare them. The fit does not look great, so maybe your friend’s value was not quite right. Run code to find best values for and simultaneously. Use the range for both and .    a)  c)  , . (The base data was , .)     "
},
{
  "id": "modelfirstestim-section-4",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-4",
  "type": "Example",
  "number": "1.11.1",
  "title": ".",
  "body": "    An object that obeys Newton’s Law of Cooling is placed in an environment at a constant temperature of C. The object starts at C, and after 10 minutes, it has reached a temperature of C. Find a function for the temperature as a function of time.    Based on Newton’s Law of Cooling, we know that the temperature satisfies the differential equation with initial condition , but we do not know the value of . In order to work this out, we should solve the differential equation with unknown constant , then figure out which value of gives us the appropriate temperature after 10 minutes. This is a first order linear equation, which can be rewritten as   The integrating factor we need is , which turns the equation into Integrating both sides and solving for gives   To satisfy the initial condition, we need that , or . Thus, our solution, still with an unknown constant , is   To determine the value of , we need to utilize the other given piece of information: that . Plugging this in gives that which we can solve for using logarithms. This will give that   Finally, we can plug that constant into our equation to get the solution for the temperature at any time value,    "
},
{
  "id": "modelfirstestim-section-8",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-8",
  "type": "Example",
  "number": "1.11.2",
  "title": ".",
  "body": "    An object is falling under the force of gravity, and has a drag component that is proportional to the square of the velocity. Data is gathered on the falling object, and the velocity at a variety of times are given in .    Data for estimating drag coefficient using least squared errors.    t (s)  v (m\/s)    0  0    0.1  0.9797    0.3  2.8625    0.5  4.4750    0.8  6.3828    0.9  6.8360    1.0  7.0334    1.5  8.1612     Use this data to estimate the coefficient of proportionality on the drag term in the equation     To solve this problem, we will use the least squared error method implemented in MATLAB. The code we need for this is the following, which makes use of the Optimization Toolbox.   global tVals global vVals  tVals = [0, 0.1, 0.3, 0.5, 0.8, 0.9, 1.0, 1.5]; vVals = [0,0.9797,2.8625,4.4750,6.3828,6.8360,7.0334,8.1612];  [aVal, errVal] = fminbnd(@(a) EstSqError(a), 0, 4)  This bit of code inputs the necessary values and uses the fminbnd function to find the minimum of the error function on a defined interval. These problems need to be done on a bounded interval, but in most physical situations there is some reasonable window for where the parameter could be. The rest of the code is the definition of the EstSqError function.   function err = EstSqError(al)  global tVals global vVals  fun = @(t,v) 9.8 - al.*v.^2; sol = ode45(fun, [0,3], 0); vTest = deval(sol, tVals);  err = sum((vVals - vTest).^2) end  The main point of this code is that it takes in a value of , over which we are trying to minimize, it numerically solves the differential equation with that value of over a desired range of values, and then compares the inputted vVals with the generated vTest array, computing the sum of squared errors, and returning the error value.  Running this code results in an value of , with an error of . That means that, based on this data, the best approximation to is .   "
},
{
  "id": "modelfirstestim-section-10-2",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-2",
  "type": "Exercise",
  "number": "1.11.1",
  "title": "",
  "body": "  Bob is getting coffee from a restaurant and knows that the temperature of the coffee will follow Newton’s Law of Cooling, which says that where is the ambient temperature and is a constant depending on the object and geometry. His car is held at a constant 20 C, and when he receives the coffee, he measures the temperature to be 90 C. Two minutes later, the temperature is 81 C.   Use these two points of data to determine the value of for this coffee. Bob only wants to drink his coffee once it reaches 65 C. How long does he have to wait for this to happen? If the coffee is too cold for Bob’s taste once it reaches 35 C, how long is the acceptable window for Bob to drink his coffee?    a)  0.06681 b)  6.42 min c)  16 min.   "
},
{
  "id": "modelfirstestim-section-10-3",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-3",
  "type": "Exercise",
  "number": "1.11.2",
  "title": "",
  "body": "  Assume that a falling object has a velocity (in meters per second) that obeys the differential equation where represents the drag coefficient of the object.   Solve this differential equation with initial condition to get a solution that depends on . Assume that you drop an object from a height of 10 meters and it hits the ground after seconds. What is the value of here? (Note: You solved for in the previous part, and now you need to get to position. What does that require?) Assume that a second object hits the ground in 6 seconds. How does this change the value of ?    a)  b) 2.94 c) 5.88   "
},
{
  "id": "modelfirstestim-section-10-4",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-4",
  "type": "Exercise",
  "number": "1.11.3",
  "title": "",
  "body": "  A restaurant is trying to analyze the to-go coffee cups that it uses in order to best serve their customers. They assume that the coffee follows Newton’s Law of Cooling and place it in a room with ambient temperature 22 C. They record the following data for the temperature of the coffee as a function of time.      t (min)  T ( C)    0  80    0.5  74    1.1  67    1.7  61    2.3  56      Use code to determine the best-fit value of for this data. The restaurant determines that to avoid any potential legal issues, the coffee can be no warmer than 60 C when it is served. If the coffee comes out of the machine at 90 , how long do they have to wait before they can serve the coffee?    a)  b)  min   "
},
{
  "id": "modelfirstestim-section-10-5",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-5",
  "type": "Exercise",
  "number": "1.11.4",
  "title": "",
  "body": "  Assume that an object falling has a velocity that follows the differential equation where the velocity is in and represents the drag coefficient. During a physics experiment, a student measures data for the velocity of a falling object over time given in the table below.  Use this data (and code) to estimate the value of for this object.   "
},
{
  "id": "modelfirstestim-section-10-6",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-6",
  "type": "Table",
  "number": "1.11.5",
  "title": "",
  "body": "    t (s)  v (m\/s)    0  0    0.1  1.0    0.2  1.9    0.4  3.6    0.6  5.2    0.9  6.8    1.1  7.4    1.3  7.9    1.5  8.2    1.8  8.5    2.1  8.8    "
},
{
  "id": "modelfirstestim-section-10-7",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-7",
  "type": "Table",
  "number": "1.11.6",
  "title": "",
  "body": "    t (d)  P (thousands)    0  50    7  60    14  70    28  97    37  117    50  148    78  220    100  268    "
},
{
  "id": "modelfirstestim-section-10-8",
  "level": "2",
  "url": "modelfirstestim-section.html#modelfirstestim-section-10-8",
  "type": "Exercise",
  "number": "1.11.5",
  "title": "",
  "body": "  Assume that a species of fish in a lake has a population that is modeled by the differential equation where , , and are parameters, representing the growth rate, the carrying capacity, and the harvesting rate, and the population is in thousands., with given in years. From previous studies, you know that the best value of is . After studying the population over a period of time, you get the data given above.   Your friend tells you that in a previous study, he found that the value of for this particular lake is . Use code to determine the best value of for this situation. Note that the equation expects in years, but the data is given in days. Search for in the range . That answer doesn’t look great. Plot the solution with these parameters along with the data and compare them. The fit does not look great, so maybe your friend’s value was not quite right. Run code to find best values for and simultaneously. Use the range for both and .    a)  c)  , . (The base data was , .)   "
},
{
  "id": "substitution-section",
  "level": "1",
  "url": "substitution-section.html",
  "type": "Section",
  "number": "1.12",
  "title": "Substitution",
  "body": " Substitution  The equation is neither separable nor linear. What can we do? One technique that worked for helping us in evaluating integrals was substitution, or change of variables. For example, in order to evaluate the integral we can do so by defining so that , and then evaluate the integral as after we have plugged our original function back in.  We can try to do the same thing here, and be careful with how we set things up. Our general strategy will be to pick a new dependent variable, find a differential equation that this new variable solves (which will come from the old equation), solve that equation, then convert back to the original variable. We will take as our new dependent variable here, which is as function . Let us try which is the inside function (it’s inside the square) of our example. In order to get to a differential equation that satisfies, we need to figure out in terms of , and . We differentiate (in ) to obtain . So . We plug this into the equation to get In other words, . Such an equation we know how to solve by separating variables: So for some constant . Note that and are also solutions; they are the in this problem. (This solution method requires partial fractions; for a review of that topic, see .)  Now we need to to obtain and also the two solutions or , and or . We solve the first equation for . Note that gives , but no value of gives the solution .  Substitution in differential equations is applied in much the same way that it is applied in calculus. You guess. Several different substitutions might work. There are some general patterns to look for. We summarize a few of these in a table.       When you see  Try substituting                         Usually you try to substitute in the part of the equation with the hopes of simplifying it. The table above is just a rule of thumb. You might have to modify your guesses. If a substitution does not work (it does not make the equation any simpler), try a different one.   Bernoulli equations  There are some forms of equations where there is a general rule for substitution that always works. One such example is the so-called   There are several things called Bernoulli equations, this is just one of them. The Bernoullis were a prominent Swiss family of mathematicians. These particular equations are named for Jacob Bernoulli (1654–1705). : This equation looks a lot like a linear equation except for the . If or , then the equation is linear and we can solve it. Otherwise, the substitution transforms the Bernoulli equation into a linear equation. Note that need not be an integer.      Find the general solution of     This equation fits the Bernoulli equation structure with and . Since there is a on the right-hand side, we take and make the substitution . With this, we see that or . Plugging this into the equation gives This last equation is now a first order linear equation, so we can solve it. The integrating factor we are looking for is which results in the euation The left-hand side is , so we can integrate both sides to get or, solving for , However, our original equation was for , not . Using the fact that , we can solve for as , giving as the general solution to this equation.    Even if we need to use integrals to write out the solution to these Bernoulli equations, we can still use the substitution method and solve back out for the desired solution at the end.      Solve     First, the equation is Bernoulli ( and ). We substitute In other words, . So and finally The equation is now linear. We can use the integrating factor method. In particular, we use formula . Let us assume that so . This assumption is OK, as our initial condition is . Let us compute the integrating factor. Here from formula is . We now plug in to  The integral in this expression is not possible to find in closed form. As we said before, it is perfectly fine to have a definite integral in our solution. Now       Homogeneous equations  Another type of equations we can solve by substitution are the so-called homogeneous equations . Note that this is not the same as a homogeneous linear equation. These equations do not have to be linear, and are solved in a very different way. Suppose that we can write the differential equation as Here we try the substitutions We note that the equation is transformed into Hence an implicit solution is       Solve     We put the equation into the form . We substitute to get the separable equation which has a solution We unsubstitute We want , so Thus and the solution we are looking for is       Exercises  Hint: Answers need not always be in closed form.    Solve , with .           Solve , .      Solve , with .           Solve , .      Solve , with .           Solve .           Solve with .           Solve .           Solve , .      Solve . (Hint: What is )           Solve .           Solve , with .           Solve .      Consider the DE    Explain why is not a linear equation. Use a Bernoulli substitution to solve .    a)  There is a term b)       "
},
{
  "id": "substitution-section-6",
  "level": "2",
  "url": "substitution-section.html#substitution-section-6",
  "type": "Table",
  "number": "1.12.1",
  "title": "",
  "body": "    When you see  Try substituting                        "
},
{
  "id": "bernoulli-equations-3",
  "level": "2",
  "url": "substitution-section.html#bernoulli-equations-3",
  "type": "Example",
  "number": "1.12.2",
  "title": ".",
  "body": "    Find the general solution of     This equation fits the Bernoulli equation structure with and . Since there is a on the right-hand side, we take and make the substitution . With this, we see that or . Plugging this into the equation gives This last equation is now a first order linear equation, so we can solve it. The integrating factor we are looking for is which results in the euation The left-hand side is , so we can integrate both sides to get or, solving for , However, our original equation was for , not . Using the fact that , we can solve for as , giving as the general solution to this equation.   "
},
{
  "id": "bernoulli-equations-5",
  "level": "2",
  "url": "substitution-section.html#bernoulli-equations-5",
  "type": "Example",
  "number": "1.12.3",
  "title": ".",
  "body": "    Solve     First, the equation is Bernoulli ( and ). We substitute In other words, . So and finally The equation is now linear. We can use the integrating factor method. In particular, we use formula . Let us assume that so . This assumption is OK, as our initial condition is . Let us compute the integrating factor. Here from formula is . We now plug in to  The integral in this expression is not possible to find in closed form. As we said before, it is perfectly fine to have a definite integral in our solution. Now    "
},
{
  "id": "homogeneous-equations-3",
  "level": "2",
  "url": "substitution-section.html#homogeneous-equations-3",
  "type": "Example",
  "number": "1.12.4",
  "title": ".",
  "body": "    Solve     We put the equation into the form . We substitute to get the separable equation which has a solution We unsubstitute We want , so Thus and the solution we are looking for is    "
},
{
  "id": "substitution-section-10-3",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-3",
  "type": "Exercise",
  "number": "1.12.3.1",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "substitution-section-10-4",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-4",
  "type": "Exercise",
  "number": "1.12.3.2",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "substitution-section-10-5",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-5",
  "type": "Exercise",
  "number": "1.12.3.3",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "substitution-section-10-6",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-6",
  "type": "Exercise",
  "number": "1.12.3.4",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "substitution-section-10-7",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-7",
  "type": "Exercise",
  "number": "1.12.3.5",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "substitution-section-10-8",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-8",
  "type": "Exercise",
  "number": "1.12.3.6",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "substitution-section-10-9",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-9",
  "type": "Exercise",
  "number": "1.12.3.7",
  "title": "",
  "body": "  Solve with .        "
},
{
  "id": "substitution-section-10-10",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-10",
  "type": "Exercise",
  "number": "1.12.3.8",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "substitution-section-10-11",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-11",
  "type": "Exercise",
  "number": "1.12.3.9",
  "title": "",
  "body": "  Solve , .   "
},
{
  "id": "substitution-section-10-12",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-12",
  "type": "Exercise",
  "number": "1.12.3.10",
  "title": "",
  "body": "  Solve . (Hint: What is )        "
},
{
  "id": "substitution-section-10-13",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-13",
  "type": "Exercise",
  "number": "1.12.3.11",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "substitution-section-10-14",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-14",
  "type": "Exercise",
  "number": "1.12.3.12",
  "title": "",
  "body": "  Solve , with .        "
},
{
  "id": "substitution-section-10-15",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-15",
  "type": "Exercise",
  "number": "1.12.3.13",
  "title": "",
  "body": "  Solve .   "
},
{
  "id": "substitution-section-10-16",
  "level": "2",
  "url": "substitution-section.html#substitution-section-10-16",
  "type": "Exercise",
  "number": "1.12.3.14",
  "title": "",
  "body": "  Consider the DE    Explain why is not a linear equation. Use a Bernoulli substitution to solve .    a)  There is a term b)     "
},
{
  "id": "solinear-section",
  "level": "1",
  "url": "solinear-section.html",
  "type": "Section",
  "number": "2.1",
  "title": "Second order linear ODEs",
  "body": " Second order linear ODEs   SOLin  The general second order ordinary differential equation is of the form for an arbitrary function of three variables. As with first order equations, if the function is not in a nice or simple form, there really isn’t a hope to find a solution for this. For second order equations, we need to be even more specific about the structure of these equations in order to find solutions than we did for first order.   The general is of the form This equation can be written in standard form by dividing throuhg by to get where , , and .  The word linear means that the equation contains no powers nor functions of , , and . In the special case when , we have a so-called homogeneous equation We have already seen some second order linear homogeneous equations.   With the examples above, we were able to find solutions. However, notice that these equations don’t have functions of as coefficients of the term. This means they are equations. It turns out that one of the few ways we can have a guaranteed method for finding solutions to these equation is if they have constant coefficients. For first order, we had a method for every linear equation, but for second order, we only have a formulaic method for constant coefficient and homogeneous linear equations.  If we know two solutions of a linear homogeneous equation, we know many more of them.   Superposition Suppose and are two solutions of the homogeneous equation . Then also solves for arbitrary constants and .  That is, we can add solutions together and multiply them by constants to obtain new and different solutions. We call the expression a of and . Let us prove this theorem; the proof is very enlightening and illustrates how linear equations work.   Proof: Let . Then   The proof becomes even simpler to state if we use the operator notation. An is an object that eats functions and spits out functions (kind of like what a function is, but a function eats numbers and spits out numbers). Define the operator by The differential equation now becomes . The operator (and the equation) being linear means that . The proof above becomes     This fact does not hold if the equation is non-linear. Show that and solve but does not.    Two different solutions to the second equation are and . Let us remind ourselves of the definition, and . Therefore, these are solutions by superposition as they are linear combinations of the two exponential solutions.    The functions and are sometimes more convenient to use than the exponential. Let us review some of their properties:     Derive these properties using the definitions of and in terms of exponentials.      Intial Value Problems  For first order equations, a lot of problems were stated as Initial Value Problems, containing both a differential equation and an initial condition of the value of at some point . What do these initial condition(s) look like for second order equations?      Solve the second-order differential equation     We can attempt to find a solution to this problem by integrating both sides twice. A first integration gives and a second integration leads to for any two constants and . We can check that differentiating this function twice gives us back the function that we wanted.    In the previous example, we ended up with two unknown constants in our answer, whereas for first order equations, we only had one. In order to specify these two constants, we will need to give two additional facts about this function. This could be the value of the function at two points, but more traditionally, it is given as the value of the function and its first derivative at a value . Fairly often, this value is , but it could be any other number.      Solve the initial value problem     We previously found our solution with unknown constants as and also found that To find the values of and , we need to plug in the two initial conditions into their corresponding functions. The initial value of the derivative gives that so that we have . We can then use the initial value of , along with this value, to conclude that Solving this out gives that . Putting these constants in gives that the solution to the initial value problem is     For first-order equations, we have theorems that told us that solutions existed and were unique, at least on small intervals. Linear first-order equations in particular had a very nice existence and uniqueness theorem (Theorem ), guaranteeing existence on a full interval wherever the coefficient functions are continuous. Linear second-order equations have an existence and uniqueness theorem that gives the same type of result when the initial condition is stated properly.   Existence and uniqueness Suppose are continuous functions on some interval , is a number in , and are constants. The equation has exactly one solution defined on the same interval satisfying the initial conditions   For example, the equation with and has the solution   The equation with and has the solution Using and in this solution allows us to solve for the initial conditions in a cleaner way than if we have used the exponentials.  As it did for first order equations, this theorem tells us what the proper form is for initial value problems for second order equations. The take-away here is that in order to fully specify a solution to an initial value problem, a second order equation requires two initial conditions. They are usually given in the form and , but could be given as and in other applications. In any case, two pieces of information are needed to determine a problem of second order, where we only needed one for first order.    Constant Coefficient Equations - Real and Distinct Roots  Now we want to try to solve some of these equations. As discussed earlier in this section, there is no explicit solution method possible for second order equations. However, if we restrict to a very simple case (which is also one that shows up frequently in physical systems) we can start to develop a method for solving these equations. The type of equation we restrict to is linear and constant coefficient equations. Constant coefficients means that the functions in front of , , and are constants, they do not depend on . The most general second order, linear, constant coefficient equation is for real constants and an arbitrary function . We will study the solution of nonhomogeneous equations (with ) in . We will first focus on finding general solutions to homogeneous equations, which are of the form   Consider the problem This is a second order linear homogeneous equation with constant coefficients, so it fits the type of equation where we want to hunt for solutions. To guess a solution, think of a function that stays essentially the same when we differentiate it, so that we can take the function and its derivatives, add some multiples of these together, and end up with zero. Yes, we are talking about the exponential.  Let us try Making an educated guess with some parameters to solve for is such a central technique in differential equations, that people sometimes use a fancy name for such a guess: , German for Yes, the Germans have a word for that. a solution of the form . Then and . Plug in to get Hence, if or , then is a solution. So let and .    Check that and are solutions.    So we have found two solutions to this differential equation! That’s great, but there may be a few concerning ideas at this point:       Did we just get lucky with this particular equation?    How do we know that there aren’t other solutions that aren’t of the form ? We made that assumption, so we could have missed something.     The second point comes back to the existence and uniqueness theorem. This differential equation satisfies the conditions of the existence and uniqueness theorem. That means that as long as we find a solution that can meet any initial condition, then we know that the solution we have found is the only solution. We have not yet verified the part about meeting initial conditions yet (that’s coming later), but once we do, we’ll know that making this assumption is completely fine, because it got us to a solution that works, and the uniqueness theorem tells us that this is the only solution.  For the first point, let’s try to generalize the calculation we did above into a method that will work for more equations. Suppose that we have an equation where are constants. We can take our same assumption that the solution is of the form to obtain Divide by to obtain the so-called of the ODE: Solve for the by using the .   There are three cases that can arise based on this equation.     If , then we have and as two real roots to the equation. This is the same as the example above, and we get and as two solutions. This is the larger class of problems to which this exact process applies.    If , then and are complex numbers. We can still use and as solutions, but this runs into some issues, which will be addressed in Section .    If , then we only get one root, since . We do get that as a solution, but that’s all we get. This is another issue, which is addressed in Section .     So, as long as we have , this method will work to give us two solutions to this differential equation.      Find two values of so that is a solution to   Our first step is to find the characteristic equation by plugging into the equation. This gives that This polynomial factors as , so we know that values of and will work. This means (check this!) that and solve this differential equation.      Linear Independence  Since and solve the linear differential equation in the previous example, we know that superposition applies, so that solves the differential equation for any and . The last thing to check is that we can pick and in order to meet any initial condition that we want. If this is possible, then we know that our method using the characteristic equation to find and as solutions was enough to always solve this problem. The end of this argument is done using the existence and uniqueness theorem as described previously.  Let’s work this out. Assume that we are given and and want to solve the initial value problem We want to do this by picking and in the expression Since we can plug zero into this equation and the equation for to get that we would need to have We can solve this system of equations by elimination. Multiplying the first equation by 5 adding them together gives so that We can then compute the value of as Therefore, we can appropriate values of and that will meet the initial conditions for arbitrary values and . This is great! This means that our method of finding solutions was sufficient for this problem.  Let’s look at this situation in more generality. Assume that we have two solutions and that solve a second order linear, homogeneous differential equation, and we want to know if can meet any initial condition for this problem. We have two unknowns and two equations ( and for some value ), so it should work out.  We can carry out the same steps as above. If we have initial conditions and , we want to satisfy which we get by taking the derivative of and plugging in . We will again use elimination to solve this. We can multiply the first equation by , multiply the second by , and subtract them. This will cancel out the term, leaving us with We want to solve for here, and once we do that, solving for happens by plugging back into one of the original equations. Most of the time, this will be completely fine, but there’s one issue left. We can’t divide by zero. So to be able to solve these equations for and , we need to know that   The left side of this equation is often called the of the functions and at the point . In general, the Wronskian is the function for two solutions to a second order differential equation. This relation (the Wronskian being non-zero) tells us that the two solutions and are different enough to allow us to meet every initial condition for the differential equation. This condition is so important to the study of second order linear equations that we give it a name. We say that two solutions and are at if holds, that is, if the Wronskian of the solutions is non-zero at that point. For two solutions of a differential equation (which is more specific than just having two random functions), two solutions being linearly independent is equivalent to holding for any Abel’s Theorem, another theoretical result, says that the Wronskian is either always zero or never zero. That means that any one value can be checked to determine if two solutions are linearly independent. Picking is usually a convenient choice. value where they are defined. Our work and calculations above leads to the following theorem:   Let be continuous functions. Let and be two linearly independent solutions to the homogeneous equation . Then every other solution is of the form for some constants and . That is, is the general solution.  Note that this theorem works for all linear homogeneous equations, not just constant coefficients ones. However, the methods that we have described here (and will in future sections) for finding these solutions will generally only work for constant coefficient equations.  This idea of linear independence can also be expressed in a different way: two solutions and are linearly independent if only way to make the expression is by setting both and . This comes from the idea of linear independence from linear algebra (see ) and uniqueness of solutions to differential equations. If there are such constants, we can also rearrange the equation to give which says that is a constant multiple of , which holds for all values of . Thus, if we have and , and there is no constant so that , then these functions are linearly independent.      Find the general solution of the differential equation .    One of the four fundamental equations in showed that the two functions and are solutions to the equation . It is not hard to see that sine and cosine are not constant multiples of each other. If for some constant  , we let and this would imply . But then for all , which is preposterous. So and are linearly independent. We could also have checked this by taking derivatives and plugging in zero. Since we have that so these solutions are linearly independent. Hence, is the general solution to .    For two functions, checking linear independence is rather simple. Let us see another example using non-constant coefficient equations. Consider . Then and are solutions. To see that they are linearly indepedent, suppose one is a multple of the other: , we just have to find out that cannot be a constant. In this case we have , this most decidedly not a constant. So is the general solution.  Now, back to our discussion of constant coefficient equations. If , then we have two distinct real roots and , giving rise to solutions of the form and . Using condition with , we compute Since , this expression is not zero, so the two solutions are linearly independent. Therefore, in this case, we know that the general solution will be Using the other formulation of linear independence of two functions, we would need to show that there is no constant so that Since this can be rewritten as and we know that , this is not a constant, so we again know that these functions are linearly independent and give rise to a general solution.      Solve the initial value problem     To start, we find the characteristic equation of this differential equation and look for the roots. The characteristic equation here is and this factors as . Thus, the two roots are and , so that the general solution (and we know it is the general solution because these are different exponents and so the solutions are linearly independent) is   In order to find the values of and , we need to use the initial conditions. Plugging zero into gives and since the derivative , the second condition gives that Subtracting the second equation from the first gives that so that and . Thus, the solution to the initial value problem is     In this second example, we solve a problem in the same way, but the roots of the characteristic equation do not work out as nicely. Even with that, the structure and process for the problem is identical to the previous example.      Solve the initial value problem     We start by looking for the characteristic equation of this differential equation and finding its roots. The characteristic equation is which has roots   There are two real and distinct roots, so we know that the two solutions and are linearly independent, so we have that the general solution to this problem is   Next, we need to find the constants and to meet the initial conditions. We can see that, by computing the first derivative, and plugging in gives that we want and to solve We can solve this by any method. One trick at the start is to subtract equation 1 from equation 2, giving that which can be rewritten as Adding these equations together and dividing by 2 gives that so that , and since , we have that . Therefore, the solution to the desired initial value problem is       Exercises    Show that and are linearly independent.    Ratio is non-constant.      Are and linearly independent? Justify.      Are and linearly independent? Justify.      Guess a solution to .      Take . Find (guess!) a solution.           Verify that and both solve . Are these two solutions linearly independent? What does that mean about the general solution to ?    Yes. This means the general solution is .      Prove the superposition principle for nonhomogeneous equations. Suppose that is a solution to and is a solution to (same linear operator ). Show that solves .    Hint: Plug in and see that it works correctly.      Determine the maximal interval of existence of the solution to the differential equation with initial condition . What about if the initial condition is ?     for . for .      For the equation , find two solutions, show that they are linearly independent and find the general solution. Hint: Try .           Find the general solution to . Hint: It is a first order ODE in .      Find the general solution of .           Solve with , .           Find the general solution of .           Find the general solution to .           Find the general solution to .           Find the solution to with and .           Find the solution to with and .           Find the general solution to .      Find the solution to , , .      Find the solution to , , , where , , , and are real numbers, and .      Write down an equation (guess) for which we have the solutions and . Hint: Try an equation of the form for constants and , plug in both and and solve for and .      Construct an equation such that is the general solution.      Give an example of a 2nd-order DE whose general solution is .           Equations of the form are called Euler’s equations or Cauchy–Euler equations . They are solved by trying and solving for (assume that for simplicity).  Suppose that .   Find a formula for the general solution of . Hint: Try and find a formula for . What happens when or ?    a)  , , General Solution: . b)  Only one solution or complex solutions.      We will revisit the case when later.  Same equation as in . Suppose . Find a formula for the general solution of . Hint: Try for the second solution.          "
},
{
  "id": "subsec-SOLin-11",
  "level": "2",
  "url": "solinear-section.html#subsec-SOLin-11",
  "type": "Checkpoint",
  "number": "2.1.1",
  "title": "",
  "body": "  This fact does not hold if the equation is non-linear. Show that and solve but does not.    Two different solutions to the second equation are and . Let us remind ourselves of the definition, and . Therefore, these are solutions by superposition as they are linear combinations of the two exponential solutions.   "
},
{
  "id": "subsec-SOLin-13",
  "level": "2",
  "url": "solinear-section.html#subsec-SOLin-13",
  "type": "Checkpoint",
  "number": "2.1.2",
  "title": "",
  "body": "  Derive these properties using the definitions of and in terms of exponentials.   "
},
{
  "id": "intial-value-problems-3",
  "level": "2",
  "url": "solinear-section.html#intial-value-problems-3",
  "type": "Example",
  "number": "2.1.3",
  "title": ".",
  "body": "    Solve the second-order differential equation     We can attempt to find a solution to this problem by integrating both sides twice. A first integration gives and a second integration leads to for any two constants and . We can check that differentiating this function twice gives us back the function that we wanted.   "
},
{
  "id": "intial-value-problems-5",
  "level": "2",
  "url": "solinear-section.html#intial-value-problems-5",
  "type": "Example",
  "number": "2.1.4",
  "title": ".",
  "body": "    Solve the initial value problem     We previously found our solution with unknown constants as and also found that To find the values of and , we need to plug in the two initial conditions into their corresponding functions. The initial value of the derivative gives that so that we have . We can then use the initial value of , along with this value, to conclude that Solving this out gives that . Putting these constants in gives that the solution to the initial value problem is    "
},
{
  "id": "constant-coefficient-equations---real-and-distinct-roots-5",
  "level": "2",
  "url": "solinear-section.html#constant-coefficient-equations---real-and-distinct-roots-5",
  "type": "Checkpoint",
  "number": "2.1.5",
  "title": "",
  "body": "  Check that and are solutions.    So we have found two solutions to this differential equation! That’s great, but there may be a few concerning ideas at this point:   "
},
{
  "id": "constant-coefficient-equations---real-and-distinct-roots-12",
  "level": "2",
  "url": "solinear-section.html#constant-coefficient-equations---real-and-distinct-roots-12",
  "type": "Example",
  "number": "2.1.6",
  "title": ".",
  "body": "    Find two values of so that is a solution to   Our first step is to find the characteristic equation by plugging into the equation. This gives that This polynomial factors as , so we know that values of and will work. This means (check this!) that and solve this differential equation.   "
},
{
  "id": "linear-independence-10",
  "level": "2",
  "url": "solinear-section.html#linear-independence-10",
  "type": "Example",
  "number": "2.1.7",
  "title": ".",
  "body": "    Find the general solution of the differential equation .    One of the four fundamental equations in showed that the two functions and are solutions to the equation . It is not hard to see that sine and cosine are not constant multiples of each other. If for some constant  , we let and this would imply . But then for all , which is preposterous. So and are linearly independent. We could also have checked this by taking derivatives and plugging in zero. Since we have that so these solutions are linearly independent. Hence, is the general solution to .   "
},
{
  "id": "linear-independence-13",
  "level": "2",
  "url": "solinear-section.html#linear-independence-13",
  "type": "Example",
  "number": "2.1.8",
  "title": ".",
  "body": "    Solve the initial value problem     To start, we find the characteristic equation of this differential equation and look for the roots. The characteristic equation here is and this factors as . Thus, the two roots are and , so that the general solution (and we know it is the general solution because these are different exponents and so the solutions are linearly independent) is   In order to find the values of and , we need to use the initial conditions. Plugging zero into gives and since the derivative , the second condition gives that Subtracting the second equation from the first gives that so that and . Thus, the solution to the initial value problem is    "
},
{
  "id": "linear-independence-15",
  "level": "2",
  "url": "solinear-section.html#linear-independence-15",
  "type": "Example",
  "number": "2.1.9",
  "title": ".",
  "body": "    Solve the initial value problem     We start by looking for the characteristic equation of this differential equation and finding its roots. The characteristic equation is which has roots   There are two real and distinct roots, so we know that the two solutions and are linearly independent, so we have that the general solution to this problem is   Next, we need to find the constants and to meet the initial conditions. We can see that, by computing the first derivative, and plugging in gives that we want and to solve We can solve this by any method. One trick at the start is to subtract equation 1 from equation 2, giving that which can be rewritten as Adding these equations together and dividing by 2 gives that so that , and since , we have that . Therefore, the solution to the desired initial value problem is    "
},
{
  "id": "solinear-section-6-2",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-2",
  "type": "Exercise",
  "number": "2.1.5.1",
  "title": "",
  "body": "  Show that and are linearly independent.    Ratio is non-constant.   "
},
{
  "id": "solinear-section-6-3",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-3",
  "type": "Exercise",
  "number": "2.1.5.2",
  "title": "",
  "body": "  Are and linearly independent? Justify.   "
},
{
  "id": "solinear-section-6-4",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-4",
  "type": "Exercise",
  "number": "2.1.5.3",
  "title": "",
  "body": "  Are and linearly independent? Justify.   "
},
{
  "id": "solinear-section-6-5",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-5",
  "type": "Exercise",
  "number": "2.1.5.4",
  "title": "",
  "body": "  Guess a solution to .   "
},
{
  "id": "solinear-section-6-6",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-6",
  "type": "Exercise",
  "number": "2.1.5.5",
  "title": "",
  "body": "  Take . Find (guess!) a solution.        "
},
{
  "id": "solinear-section-6-7",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-7",
  "type": "Exercise",
  "number": "2.1.5.6",
  "title": "",
  "body": "  Verify that and both solve . Are these two solutions linearly independent? What does that mean about the general solution to ?    Yes. This means the general solution is .   "
},
{
  "id": "solinear-section-6-8",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-8",
  "type": "Exercise",
  "number": "2.1.5.7",
  "title": "",
  "body": "  Prove the superposition principle for nonhomogeneous equations. Suppose that is a solution to and is a solution to (same linear operator ). Show that solves .    Hint: Plug in and see that it works correctly.   "
},
{
  "id": "solinear-section-6-9",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-9",
  "type": "Exercise",
  "number": "2.1.5.8",
  "title": "",
  "body": "  Determine the maximal interval of existence of the solution to the differential equation with initial condition . What about if the initial condition is ?     for . for .   "
},
{
  "id": "solinear-section-6-10",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-10",
  "type": "Exercise",
  "number": "2.1.5.9",
  "title": "",
  "body": "  For the equation , find two solutions, show that they are linearly independent and find the general solution. Hint: Try .        "
},
{
  "id": "solinear-section-6-11",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-11",
  "type": "Exercise",
  "number": "2.1.5.10",
  "title": "",
  "body": "  Find the general solution to . Hint: It is a first order ODE in .   "
},
{
  "id": "solinear-section-6-12",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-12",
  "type": "Exercise",
  "number": "2.1.5.11",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "solinear-section-6-13",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-13",
  "type": "Exercise",
  "number": "2.1.5.12",
  "title": "",
  "body": "  Solve with , .        "
},
{
  "id": "solinear-section-6-14",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-14",
  "type": "Exercise",
  "number": "2.1.5.13",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "solinear-section-6-15",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-15",
  "type": "Exercise",
  "number": "2.1.5.14",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "solinear-section-6-16",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-16",
  "type": "Exercise",
  "number": "2.1.5.15",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "solinear-section-6-17",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-17",
  "type": "Exercise",
  "number": "2.1.5.16",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "solinear-section-6-18",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-18",
  "type": "Exercise",
  "number": "2.1.5.17",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "solinear-section-6-19",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-19",
  "type": "Exercise",
  "number": "2.1.5.18",
  "title": "",
  "body": "  Find the general solution to .   "
},
{
  "id": "solinear-section-6-20",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-20",
  "type": "Exercise",
  "number": "2.1.5.19",
  "title": "",
  "body": "  Find the solution to , , .   "
},
{
  "id": "solinear-section-6-21",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-21",
  "type": "Exercise",
  "number": "2.1.5.20",
  "title": "",
  "body": "  Find the solution to , , , where , , , and are real numbers, and .   "
},
{
  "id": "solinear-section-6-22",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-22",
  "type": "Exercise",
  "number": "2.1.5.21",
  "title": "",
  "body": "  Write down an equation (guess) for which we have the solutions and . Hint: Try an equation of the form for constants and , plug in both and and solve for and .   "
},
{
  "id": "solinear-section-6-23",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-23",
  "type": "Exercise",
  "number": "2.1.5.22",
  "title": "",
  "body": "  Construct an equation such that is the general solution.   "
},
{
  "id": "solinear-section-6-24",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-24",
  "type": "Exercise",
  "number": "2.1.5.23",
  "title": "",
  "body": "  Give an example of a 2nd-order DE whose general solution is .        "
},
{
  "id": "solinear-section-6-25",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-25",
  "type": "Exercise",
  "number": "2.1.5.24",
  "title": "",
  "body": "  Equations of the form are called Euler’s equations or Cauchy–Euler equations . They are solved by trying and solving for (assume that for simplicity).  Suppose that .   Find a formula for the general solution of . Hint: Try and find a formula for . What happens when or ?    a)  , , General Solution: . b)  Only one solution or complex solutions.   "
},
{
  "id": "solinear-section-6-26",
  "level": "2",
  "url": "solinear-section.html#solinear-section-6-26",
  "type": "Exercise",
  "number": "2.1.5.25",
  "title": "",
  "body": "  We will revisit the case when later.  Same equation as in . Suppose . Find a formula for the general solution of . Hint: Try for the second solution.        "
},
{
  "id": "complexroots-section",
  "level": "1",
  "url": "complexroots-section.html",
  "type": "Section",
  "number": "2.2",
  "title": "Complex Roots and Euler’s Formula",
  "body": " Complex Roots and Euler’s Formula   complexgen  The next case to consider for constant coefficient second order equations is the one where . This results in two roots and , but they are complex roots. In order to solve differential equations with , we need to be able to manipulate and use some properties of complex numbers. Complex numbers may seem a strange concept, especially because of the terminology. There is nothing imaginary or really complicated about complex numbers. For more bachground information on complex numbers, see .  To start with, we define . Since this is the square root of a negative number, this is not a real number. A complex number is written in the form where and are real numbers. For a complex number we call the and the of the number. Often the following notation is used, The real numbers are contained in the complex numbers as those complex numbers with the imaginary part being zero.  When trying to do arithmetic with complex numbers, we treat as though it is a variable, and do computations just as we would with polynomials. The important fact that we will use to simplify is the fact that since , we have that . So whenever we see , we replace it by . For example,   The numbers and are the two roots of . Engineers often use the letter instead of for the square root of . We use the mathematicians’ convention and use .    Make sure you understand (that you can justify) the following identities:   (2) , , , , , , .    In order to solve differential equations where the characteristic equation has complex roots, we need to deal with the exponential of complex numbers. We do this by writing down the Taylor series and plugging in the complex number. Because most properties of the exponential can be proved by looking at the Taylor series, these properties still hold for the complex exponential. For example the very important property: . This means that . Hence if we can compute , we can compute . For , we use the so-called .     Euler’s formula   In other words, .    Using Euler’s formula, check the identities:       Double angle identities: Start with . Use Euler on each side and deduce:       Complex roots  Suppose the equation has the characteristic equation that has . By the quadratic formula, the roots are . These roots are complex if . In this case the roots are As you can see, we always get a pair of roots of the form . In this case we can still write the solution as However, the exponential is now complex-valued, and so (real) linear combinations of these solutions will be complex valued. If we are using these equations to model physical problems, the answer should be real-valued, as the position of a mass-on-a-spring can not be a complex number. To do this, we need to determine two real-valued, linearly independent solutions to this differential equation.  To do this, we use the following result.   Consider the differential equation where and are real-valued continuous functions on some interval . If is a complex-valued solution to this differential equation and we can split into its real and imaginary parts and , then and are both solutions to .    Proof. This is based on the fact that the differential equation is linear. We can compute derivatives of  Then, we can plug this into the differential equation Since the equation at the end of this chain is equal to zero, it must be zero as a complex number, which means that both the real and imaginary parts must be zero. This means that so that both and solve the original differential equation. ◻  To use this to solve the problem at hand, we have our solution and we need to split this into its real and imaginary parts. Since the real and imaginary parts of this function are which, by the previous theorem, we know are also solutions. These are two solutions to our original differential equation that are also real-valued!  On the other hand, assume that we take the other complex solution, which will be If we split this into real and imaginary parts, we will get so that the real and imaginary parts of this solution are These are exactly the same as the previous real and imaginary parts, up to the minus sign on . Since we are going to incorporate these with constants and eventually, they will give rise to the same general solution. So, we only need one of these two complex solutions to generate our two linearly independent real-valued solutions, and either of the two complex solutions give the same pair of real-valued solutions.    For , check that and are linearly independent.    With that fact, we have the following theorem.     Take the equation If the characteristic equation has the roots (when ), then the general solution is       Find the general solution of , for a constant .    The characteristic equation is . Therefore, the roots are , and by the theorem, we have the general solution         Find the solution of , , .    The characteristic equation is . By completing the square we get and hence the roots are . By the theorem we have the general solution To find the solution satisfying the initial conditions, we first plug in zero to get Hence, and . We differentiate, We again plug in the initial condition and obtain , or . The solution we are seeking is     In this previous example, we can get a fairly good idea of how to sketch out the graph of this function. Since oscillates between and , the graph of will oscillate between the graphs of and . These curves that surround the graph of the solution are called envelope curves for the solution. In , this phenomenon is illustrated for the function .    This is simple when there is only one term in the function we want to draw. When both sine and cosine terms appear, this can get more tricky, but we can still work it out. In the more general case, the solution will look something like We can first factor out an , and then we want to write as a single trigonometric function. The identity we want to use here is the trigonometric identity If there is an angle so that and , then we could write and we would be done. However, this does not always happen; the main issue being that for all , but it is not necessarily the case that . But we can force this last condition. If we define , then we can rewrite this expression as where is the angle so that and such an angle will always exist. Therefore, we can represent the original solution as where Therefore, the envelope curves for this solution will be   Note that in order to determine these envelope curves, you do not need to determine the value in the representation of the solution. All you need is the value of , which can be computed as where and are the coefficients of the sine and cosine terms in the solution.      Find the solution to the initial value problem Determine a value where the solution satisfies for all .    We solve the initial value problem by normal techniques from this section. The characteristic equation is , which has roots . Therefore, the general solution of the differential equation is Plugging in gives that , and the derivative of this general solution is Plugging in here gives Since , this gives that . So, our solution is   Through the work above, we can find . Therefore, the envelope curves for the solution are In order to find this threshold where the solution will stay within of zero, we need to figure out when this envelope curves get to the threshold. Once the envelope curves get to that level, we know that the full solution must be trapped there as well. We can solve   So, for all values of larger than 3.454, the solution will be within of zero. This is illustrated in . Note that we did not find the best value here, as it probably could be made smaller using the actual solution. The issue here is that because the solution is oscillating, it may end up staying inside the cutoff before that value of time, but this is the lowest value of that we can prove and validate using envelope curves.        Exercises    Write in the form .      Write in the form .           Write in the form .           Show that and are linearly independent.    Ratio is non-constant.      Find the general solution of .           Find the general solution of .           Find the solution to with and .           Find the general solution of .           Find the solution to , , .      Find the solution to , , .      Let us revisit the Cauchy–Euler equations of . Suppose now that . Find a formula for the general solution of . Hint: Note that .           Construct an equation such that is the general solution.           Find a second order, constant coefficient differential equation with general solution given by or explain why there is no such thing.      Find a second order, constant coefficient differential equation with general solution given by or explain why there is no such thing.           Find the solution to the initial value problem Determine a value so that for all .     ,       Find the solution to the initial value problem Determine a value so that for all .     , .     "
},
{
  "id": "subsec-complexgen-6",
  "level": "2",
  "url": "complexroots-section.html#subsec-complexgen-6",
  "type": "Checkpoint",
  "number": "2.2.1",
  "title": "",
  "body": "  Make sure you understand (that you can justify) the following identities:   (2) , , , , , , .    In order to solve differential equations where the characteristic equation has complex roots, we need to deal with the exponential of complex numbers. We do this by writing down the Taylor series and plugging in the complex number. Because most properties of the exponential can be proved by looking at the Taylor series, these properties still hold for the complex exponential. For example the very important property: . This means that . Hence if we can compute , we can compute . For , we use the so-called .   "
},
{
  "id": "subsec-complexgen-9",
  "level": "2",
  "url": "complexroots-section.html#subsec-complexgen-9",
  "type": "Checkpoint",
  "number": "2.2.2",
  "title": "",
  "body": "  Using Euler’s formula, check the identities:    "
},
{
  "id": "subsec-complexgen-10",
  "level": "2",
  "url": "complexroots-section.html#subsec-complexgen-10",
  "type": "Checkpoint",
  "number": "2.2.3",
  "title": "",
  "body": "  Double angle identities: Start with . Use Euler on each side and deduce:    "
},
{
  "id": "complex-roots-8",
  "level": "2",
  "url": "complexroots-section.html#complex-roots-8",
  "type": "Checkpoint",
  "number": "2.2.4",
  "title": "",
  "body": "  For , check that and are linearly independent.    With that fact, we have the following theorem.   "
},
{
  "id": "complex-roots-10",
  "level": "2",
  "url": "complexroots-section.html#complex-roots-10",
  "type": "Example",
  "number": "2.2.5",
  "title": ".",
  "body": "    Find the general solution of , for a constant .    The characteristic equation is . Therefore, the roots are , and by the theorem, we have the general solution    "
},
{
  "id": "complex-roots-11",
  "level": "2",
  "url": "complexroots-section.html#complex-roots-11",
  "type": "Example",
  "number": "2.2.6",
  "title": ".",
  "body": "    Find the solution of , , .    The characteristic equation is . By completing the square we get and hence the roots are . By the theorem we have the general solution To find the solution satisfying the initial conditions, we first plug in zero to get Hence, and . We differentiate, We again plug in the initial condition and obtain , or . The solution we are seeking is    "
},
{
  "id": "complex-roots-15",
  "level": "2",
  "url": "complexroots-section.html#complex-roots-15",
  "type": "Example",
  "number": "2.2.7",
  "title": ".",
  "body": "    Find the solution to the initial value problem Determine a value where the solution satisfies for all .    We solve the initial value problem by normal techniques from this section. The characteristic equation is , which has roots . Therefore, the general solution of the differential equation is Plugging in gives that , and the derivative of this general solution is Plugging in here gives Since , this gives that . So, our solution is   Through the work above, we can find . Therefore, the envelope curves for the solution are In order to find this threshold where the solution will stay within of zero, we need to figure out when this envelope curves get to the threshold. Once the envelope curves get to that level, we know that the full solution must be trapped there as well. We can solve   So, for all values of larger than 3.454, the solution will be within of zero. This is illustrated in . Note that we did not find the best value here, as it probably could be made smaller using the actual solution. The issue here is that because the solution is oscillating, it may end up staying inside the cutoff before that value of time, but this is the lowest value of that we can prove and validate using envelope curves.   "
},
{
  "id": "complexroots-section-4-2",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-2",
  "type": "Exercise",
  "number": "2.2.3.1",
  "title": "",
  "body": "  Write in the form .   "
},
{
  "id": "complexroots-section-4-3",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-3",
  "type": "Exercise",
  "number": "2.2.3.2",
  "title": "",
  "body": "  Write in the form .        "
},
{
  "id": "complexroots-section-4-4",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-4",
  "type": "Exercise",
  "number": "2.2.3.3",
  "title": "",
  "body": "  Write in the form .        "
},
{
  "id": "complexroots-section-4-5",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-5",
  "type": "Exercise",
  "number": "2.2.3.4",
  "title": "",
  "body": "  Show that and are linearly independent.    Ratio is non-constant.   "
},
{
  "id": "complexroots-section-4-6",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-6",
  "type": "Exercise",
  "number": "2.2.3.5",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "complexroots-section-4-7",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-7",
  "type": "Exercise",
  "number": "2.2.3.6",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "complexroots-section-4-8",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-8",
  "type": "Exercise",
  "number": "2.2.3.7",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "complexroots-section-4-9",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-9",
  "type": "Exercise",
  "number": "2.2.3.8",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "complexroots-section-4-10",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-10",
  "type": "Exercise",
  "number": "2.2.3.9",
  "title": "",
  "body": "  Find the solution to , , .   "
},
{
  "id": "complexroots-section-4-11",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-11",
  "type": "Exercise",
  "number": "2.2.3.10",
  "title": "",
  "body": "  Find the solution to , , .   "
},
{
  "id": "complexroots-section-4-12",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-12",
  "type": "Exercise",
  "number": "2.2.3.11",
  "title": "",
  "body": "  Let us revisit the Cauchy–Euler equations of . Suppose now that . Find a formula for the general solution of . Hint: Note that .        "
},
{
  "id": "complexroots-section-4-13",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-13",
  "type": "Exercise",
  "number": "2.2.3.12",
  "title": "",
  "body": "  Construct an equation such that is the general solution.        "
},
{
  "id": "complexroots-section-4-14",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-14",
  "type": "Exercise",
  "number": "2.2.3.13",
  "title": "",
  "body": "  Find a second order, constant coefficient differential equation with general solution given by or explain why there is no such thing.   "
},
{
  "id": "complexroots-section-4-15",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-15",
  "type": "Exercise",
  "number": "2.2.3.14",
  "title": "",
  "body": "  Find a second order, constant coefficient differential equation with general solution given by or explain why there is no such thing.        "
},
{
  "id": "complexroots-section-4-16",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-16",
  "type": "Exercise",
  "number": "2.2.3.15",
  "title": "",
  "body": "  Find the solution to the initial value problem Determine a value so that for all .     ,    "
},
{
  "id": "complexroots-section-4-17",
  "level": "2",
  "url": "complexroots-section.html#complexroots-section-4-17",
  "type": "Exercise",
  "number": "2.2.3.16",
  "title": "",
  "body": "  Find the solution to the initial value problem Determine a value so that for all .     , .   "
},
{
  "id": "reproots-section",
  "level": "1",
  "url": "reproots-section.html",
  "type": "Section",
  "number": "2.3",
  "title": "Repeated Roots and Reduction of Order",
  "body": " Repeated Roots and Reduction of Order  The last case we have to handle for solving all second order linear constant coefficient equations is the case where in the equation When we try to find the characteristic equation and find solutions to this equation, we get a double root at , so that the characteristic polynomial is . For this, we get that is a solution. However, that’s the only solution we get. We need to have two linearly independent solutions in order to get the general solution to the differential equation, so we need to find some method to get another solution. The standard method, and the one we apply here is reduction of order . Let’s see how this works through an example.      Find two linearly independent solutions to the differential equation     To start, we find the first solution using our original method. The characteristic equation here is , which is . Therefore, we have a double root at , so that is a solution.  To find a second solution, the reduction of order method suggests that we try to plug in for an unknown function . The goal is to figure out an equation that must satisfy to see if this leads us to a second solution to the original equation. We can compute the first two derivatives of  and then plug them into the original differential equation Since is never zero, this means we must have . This is still a second order equation, but we know how to solve it. We can integrate both sides twice to get that for any constants and .  Our goal with all of this was to find a solution of the form . The set up here means that will solve the differential equation. Since we already knew that was a solution, the new information we gained here was that , or in particular, is a solution to the differential equation. Thus, our two solutions are and .      Check that and both solve , and that these solutions are linearly independent.    The applies more generally to any second order linear homogenous equation and the goal is the same: use one solution of the differential equation to generate another one. The idea is that if we somehow found as a solution of we try a second solution of the form . We just need to find . We plug into the equation: In other words, . Using we have the first order linear equation . After solving this equation for (integrating factor), we find by antidifferentiating . We then form by computing . For example, suppose we somehow know is a solution to . The equation for is then . We find a solution, , and we find an antiderivative . Hence . Any works and so makes . Thus, the general solution is .    The easiest way to work out these problems is to remember that we need to try and find as we did above. Also, the technique works for higher order equations too: you get to reduce the order for each solution you find.  In summary, for constant coefficient equations with a repeated root, the reduction of order method will always give the equation , and so the solution is . Multiplying by the solution gives that is the other solution. Therefore, the general solution for repeated root equations is always of the form       Find the general solution of     The characteristic equation is . The equation has a double root . The general solution is, therefore,      Check that and are linearly independent.    That solves the equation is clear. If solves the equation, then we know we are done. Let us compute and . Plug in     In some sense, a doubled root rarely happens. If coefficients are picked randomly, a doubled root is unlikely. There are, however, some natural phenomena where a doubled root does happen, so we cannot just dismiss this case. In addition, there are specific physical applications that involve the double root problem, which we will discuss in Section . Finally, the solution with a doubled root can be thought of as an approximation of the solution with two roots that are very close together, and the behavior of this solution will approximate nearby solutions as well.      Find the solution to the initial value problem     The characteristic polynomials for this differential equation is which factors as , so that we have a double root at . With the work done previously, we know that the general solution is   If we use the initial conditions, we can set to get that so that . Differentiating the general solution gives that and plugging in zero here gives Since , this implies that . Therefore, the solution to this initial value problem is      Exercises    Find the general solution to .           Find the general solution to .      Find the solution to with and .           Solve for , .           Find the general solution of using the methods of this section.           The method of this section applies to equations of other orders than two. We will see higher orders later. Try to solve the first order equation using the methods of this section.           Consider the second-order DE    Does the superposition principle apply to this DE? Give a one- or two-sentence explanation wither way. Find a value of so that is a solution to Using your result from the previous page, apply reduction of order to find the general solution to .    a) Yes, it is linear b)  c)        Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.      Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.      Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.      Write down a differential equation with general solution , or explain why there is no such thing.           Find the solution to , , , where , , and are real numbers.           Suppose is a solution to . By directly plugging into the equation, show that is also a solution.    Yes      Take .   Show that is a solution. Use reduction of order to find a second linearly independent solution. Write down the general solution.    a) Works b)  c)        Take .   Show that is a solution. Use reduction of order to find a second linearly independent solution. (It’s OK to leave a definite integral in the formula.) Write down the general solution.    a)  Works b)  c)        The rest of these exercises can be solved using any of the methods discussed in the last three sections. Pick the appropriate method in order to solve the problem.  Find the general solution of .           Find the general solution of .           Find the general solution of .           Find the general solution of .           Find the solution to with and .           Find the solution to with and .           Find the solution to with and .          "
},
{
  "id": "reproots-section-3",
  "level": "2",
  "url": "reproots-section.html#reproots-section-3",
  "type": "Example",
  "number": "2.3.1",
  "title": ".",
  "body": "    Find two linearly independent solutions to the differential equation     To start, we find the first solution using our original method. The characteristic equation here is , which is . Therefore, we have a double root at , so that is a solution.  To find a second solution, the reduction of order method suggests that we try to plug in for an unknown function . The goal is to figure out an equation that must satisfy to see if this leads us to a second solution to the original equation. We can compute the first two derivatives of  and then plug them into the original differential equation Since is never zero, this means we must have . This is still a second order equation, but we know how to solve it. We can integrate both sides twice to get that for any constants and .  Our goal with all of this was to find a solution of the form . The set up here means that will solve the differential equation. Since we already knew that was a solution, the new information we gained here was that , or in particular, is a solution to the differential equation. Thus, our two solutions are and .   "
},
{
  "id": "reproots-section-4",
  "level": "2",
  "url": "reproots-section.html#reproots-section-4",
  "type": "Checkpoint",
  "number": "2.3.2",
  "title": "",
  "body": "  Check that and both solve , and that these solutions are linearly independent.    The applies more generally to any second order linear homogenous equation and the goal is the same: use one solution of the differential equation to generate another one. The idea is that if we somehow found as a solution of we try a second solution of the form . We just need to find . We plug into the equation: In other words, . Using we have the first order linear equation . After solving this equation for (integrating factor), we find by antidifferentiating . We then form by computing . For example, suppose we somehow know is a solution to . The equation for is then . We find a solution, , and we find an antiderivative . Hence . Any works and so makes . Thus, the general solution is .   "
},
{
  "id": "reproots-section-7",
  "level": "2",
  "url": "reproots-section.html#reproots-section-7",
  "type": "Example",
  "number": "2.3.3",
  "title": ".",
  "body": "    Find the general solution of     The characteristic equation is . The equation has a double root . The general solution is, therefore,    "
},
{
  "id": "reproots-section-8",
  "level": "2",
  "url": "reproots-section.html#reproots-section-8",
  "type": "Checkpoint",
  "number": "2.3.4",
  "title": "",
  "body": "  Check that and are linearly independent.    That solves the equation is clear. If solves the equation, then we know we are done. Let us compute and . Plug in    "
},
{
  "id": "reproots-section-10",
  "level": "2",
  "url": "reproots-section.html#reproots-section-10",
  "type": "Example",
  "number": "2.3.5",
  "title": ".",
  "body": "    Find the solution to the initial value problem     The characteristic polynomials for this differential equation is which factors as , so that we have a double root at . With the work done previously, we know that the general solution is   If we use the initial conditions, we can set to get that so that . Differentiating the general solution gives that and plugging in zero here gives Since , this implies that . Therefore, the solution to this initial value problem is    "
},
{
  "id": "reproots-section-11-2",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-2",
  "type": "Exercise",
  "number": "2.3.1",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "reproots-section-11-3",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-3",
  "type": "Exercise",
  "number": "2.3.2",
  "title": "",
  "body": "  Find the general solution to .   "
},
{
  "id": "reproots-section-11-4",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-4",
  "type": "Exercise",
  "number": "2.3.3",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "reproots-section-11-5",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-5",
  "type": "Exercise",
  "number": "2.3.4",
  "title": "",
  "body": "  Solve for , .        "
},
{
  "id": "reproots-section-11-6",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-6",
  "type": "Exercise",
  "number": "2.3.5",
  "title": "",
  "body": "  Find the general solution of using the methods of this section.        "
},
{
  "id": "reproots-section-11-7",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-7",
  "type": "Exercise",
  "number": "2.3.6",
  "title": "",
  "body": "  The method of this section applies to equations of other orders than two. We will see higher orders later. Try to solve the first order equation using the methods of this section.        "
},
{
  "id": "reproots-section-11-8",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-8",
  "type": "Exercise",
  "number": "2.3.7",
  "title": "",
  "body": "  Consider the second-order DE    Does the superposition principle apply to this DE? Give a one- or two-sentence explanation wither way. Find a value of so that is a solution to Using your result from the previous page, apply reduction of order to find the general solution to .    a) Yes, it is linear b)  c)     "
},
{
  "id": "reproots-section-11-9",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-9",
  "type": "Exercise",
  "number": "2.3.8",
  "title": "",
  "body": "  Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.   "
},
{
  "id": "reproots-section-11-10",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-10",
  "type": "Exercise",
  "number": "2.3.9",
  "title": "",
  "body": "  Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.   "
},
{
  "id": "reproots-section-11-11",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-11",
  "type": "Exercise",
  "number": "2.3.10",
  "title": "",
  "body": "  Consider the differential equation .   Verify that is a solution. Use reduction of order to find a second linearly independent solution. Write out the general solution.   "
},
{
  "id": "reproots-section-11-12",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-12",
  "type": "Exercise",
  "number": "2.3.11",
  "title": "",
  "body": "  Write down a differential equation with general solution , or explain why there is no such thing.        "
},
{
  "id": "reproots-section-11-13",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-13",
  "type": "Exercise",
  "number": "2.3.12",
  "title": "",
  "body": "  Find the solution to , , , where , , and are real numbers.        "
},
{
  "id": "reproots-section-11-14",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-14",
  "type": "Exercise",
  "number": "2.3.13",
  "title": "",
  "body": "  Suppose is a solution to . By directly plugging into the equation, show that is also a solution.    Yes   "
},
{
  "id": "reproots-section-11-15",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-15",
  "type": "Exercise",
  "number": "2.3.14",
  "title": "",
  "body": "  Take .   Show that is a solution. Use reduction of order to find a second linearly independent solution. Write down the general solution.    a) Works b)  c)     "
},
{
  "id": "reproots-section-11-16",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-16",
  "type": "Exercise",
  "number": "2.3.15",
  "title": "",
  "body": "  Take .   Show that is a solution. Use reduction of order to find a second linearly independent solution. (It’s OK to leave a definite integral in the formula.) Write down the general solution.    a)  Works b)  c)     "
},
{
  "id": "reproots-section-11-17",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-17",
  "type": "Exercise",
  "number": "2.3.16",
  "title": "",
  "body": "  The rest of these exercises can be solved using any of the methods discussed in the last three sections. Pick the appropriate method in order to solve the problem.  Find the general solution of .        "
},
{
  "id": "reproots-section-11-18",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-18",
  "type": "Exercise",
  "number": "2.3.17",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "reproots-section-11-19",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-19",
  "type": "Exercise",
  "number": "2.3.18",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "reproots-section-11-20",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-20",
  "type": "Exercise",
  "number": "2.3.19",
  "title": "",
  "body": "  Find the general solution of .        "
},
{
  "id": "reproots-section-11-21",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-21",
  "type": "Exercise",
  "number": "2.3.20",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "reproots-section-11-22",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-22",
  "type": "Exercise",
  "number": "2.3.21",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "reproots-section-11-23",
  "level": "2",
  "url": "reproots-section.html#reproots-section-11-23",
  "type": "Exercise",
  "number": "2.3.22",
  "title": "",
  "body": "  Find the solution to with and .        "
},
{
  "id": "sec-mv",
  "level": "1",
  "url": "sec-mv.html",
  "type": "Section",
  "number": "2.4",
  "title": "Mechanical vibrations",
  "body": " Mechanical vibrations   mechgeneral  In the last few sections, we have discussed all of the different possible solutions to constant coefficient second order differential equations, whether the roots of the characteristic polynomial real and distinct, complex, or repeated. Now, we want to look at applications of these equations, now that we know how to solve them. Since Newton’s Second Law involves the second derivative of position (acceleration), it is reasonable that a lot of physical systems will be defined by second order differential equations.   2.0in2.3in  Our first example is a mass on a spring. Suppose we have a mass (in kilograms) connected by a spring with spring constant (in newtons per meter) to a fixed wall. There may be some external force (in newtons) acting on the mass. Finally, there is some friction measured by (in newton-seconds per meter) as the mass slides along the floor (or perhaps a damper is connected).  Let be the displacement of the mass ( is the rest position), with growing to the right (away from the wall). The force exerted by the spring is proportional to the compression of the spring by . Therefore, it is in the negative direction. Similarly the amount of force exerted by friction is proportional to the velocity of the mass. By we know that force equals mass times acceleration and hence or This is a linear second order constant coefficient ODE. We say the motion is     forced , if (if is not identically zero),     unforced or free , if (if is identically zero),     damped , if , and     undamped , if .    This system appears in lots of applications even if it does not at first seem like it. Many real-world scenarios can be simplified to a mass on a spring. For example, a bungee jump setup is essentially a mass and spring system (you are the mass). It would be good if someone did the math before you jump off the bridge, right? Let us give two other examples.   1.35in1.65in  Here is an example for electrical engineers. Consider the pictured . There is a resistor with a resistance of ohms, an inductor with an inductance of henries, and a capacitor with a capacitance of farads. There is also an electric source (such as a battery) giving a voltage of volts at time (measured in seconds). Let be the charge in coulombs on the capacitor and be the current in the circuit. The relation between the two is . By elementary principles we find . Since , this means that , and we can write this equation as We can also write this a different way by differentiating the entire equation in to get a second order equation for : This is a nonhomogeneous second order constant coefficient linear equation. As , and are all positive, this system behaves just like the mass and spring system. Position of the mass is replaced by current. Mass is replaced by inductance, damping is replaced by resistance, and the spring constant is replaced by one over the capacitance. The change in voltage becomes the forcing function—for constant voltage this is an unforced motion.   1.8in2.16in  Our next example behaves like a mass and spring system only approximately. Suppose a mass hangs on a pendulum of length . We seek an equation for the angle (in radians). Let be the force of gravity. Elementary physics mandates that the equation is   Let us derive this equation using : force equals mass times acceleration. The acceleration is and mass is . So has to be equal to the tangential component of the force given by the gravity, which is in the opposite direction. So . The curiously cancels from the equation.  Now we make our approximation. For small we have that approximately . This can be seen by looking at the graph. In we can see that for approximately (in radians) the graphs of and are almost the same.  Therefore, when the swings are small, is small and we can model the behavior by the simpler linear equation The errors from this approximation build up. So after a long time, the state of the real-world system might be substantially different from our solution. Also we will see that in a mass-spring system, the amplitude is independent of the period. This is not true for a pendulum. Nevertheless, for reasonably short periods of time and small swings (that is, only small angles ), the approximation is reasonably good.   3.1in  In real-world problems it is often necessary to make these types of simplifications. We must understand both the mathematics and the physics of the situation to see if the simplification is valid in the context of the questions we are trying to answer.    Free undamped motion  In this section we only consider free or unforced motion, as we do not know yet how to solve nonhomogeneous equations. Let us start with motion where . The equation is We divide by and let to rewrite the equation as The general solution to this equation is By a trigonometric identity that we discussed previously in , for two constants and . Earlier, we found that we can compute these constants as and . Therefore, we let and be our arbitrary constants and write .    Justify the identity and verify the equations for and . Hint: Start with and multiply by . Then what should and be?    While it is generally easier to use the first form with and to solve for the initial conditions, the second form is much more natural to use for interpretation of physical systems, since the constants and have nice physical interpretation. Write the solution as This is a pure-frequency oscillation (a sine wave). The is , is the (angular) , and is the so-called . The phase shift just shifts the graph left or right. We call the . This entire setup is called .    Let us pause to explain the word angular before the word frequency . The units of are radians per unit time, not cycles per unit time as is the usual measure of frequency. Because one cycle is radians, the usual frequency is given by . It is simply a matter of where we put the constant , and that is a matter of taste.  The of the motion is one over the frequency (in cycles per unit time) and hence . That is the amount of time it takes to complete one full cycle.      Suppose that and . The whole mass and spring setup is sitting on a truck that was traveling at . The truck crashes and hence stops. The mass was held in place 0.5 meters forward from the rest position. During the crash the mass gets loose. That is, the mass is now moving forward at , while the other end of the spring is held in place. The mass therefore starts oscillating. What is the frequency of the resulting oscillation? What is the amplitude? The units are the mks units (meters-kilograms-seconds).    The setup means that the mass was at half a meter in the positive direction during the crash and relative to the wall the spring is mounted to, the mass was moving forward (in the positive direction) at . This gives us the initial conditions.   3.25in  So the equation with initial conditions is We directly compute . Hence the angular frequency is 2. The usual frequency in Hertz (cycles per second) is .  The general solution is Letting means . Then . Letting we get . Therefore, the amplitude is . The solution is A plot of is shown in .    In general, for free undamped motion, a solution of the form corresponds to the initial conditions and . Therefore, it is easy to figure out and from the initial conditions. The amplitude and the phase shift can then be computed from and . In the example, we have already found the amplitude . Let us compute the phase shift. We know that . We take the arctangent of 1 and get or approximately 0.785. We still need to check if this is in the correct quadrant (and add to if it is not). Since both and are positive, then should be in the first quadrant, radians is in the first quadrant, so .  Note: Many calculators and computer software have not only the atan function for arctangent, but also what is sometimes called atan2 . This function takes two arguments, and , and returns a in the correct quadrant for you.    Free damped motion   Let us now focus on motion. Let us rewrite the equation as where The characteristic equation is Using the quadratic formula we get that the roots are The form of the solution depends on whether we get complex or real roots. We get real roots if and only if the following number is nonnegative: The sign of is the same as the sign of . Thus we get real roots if and only if is nonnegative, or in other words if . If these look familiar, that is not surprising, as they are the same as the conditions we had for the different types of roots in second order constant coefficient equations.    Overdamping  When , the system is . In this case, there are two distinct real roots and . Both roots are negative: As is always less than , then is negative in either case.  The solution is Since are negative, as . Thus the mass will tend towards the rest position as time goes to infinity. For a few sample plots for different initial conditions, see .   3.25in  No oscillation happens. In fact, the graph crosses the -axis at most once. To see why, we try to solve . Therefore, and using laws of exponents we obtain This equation has at most one solution . For some initial conditions the graph never crosses the -axis, as is evident from the sample graphs.      Suppose the mass is released from rest. That is and . Then It is not hard to see that this satisfies the initial conditions.      Critical damping  When , the system is . In this case, there is one root of multiplicity 2 and this root is . Our solution is    3.25in  The behavior of a critically damped system is very similar to an overdamped system. After all a critically damped system is in some sense a limit of overdamped systems. Even though our models are only approximations of the real world problem, the idea of critical damping can be helpful in optimizing systems. shows how the solution to for different values of and initial conditions and . This solution is critically damped if , as that will give us a repeated root in the characteristic equation. Comparing these solutions, we see that the critically damped solution gets back to equilibrium faster than any of the more overdamped solution. When trying to design a system, if we want it to settle back to the zero point as quickly as possible, then we should try to get as closed to critically damped as possible. Even though we are always a little bit underdamped or a little bit overdamped, getting as close as possible will give the best possible result for returning to equilibrium.    Underdamping   3.25in  When , the system is . In this case, the roots are complex. where . Our solution is or An example plot is given in . Note that we still have that as .  The figure also shows the  and . The solution is the oscillating line between the two envelope curves. The envelope curves give the maximum amplitude of the oscillation at any given point in time. For example, if you are bungee jumping, you are really interested in computing the envelope curve as not to hit the concrete with your head.  The phase shift shifts the oscillation left or right, but within the envelope curves (the envelope curves do not change if changes).  Notice that the angular We do not call a frequency since the solution is not really a periodic function. or becomes smaller when the damping (and hence ) becomes larger. This makes sense. When we change the damping just a little bit, we do not expect the behavior of the solution to change dramatically. If we keep making larger, then at some point the solution should start looking like the solution for critical damping or overdamping, where no oscillation happens. So if approaches , we want to approach 0. Since with and , we have that which does go to zero as gets closer to .  On the other hand, when gets smaller, approaches ( is always smaller than ), and the solution looks more and more like the steady periodic motion of the undamped case. The envelope curves become flatter and flatter as (and hence ) goes to 0.     Exercises     Consider a mass and spring system with a mass , spring constant , and damping constant .   Set up and find the general solution of the system. Is the system underdamped, overdamped or critically damped? If the system is not critically damped, find a that makes the system critically damped.    a)  b)  Underdamped c)        Do for , , and .    a)  b)  Critically Damped      Using the mks units (meters-kilograms-seconds), suppose you have a spring with spring constant . You want to use it to weigh items. Assume no friction. You place the mass on the spring and put it in motion.   You count and find that the frequency is [ 0 8 ] Hz ( cycles per second ) What is the mass ? ( Be careful with the units here , the frequency is given in cycles per second , not radians per second )  Find a formula for the mass given the frequency in Hz.    a)  6.317 kg b)  .      A mass of kilograms is on a spring with spring constant newtons per meter with no damping. Suppose the system is at rest and at time the mass is kicked and starts traveling at 2 meters per second. How large does have to be to so that the mass does not go further than 3 meters from the rest position?      Suppose we add possible friction to . Further, suppose you do not know the spring constant, but you have two reference weights kg and kg to calibrate your setup. You put each in motion on your spring and measure the quasi-frequency. For the kg weight you measured [ 1 1 ] Hz , for the kg weight you measured [ 0 8 ] Hz.   Find (spring constant) and (damping constant). Find a formula for the mass in terms of the frequency in Hz. Note that there may be more than one possible mass for a given frequency. For an unknown object you measured [ 0 2 ] Hz , what is the mass of the object ? Suppose that you know that the mass of the unknown object is more than a kilogram.    a)  , b)  , frequency is Hz c)  33.65 kg      Suppose you wish to measure the friction a mass of [ 0 1 ] kg experiences as it slides along a floor ( you wish to find ). You have a spring with spring constant . You take the spring, you attach it to the mass and fix it to a wall. Then you pull on the spring and let the mass go. You find that the mass oscillates with quasi-frequency Hz. What is the friction?           A kg railcar hits a bumper (a spring) at , and the spring compresses by [ 0 1 ] m Assume no damping.   Find . How far does the spring compress when a kg railcar hits the spring at the same speed? If the spring would break if it compresses further than [ 0 3 ] m , what is the maximum mass of a railcar that can hit it at  ?  What is the maximum mass of a railcar that can hit the spring without breaking at  ?      When attached to a spring, a kg mass stretches the spring by [ 0 49 ] m.   What is the spring constant of this spring? Use as the gravity constant. This mass is allowed to come to rest, lifted up by [ 0 4 ] m and then released If there is no damping , set up and solve an initial value problem for the position of the mass as a function of time  For a next experiment , you attach a dampener of coefficient  to the system , and give the same initial condition Set up and solve an initial value problem for the position of the mass What type of ` ` dampening ' ' would be used to characterize this situation ?    a)  N\/m b)  c)  , Underdamped      A mass of kg is on a spring with and . Find the mass for which there is critical damping. If , does the system oscillate or not, that is, is it underdamped or overdamped?      Suppose we have an RLC circuit with a resistor of 100 milliohms (0.1 ohms), inductor of inductance of 50 millihenries (0.05 henries), and a capacitor of 5 farads, with constant voltage.   Set up the ODE equation for the current . Find the general solution. Solve for and .      For RLC circuits, we can use either charge or current to set up the equation. Let’s see how the two of those compare.   Assume that we have an RLC circuit with a 30 millihenry inductor, a 120 milliohm resistor, and a capacitor with capacitance F. Set up a differential equation for the charge on the capacitor as a function of time. Use the same circuit to set up a differential equation for the current through the circuit as a function of time. How do these equations relate? Find the general solution to each of these equations. Solve the initial value problem for the charge with and . Using the fact that , determine the appropriate initial conditions needed for in order to solve for the current in this same setup (with those initial values for charge). Now, we’ll do the same in the other direction. Solve the initial value problem for current with and , and see what the initial conditions would be for for this setup.    a)  b)  c)  d)  e)  , f)  , ,       Assume that the system is either critically or overdamped. Prove that the solution can pass through zero at most once , regardless of initial conditions. Hint: Try to find all values of for which , given the form of the solution.    Overdamped: , Critically Damped      "
},
{
  "id": "free-undamped-motion-3",
  "level": "2",
  "url": "sec-mv.html#free-undamped-motion-3",
  "type": "Checkpoint",
  "number": "2.4.1",
  "title": "",
  "body": "  Justify the identity and verify the equations for and . Hint: Start with and multiply by . Then what should and be?    While it is generally easier to use the first form with and to solve for the initial conditions, the second form is much more natural to use for interpretation of physical systems, since the constants and have nice physical interpretation. Write the solution as This is a pure-frequency oscillation (a sine wave). The is , is the (angular) , and is the so-called . The phase shift just shifts the graph left or right. We call the . This entire setup is called .   "
},
{
  "id": "free-undamped-motion-6",
  "level": "2",
  "url": "sec-mv.html#free-undamped-motion-6",
  "type": "Example",
  "number": "2.4.2",
  "title": ".",
  "body": "    Suppose that and . The whole mass and spring setup is sitting on a truck that was traveling at . The truck crashes and hence stops. The mass was held in place 0.5 meters forward from the rest position. During the crash the mass gets loose. That is, the mass is now moving forward at , while the other end of the spring is held in place. The mass therefore starts oscillating. What is the frequency of the resulting oscillation? What is the amplitude? The units are the mks units (meters-kilograms-seconds).    The setup means that the mass was at half a meter in the positive direction during the crash and relative to the wall the spring is mounted to, the mass was moving forward (in the positive direction) at . This gives us the initial conditions.   3.25in  So the equation with initial conditions is We directly compute . Hence the angular frequency is 2. The usual frequency in Hertz (cycles per second) is .  The general solution is Letting means . Then . Letting we get . Therefore, the amplitude is . The solution is A plot of is shown in .   "
},
{
  "id": "overdamping-6",
  "level": "2",
  "url": "sec-mv.html#overdamping-6",
  "type": "Example",
  "number": "2.4.3",
  "title": ".",
  "body": "    Suppose the mass is released from rest. That is and . Then It is not hard to see that this satisfies the initial conditions.   "
},
{
  "id": "sec-mv-5-2",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-2",
  "type": "Exercise",
  "number": "2.4.4.1",
  "title": "",
  "body": "  Consider a mass and spring system with a mass , spring constant , and damping constant .   Set up and find the general solution of the system. Is the system underdamped, overdamped or critically damped? If the system is not critically damped, find a that makes the system critically damped.    a)  b)  Underdamped c)     "
},
{
  "id": "sec-mv-5-3",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-3",
  "type": "Exercise",
  "number": "2.4.4.2",
  "title": "",
  "body": "  Do for , , and .    a)  b)  Critically Damped   "
},
{
  "id": "sec-mv-5-4",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-4",
  "type": "Exercise",
  "number": "2.4.4.3",
  "title": "",
  "body": "  Using the mks units (meters-kilograms-seconds), suppose you have a spring with spring constant . You want to use it to weigh items. Assume no friction. You place the mass on the spring and put it in motion.   You count and find that the frequency is [ 0 8 ] Hz ( cycles per second ) What is the mass ? ( Be careful with the units here , the frequency is given in cycles per second , not radians per second )  Find a formula for the mass given the frequency in Hz.    a)  6.317 kg b)  .   "
},
{
  "id": "sec-mv-5-5",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-5",
  "type": "Exercise",
  "number": "2.4.4.4",
  "title": "",
  "body": "  A mass of kilograms is on a spring with spring constant newtons per meter with no damping. Suppose the system is at rest and at time the mass is kicked and starts traveling at 2 meters per second. How large does have to be to so that the mass does not go further than 3 meters from the rest position?   "
},
{
  "id": "sec-mv-5-6",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-6",
  "type": "Exercise",
  "number": "2.4.4.5",
  "title": "",
  "body": "  Suppose we add possible friction to . Further, suppose you do not know the spring constant, but you have two reference weights kg and kg to calibrate your setup. You put each in motion on your spring and measure the quasi-frequency. For the kg weight you measured [ 1 1 ] Hz , for the kg weight you measured [ 0 8 ] Hz.   Find (spring constant) and (damping constant). Find a formula for the mass in terms of the frequency in Hz. Note that there may be more than one possible mass for a given frequency. For an unknown object you measured [ 0 2 ] Hz , what is the mass of the object ? Suppose that you know that the mass of the unknown object is more than a kilogram.    a)  , b)  , frequency is Hz c)  33.65 kg   "
},
{
  "id": "sec-mv-5-7",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-7",
  "type": "Exercise",
  "number": "2.4.4.6",
  "title": "",
  "body": "  Suppose you wish to measure the friction a mass of [ 0 1 ] kg experiences as it slides along a floor ( you wish to find ). You have a spring with spring constant . You take the spring, you attach it to the mass and fix it to a wall. Then you pull on the spring and let the mass go. You find that the mass oscillates with quasi-frequency Hz. What is the friction?        "
},
{
  "id": "sec-mv-5-8",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-8",
  "type": "Exercise",
  "number": "2.4.4.7",
  "title": "",
  "body": "  A kg railcar hits a bumper (a spring) at , and the spring compresses by [ 0 1 ] m Assume no damping.   Find . How far does the spring compress when a kg railcar hits the spring at the same speed? If the spring would break if it compresses further than [ 0 3 ] m , what is the maximum mass of a railcar that can hit it at  ?  What is the maximum mass of a railcar that can hit the spring without breaking at  ?   "
},
{
  "id": "sec-mv-5-9",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-9",
  "type": "Exercise",
  "number": "2.4.4.8",
  "title": "",
  "body": "  When attached to a spring, a kg mass stretches the spring by [ 0 49 ] m.   What is the spring constant of this spring? Use as the gravity constant. This mass is allowed to come to rest, lifted up by [ 0 4 ] m and then released If there is no damping , set up and solve an initial value problem for the position of the mass as a function of time  For a next experiment , you attach a dampener of coefficient  to the system , and give the same initial condition Set up and solve an initial value problem for the position of the mass What type of ` ` dampening ' ' would be used to characterize this situation ?    a)  N\/m b)  c)  , Underdamped   "
},
{
  "id": "sec-mv-5-10",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-10",
  "type": "Exercise",
  "number": "2.4.4.9",
  "title": "",
  "body": "  A mass of kg is on a spring with and . Find the mass for which there is critical damping. If , does the system oscillate or not, that is, is it underdamped or overdamped?   "
},
{
  "id": "sec-mv-5-11",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-11",
  "type": "Exercise",
  "number": "2.4.4.10",
  "title": "",
  "body": "  Suppose we have an RLC circuit with a resistor of 100 milliohms (0.1 ohms), inductor of inductance of 50 millihenries (0.05 henries), and a capacitor of 5 farads, with constant voltage.   Set up the ODE equation for the current . Find the general solution. Solve for and .   "
},
{
  "id": "sec-mv-5-12",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-12",
  "type": "Exercise",
  "number": "2.4.4.11",
  "title": "",
  "body": "  For RLC circuits, we can use either charge or current to set up the equation. Let’s see how the two of those compare.   Assume that we have an RLC circuit with a 30 millihenry inductor, a 120 milliohm resistor, and a capacitor with capacitance F. Set up a differential equation for the charge on the capacitor as a function of time. Use the same circuit to set up a differential equation for the current through the circuit as a function of time. How do these equations relate? Find the general solution to each of these equations. Solve the initial value problem for the charge with and . Using the fact that , determine the appropriate initial conditions needed for in order to solve for the current in this same setup (with those initial values for charge). Now, we’ll do the same in the other direction. Solve the initial value problem for current with and , and see what the initial conditions would be for for this setup.    a)  b)  c)  d)  e)  , f)  , ,    "
},
{
  "id": "sec-mv-5-13",
  "level": "2",
  "url": "sec-mv.html#sec-mv-5-13",
  "type": "Exercise",
  "number": "2.4.4.12",
  "title": "",
  "body": "  Assume that the system is either critically or overdamped. Prove that the solution can pass through zero at most once , regardless of initial conditions. Hint: Try to find all values of for which , given the form of the solution.    Overdamped: , Critically Damped    "
},
{
  "id": "sec-nonhom",
  "level": "1",
  "url": "sec-nonhom.html",
  "type": "Section",
  "number": "2.5",
  "title": "Nonhomogeneous equations",
  "body": " Nonhomogeneous equations   Solving nonhomogeneous equations  We have solved linear constant coefficient homogeneous equations. What about nonhomogeneous linear ODEs? For example, the equations for forced mechanical vibrations, where we add a forcing term, which is a function on the right-hand side of the equation. That is, suppose we have an equation such as   We will write , where represents the entire left-hand side of , when the exact form of the operator is not important. We solve in the following manner. First, we find the general solution to the  We call the . Next, we find a single  to in some way (that is the point of this section). Then is the general solution to . We have and . As is a we verify that is a solution, . Let us see why we obtain the general solution.  Let and be two different particular solutions to . Write the difference as . Then plug into the left-hand side of the equation to get Using the operator notation the calculation becomes simpler. As is a linear operator we write So is a solution to , that is . However, we know what all solutions to look like, as this is a homogeneous equation that we have solved previously. Therefore, any two solutions of differ by a solution to the homogeneous equation . The solution includes all solutions to , since is the general solution to the associated homogeneous equation.   Let be a linear ODE (not necessarily constant coefficient). Let be the complementary solution (the general solution to the associated homogeneous equation ) and let be any particular solution to . Then the general solution to is   The moral of the story is that we can find the particular solution in any old way. If we find a different particular solution (by a different method, or simply by guessing), then we still get the same general solution. The formula may look different, and the constants we have to choose to satisfy the initial conditions may be different, but it is the same solution.    Undetermined coefficients  The trick is to somehow, in a smart way, guess one particular solution to . Note that is a polynomial, and the left-hand side of the equation (with all of the derivatives) will still be a polynomial if we let be a polynomial of the same degree. Let us try We plug into the left hand side to obtain So . If we match up the coefficients of in this equation, we get that or . In order for the constant terms to match, we need that . Since we know the value of , this tells us that . That means . Solving the complementary problem (exercise!) we get Hence the general solution to is Now suppose we are further given some initial conditions. For example, and . First find . Then We solve to get and . The particular solution we want is     Check that really solves the equation and the given initial conditions.    Note: A common mistake is to solve for constants using the initial conditions with and only add the particular solution after that. That will not work. You need to first compute and only then solve for the constants using the initial conditions.    A right-hand side consisting of exponentials, sines, and cosines can be handled similarly.      One example of this is     Let us find some . We start by guessing that the solution includes some multiple of . We try Plugging this into the differential equation gives Simplifying this expression gives and we have a problem. Since there is no sine term on the right-hand side, we are forced to pick , which means our non-homogeneous solution is zero, and that’s not good. What happened here? In the previous example, when we differentiated a polynomial (as part of the guess) the function stayed a polynomial, and so we did not add any new types of terms. In this case, however, when we differentiate the cosine term in our guess, it becomes a sine, which we did not have in our initial guess.  Thus, we will also want to add a multiple of to our guess since derivatives of cosine are sines. We try We plug into the equation and we get or The left-hand side must equal to right-hand side. Namely, and . So and . We can solve this system of equations to get that and . So     Similarly, if the right-hand side contains exponentials we try exponentials. If we try as our guess and try to solve for .  When the right-hand side is a multiple of sines, cosines, exponentials, and polynomials, we can use the product rule for differentiation to come up with a guess. We need to guess a form for such that is of the same form, and has all the terms needed to for the right-hand side. For example, For this equation, we guess We plug in and then hopefully get equations that we can solve for , , , , , and . As you can see this can make for a very long and calculation very quickly. C’est !  There is one hiccup in all this. It could be that our guess actually solves the associated homogeneous equation. That is, suppose we have We would love to guess , but if we plug this into the left-hand side of the equation we get There is no way we can choose to make the left-hand side be . The trick in this case is to multiply our guess by to get rid of duplication with the complementary solution. That is first we compute (solution to ) and we note that the term is a duplicate with our desired guess. We modify our guess to so that there is no duplication anymore. Let us try: and , so Thus is supposed to equal . Hence, and so . We can now write the general solution as   Notice that the term of the form does not show up on the left-hand side after differentiating the equation, and the only term that survives is the term that showed up from the derivatives. This works out because solves the homogeneous problem. With that though, make sure to remember to include the when you write out the general solution at the end of the problem, because it does appear there.  It is possible that multiplying by does not get rid of all duplication. For example, The complementary solution is . Guessing would not get us anywhere. In this case we want to guess . Basically, we want to multiply our guess by until all duplication is gone. But no more! Multiplying too many times will not work (in that case, the derivatives won’t actually get down to the plain term that you need in order to solve the problem).  Finally, what if the right-hand side has several terms, such as In this case we find that solves and that solves (that is, do each term separately). Then note that if , then . This is because is linear; we have .  To summarize all of this, we can make a table of the different guesses we should make given the form of the right hand side.       Right hand side  Guess                       If there is a product of above terms, guess the product of the guesses. So, for a right hand side of , the guess should be , and for a right hand side of , the guess should be .    If any part solves the homogeneous problem, multiply that entire component by until nothing does.        Find the solution to the initial value problem     To start this problem, we look for the solution to the homogeneous problem. The characteristic equation for the left hand side is , which factors as . Therefore the general solution to the homogeneous problem (or the complementary solution) is   Next, we want to use undetermined coefficients to solve the non-homogeneous problem. Note that we have to wait until after this part to meet the initial conditions. Since our right-hand side is , we need to guess two components for the two different terms in this function. For the first term, we would want to guess , but this function solves the homogeneous problem. Therefore, we need to multiply by to use as our guess. For the sine term, we need to guess both sine and cosine, so we add to our guess. Therefore, our total guess for the non-homogeneous solution is   We take two derivatives of this function and then plug it into the differential equation so that which can be simplified to Since we want this to equal , this means that we need , so , as well as and . The second of these implies that , or , so that the first equation gives . This implies that so that We can then find as Therefore, the general solution to this non-homogeneous problem is   Now we can look to meet the initial conditions. We want to differentiate this expression to get and then plug zero into both and to get that which gives rise to the system Adding the equations together gives so that and then . Therefore the solution to the initial value problem is       Verify that this solves the initial value problem!      Variation of parameters  The method of undetermined coefficients works for many basic problems that crop up. But it does not work all the time. It only works when the right-hand side of the equation has finitely many linearly independent derivatives, so that we can write a guess that consists of them all. Some equations are a bit tougher. Consider Each new derivative of looks completely different and cannot be written as a linear combination of the previous derivatives. If we start differentiating , we get:   This equation calls for a different method. We present the method of , which handles any equation of the form , provided we can solve certain integrals. For simplicity, we restrict ourselves to second order constant coefficient equations, but the method works for higher order equations just as well (the computations become more ). The method also works for equations with nonconstant coefficients, provided we can solve the associated homogeneous equation.  Perhaps it is best to explain this method by example. Let us try to solve the equation First we find the complementary solution (solution to ). We get , where and . To find a particular solution to the nonhomogeneous equation we try where and are functions and not constants. We are trying to satisfy . That gives us one condition on the functions and . Compute (note the product rule!) We can still impose one more condition at our discretion to simplify computations (we have two unknown functions, so we should be allowed two conditions). We require that . This makes computing the second derivative easier. Since and are solutions to , we find and . (If the equation was a more general , we would have .) So We have and so and hence For to satisfy we must have .  What we need to solve are the two equations (conditions) we imposed on and : We solve for and in terms of , and . We always get these formulas for any , where . There is a general formula for the solution we could just plug into, but instead of memorizing that, it is better, and easier, to just repeat what we do below. In our case the two equations are Hence And thus We integrate and to get and . So our particular solution is The general solution to is, therefore,   In more generality, we can take the system of equations and solve out for and using elimination. If we do that, we get that   We know that solving the equations this way will work out because we start with the assumption that and are linearly independent solutions, and the denominator of both of these fractions is exactly what we know is not zero from this assumption. Therefore, both of these functions can be written this way, we can integrate both of them, and set up our particular solution of the form to get where is any conveniently chosen value (usually zero). Notice the use of as a dummy variable here to separate the functions being integrated from the actual variable that shows up in the solution. This formula will always work for finding a particular solution to a non-homogeneous equation given that we know the solution to the homogeneous equation, but we may not be able to work out the integrals explicitly. This is the downside of this method, it may always work, but can be very tedious and may not result in nice, closed-form expressions like we might get from other methods.      Find the general solution to the differential equation using both undetermined coefficients and variation of parameters.    For both methods of solving non-homogeneous equations, we need the solution to the homogeneous problem. For this equation, the characteristic polynomial is , which factors as , so the general solution to the homogeneous problem is   To use undetermined coefficients, we need to get the appropriate guess for the right-hand side, which in this case is . Plugging this in to the differential equation gives which simplifies to so that and . Thus, the general solution to the non-homogeneous equation is   In order to use variation of parameters, we let and be the two linearly independent solutions that we found to the homogeneous problem. Our right-hand side function is and we can compute the expression   Therefore, we can use the formulas from the method of variation of parameters to compute that Then we can compute Then, we can write out the full general solution as or which, after combining the terms, is the same as the solution that we obtained via undetermined coefficients.      Exercises    Find a particular solution of .           Find a particular solution of .           Find a particular solution to       Solve the initial value problem for , .           Set up the form of the particular solution but do not solve for the coefficients for .           Set up the form of the particular solution but do not solve for the coefficients for .           Solve , , .      Use the method of undetermined coefficients to solve the DE .            Using variation of parameters find a particular solution of . Find a particular solution using undetermined coefficients. Are the two solutions you found the same? See also .             Find a particular solution to . Find the general solution.      Find the general solution to .           Find the general solution to .           Find the general solution to .           Find the general solution to .           Find the general solution to using variation of parameters.           Find the solution of the initial value problem , , .           Find the solution of the initial value problem , , .           The following differential equations are all related. Find the general solution to each of them and compare and contrast the different solutions and the methods used to approach them.           a)  b)  c)  d)        The following differential equations are all related. Find the general solution to each of them and compare and contrast the different solutions and the methods used to approach them.           a)  b)  c)  d)        Find a particular solution of . It is OK to leave the answer as a definite integral.           Use variation of parameters to find a particular solution of .      Recall that a homogeneous is one of the form and is solved by using the guess and solving for the potential values of .   Solve . Let and be a fundamental set for the above equation. Use the variation of parameters equations , to solve the non-homogeneous equation . (Do not attempt method of undetermined coefficients instead; it won’t work.)    a)  b)        For an arbitrary constant find the general solution to .      For an arbitrary constant find a particular solution to . Hint: Make sure to handle every possible real .     : ,   : ,   :          Using variation of parameters find a particular solution of . Find a particular solution using undetermined coefficients. Are the two solutions you found the same? What is going on?    a)  b)  c) They differ by a term     "
},
{
  "id": "undetermined-coefficients-3",
  "level": "2",
  "url": "sec-nonhom.html#undetermined-coefficients-3",
  "type": "Checkpoint",
  "number": "2.5.1",
  "title": "",
  "body": "  Check that really solves the equation and the given initial conditions.    Note: A common mistake is to solve for constants using the initial conditions with and only add the particular solution after that. That will not work. You need to first compute and only then solve for the constants using the initial conditions.   "
},
{
  "id": "undetermined-coefficients-5",
  "level": "2",
  "url": "sec-nonhom.html#undetermined-coefficients-5",
  "type": "Example",
  "number": "2.5.2",
  "title": ".",
  "body": "    One example of this is     Let us find some . We start by guessing that the solution includes some multiple of . We try Plugging this into the differential equation gives Simplifying this expression gives and we have a problem. Since there is no sine term on the right-hand side, we are forced to pick , which means our non-homogeneous solution is zero, and that’s not good. What happened here? In the previous example, when we differentiated a polynomial (as part of the guess) the function stayed a polynomial, and so we did not add any new types of terms. In this case, however, when we differentiate the cosine term in our guess, it becomes a sine, which we did not have in our initial guess.  Thus, we will also want to add a multiple of to our guess since derivatives of cosine are sines. We try We plug into the equation and we get or The left-hand side must equal to right-hand side. Namely, and . So and . We can solve this system of equations to get that and . So    "
},
{
  "id": "undetermined-coefficients-13",
  "level": "2",
  "url": "sec-nonhom.html#undetermined-coefficients-13",
  "type": "Table",
  "number": "2.5.3",
  "title": "",
  "body": "    Right hand side  Guess                    "
},
{
  "id": "undetermined-coefficients-15",
  "level": "2",
  "url": "sec-nonhom.html#undetermined-coefficients-15",
  "type": "Example",
  "number": "2.5.4",
  "title": ".",
  "body": "    Find the solution to the initial value problem     To start this problem, we look for the solution to the homogeneous problem. The characteristic equation for the left hand side is , which factors as . Therefore the general solution to the homogeneous problem (or the complementary solution) is   Next, we want to use undetermined coefficients to solve the non-homogeneous problem. Note that we have to wait until after this part to meet the initial conditions. Since our right-hand side is , we need to guess two components for the two different terms in this function. For the first term, we would want to guess , but this function solves the homogeneous problem. Therefore, we need to multiply by to use as our guess. For the sine term, we need to guess both sine and cosine, so we add to our guess. Therefore, our total guess for the non-homogeneous solution is   We take two derivatives of this function and then plug it into the differential equation so that which can be simplified to Since we want this to equal , this means that we need , so , as well as and . The second of these implies that , or , so that the first equation gives . This implies that so that We can then find as Therefore, the general solution to this non-homogeneous problem is   Now we can look to meet the initial conditions. We want to differentiate this expression to get and then plug zero into both and to get that which gives rise to the system Adding the equations together gives so that and then . Therefore the solution to the initial value problem is    "
},
{
  "id": "undetermined-coefficients-16",
  "level": "2",
  "url": "sec-nonhom.html#undetermined-coefficients-16",
  "type": "Checkpoint",
  "number": "2.5.5",
  "title": "",
  "body": "  Verify that this solves the initial value problem!   "
},
{
  "id": "variation-of-parameters-8",
  "level": "2",
  "url": "sec-nonhom.html#variation-of-parameters-8",
  "type": "Example",
  "number": "2.5.6",
  "title": ".",
  "body": "    Find the general solution to the differential equation using both undetermined coefficients and variation of parameters.    For both methods of solving non-homogeneous equations, we need the solution to the homogeneous problem. For this equation, the characteristic polynomial is , which factors as , so the general solution to the homogeneous problem is   To use undetermined coefficients, we need to get the appropriate guess for the right-hand side, which in this case is . Plugging this in to the differential equation gives which simplifies to so that and . Thus, the general solution to the non-homogeneous equation is   In order to use variation of parameters, we let and be the two linearly independent solutions that we found to the homogeneous problem. Our right-hand side function is and we can compute the expression   Therefore, we can use the formulas from the method of variation of parameters to compute that Then we can compute Then, we can write out the full general solution as or which, after combining the terms, is the same as the solution that we obtained via undetermined coefficients.   "
},
{
  "id": "sec-nonhom-5-2",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-2",
  "type": "Exercise",
  "number": "2.5.4.1",
  "title": "",
  "body": "  Find a particular solution of .        "
},
{
  "id": "sec-nonhom-5-3",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-3",
  "type": "Exercise",
  "number": "2.5.4.2",
  "title": "",
  "body": "  Find a particular solution of .        "
},
{
  "id": "sec-nonhom-5-4",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-4",
  "type": "Exercise",
  "number": "2.5.4.3",
  "title": "",
  "body": "  Find a particular solution to    "
},
{
  "id": "sec-nonhom-5-5",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-5",
  "type": "Exercise",
  "number": "2.5.4.4",
  "title": "",
  "body": "  Solve the initial value problem for , .        "
},
{
  "id": "sec-nonhom-5-6",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-6",
  "type": "Exercise",
  "number": "2.5.4.5",
  "title": "",
  "body": "  Set up the form of the particular solution but do not solve for the coefficients for .        "
},
{
  "id": "sec-nonhom-5-7",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-7",
  "type": "Exercise",
  "number": "2.5.4.6",
  "title": "",
  "body": "  Set up the form of the particular solution but do not solve for the coefficients for .        "
},
{
  "id": "sec-nonhom-5-8",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-8",
  "type": "Exercise",
  "number": "2.5.4.7",
  "title": "",
  "body": "  Solve , , .   "
},
{
  "id": "sec-nonhom-5-9",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-9",
  "type": "Exercise",
  "number": "2.5.4.8",
  "title": "",
  "body": "  Use the method of undetermined coefficients to solve the DE .        "
},
{
  "id": "sec-nonhom-5-10",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-10",
  "type": "Exercise",
  "number": "2.5.4.9",
  "title": "",
  "body": "   Using variation of parameters find a particular solution of . Find a particular solution using undetermined coefficients. Are the two solutions you found the same? See also .        "
},
{
  "id": "sec-nonhom-5-11",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-11",
  "type": "Exercise",
  "number": "2.5.4.10",
  "title": "",
  "body": "   Find a particular solution to . Find the general solution.   "
},
{
  "id": "sec-nonhom-5-12",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-12",
  "type": "Exercise",
  "number": "2.5.4.11",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "sec-nonhom-5-13",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-13",
  "type": "Exercise",
  "number": "2.5.4.12",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "sec-nonhom-5-14",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-14",
  "type": "Exercise",
  "number": "2.5.4.13",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "sec-nonhom-5-15",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-15",
  "type": "Exercise",
  "number": "2.5.4.14",
  "title": "",
  "body": "  Find the general solution to .        "
},
{
  "id": "sec-nonhom-5-16",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-16",
  "type": "Exercise",
  "number": "2.5.4.15",
  "title": "",
  "body": "  Find the general solution to using variation of parameters.        "
},
{
  "id": "sec-nonhom-5-17",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-17",
  "type": "Exercise",
  "number": "2.5.4.16",
  "title": "",
  "body": "  Find the solution of the initial value problem , , .        "
},
{
  "id": "sec-nonhom-5-18",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-18",
  "type": "Exercise",
  "number": "2.5.4.17",
  "title": "",
  "body": "  Find the solution of the initial value problem , , .        "
},
{
  "id": "sec-nonhom-5-19",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-19",
  "type": "Exercise",
  "number": "2.5.4.18",
  "title": "",
  "body": "  The following differential equations are all related. Find the general solution to each of them and compare and contrast the different solutions and the methods used to approach them.           a)  b)  c)  d)     "
},
{
  "id": "sec-nonhom-5-20",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-20",
  "type": "Exercise",
  "number": "2.5.4.19",
  "title": "",
  "body": "  The following differential equations are all related. Find the general solution to each of them and compare and contrast the different solutions and the methods used to approach them.           a)  b)  c)  d)     "
},
{
  "id": "sec-nonhom-5-21",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-21",
  "type": "Exercise",
  "number": "2.5.4.20",
  "title": "",
  "body": "  Find a particular solution of . It is OK to leave the answer as a definite integral.        "
},
{
  "id": "sec-nonhom-5-22",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-22",
  "type": "Exercise",
  "number": "2.5.4.21",
  "title": "",
  "body": "  Use variation of parameters to find a particular solution of .   "
},
{
  "id": "sec-nonhom-5-23",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-23",
  "type": "Exercise",
  "number": "2.5.4.22",
  "title": "",
  "body": "  Recall that a homogeneous is one of the form and is solved by using the guess and solving for the potential values of .   Solve . Let and be a fundamental set for the above equation. Use the variation of parameters equations , to solve the non-homogeneous equation . (Do not attempt method of undetermined coefficients instead; it won’t work.)    a)  b)     "
},
{
  "id": "sec-nonhom-5-24",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-24",
  "type": "Exercise",
  "number": "2.5.4.23",
  "title": "",
  "body": "  For an arbitrary constant find the general solution to .   "
},
{
  "id": "sec-nonhom-5-25",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-25",
  "type": "Exercise",
  "number": "2.5.4.24",
  "title": "",
  "body": "  For an arbitrary constant find a particular solution to . Hint: Make sure to handle every possible real .     : ,   : ,   :    "
},
{
  "id": "sec-nonhom-5-26",
  "level": "2",
  "url": "sec-nonhom.html#sec-nonhom-5-26",
  "type": "Exercise",
  "number": "2.5.4.25",
  "title": "",
  "body": "     Using variation of parameters find a particular solution of . Find a particular solution using undetermined coefficients. Are the two solutions you found the same? What is going on?    a)  b)  c) They differ by a term   "
},
{
  "id": "forcedo-section",
  "level": "1",
  "url": "forcedo-section.html",
  "type": "Section",
  "number": "2.6",
  "title": "Forced oscillations and resonance",
  "body": " Forced oscillations and resonance    2.0in2.3in  Let us return back to the example of a mass on a spring. We examine the case of forced oscillations, which we did not yet handle. That is, we consider the equation for some nonzero . The setup is again: is mass, is friction, is the spring constant, and is an external force acting on the mass.  We are interested in periodic forcing, such as noncentered rotating parts, or perhaps loud sounds, or other sources of periodic force.    Undamped forced motion and resonance  First let us consider undamped ( ) motion. We have the equation This equation has the complementary solution (solution to the associated homogeneous equation) where is the (angular). It is the frequency at which the system without external interference.  Suppose that . We try the solution and solve for . We do not need a sine in our trial solution as after plugging in we only have cosines. If you include a sine, it is fine; you will find that its coefficient is zero (I could not find a second rhyme).  We solve using the method of undetermined coefficients. We find that We leave it as an exercise to do the algebra required.  The general solution is Written another way The solution is a superposition of two cosine waves at different frequencies.      Take     Let us compute. First we read off the parameters: , , , . The general solution is    3.25in  Solve for and using the initial conditions: and . Hence   Notice the behavior in . First use the trigonometric identity to get The function is a high frequency wave modulated by a low frequency wave.    The beating behavior can be experienced even more readily by considering a higher frequency and viewing the resulting function as a sound wave. A sound wave of frequency 440 Hz produces and A4 sound, which is the A above middle C on a piano. This means that the function will produce a sound wave equivalent to this A4 sound. In MATLAB, this can be done with the code   omega0 = 440*2*pi; tVals = linspace(0, 5, 5*8192);  testSound = sin(omega0*tVals); sound(testSound);  which will play this pitch for 5 seconds. Now, we want to see what happens if we take a mass-on-a-spring with this natural frequency and apply a forcing function with frequency close to this value. The following code assumes a forcing function of frequency 444 Hz. The multiple of in front of the forcing function is only for scaling purposes; otherwise the resulting sound would be too quiet.   omega = 444*2*pi;  syms ys(t); [V] = odeToVectorField(diff(ys, 2) + omega0^2*ys == omega0*cos(omega*t)); MS = matlabFunction(V, ’vars’, ’t’, ’Y’); soln = ode45(MS, [0,10], [0,0]);  ySound = deval(soln, tVals); ySound = ySound(1, :); sound(ySound);  A graph of the solution ySound can be found in . This exhibits the beating behavior before on a large scale. The sound played during this code also shows the beating or amplitude modulation that can happen in these sorts of solutions. In terms of tuning instruments, these beats are some of the main things musicians will listen for to know if their instrument is close to the right pitch, but just slightly off.    Now suppose . We cannot try the solution and then use the method of undetermined coefficients, since we notice that solves the associated homogeneous equation. Therefore, we try . This time we need the sine term, since the second derivative of contains sines. We write the equation Plugging into the left-hand side we get Hence and . Our particular solution is and our general solution is   The important term is the last one (the particular solution we found). This term grows without bound as . In fact it oscillates between and . The first two terms only oscillate between , which becomes smaller and smaller in proportion to the oscillations of the last term as gets larger. In we see the graph with , , , .   3.25in  By forcing the system in just the right frequency we produce very wild oscillations. This kind of behavior is called or perhaps . Sometimes resonance is desired. For example, remember when as a kid you could start swinging by just moving back and forth on the swing seat in the ? You were trying to achieve resonance. The force of each one of your moves was small, but after a while it produced large swings.  On the other hand resonance can be destructive. In an earthquake some buildings collapse while others may be relatively undamaged. This is due to different buildings having different resonance frequencies. So figuring out the resonance frequency can be very important.  A common (but wrong) example of destructive force of resonance is the Tacoma Narrows bridge failure. It turns out there was a different phenomenon at play K. Billah and R. Scanlan, Resonance, Tacoma Narrows Bridge Failure, and Undergraduate Physics Textbooks , American Journal of Physics, 59(2), 1991, 118–124, http:\/\/www.ketchum.org\/billah\/Billah-Scanlan.pdf  .    Damped forced motion and practical resonance  In real life things are not as simple as they were above. There is, of course, some damping. Our equation becomes for some . We solved the homogeneous problem before. We let We replace equation with The roots of the characteristic equation of the associated homogeneous problem are . The form of the general solution of the associated homogeneous equation depends on the sign of , or equivalently on the sign of , as before: where . In any case, we see that as .  Let us find a particular solution. There can be no conflicts when trying to solve for the undetermined coefficients by trying , because the solution to the homogeneous problem will always have exponential factors (since we have damping) and so there is no where this will exactly match the form of the homogeneous solution. Let us plug in and solve for and . We get (the details are left to reader)   We solve for and : We also compute to be Thus our particular solution is Or in the alternative notation we have amplitude and phase shift where (if ) Hence, If , then , , and .  For reasons we will explain in a moment, we call the and denote it by . We call the from above the and denote it by . The general solution is   The transient solution goes to zero as , as all the terms involve an exponential with a negative exponent. So for large , the effect of is negligible and we see essentially only . Hence the name transient . Notice that involves no arbitrary constants, and the initial conditions only affect . Thus, the effect of the initial conditions is negligible after some period of time. We might as well focus on the steady periodic solution and ignore the transient solution. See for a graph given several different initial conditions.   3.25in  The speed at which goes to zero depends on (and hence ). The bigger is (the bigger is), the becomes negligible. So the smaller the damping, the longer the This is consistent with the observation that when , the initial conditions affect the behavior for all time (i.e. an infinite ).  Let us describe what we mean by resonance when damping is present. Since there were no conflicts when solving with undetermined coefficient, there is no term that goes to infinity. We look instead at the maximum value of the amplitude of the steady periodic solution. Let be the amplitude of . If we plot as a function of (with all other parameters fixed), we can find its maximum. We call the that achieves this maximum the . We call the maximal amplitude the . Thus when damping is present we talk of rather than pure resonance. A sample plot for three different values of is given in . As you can see the practical resonance amplitude grows as damping gets smaller, and practical resonance can disappear altogether when damping is large.    The main takeaways from is that the amplitude can be larger than 1, which is the idea of resonance in this case. Based on Hooke’s law, we know that a constant force of magnitude will stretch (or compress) a spring with constant a length of . If we take and , as is done in , then the resulting magnitude should be . However, if we don’t use a constant force of magnitude , but instead use an oscillatory force with frequency of the form , we get an amplitude of . This graph indicates how the forcing frequency changes the amplitude of the resulting oscillation. Since the amplitude should be based on , if , then the frequency chosen is causing an increase in the amplitude, which is the idea of practical resonance.  To find the maximum, or determine if there is a maximum, we need to find the derivative . Computation shows This is zero either when or when . In other words, when If is positive, then there is a positive value of , namely where the amplitude attains a maximum value. Since we know that the amplitude is or when , the maximum will be larger than this. As described above, this value, is the expected amplitude, that is, the amplitude you would get with no oscillation, so that if the amplitude is larger than this for some value of , this means that the oscillation at frequency is resonating with the system to create a larger oscillation. This is the idea of . It is practical because there is damping, so the situation is more physically relevant (to contrast with pure resonance), and still results in larger amplitudes of oscillation.  Our previous work indicates that a system will exhibit practical resonance for some values of whenever is positive, and the frequency where the amplitude hits the maximum value is at . This follows by the first derivative test for example as then for small in this case. If on the other hand is not positive, then achieves its maximum at , and there is no practical resonance since we assume in our system. In this case the amplitude gets larger as the forcing frequency gets smaller.  If practical resonance occurs, the peak frequency is smaller than . As the damping (and hence ) becomes smaller, the peak practical resonance frequency goes to . So when damping is very small, is a good estimate of the peak practical resonance frequency. This behavior agrees with the observation that when , then is the resonance frequency.  Another interesting observation to make is that when , then . This means that if the forcing frequency gets too high it does not manage to get the mass moving in the mass-spring system. This is quite reasonable intuitively. If we wiggle back and forth really fast while sitting on a swing, we will not get it moving at all, no matter how forceful. Fast vibrations just cancel each other out before the mass has any chance of responding by moving one way or the other.  The behavior is more complicated if the forcing function is not an exact cosine wave, but for example a . A general periodic function will be the sum (superposition) of many cosine waves of different frequencies. The reader is encouraged to come back to this section once we have learned about the ideas of Fourier series.    Exercises    Write as a product of two sine functions.           Write as a product of two sine functions.           Write as a product of two sine functions.           Derive a formula for if the equation is . Assume .           Derive a formula for if the equation is . Assume .            Derive a formula for for , where is some constant. Assume .      Take . Fix , , and . Consider the function . For what values of (solve in terms of , , and ) will there be no practical resonance (that is, for what values of is there no maximum of for )?           Take . Fix , , and . Consider the function . For what values of (solve in terms of , , and ) will there be no practical resonance (that is, for what values of is there no maximum of for )?           A mass of kg on a spring with and a damping constant . Suppose that . Using forcing function , find the that causes the maximum amount of practical resonance and find the amplitude.      An infant is bouncing in a spring chair. The infant has a mass of kg, and the chair functions as a spring with spring constant . The bouncing of the infant applies a force of the form for some frequency . Assume that the infant starts at rest at the equilibrium position of the chair.   If there is no dampening coefficient, what frequency would the infant need to force at in order to generate pure resonance? Assume that the chair is built with a dampener with coefficient . Set up an initial value problem for this situation if the child behaves in the same way. Solve this initial value problem. There are several options for chairs you can buy. There is the one with dampening coefficient , one with , and one with . Which of these would be most fun for the infant? How do you know?    a)  rad\/s or Hz b)  , c)  d) 1 is bouncier      A water tower in an earthquake acts as a mass-spring system. Assume that the container on top is full and the water does not move around. The container then acts as the mass and the support acts as the spring, where the induced vibrations are horizontal. The container with water has a mass of . It takes a force of 1000 newtons to displace the container 1 meter. For simplicity assume no friction. When the earthquake hits the water tower is at rest (it is not moving). The earthquake induces an external force .   What is the natural frequency of the water tower? If is not the natural frequency, find a formula for the maximal amplitude of the resulting oscillations of the water container (the maximal deviation from the rest position). The motion will be a high frequency wave modulated by a low frequency wave, so simply find the constant in front of the sines. Suppose and an earthquake with frequency 0.5 cycles per second comes. What is the amplitude of the oscillations? Suppose that if the water tower moves more than 1.5 meter from the rest position, the tower collapses. Will the tower collapse?    a)  b)  c) Yes      Suppose there is no damping in a mass and spring system with , , and . Suppose is chosen to be precisely the resonance frequency.   Find . Find the amplitude of the oscillations at time , given the system is at rest at .      Assume that a 2 kg mass is attached to a spring that is acted on by a forcing function . Assume that there is no dampening on the spring.   What should the spring constant be in order for this system to exhibit pure resonance? If we wanted the system to exhibit practical resonance instead, what do or can we change about it to get this? Assume that we set to be the value determined in (a), and that the rest of the problem is situated so that the system exhibits practical resonance. What would we expect to see for the amplitude of the solution? This should be a generic comment, not a specific value.    a)  8 N\/m b)  Add a small amount of damping (needs ) and keep close to 8 N\/m c) Larger than .      Assume that we have a mass-on-a-spring system defined by the equation    Identify the mass, dampening coefficient, and spring constant for the system. Use the entire equation to find the natural frequency, forcing frequency, and quasi-frequency of this oscillation. Two of these frequencies will show up in the general solution to this problem. Which are they, and in which part (transient, steady-periodic) do they appear? Find the general solution of this problem.    a)  kg, Ns\/m, N\/m b) Natural is rad\/s, Forcing is rad\/s, Quasi-frequency is rad\/s c) Quasifrequency is in the transient, and forcing is in steady periodic. d)        A circuit is built with an Henry inductor, and Ohm resistor, and a Farad capacitor. All of the units are correct, but you do not know any of their values. To study this circuit, you apply an external voltage source of , and the circuit starts with no initial charge or current.   Write an initial value problem to model this situation. Your friend (who knows more about this circuit than you do) takes a reading from this circuit after it is running and says The amplitude of the charge oscillation is greater than 100 coulombs, which means this circuit is exhibiting practical resonance. There are three facts that you can learn about this circuit from the statement here that will tell you about the values of , , and .     This statement seems to imply that the expected amplitude of the oscillation is 100 coulombs. What does this mean about the value of ?    Your friend says that this circuit is in practical resonance. What does this tell you about the value of in this case?    Finally, being in practical resonance says something about how the forcing frequency compares to the natural frequency of this system. What is that, and how does it relate to the value of ?     What is the frequency of the steady-periodic oscillation that your friend mentioned above?    a)  b)  (i) F, (ii) but small, (iii) c)       "
},
{
  "id": "undamped-forced-motion-and-resonance-6",
  "level": "2",
  "url": "forcedo-section.html#undamped-forced-motion-and-resonance-6",
  "type": "Example",
  "number": "2.6.1",
  "title": ".",
  "body": "    Take     Let us compute. First we read off the parameters: , , , . The general solution is    3.25in  Solve for and using the initial conditions: and . Hence   Notice the behavior in . First use the trigonometric identity to get The function is a high frequency wave modulated by a low frequency wave.   "
},
{
  "id": "forcedo-section-5-2",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-2",
  "type": "Exercise",
  "number": "2.6.3.1",
  "title": "",
  "body": "  Write as a product of two sine functions.        "
},
{
  "id": "forcedo-section-5-3",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-3",
  "type": "Exercise",
  "number": "2.6.3.2",
  "title": "",
  "body": "  Write as a product of two sine functions.        "
},
{
  "id": "forcedo-section-5-4",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-4",
  "type": "Exercise",
  "number": "2.6.3.3",
  "title": "",
  "body": "  Write as a product of two sine functions.        "
},
{
  "id": "forcedo-section-5-5",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-5",
  "type": "Exercise",
  "number": "2.6.3.4",
  "title": "",
  "body": "  Derive a formula for if the equation is . Assume .        "
},
{
  "id": "forcedo-section-5-6",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-6",
  "type": "Exercise",
  "number": "2.6.3.5",
  "title": "",
  "body": "  Derive a formula for if the equation is . Assume .         "
},
{
  "id": "forcedo-section-5-7",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-7",
  "type": "Exercise",
  "number": "2.6.3.6",
  "title": "",
  "body": "  Derive a formula for for , where is some constant. Assume .   "
},
{
  "id": "forcedo-section-5-8",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-8",
  "type": "Exercise",
  "number": "2.6.3.7",
  "title": "",
  "body": "  Take . Fix , , and . Consider the function . For what values of (solve in terms of , , and ) will there be no practical resonance (that is, for what values of is there no maximum of for )?        "
},
{
  "id": "forcedo-section-5-9",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-9",
  "type": "Exercise",
  "number": "2.6.3.8",
  "title": "",
  "body": "  Take . Fix , , and . Consider the function . For what values of (solve in terms of , , and ) will there be no practical resonance (that is, for what values of is there no maximum of for )?        "
},
{
  "id": "forcedo-section-5-10",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-10",
  "type": "Exercise",
  "number": "2.6.3.9",
  "title": "",
  "body": "  A mass of kg on a spring with and a damping constant . Suppose that . Using forcing function , find the that causes the maximum amount of practical resonance and find the amplitude.   "
},
{
  "id": "forcedo-section-5-11",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-11",
  "type": "Exercise",
  "number": "2.6.3.10",
  "title": "",
  "body": "  An infant is bouncing in a spring chair. The infant has a mass of kg, and the chair functions as a spring with spring constant . The bouncing of the infant applies a force of the form for some frequency . Assume that the infant starts at rest at the equilibrium position of the chair.   If there is no dampening coefficient, what frequency would the infant need to force at in order to generate pure resonance? Assume that the chair is built with a dampener with coefficient . Set up an initial value problem for this situation if the child behaves in the same way. Solve this initial value problem. There are several options for chairs you can buy. There is the one with dampening coefficient , one with , and one with . Which of these would be most fun for the infant? How do you know?    a)  rad\/s or Hz b)  , c)  d) 1 is bouncier   "
},
{
  "id": "forcedo-section-5-12",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-12",
  "type": "Exercise",
  "number": "2.6.3.11",
  "title": "",
  "body": "  A water tower in an earthquake acts as a mass-spring system. Assume that the container on top is full and the water does not move around. The container then acts as the mass and the support acts as the spring, where the induced vibrations are horizontal. The container with water has a mass of . It takes a force of 1000 newtons to displace the container 1 meter. For simplicity assume no friction. When the earthquake hits the water tower is at rest (it is not moving). The earthquake induces an external force .   What is the natural frequency of the water tower? If is not the natural frequency, find a formula for the maximal amplitude of the resulting oscillations of the water container (the maximal deviation from the rest position). The motion will be a high frequency wave modulated by a low frequency wave, so simply find the constant in front of the sines. Suppose and an earthquake with frequency 0.5 cycles per second comes. What is the amplitude of the oscillations? Suppose that if the water tower moves more than 1.5 meter from the rest position, the tower collapses. Will the tower collapse?    a)  b)  c) Yes   "
},
{
  "id": "forcedo-section-5-13",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-13",
  "type": "Exercise",
  "number": "2.6.3.12",
  "title": "",
  "body": "  Suppose there is no damping in a mass and spring system with , , and . Suppose is chosen to be precisely the resonance frequency.   Find . Find the amplitude of the oscillations at time , given the system is at rest at .   "
},
{
  "id": "forcedo-section-5-14",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-14",
  "type": "Exercise",
  "number": "2.6.3.13",
  "title": "",
  "body": "  Assume that a 2 kg mass is attached to a spring that is acted on by a forcing function . Assume that there is no dampening on the spring.   What should the spring constant be in order for this system to exhibit pure resonance? If we wanted the system to exhibit practical resonance instead, what do or can we change about it to get this? Assume that we set to be the value determined in (a), and that the rest of the problem is situated so that the system exhibits practical resonance. What would we expect to see for the amplitude of the solution? This should be a generic comment, not a specific value.    a)  8 N\/m b)  Add a small amount of damping (needs ) and keep close to 8 N\/m c) Larger than .   "
},
{
  "id": "forcedo-section-5-15",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-15",
  "type": "Exercise",
  "number": "2.6.3.14",
  "title": "",
  "body": "  Assume that we have a mass-on-a-spring system defined by the equation    Identify the mass, dampening coefficient, and spring constant for the system. Use the entire equation to find the natural frequency, forcing frequency, and quasi-frequency of this oscillation. Two of these frequencies will show up in the general solution to this problem. Which are they, and in which part (transient, steady-periodic) do they appear? Find the general solution of this problem.    a)  kg, Ns\/m, N\/m b) Natural is rad\/s, Forcing is rad\/s, Quasi-frequency is rad\/s c) Quasifrequency is in the transient, and forcing is in steady periodic. d)     "
},
{
  "id": "forcedo-section-5-16",
  "level": "2",
  "url": "forcedo-section.html#forcedo-section-5-16",
  "type": "Exercise",
  "number": "2.6.3.15",
  "title": "",
  "body": "  A circuit is built with an Henry inductor, and Ohm resistor, and a Farad capacitor. All of the units are correct, but you do not know any of their values. To study this circuit, you apply an external voltage source of , and the circuit starts with no initial charge or current.   Write an initial value problem to model this situation. Your friend (who knows more about this circuit than you do) takes a reading from this circuit after it is running and says The amplitude of the charge oscillation is greater than 100 coulombs, which means this circuit is exhibiting practical resonance. There are three facts that you can learn about this circuit from the statement here that will tell you about the values of , , and .     This statement seems to imply that the expected amplitude of the oscillation is 100 coulombs. What does this mean about the value of ?    Your friend says that this circuit is in practical resonance. What does this tell you about the value of in this case?    Finally, being in practical resonance says something about how the forcing frequency compares to the natural frequency of this system. What is that, and how does it relate to the value of ?     What is the frequency of the steady-periodic oscillation that your friend mentioned above?    a)  b)  (i) F, (ii) but small, (iii) c)     "
},
{
  "id": "sec-hol",
  "level": "1",
  "url": "sec-hol.html",
  "type": "Section",
  "number": "2.7",
  "title": "Higher order linear ODEs",
  "body": " Higher order linear ODEs   hointro  In this section, we will briefly study higher order equations. Equations appearing in applications tend to be second order. Higher order equations do appear from time to time, but generally the world around us is  The basic results about linear ODEs of higher order are essentially the same as for second order equations, with 2 replaced by . The important concept of linear independence is somewhat more complicated when more than two functions are involved. For higher order constant coefficient ODEs, the methods developed are also somewhat harder to apply, but we will not dwell on these complications. It is also possible to use the methods for systems of linear equations from to solve higher order constant coefficient equations.  Let us start with a general homogeneous linear equation    Superposition Suppose , , …, are solutions of the homogeneous equation . Then also solves for arbitrary constants .  In other words, a of solutions to is also a solution to . We also have the existence and uniqueness theorem for nonhomogeneous linear equations.   Existence and uniqueness Suppose through , and are continuous functions on some interval , is a number in , and are constants. The equation has exactly one solution defined on the same interval satisfying the initial conditions     Linear independence  When we had two functions and we said they were linearly independent if one was not the multiple of the other. Same idea holds for functions. In this case, it is easier to state as follows. The functions , , …, are if the equation has only the trivial solution , where the equation must hold for all . If we can solve equation with some constants where for example , then we can solve for as a linear combination of the others. If the functions are not linearly independent, they are .      Show that are linearly independent.    Let us give several ways to show this fact. Many textbooks (including and ) introduce Wronskians for higher order equations, but it is harder to analyze them without tools from linear algebra (see ). Once there are more than two functions involved, there is not a nice, simple formula for the Wronskian (like for two functions) and linear algebra is required to analyze what is happening here. Instead, we will take a slightly different and more improvized approach to see why these functions are linearly independent.  Let us write down We use rules of exponentials and write . Hence and . Then we have The left-hand side is a third degree polynomial in . It is either identically zero, or it has at most 3 zeros. Therefore, it is identically zero, , and the functions are linearly independent.  Let us try another way. As before we write This equation has to hold for all . We divide through by to get As the equation is true for all , let . After taking the limit we see that . Hence our equation becomes Rinse, repeat!  How about yet another way. We again write We can evaluate the equation and its derivatives at different values of to obtain equations for , , and . Let us first divide by for simplicity. We set to get the equation . Now differentiate both sides We set to get . We divide by again and differentiate to get . It is clear that is zero. Then must be zero as , and must be zero because .  There is no one best way to do it. All of these methods are perfectly valid. The important thing is to understand why the functions are linearly independent.      Here is the linear algebra method for after reading through that chapter. Let , and . Verify that and use that to determine that these functions are linearly independent by showing that so that this matrix is invertible.        On the other hand, the functions , , and are linearly dependent. Simply apply definition of the hyperbolic cosine: This second form here is a linear combination (coefficients , , and ) of the three functions that adds to zero.      Constant coefficient higher order ODEs  When we have a higher order constant coefficient homogeneous linear equation, the song and dance is exactly the same as it was for second order. We just need to find more solutions. If the equation is order, we need to find linearly independent solutions. It is best seen by example.      Find the general solution to     Try: . We plug in and get We divide through by . Then The trick now is to find the roots. There is a formula for the roots of degree 3 and 4 polynomials but it is very complicated. There is no formula for higher degree polynomials. That does not mean that the roots do not exist. There are always roots for an degree polynomial. They may be repeated and they may be complex. Computers are pretty good at finding roots approximately for reasonable size polynomials.  A good place to start is to plot the polynomial and check where it is zero. We can also simply try plugging in. We just start plugging in numbers and see if we get a hit (we can also try complex numbers). Even if we do not get a hit, we may get an indication of where the root is. For example, we plug into our polynomial and get ; we plug in and get 3. That means there is a root between and , because the sign changed. If we find one root, say , then we know is a factor of our polynomial. Polynomial long division can then be used.  Another technique for guessing roots of polynomials is the Rational Roots Theorem, which says that any rational root of the polynomial must be of the form where divides the constant term of the polynomial and divides the leading term, provided neither of them are zero. For more information on this see . In this case, we would know that must divide , and must divide . Therefore, the only possible options here are and . These would be good places to start to look for rational roots.  A good strategy is to begin with , , or . These are easy to compute. Our polynomial has two such roots, and . There should be 3 roots and the last root is reasonably easy to find. The constant term in a monic The word monic means that the coefficient of the top degree , in our case , is 1. polynomial such as this is the multiple of the negations of all the roots because . So You should check that really is a root. Hence , and are solutions to . They are linearly independent as can easily be checked, and there are 3 of them, which happens to be exactly the number we need. So the general solution is   Another possible way to work out this general solution is by factoring the original polynomial. Since we want to solve we can rewrite the polynomial as which factors as Finally, using difference of two squares on the first factor gives This gives roots of , , and , and so the same general solution as above.  Suppose we were given some initial conditions , , and . Then It is possible to find the solution by high school algebra, but it would be a pain. The sensible way to solve a system of equations such as this is to use matrix algebra, see or . For now we note that the solution is , , and . The specific solution to the ODE is     Next, suppose that we have real roots, but they are repeated. Let us say we have a root repeated times. In the spirit of the second order solution, and for the same reasons, we have the solutions We take a linear combination of these solutions to find the general solution.      Solve     We note that the characteristic equation is By inspection we note that . Hence the roots given with are . Thus the general solution is         Find the general solution of     The characteristic equation for this example is There is no convenient factoring by grouping or other quick formula to get to the roots here. The best hope we have is to try to guess the roots and see if we come up with anything. Once we get one root, we’ll be able to factor a term out and get down to a quadratic equation, where the quadratic formula will give us the other two roots.  The properties of polynomials tell us that all rational roots of this polynomial must be factors of or . Thus, the options are , and . At this point, the best bet is to start guessing and see if we can find one. Let’s start with . Plugging this into the polynomial gives Trying next, we get Therefore, is as root, and so is a factor of this polynomial.  We can then use synthetic (or long) division to see that   For the quadratic, we can either use the quadratic formula, or just recognize that this factors as to get that the characteric equation factors as Therefore, the roots are , and , so that the general solution to the differential equation is     For more information on synthetic division and finding roots of polynomials, see .  The case of complex roots is similar to second order equations. Complex roots always come in pairs . Suppose we have two such complex roots, each repeated times. The corresponding solution is where , …, , , …, are arbitrary constants.      Solve     The characteristic equation is Hence the roots are , both with multiplicity 2. Hence the general solution to the ODE is The way we solved the characteristic equation above is really by guessing or by inspection. It is not so easy in general. We could also have asked a computer or an advanced calculator for the roots.      Non-Homogeneous Equations  Just like for second order equation, we can solve higher order non-homogeneous equations. The theory is the same; if we can find any single solution to the non-homogeneous problem, then the general solution of the non-homogeneous problem is this single solution plus the general solution to the corresponding homogeneous problem. The trick comes down to finding this single solution, and undetermined coefficients is the main method here.  In using undetermined coefficients, the guesses we want to make are the same as for second order equations. The only way it really gets more complicated is that now it is possible for any exponential or trigonometric function to be a solution to the homogeneous problem, and so more things will need to be multiplied by in order to get the appropriate guess for the non-homogeneous solution.      Find the general solution to     We found the general solution of the homogeneous problem in , which is   Now, to solve the non-homogeneous problem, we use the method of undetermined coefficients. Since the non-homogeneous part of the equation has terms of the form and , we would want to guess However, solves the homogeneous problem, so we need to multiply it by , making our actual guess become In order to plug this in, we need to take three derivatives of this guess, which are By putting this into the non-homogeneous equation we want to solve, we get   Simplifying the left hand side of this expression gives   To satisfy this equation, we want to set and . Therefore, the general solution to the non-homogeneous problem is         Determine the form of the guess using undetermined coefficients for finding a particular solution of the non-homogeneous problem     To determine the guess, we need to first find the solution to the homogeneous equations. The characteristic equation of the homogeneous equation is We could use the root guessing method for this example, and all rational roots must be . However, that method is not great for polynomials that are of degree higher than around 3 or 4. So, we’ll want to use some other technique to find all of the root.  If we start by grouping pairs of terms, we can rewrite this polynomial as so that it can be rewritten as The second factor looks a lot like if we take . Since using difference of squares twice. Thus, the entire characteristic equation can be written as Therefore, we have a triple root at , a double root at , and two copies of , which has a root of , corresponding to solutions and . Putting all of this together, the general solution to the homogeneous equation is This has unknown constants in it, which is expected from the ninth order equation.  Now, we need to figure out the appropriate guess for the non-homogeneous solution. Since the non-homogeneous part of the equation is , the base guess would be of the form because we always need to include both and whenever either of them appear. However, we need to factor in what terms show up in the homogeneous solution. For instance, the term has a term with and in the homogeneous solution, we need to include the next one up in our guess for the solution to the non-homogeneous problem. Taking this into account for all terms gives the desired guess as     There is also an extension of variation of parameters to higher order equations. However, the fact that there are more terms in the solution means that the form of the expression is much more complicated that for second order, and is not worth looking into or trying to remember. The easier way to handle these situations using variation of parameters is by converting the higher order equation into a first order system and applying the methods there, which will be covered in and respectively.    Exercises    Find the general solution for .           Find the general solution of .      Find the general solution for .           Find the general solution for .           Suppose the characteristic equation for an ODE is .   Find such a differential equation. Find its general solution.    a)  b)        Suppose that a fourth order equation has a solution .   Find such an equation. Find the initial conditions that the given solution satisfies.    a)  b)  , , ,       Suppose that the characteristic equation of a third order differential equation has roots and 3.   What is the characteristic equation? Find the corresponding differential equation. Find the general solution.      Find the general solution for the equation of .           Find the general solution of       Find the general solution of            Find the general solution of            Find the general solution of            Find the general solution of Hint: Remember, the guess needs to make sure that no terms in it solve the homogeneous equation.           Show that is a solution to . This tells us something about the factorization of the characteristic polynomial of this DE. Factor the characteristic polynomial completely, and solve the DE.           Consider    Show that is a solution of . Find the general solution to . Solve .    b)  c)        Let , , and . Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    No      Let , , and . Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    No      Are , , , linearly independent? If so, show it, if not find a linear combination that works.      Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    Yes. (Hint: How many roots can a polynomial have?)      Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    Yes. Factor out an first.      Are , , linearly independent? If so, show it, if not find a linear combination that works.      Show that is a linearly independent set.    Hint: Try to find the value when they match, and determine that it can’t be all .      Solve , , , .      Could be a solution of a homogeneous DE with constant real coefficients? If so, give the minimum possible order of such a DE, and state which functions must also be solutions. If not, explain why this is impossible.    Yes. Order 6. , , , ,       Find a linear DE with constant real coefficients whose general solution is or explain why there is no such thing.    Not possible.      Find an equation such that is a solution.           Find an equation of minimal order such that , , are solutions.      Find an equation of minimal order such that , , are solutions.           Find a homogeneous DE with general solution           "
},
{
  "id": "linear-independence-3",
  "level": "2",
  "url": "sec-hol.html#linear-independence-3",
  "type": "Example",
  "number": "2.7.1",
  "title": ".",
  "body": "    Show that are linearly independent.    Let us give several ways to show this fact. Many textbooks (including and ) introduce Wronskians for higher order equations, but it is harder to analyze them without tools from linear algebra (see ). Once there are more than two functions involved, there is not a nice, simple formula for the Wronskian (like for two functions) and linear algebra is required to analyze what is happening here. Instead, we will take a slightly different and more improvized approach to see why these functions are linearly independent.  Let us write down We use rules of exponentials and write . Hence and . Then we have The left-hand side is a third degree polynomial in . It is either identically zero, or it has at most 3 zeros. Therefore, it is identically zero, , and the functions are linearly independent.  Let us try another way. As before we write This equation has to hold for all . We divide through by to get As the equation is true for all , let . After taking the limit we see that . Hence our equation becomes Rinse, repeat!  How about yet another way. We again write We can evaluate the equation and its derivatives at different values of to obtain equations for , , and . Let us first divide by for simplicity. We set to get the equation . Now differentiate both sides We set to get . We divide by again and differentiate to get . It is clear that is zero. Then must be zero as , and must be zero because .  There is no one best way to do it. All of these methods are perfectly valid. The important thing is to understand why the functions are linearly independent.   "
},
{
  "id": "linear-independence-4",
  "level": "2",
  "url": "sec-hol.html#linear-independence-4",
  "type": "Checkpoint",
  "number": "2.7.2",
  "title": "",
  "body": "  Here is the linear algebra method for after reading through that chapter. Let , and . Verify that and use that to determine that these functions are linearly independent by showing that so that this matrix is invertible.   "
},
{
  "id": "linear-independence-5",
  "level": "2",
  "url": "sec-hol.html#linear-independence-5",
  "type": "Example",
  "number": "2.7.3",
  "title": ".",
  "body": "    On the other hand, the functions , , and are linearly dependent. Simply apply definition of the hyperbolic cosine: This second form here is a linear combination (coefficients , , and ) of the three functions that adds to zero.   "
},
{
  "id": "constant-coefficient-higher-order-odes-3",
  "level": "2",
  "url": "sec-hol.html#constant-coefficient-higher-order-odes-3",
  "type": "Example",
  "number": "2.7.4",
  "title": ".",
  "body": "    Find the general solution to     Try: . We plug in and get We divide through by . Then The trick now is to find the roots. There is a formula for the roots of degree 3 and 4 polynomials but it is very complicated. There is no formula for higher degree polynomials. That does not mean that the roots do not exist. There are always roots for an degree polynomial. They may be repeated and they may be complex. Computers are pretty good at finding roots approximately for reasonable size polynomials.  A good place to start is to plot the polynomial and check where it is zero. We can also simply try plugging in. We just start plugging in numbers and see if we get a hit (we can also try complex numbers). Even if we do not get a hit, we may get an indication of where the root is. For example, we plug into our polynomial and get ; we plug in and get 3. That means there is a root between and , because the sign changed. If we find one root, say , then we know is a factor of our polynomial. Polynomial long division can then be used.  Another technique for guessing roots of polynomials is the Rational Roots Theorem, which says that any rational root of the polynomial must be of the form where divides the constant term of the polynomial and divides the leading term, provided neither of them are zero. For more information on this see . In this case, we would know that must divide , and must divide . Therefore, the only possible options here are and . These would be good places to start to look for rational roots.  A good strategy is to begin with , , or . These are easy to compute. Our polynomial has two such roots, and . There should be 3 roots and the last root is reasonably easy to find. The constant term in a monic The word monic means that the coefficient of the top degree , in our case , is 1. polynomial such as this is the multiple of the negations of all the roots because . So You should check that really is a root. Hence , and are solutions to . They are linearly independent as can easily be checked, and there are 3 of them, which happens to be exactly the number we need. So the general solution is   Another possible way to work out this general solution is by factoring the original polynomial. Since we want to solve we can rewrite the polynomial as which factors as Finally, using difference of two squares on the first factor gives This gives roots of , , and , and so the same general solution as above.  Suppose we were given some initial conditions , , and . Then It is possible to find the solution by high school algebra, but it would be a pain. The sensible way to solve a system of equations such as this is to use matrix algebra, see or . For now we note that the solution is , , and . The specific solution to the ODE is    "
},
{
  "id": "constant-coefficient-higher-order-odes-5",
  "level": "2",
  "url": "sec-hol.html#constant-coefficient-higher-order-odes-5",
  "type": "Example",
  "number": "2.7.5",
  "title": ".",
  "body": "    Solve     We note that the characteristic equation is By inspection we note that . Hence the roots given with are . Thus the general solution is    "
},
{
  "id": "constant-coefficient-higher-order-odes-6",
  "level": "2",
  "url": "sec-hol.html#constant-coefficient-higher-order-odes-6",
  "type": "Example",
  "number": "2.7.6",
  "title": ".",
  "body": "    Find the general solution of     The characteristic equation for this example is There is no convenient factoring by grouping or other quick formula to get to the roots here. The best hope we have is to try to guess the roots and see if we come up with anything. Once we get one root, we’ll be able to factor a term out and get down to a quadratic equation, where the quadratic formula will give us the other two roots.  The properties of polynomials tell us that all rational roots of this polynomial must be factors of or . Thus, the options are , and . At this point, the best bet is to start guessing and see if we can find one. Let’s start with . Plugging this into the polynomial gives Trying next, we get Therefore, is as root, and so is a factor of this polynomial.  We can then use synthetic (or long) division to see that   For the quadratic, we can either use the quadratic formula, or just recognize that this factors as to get that the characteric equation factors as Therefore, the roots are , and , so that the general solution to the differential equation is    "
},
{
  "id": "constant-coefficient-higher-order-odes-9",
  "level": "2",
  "url": "sec-hol.html#constant-coefficient-higher-order-odes-9",
  "type": "Example",
  "number": "2.7.7",
  "title": ".",
  "body": "    Solve     The characteristic equation is Hence the roots are , both with multiplicity 2. Hence the general solution to the ODE is The way we solved the characteristic equation above is really by guessing or by inspection. It is not so easy in general. We could also have asked a computer or an advanced calculator for the roots.   "
},
{
  "id": "non-homogeneous-equations-4",
  "level": "2",
  "url": "sec-hol.html#non-homogeneous-equations-4",
  "type": "Example",
  "number": "2.7.8",
  "title": ".",
  "body": "    Find the general solution to     We found the general solution of the homogeneous problem in , which is   Now, to solve the non-homogeneous problem, we use the method of undetermined coefficients. Since the non-homogeneous part of the equation has terms of the form and , we would want to guess However, solves the homogeneous problem, so we need to multiply it by , making our actual guess become In order to plug this in, we need to take three derivatives of this guess, which are By putting this into the non-homogeneous equation we want to solve, we get   Simplifying the left hand side of this expression gives   To satisfy this equation, we want to set and . Therefore, the general solution to the non-homogeneous problem is    "
},
{
  "id": "non-homogeneous-equations-5",
  "level": "2",
  "url": "sec-hol.html#non-homogeneous-equations-5",
  "type": "Example",
  "number": "2.7.9",
  "title": ".",
  "body": "    Determine the form of the guess using undetermined coefficients for finding a particular solution of the non-homogeneous problem     To determine the guess, we need to first find the solution to the homogeneous equations. The characteristic equation of the homogeneous equation is We could use the root guessing method for this example, and all rational roots must be . However, that method is not great for polynomials that are of degree higher than around 3 or 4. So, we’ll want to use some other technique to find all of the root.  If we start by grouping pairs of terms, we can rewrite this polynomial as so that it can be rewritten as The second factor looks a lot like if we take . Since using difference of squares twice. Thus, the entire characteristic equation can be written as Therefore, we have a triple root at , a double root at , and two copies of , which has a root of , corresponding to solutions and . Putting all of this together, the general solution to the homogeneous equation is This has unknown constants in it, which is expected from the ninth order equation.  Now, we need to figure out the appropriate guess for the non-homogeneous solution. Since the non-homogeneous part of the equation is , the base guess would be of the form because we always need to include both and whenever either of them appear. However, we need to factor in what terms show up in the homogeneous solution. For instance, the term has a term with and in the homogeneous solution, we need to include the next one up in our guess for the solution to the non-homogeneous problem. Taking this into account for all terms gives the desired guess as    "
},
{
  "id": "sec-hol-6-2",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-2",
  "type": "Exercise",
  "number": "2.7.5.1",
  "title": "",
  "body": "  Find the general solution for .        "
},
{
  "id": "sec-hol-6-3",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-3",
  "type": "Exercise",
  "number": "2.7.5.2",
  "title": "",
  "body": "  Find the general solution of .   "
},
{
  "id": "sec-hol-6-4",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-4",
  "type": "Exercise",
  "number": "2.7.5.3",
  "title": "",
  "body": "  Find the general solution for .        "
},
{
  "id": "sec-hol-6-5",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-5",
  "type": "Exercise",
  "number": "2.7.5.4",
  "title": "",
  "body": "  Find the general solution for .        "
},
{
  "id": "sec-hol-6-6",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-6",
  "type": "Exercise",
  "number": "2.7.5.5",
  "title": "",
  "body": "  Suppose the characteristic equation for an ODE is .   Find such a differential equation. Find its general solution.    a)  b)     "
},
{
  "id": "sec-hol-6-7",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-7",
  "type": "Exercise",
  "number": "2.7.5.6",
  "title": "",
  "body": "  Suppose that a fourth order equation has a solution .   Find such an equation. Find the initial conditions that the given solution satisfies.    a)  b)  , , ,    "
},
{
  "id": "sec-hol-6-8",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-8",
  "type": "Exercise",
  "number": "2.7.5.7",
  "title": "",
  "body": "  Suppose that the characteristic equation of a third order differential equation has roots and 3.   What is the characteristic equation? Find the corresponding differential equation. Find the general solution.   "
},
{
  "id": "sec-hol-6-9",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-9",
  "type": "Exercise",
  "number": "2.7.5.8",
  "title": "",
  "body": "  Find the general solution for the equation of .        "
},
{
  "id": "sec-hol-6-10",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-10",
  "type": "Exercise",
  "number": "2.7.5.9",
  "title": "",
  "body": "  Find the general solution of    "
},
{
  "id": "sec-hol-6-11",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-11",
  "type": "Exercise",
  "number": "2.7.5.10",
  "title": "",
  "body": "  Find the general solution of         "
},
{
  "id": "sec-hol-6-12",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-12",
  "type": "Exercise",
  "number": "2.7.5.11",
  "title": "",
  "body": "  Find the general solution of         "
},
{
  "id": "sec-hol-6-13",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-13",
  "type": "Exercise",
  "number": "2.7.5.12",
  "title": "",
  "body": "  Find the general solution of         "
},
{
  "id": "sec-hol-6-14",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-14",
  "type": "Exercise",
  "number": "2.7.5.13",
  "title": "",
  "body": "  Find the general solution of Hint: Remember, the guess needs to make sure that no terms in it solve the homogeneous equation.        "
},
{
  "id": "sec-hol-6-15",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-15",
  "type": "Exercise",
  "number": "2.7.5.14",
  "title": "",
  "body": "  Show that is a solution to . This tells us something about the factorization of the characteristic polynomial of this DE. Factor the characteristic polynomial completely, and solve the DE.        "
},
{
  "id": "sec-hol-6-16",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-16",
  "type": "Exercise",
  "number": "2.7.5.15",
  "title": "",
  "body": "  Consider    Show that is a solution of . Find the general solution to . Solve .    b)  c)     "
},
{
  "id": "sec-hol-6-17",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-17",
  "type": "Exercise",
  "number": "2.7.5.16",
  "title": "",
  "body": "  Let , , and . Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    No   "
},
{
  "id": "sec-hol-6-18",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-18",
  "type": "Exercise",
  "number": "2.7.5.17",
  "title": "",
  "body": "  Let , , and . Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    No   "
},
{
  "id": "sec-hol-6-19",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-19",
  "type": "Exercise",
  "number": "2.7.5.18",
  "title": "",
  "body": "  Are , , , linearly independent? If so, show it, if not find a linear combination that works.   "
},
{
  "id": "sec-hol-6-20",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-20",
  "type": "Exercise",
  "number": "2.7.5.19",
  "title": "",
  "body": "  Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    Yes. (Hint: How many roots can a polynomial have?)   "
},
{
  "id": "sec-hol-6-21",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-21",
  "type": "Exercise",
  "number": "2.7.5.20",
  "title": "",
  "body": "  Are , , and linearly independent? If so, show it, if not, find a linear combination that works.    Yes. Factor out an first.   "
},
{
  "id": "sec-hol-6-22",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-22",
  "type": "Exercise",
  "number": "2.7.5.21",
  "title": "",
  "body": "  Are , , linearly independent? If so, show it, if not find a linear combination that works.   "
},
{
  "id": "sec-hol-6-23",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-23",
  "type": "Exercise",
  "number": "2.7.5.22",
  "title": "",
  "body": "  Show that is a linearly independent set.    Hint: Try to find the value when they match, and determine that it can’t be all .   "
},
{
  "id": "sec-hol-6-24",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-24",
  "type": "Exercise",
  "number": "2.7.5.23",
  "title": "",
  "body": "  Solve , , , .   "
},
{
  "id": "sec-hol-6-25",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-25",
  "type": "Exercise",
  "number": "2.7.5.24",
  "title": "",
  "body": "  Could be a solution of a homogeneous DE with constant real coefficients? If so, give the minimum possible order of such a DE, and state which functions must also be solutions. If not, explain why this is impossible.    Yes. Order 6. , , , ,    "
},
{
  "id": "sec-hol-6-26",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-26",
  "type": "Exercise",
  "number": "2.7.5.25",
  "title": "",
  "body": "  Find a linear DE with constant real coefficients whose general solution is or explain why there is no such thing.    Not possible.   "
},
{
  "id": "sec-hol-6-27",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-27",
  "type": "Exercise",
  "number": "2.7.5.26",
  "title": "",
  "body": "  Find an equation such that is a solution.        "
},
{
  "id": "sec-hol-6-28",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-28",
  "type": "Exercise",
  "number": "2.7.5.27",
  "title": "",
  "body": "  Find an equation of minimal order such that , , are solutions.   "
},
{
  "id": "sec-hol-6-29",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-29",
  "type": "Exercise",
  "number": "2.7.5.28",
  "title": "",
  "body": "  Find an equation of minimal order such that , , are solutions.        "
},
{
  "id": "sec-hol-6-30",
  "level": "2",
  "url": "sec-hol.html#sec-hol-6-30",
  "type": "Exercise",
  "number": "2.7.5.29",
  "title": "",
  "body": "  Find a homogeneous DE with general solution         "
},
{
  "id": "vecsandmaps-section",
  "level": "1",
  "url": "vecsandmaps-section.html",
  "type": "Section",
  "number": "3.1",
  "title": "Vectors, mappings, and matrices",
  "body": " Vectors, mappings, and matrices   In real life, there is most often more than one variable. We wish to organize dealing with multiple variables in a consistent manner, and in particular organize dealing with linear equations and linear mappings, as those both rather useful and rather easy to handle. Mathematicians joke that And well, they (the engineers) are not wrong. Quite often, solving an engineering problem is figuring out the right finite-dimensional linear problem to solve, which is then solved with some matrix manipulation. Most importantly, linear problems are the ones that we know how to solve, and we have many tools to solve them. For engineers, mathematicians, physicists, and anybody in a technical field it is absolutely vital to learn linear algebra.  As motivation, suppose we wish to solve for and , that is, find numbers and such that the two equations are satisfied. Let us perhaps start by adding the equations together to find In other words, . Once we have that, we plug in into the first equation to find , so . OK, that was easy. What is all this fuss about linear equations. Well, try doing this if you have 5000 unknowns One of the downsides of making everything look like a linear problem is that the number of variables tends to become huge. . Also, we may have such equations not of just numbers, but of functions and derivatives of functions in differential equations. Clearly we need a more systematic way of doing things. A nice consequence of making things systematic and simpler to write down is that it becomes easier to have computers do the work for us. Computers are rather stupid, they do not think, but are very good at doing lots of repetitive tasks precisely, as long as we figure out a systematic way for them to perform the tasks.    Vectors and operations on vectors  Consider real numbers as an -tuple: The set of such -tuples is the so-called -dimensional space , often denoted by . Sometimes we call this the -dimensional  Named after the ancient Greek mathematician Euclid of Alexandria (around 300 BC), possibly the most famous of mathematicians; even small towns often have Euclid Street or Euclid Avenue. . In two dimensions, is called the  Named after the French mathematician René Descartes (1596–1650). It is as his name in Latin is Renatus Cartesius. , and in three dimensions, it is the same that is dealt with in multivariable calculus. Each such -tuple represents a point in the -dimensional space. For example, the point in the plane is one unit to the right and two units up from the origin.  When we do algebra with these -tuples of numbers we call them vectors A common notation to distinguish vectors from points is to write for the point and for the vector. We write both as . . Mathematicians are keen on separating what is a vector and what is a point of the space or in the plane, and it turns out to be an important distinction, however, for the purposes of linear algebra we can think of everything being represented by a vector. A way to think of a vector, which is especially useful in calculus and differential equations, is an arrow. It is an object that has a and a magnitude . For example, the vector is the arrow from the origin to the point in the plane. The magnitude is the length of the arrow. See . If we think of vectors as arrows, the arrow doesn’t always have to start at the origin. If we do move it around, however, it should always keep the same direction and the same magnitude.    As vectors are arrows, when we want to give a name to a vector, we draw a little arrow above it: Another popular notation is , although we will use the little arrows. It may be easy to write a bold letter in a book, but it is not so easy to write it by hand on paper or on the board. Mathematicians often don’t even write the arrows. A mathematician would write and just remember that is a vector and not a number. Just like you remember that Bob is your uncle, and you don’t have to keep repeating and you can just say In this book, however, we will call Bob and write vectors with the little arrows.  The can be computed using Pythagorean theorem. The vector drawn in the figure has magnitude . The magnitude is denoted by , and, in any number of dimensions, it can be computed in the same way:   For reasons that will become clear in the next section, we often write vectors as so-called column vectors : Don’t worry. It is just a different way of writing the same thing, and it will be useful later. For example, the vector can be written as    3.25in  The fact that we write arrows above vectors allows us to write several vectors , , etc., without confusing these with the components of some other vector .  So where is the algebra from linear algebra ? Well, arrows can be added, subtracted, and multiplied by numbers. First we consider addition . If we have two arrows, we simply move along one, and then along the other. See .  It is rather easy to see what it does to the numbers that represent the vectors. Suppose we want to add to as in the figure. So we travel along and then we travel along in the sense of tip-to-tail addition that you may have seen in previous classes. What we did was travel one unit right, two units up, and then we travelled two units right, and three units down (the negative three). That means that we ended up at . And that’s how addition always works:    3.25in   Subtracting is similar. What means visually is that we first travel along , and then we travel backwards along . See . It is like adding where is the arrow we obtain by erasing the arrow head from one side and drawing it on the other side, that is, we reverse the direction. In terms of the numbers, we simply go backwards in both directions, so we negate both numbers. For example, if is , then is .  Another intuitive thing to do to a vector is to scale it. We represent this by multiplication of a number with a vector. Because of this, when we wish to distinguish between vectors and numbers, we call the numbers scalars . For example, suppose we want to travel three times further. If the vector is , travelling 3 times further means going 3 units to the right and 6 units up, so we get the vector . We just multiply each number in the vector by 3. If is a number, then Scaling (by a positive number) multiplies the magnitude and leaves direction untouched. The magnitude of is . The magnitude of 3 times , that is, , is .  When the scalar is negative, then when we multiply a vector by it, the vector is not only scaled, but it also switches direction. So multiplying by means we should go 3 times further but in the opposite direction, so 3 units to the left and 6 units down, or in other words, . As we mentioned above, is a reverse of , and this is the same as .  In , you can see a couple of examples of what scaling a vector means visually.    We put all of these operations together to work out more complicated expressions. Let us compute a small example:   As we said a vector is a direction and a magnitude. Magnitude is easy to represent, it is just a number. The is usually given by a vector with magnitude one. We call such a vector a . That is, is a unit vector when . For example, the vectors , , and are all unit vectors.  To represent the direction of a vector , we need to find the unit vector in the same direction. To do so, we simply rescale by the reciprocal of the magnitude, that is , or more concisely .  For example, the unit vector in the direction of is the vector     Linear Combinations and Linear Independence  If we have vectors of a given size (say a collection of 3 component vectors), there are only two different operations we can perform on them; adding them together and multiplying them by real numbers. While this may seem fairly limited, we can take a small number of vectors and generate a lot more vectors from them. By putting these operations together, we get the definition of a linear combination.   Given row or column vectors , a is an expression of the form where are all scalars.  For example, is a linear combination of , , and . Another example is that can be written as a linear combination of ,  , and as   Given any collection of vectors , it is always possible to write as a linear combination of these vectors by choosing for all . Then we are adding a bunch of zeros together and so get zero. However, this may not be the only way to get zero. Whether or not it is depends heavily on the exact vectors involved.   We say the vectors , , …, are if the only way to pick to satisfy is . Otherwise, we say the vectors are .      The vectors and are linearly independent.    Let’s try: So , and then it is clear that as well. In other words, the vectors are linearly independent.    If a set of vectors is linearly dependent, that is, we have an expression of the form with some of the ’s are nonzero, then we can solve for one vector in terms of the others. Suppose . Since , then For example, and so   In particular, this tells us that if two vectors and are linearly dependent, then it must be the case that for some constant , namely where . If this is not the case, then the vectors are linearly independent. For more than two vectors, the process is more complicated and involves solving a system of linear equations, which we will deal with in .    Matrices  The next object we need to define here is a .   In general, an matrix is a rectangular array of numbers, An matrix indicates that it will have rows and columns.  Matrices, just like vectors, are generally written with square brackets on the outside, although some books will use parentheses for this. The convention for notation is that matrices will be denoted by capital letters ( ) and the individual of the matrix, the numbers that make it up, will be denoted using lowercase letters ( ) where the first number indicates which row of the matrix we are talking about, and the second number indicates which column. For example, in the matrix we could talk about the entire matrix usint , but would also have that and .  Note that an matrix is just a column vector, so in terms of the basic structure, matrices are an extension of vectors. However, they can be used for so much more, as we will see in future sections.  Another way to view matrices is as a set of column vectors all laid out side-by-side. If we have , and , three different four component vectors, we can form a matrix as that uses each of the given vectors as a column of the matrix. In this case, the vertical lines are used to indicate that this is actually a matrix, because each of the entries given there are vectors, not just individual numbers. If we wanted to write a matrix this way, these vertical lines will not be included.  We will go into more properties of matrices and the operations we can perform on them in . To conclude this section though, we will look at one other way that matrices come about, and that is as the representation of a linear map.    Linear mappings and matrices  A  is a rule that takes a vector and returns another vector . For example, could be a scaling that doubles the size of vectors: For example, If is a mapping that takes vectors in to (such as the above), we write The words function and mapping are used rather interchangeably, although more often than not, mapping is used when talking about a vector-valued function, and the word function is often used when the function is scalar-valued.  A beginning student of mathematics (and many a seasoned mathematician), that sees an expression such as yearns to write After all, who hasn’t wanted to write or something like that at some point in their mathematical lives. Wouldn’t life be simple if we could do that? Of course we can’t always do that (for example, not with the square roots!) It turns out there are many functions where we can do exactly the above. Such functions are called linear .  A mapping is called linear if for any vectors and , and also for any scalar . The we defined above that doubles the size of all vectors is linear. Let us check: and also   We also call a linear function a linear transformation . If you want to be really fancy and impress your friends, you can call it a linear operator .  When a mapping is linear we often do not write the parentheses. We write simply instead of . We do this because linearity means that the mapping behaves like multiplying by That something is a matrix.  Now how does a matrix relate to a linear mapping? Well a matrix tells you where certain special vectors go. Let’s give a name to those certain vectors. The of are For example, in these vectors are You may recall from calculus of several variables that these are sometimes called , , .  The reason these are called a is that every other vector can be written as a of them. For example, in the vector can be written as Keep this idea of linear combinations of vectors in mind; we’ll see a lot more of it later.  So how does a matrix represent a linear mapping? Well, the columns of the matrix are the vectors where as a linear mapping takes , , etc. For example, consider As a linear mapping takes to and to . In other words,   More generally, if we have an matrix , that is we have rows and columns, then the mapping takes to the column of . For example, represents a mapping from to that does   But what if I have another vector ? Where does it go? Well we use linearity. First write the vector as a linear combination of the standard basis vectors: Then If we know where takes all the basis vectors, we know where it takes all vectors.  As an example, suppose is the matrix from above, and suppose we wish to find   Every linear mapping from to can be represented by an matrix. You just figure out where it takes the standard basis vectors. Conversely, every matrix represents a linear mapping. Hence, we may think of matrices being linear mappings, and linear mappings being matrices.  Or can we? In this book we study mostly linear differential operators, and linear differential operators are linear mappings, although they are not acting on , but on an infinite-dimensional space of functions: for a function we get a function , and is linear in the sense that for any number (scalars) and all functions and .  So the answer is not really. But if we consider vectors in finite-dimensional spaces then yes, every linear mapping is a matrix. We have mentioned at the beginning of this section, that we can That’s not strictly true, but it is true approximately. Those spaces of functions can be approximated by a finite-dimensional space, and then linear operators are just matrices. So approximately, this is true. And as far as actual computations that we can do on a computer, we can work only with finitely many dimensions anyway. If you ask a computer or your calculator to plot a function, it samples the function at finitely many points and then connects the dots In Matlab, you may have noticed that to plot a function, we take a vector of inputs, ask Matlab to compute the corresponding vector of values of the function, and then we ask it to plot the result. . It does not actually give you infinitely many values. So the way that you have been using the computer or your calculator so far has already been a certain approximation of the space of functions by a finite-dimensional space.    Exercises    On a piece of graph paper draw the vectors:   (3)       a)       image   b)     image   c)     image     On a piece of graph paper draw the vector starting at (based at) the given point:   (3) based at based at based at     a)       image   b)     image   c)     image     On a piece of graph paper draw the following operations. Draw and label the vectors involved in the operations as well as the result:   (3)       a)       image   b)     image   c)     image     Compute the magnitude of   (3)       a)  b ) c)        Compute the magnitude of   (3)         Compute   (3)          a) b)  c)  d)  e)  f)        Compute   (3)            Find the unit vector in the direction of the given vector   (3)       a)  b)  c)        Find the unit vector in the direction of the given vector   (3)         If and are added together, we find . What is ?           If and , compute and .     ,       Write as a linear combination of the standard basis vectors , , and .           Determine if the following sets of vectors are linearly independent.   (2)          a) Yes b) No c) No d) No e) Yes f) No      If the magnitude of is 4, what is the magnitude of   (6)          a)  0 b)  12 c)  4 d)  16 e)  8 f)  0      If the magnitude of is 5, what is the magnitude of   (3)         Suppose a linear mapping takes to and it takes to . Where does it take   (3)       a)  b)  c)        Suppose a linear mapping takes to and it takes to and it takes to . Write down the matrix representing the mapping .           Suppose that a mapping takes to , to , and it takes to . Explain why is not linear.           Suppose a linear mapping takes to and it takes to . Where does it take   (3)         Let represent the space of quadratic polynomials in : a point in represents the polynomial . Consider the derivative as a mapping of to , and note that is linear. Write down as a matrix.          "
},
{
  "id": "linear-combinations-and-linear-independence-7",
  "level": "2",
  "url": "vecsandmaps-section.html#linear-combinations-and-linear-independence-7",
  "type": "Example",
  "number": "3.1.1",
  "title": ".",
  "body": "    The vectors and are linearly independent.    Let’s try: So , and then it is clear that as well. In other words, the vectors are linearly independent.   "
},
{
  "id": "vecsandmaps-section-7-2",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-2",
  "type": "Exercise",
  "number": "3.1.5.1",
  "title": "",
  "body": "  On a piece of graph paper draw the vectors:   (3)       a)    "
},
{
  "id": "vecsandmaps-section-7-3",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-3",
  "type": "Figure",
  "number": "3.1.2",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-5",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-5",
  "type": "Figure",
  "number": "3.1.3",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-7",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-7",
  "type": "Figure",
  "number": "3.1.4",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-8",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-8",
  "type": "Exercise",
  "number": "3.1.5.2",
  "title": "",
  "body": "  On a piece of graph paper draw the vector starting at (based at) the given point:   (3) based at based at based at     a)    "
},
{
  "id": "vecsandmaps-section-7-9",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-9",
  "type": "Figure",
  "number": "3.1.5",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-11",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-11",
  "type": "Figure",
  "number": "3.1.6",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-13",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-13",
  "type": "Figure",
  "number": "3.1.7",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-14",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-14",
  "type": "Exercise",
  "number": "3.1.5.3",
  "title": "",
  "body": "  On a piece of graph paper draw the following operations. Draw and label the vectors involved in the operations as well as the result:   (3)       a)    "
},
{
  "id": "vecsandmaps-section-7-15",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-15",
  "type": "Figure",
  "number": "3.1.8",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-17",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-17",
  "type": "Figure",
  "number": "3.1.9",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-19",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-19",
  "type": "Figure",
  "number": "3.1.10",
  "title": "",
  "body": "  image  "
},
{
  "id": "vecsandmaps-section-7-20",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-20",
  "type": "Exercise",
  "number": "3.1.5.4",
  "title": "",
  "body": "  Compute the magnitude of   (3)       a)  b ) c)     "
},
{
  "id": "vecsandmaps-section-7-21",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-21",
  "type": "Exercise",
  "number": "3.1.5.5",
  "title": "",
  "body": "  Compute the magnitude of   (3)      "
},
{
  "id": "vecsandmaps-section-7-22",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-22",
  "type": "Exercise",
  "number": "3.1.5.6",
  "title": "",
  "body": "  Compute   (3)          a) b)  c)  d)  e)  f)     "
},
{
  "id": "vecsandmaps-section-7-23",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-23",
  "type": "Exercise",
  "number": "3.1.5.7",
  "title": "",
  "body": "  Compute   (3)         "
},
{
  "id": "vecsandmaps-section-7-24",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-24",
  "type": "Exercise",
  "number": "3.1.5.8",
  "title": "",
  "body": "  Find the unit vector in the direction of the given vector   (3)       a)  b)  c)     "
},
{
  "id": "vecsandmaps-section-7-25",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-25",
  "type": "Exercise",
  "number": "3.1.5.9",
  "title": "",
  "body": "  Find the unit vector in the direction of the given vector   (3)      "
},
{
  "id": "vecsandmaps-section-7-26",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-26",
  "type": "Exercise",
  "number": "3.1.5.10",
  "title": "",
  "body": "  If and are added together, we find . What is ?        "
},
{
  "id": "vecsandmaps-section-7-27",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-27",
  "type": "Exercise",
  "number": "3.1.5.11",
  "title": "",
  "body": "  If and , compute and .     ,    "
},
{
  "id": "vecsandmaps-section-7-28",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-28",
  "type": "Exercise",
  "number": "3.1.5.12",
  "title": "",
  "body": "  Write as a linear combination of the standard basis vectors , , and .        "
},
{
  "id": "vecsandmaps-section-7-29",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-29",
  "type": "Exercise",
  "number": "3.1.5.13",
  "title": "",
  "body": "  Determine if the following sets of vectors are linearly independent.   (2)          a) Yes b) No c) No d) No e) Yes f) No   "
},
{
  "id": "vecsandmaps-section-7-30",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-30",
  "type": "Exercise",
  "number": "3.1.5.14",
  "title": "",
  "body": "  If the magnitude of is 4, what is the magnitude of   (6)          a)  0 b)  12 c)  4 d)  16 e)  8 f)  0   "
},
{
  "id": "vecsandmaps-section-7-31",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-31",
  "type": "Exercise",
  "number": "3.1.5.15",
  "title": "",
  "body": "  If the magnitude of is 5, what is the magnitude of   (3)      "
},
{
  "id": "vecsandmaps-section-7-32",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-32",
  "type": "Exercise",
  "number": "3.1.5.16",
  "title": "",
  "body": "  Suppose a linear mapping takes to and it takes to . Where does it take   (3)       a)  b)  c)     "
},
{
  "id": "vecsandmaps-section-7-33",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-33",
  "type": "Exercise",
  "number": "3.1.5.17",
  "title": "",
  "body": "  Suppose a linear mapping takes to and it takes to and it takes to . Write down the matrix representing the mapping .        "
},
{
  "id": "vecsandmaps-section-7-34",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-34",
  "type": "Exercise",
  "number": "3.1.5.18",
  "title": "",
  "body": "  Suppose that a mapping takes to , to , and it takes to . Explain why is not linear.        "
},
{
  "id": "vecsandmaps-section-7-35",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-35",
  "type": "Exercise",
  "number": "3.1.5.19",
  "title": "",
  "body": "  Suppose a linear mapping takes to and it takes to . Where does it take   (3)      "
},
{
  "id": "vecsandmaps-section-7-36",
  "level": "2",
  "url": "vecsandmaps-section.html#vecsandmaps-section-7-36",
  "type": "Exercise",
  "number": "3.1.5.20",
  "title": "",
  "body": "  Let represent the space of quadratic polynomials in : a point in represents the polynomial . Consider the derivative as a mapping of to , and note that is linear. Write down as a matrix.        "
},
{
  "id": "matalg-section",
  "level": "1",
  "url": "matalg-section.html",
  "type": "Section",
  "number": "3.2",
  "title": "Matrix algebra",
  "body": " Matrix algebra   One-by-one matrices  Let us motivate what we want to achieve with matrices. What do real-valued linear mappings look like? A linear function of real numbers that you have seen in calculus is of the form However, the properties of linear mappings discussed in the previous section are that Plugging in the definition from above gives that and neither of these match up appropriately, since In order for these to work, we need to have . Therefore, real-valued linear mappings of the real line, linear functions that eat numbers and spit out numbers, are just multiplications by a number.  Consider a mapping defined by multiplying by a number. Let’s call this number . The mapping then takes to . What we can do is to add such mappings. If we have another mapping , then We get a new mapping that multiplies by, well, . If is a mapping that doubles things, , and is a mapping that triples, , then is a mapping that multiplies by , .  Similarly we can compose such mappings, that is, we could apply one and then the other. We take , we run it through the first mapping to get times , then we run through the second mapping . In other words, We just multiply those two numbers. Using our doubling and tripling mappings, if we double and then triple, that is then we obtain . The composition is the mapping that multiplies by . For larger matrices, composition also ends up being a kind of multiplication.    Matrix addition and scalar multiplication  The mappings that multiply numbers by numbers are just matrices. The number above could be written as a matrix . So perhaps we would want to do the same things to all matrices that we did to those matrices at the start of this section above. First, let us add matrices. If we have a matrix and a matrix that are of the same size, say , then they are mappings from to . The mapping should also be a mapping from to , and it should do the following to vectors: It turns out you just add the matrices element-wise: If the entry of is , and the entry of is , then the entry of is . If then Let us illustrate on a more concrete example: Let’s check that this does the right thing to a vector. Let’s use some of the vector algebra that we already know, and regroup things: If we replaced the numbers by letters that would constitute a proof! You’ll notice that we didn’t really have to even compute what the result is to convince ourselves that the two expressions were equal.  If the sizes of the matrices do not match, then addition is not defined. If is and is , then we cannot add these matrices. We don’t know what that could possibly mean.  It is also useful to have a matrix that when added to any other matrix does nothing. This is the zero matrix, the matrix of all zeros: We often denote the zero matrix by without specifying size. We would then just write , where we just assume that is the zero matrix of the same size as .  There are really two things we can multiply matrices by. We can multiply matrices by scalars or we can multiply by other matrices. Let us first consider multiplication by scalars. For a matrix and a scalar we want to be the matrix that accomplishes That is just scaling the result by . If you think about it, scaling every term in by accomplishes just that: If For example,   Let us list some properties of matrix addition and scalar multiplication. Denote by the zero matrix, by , scalars, and by , , matrices. Then: These rules should look very familiar.    Matrix multiplication  As we mentioned above, composition of linear mappings is also a multiplication of matrices. Suppose is an matrix, that is, takes to , and is an matrix, that is, takes to . The composition should work as follows First, a vector in gets taken to the vector in . Then the mapping takes it to the vector in . In other words, the composition should be an matrix. In terms of sizes we should have Notice how the middle size must match.  OK, now we know what sizes of matrices we should be able to multiply, and what the product should be. Let us see how to actually compute matrix multiplication. We start with the so-called (or ) of two vectors. Usually this is a row vector multiplied with a column vector of the same size. Dot product multiplies each pair of entries from the first and the second vector and sums these products. The result is a single number. For example, And similarly for larger (or smaller) vectors. A dot product is really a product of two matrices: a matrix and an matrix resulting in a matrix, that is, a number.  Armed with the dot product we define the . First let us denote by the row of and by the column of . For an matrix and an matrix we can compute the product . The matrix is an matrix whose entry is the dot product For example, given a and a matrix we should end up with a matrix: or with some numbers:   A useful consequence of the definition is that the evaluation for a matrix and a (column) vector is also matrix multiplication. That is really why we think of vectors as column vectors, or matrices. For example, If you look at the last section, that is precisely the last example we gave.  You should stare at the computation of multiplication of matrices and the previous definition of as a mapping for a moment. What we are doing with matrix multiplication is applying the mapping to the columns of . This is usually written as follows. Suppose we write the matrix , where are the columns of . Then for an matrix , The columns of the matrix are the vectors . For example, in , the columns of are This is a very useful way to understand what matrix multiplication is. It should also make it easier to remember how to perform matrix multiplication.  We can go one step farther with this connection. The idea of a of vectors was defined in : for a set of vectors , , ..., , a linear combination of those vectors is a vector of the form for some real numbers , ..., . If we write out the product from the end of the last example, we see Thus, computing the product of a matrix and a vector gives a new vector which is a linear combination of the columns of the matrix, where the coefficients are the entries in the vector. This gives two connections between matrix multiplication and linear independence and linear combinations.     If there is a solution to the vector equation , this means that the vector can be written as a linear combination of the columns of .    If there is a non-zero solution to the equation , then the columns of are linearly dependent, and the solution gives the coefficients necessary to give a linear combination that equals zero.     We’ll see a lot more about this, and how to determine it, in .    Some rules of matrix algebra  For multiplication we want an analogue of a 1. That is, we desire a matrix that just leaves everything as it found it. This analogue is the so-called . The identity matrix is a square matrix with 1s on the main diagonal and zeros everywhere else. It is usually denoted by . For each size we have a different identity matrix and so sometimes we may denote the size as a subscript. For example, the would be the identity matrix Let us see how the matrix works on a smaller example, Multiplication by the identity from the left looks similar, and also does not touch anything.  We have the following rules for matrix multiplication. Suppose that , , are matrices of the correct sizes so that the following make sense. Let denote a scalar (number). Then       Let us demonstrate a couple of these rules. For example, the associative law: and Or how about multiplication by scalars:  and     A multiplication rule you have used since primary school on numbers is quite conspicuously missing for matrices. That is, matrix multiplication is not commutative. Firstly, just because makes sense, it may be that is not even defined. For example, if is , and is , the we can multiply but not .  Even if and are both defined, does not mean that they are equal. For example, take and :     Inverse  A couple of other algebra rules you know for numbers do not quite work on matrices:      does not necessarily imply , even if is not 0.     does not necessarily mean that or .     For example:   To make these rules hold, we do not just need one of the matrices to not be zero, we would need to by a matrix. This is where the comes in.   Suppose that and are matrices such that Then we call the inverse of and we denote by .  If the inverse of exists, then we say is invertible . If is not invertible, we say is singular .  Perhaps not surprisingly, , since if the inverse of is , then the inverse of is .  If is a matrix, then is . That is where the notation comes from. The computation is not nearly as simple when is larger.  The proper formulation of the cancellation rule is:    If is invertible, then implies .   The computation is what you would do in regular algebra with numbers, but you have to be careful never to commute matrices: And similarly for cancellation on the right:    If is invertible, then implies .   The rule says, among other things, that the inverse of a matrix is unique if it exists: If , then is invertible and .  We will see later how to compute an inverse of a matrix in general. For now, let us note that there is a simple formula for the inverse of a matrix   For example: Let’s try it: Just as we cannot divide by every number, not every matrix is invertible. In the case of matrices however we may have singular matrices that are not zero. For example, is a singular matrix. But didn’t we just give a formula for an inverse? Let us try it: We get into a bit of trouble; we are trying to divide by zero.  So a matrix is invertible whenever and otherwise it is singular. The expression is called the determinant and we will look at it more carefully in a later section. There is a similar expression for a square matrix of any size.    Special types of matrices  A simple (and surprisingly useful) type of a square matrix is a so-called . It is a matrix whose entries are all zero except those on the main diagonal from top left to bottom right. For example a diagonal matrix is of the form Such matrices have nice properties when we multiply by them. If we multiply them by a vector, they multiply the entry by . For example, Similarly, when they multiply another matrix from the left, they multiply the row by . For example, On the other hand, multiplying on the right, they multiply the columns: And it is really easy to multiply two diagonal matrices together:   For this last reason, they are easy to invert, you simply invert each diagonal element: Let us check an example It is no wonder that the way we solve many problems in linear algebra (and in differential equations) is to try to reduce the problem to the case of diagonal matrices.  Another type of matrix that has similarly nice properties are matrices. A matrix is upper triangular if all of the entries below the diagonal are zero. For a matrix, an upper triangular matrix looks like where the can be any number. Similarly, a lower triangular matrix is one where all of the entries above the diagonal are zero, or, for a matrix, something that looks like A matrix that is both upper and lower triangular is diagonal, because only the entries on the diagonal can be non-zero.    Transpose  Vectors do not always have to be column vectors, that is just a convention. Swapping rows and columns is from time to time needed. The operation that swaps rows and columns is the so-called . The transpose of is denoted by . Example: So transpose takes an matrix to an matrix.  A key fact about the transpose is that if the product makes sense then also makes sense, at least from the point of view of sizes. In fact, we get precisely the transpose of . That is: For example, It is left to the reader to verify that computing the matrix product on the left and then transposing is the same as computing the matrix product on the right.  If we have a column vector to which we apply a matrix and we transpose the result, then the row vector applies to from the left:   Another place where transpose is useful is when we wish to apply the dot product As a side note, mathematicians write and physicists write . Shhh…don’t tell anyone, but the physicists are probably right on this. to two column vectors: That is the way that one often writes the dot product in software.  We say a matrix is symmetric if . For example, is a symmetric matrix. Notice that a symmetric matrix is always square, that is, . Symmetric matrices have many nice properties Although so far we have not learned enough about matrices to really appreciate them. , and come up quite often in applications.  To end the section, we notice how can be written more succintly. Suppose Then For example,   In other words, you take a row of the matrix, you multiply them by the entries in your vector, you add things up, and that’s the corresponding entry in the resulting vector.    Exercises    Add the following matrices   (2)      a)  b)        Add the following matrices   (2)        Compute   (2)      a)  b)        Compute   (2)        Multiply the following matrices   (2)        a)  b)  c)  d)        Multiply the following matrices   (2)              How must the dimensions of two matrices line up in order to multiply them together? If they can be multiplied, what is the dimension of the product? If is a matrix and the product is a matrix, then what are the dimensions of ? If is a matrix, is it possible to find a matrix so that the product is a matrix? What about a matrix so that the product is a matrix?    a)  Inner dimensions must match, outer give the product. b)  c) not possible, is .      Assume that is a matrix.   What must the dimensions of be in order for the product to be defined? What must the dimensions of be in order for the product to be defined? What about if we want to compute or ?    a)  for any b)  for any c)  Must be       Complete but with being a matrix.    a)  for any b)  for any c)  Must be       Compute the inverse of the given matrices   (4)        a)  b)  c)  d)        Compute the inverse of the given matrices   (4)          Compute the inverse of the given matrices   (3)       a)  b)  c)        Compute the inverse of the given matrices   (3)         Consider the matrices    Compute the products and . Verify that for these matrices , but .           Consider the matrices Verify that and are both equal to zero, but neither of the matrices and are zero.    Yes          Let be a matrix. What dimension does the vector need to be in order for the product to be defined? If this product is defined, what is the dimension of the product ? Let be a matrix. What dimension does the vector need to be in order for the product to be defined? If this product is defined, what is the dimension of the product ?    a)  must be 4 component, is component. b)  must be 3 component, is also component.     "
},
{
  "id": "some-rules-of-matrix-algebra-4",
  "level": "2",
  "url": "matalg-section.html#some-rules-of-matrix-algebra-4",
  "type": "Example",
  "number": "3.2.1",
  "title": ".",
  "body": "    Let us demonstrate a couple of these rules. For example, the associative law: and Or how about multiplication by scalars:  and    "
},
{
  "id": "matalg-section-9-2",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-2",
  "type": "Exercise",
  "number": "3.2.8.1",
  "title": "",
  "body": "  Add the following matrices   (2)      a)  b)     "
},
{
  "id": "matalg-section-9-3",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-3",
  "type": "Exercise",
  "number": "3.2.8.2",
  "title": "",
  "body": "  Add the following matrices   (2)     "
},
{
  "id": "matalg-section-9-4",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-4",
  "type": "Exercise",
  "number": "3.2.8.3",
  "title": "",
  "body": "  Compute   (2)      a)  b)     "
},
{
  "id": "matalg-section-9-5",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-5",
  "type": "Exercise",
  "number": "3.2.8.4",
  "title": "",
  "body": "  Compute   (2)     "
},
{
  "id": "matalg-section-9-6",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-6",
  "type": "Exercise",
  "number": "3.2.8.5",
  "title": "",
  "body": "  Multiply the following matrices   (2)        a)  b)  c)  d)     "
},
{
  "id": "matalg-section-9-7",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-7",
  "type": "Exercise",
  "number": "3.2.8.6",
  "title": "",
  "body": "  Multiply the following matrices   (2)       "
},
{
  "id": "matalg-section-9-8",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-8",
  "type": "Exercise",
  "number": "3.2.8.7",
  "title": "",
  "body": "      How must the dimensions of two matrices line up in order to multiply them together? If they can be multiplied, what is the dimension of the product? If is a matrix and the product is a matrix, then what are the dimensions of ? If is a matrix, is it possible to find a matrix so that the product is a matrix? What about a matrix so that the product is a matrix?    a)  Inner dimensions must match, outer give the product. b)  c) not possible, is .   "
},
{
  "id": "matalg-section-9-9",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-9",
  "type": "Exercise",
  "number": "3.2.8.8",
  "title": "",
  "body": "  Assume that is a matrix.   What must the dimensions of be in order for the product to be defined? What must the dimensions of be in order for the product to be defined? What about if we want to compute or ?    a)  for any b)  for any c)  Must be    "
},
{
  "id": "matalg-section-9-10",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-10",
  "type": "Exercise",
  "number": "3.2.8.9",
  "title": "",
  "body": "  Complete but with being a matrix.    a)  for any b)  for any c)  Must be    "
},
{
  "id": "matalg-section-9-11",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-11",
  "type": "Exercise",
  "number": "3.2.8.10",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (4)        a)  b)  c)  d)     "
},
{
  "id": "matalg-section-9-12",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-12",
  "type": "Exercise",
  "number": "3.2.8.11",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (4)       "
},
{
  "id": "matalg-section-9-13",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-13",
  "type": "Exercise",
  "number": "3.2.8.12",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (3)       a)  b)  c)     "
},
{
  "id": "matalg-section-9-14",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-14",
  "type": "Exercise",
  "number": "3.2.8.13",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (3)      "
},
{
  "id": "matalg-section-9-15",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-15",
  "type": "Exercise",
  "number": "3.2.8.14",
  "title": "",
  "body": "  Consider the matrices    Compute the products and . Verify that for these matrices , but .        "
},
{
  "id": "matalg-section-9-16",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-16",
  "type": "Exercise",
  "number": "3.2.8.15",
  "title": "",
  "body": "  Consider the matrices Verify that and are both equal to zero, but neither of the matrices and are zero.    Yes   "
},
{
  "id": "matalg-section-9-17",
  "level": "2",
  "url": "matalg-section.html#matalg-section-9-17",
  "type": "Exercise",
  "number": "3.2.8.16",
  "title": "",
  "body": "      Let be a matrix. What dimension does the vector need to be in order for the product to be defined? If this product is defined, what is the dimension of the product ? Let be a matrix. What dimension does the vector need to be in order for the product to be defined? If this product is defined, what is the dimension of the product ?    a)  must be 4 component, is component. b)  must be 3 component, is also component.   "
},
{
  "id": "elim-section",
  "level": "1",
  "url": "elim-section.html",
  "type": "Section",
  "number": "3.3",
  "title": "Elimination",
  "body": " Elimination   Linear systems of equations  One application of matrices is to solve systems of linear equations Although perhaps we have this backwards, quite often we solve a linear system of equations to find out something about matrices, rather than vice versa. . Consider the following system of linear equations   There is a systematic procedure called to solve such a system. In this procedure, we attempt to eliminate each variable from all but one equation. We want to end up with equations such as , where we can just read off the answer.  We write a system of linear equations as a matrix equation: The system is written as If we knew the inverse of , then we would be done; we would simply solve the equation: Well, but that is part of the problem, we do not know how to compute the inverse for matrices bigger than . We will see later that to compute the inverse we are really solving for several different . In other words, we will need to do elimination to find . In addition, we may wish to solve even if is not invertible, or perhaps not even square.  Let us return to the equations themselves and see how we can manipulate them. There are a few operations we can perform on the equations that do not change the solution. First, perhaps an operation that may seem stupid, we can swap two equations in : Clearly these new equations have the same solutions . A second operation is that we can multiply an equation by a nonzero number. For example, we multiply the third equation in by 3: Finally we can add a multiple of one equation to another equation. For example, we add 3 times the third equation in to the second equation: The same should still be solutions to the new equations. These were just examples; we did not get any closer to the solution. We must to do these three operations in some more logical manner, but it turns out these three operations suffice to solve every linear equation.  The first thing is to write the equations in a more compact manner. Given we write down the so-called  where the vertical line is just a marker for us to know where the of the equation starts. For example, for the system the augmented matrix is The entire process of elimination, which we will describe, is often applied to any sort of matrix, not just an augmented matrix. Simply think of the matrix as the matrix     Row echelon form and elementary operations  We apply the three operations above to the matrix. We call these the or .   The elementary row operations on a matrix are:     Swap two rows.    Multiply a row by a nonzero number.    Add a multiple of one row to another row.     Note that these are the same three operations that we could do with equations to try to solve them earliner in this section. We run these operations until we get into a state where it is easy to read off the answer, or until we get into a contradiction indicating no solution.  More specifically, we run the operations until we obtain the so-called . Let us call the first (from the left) nonzero entry in each row the . A matrix is in row echelon form if the following conditions are satisfied:     The leading entry in any row is strictly to the right of the leading entry of the row above.    Any zero rows are below all the nonzero rows.    All leading entries are 1. Some books do not require this and allow the entries to be any non-zero number, putting this as a requirement for reduced row echelon form. I like leaving this here because it makes the process of row reduction seem more defined and algorithmic. They are equivalent though and with or without the 1 requirement can be used to answer the same questions.      A matrix is in if furthermore the following condition is satisfied.     All the entries above a leading entry are zero.         The following matrices are in row echelon form. The leading entries are marked: Note that the definition applies to matrices of any size. None of the matrices above are in reduced row echelon form. For example, in the first matrix none of the entries above the second and third leading entries are zero; they are 9, 3, and 5.  The following matrices are in reduced row echelon form. The leading entries are marked:     The procedure we will describe to find a reduced row echelon form of a matrix is called . The first part of it, which obtains a row echelon form, is called or . For some problems, a row echelon form is sufficient, and it is a bit less work to only do this first part.  To attain the row echelon form we work systematically . We go column by column, starting at the first column. We find topmost entry in the first column that is not zero, and we call it the . If there is no nonzero entry we move to the next column. We swap rows to put the row with the pivot as the first row. We divide the first row by the pivot to make the pivot entry be a 1. Now look at all the rows below and subtract the correct multiple of the pivot row so that all the entries below the pivot become zero.  After this procedure we forget that we had a first row (it is now fixed), and we forget about the column with the pivot and all the preceding zero columns. Below the pivot row, all the entries in these columns are just zero. Then we focus on the smaller matrix and we repeat the steps above.  It is best shown by example, so let us go back to the example from the beginning of the section. We keep the vertical line in the matrix, even though the procedure works on any matrix, not just an augmented matrix. We start with the first column and we locate the pivot, in this case the first entry of the first column. We multiply the first row by . We subtract the first row from the second and third row (two elementary operations). We are done with the first column and the first row for now. We almost pretend the matrix doesn’t have the first column and the first row.   OK, look at the second column, and notice that now the pivot is in the third row. We swap rows. And we divide the pivot row by 3. We do not need to subtract anything as everything below the pivot is already zero. We move on, we again start ignoring the second row and second column and focus on We find the pivot, then divide that row by 2: The matrix is now in row echelon form.  The equation corresponding to the last row is . We know and we could substitute it into the first two equations to get equations for and . Then we could do the same thing with , until we solve for all 3 variables. This procedure is called and we can achieve it via elementary operations. We start from the lowest pivot (leading entry in the row echelon form) and subtract the right multiple from the row above to make all the entries above this pivot zero. Then we move to the next pivot and so on. After we are done, we will have a matrix in reduced row echelon form.  We continue our example. Subtract the last row from the first to get The entries above the pivot in the third row is already zero. So we move onto the next pivot, the one in the second row. We subtract this row from the top row to get The matrix is in reduced row echelon form.  If we now write down the equations for , we find In other words, we have solved the system.      Solve the following system of equations using row reduction:     In order to solve this problem, we need to set up the augmented matrix for this system, which is   To carry out the process, we need to get a 1 in the top left corner, then work from there. We multiply the first row by -1 to get   Next, we want to use row 1 to cancel out the and in column 1. To do this, we add three copies of row 1 to row 2, and two copies of row 1 to row 3 to get the augmented matrix   Normally, the next step would be to divide the second row by in order to put a in that pivot spot. However, since both the second and third rows have a in the second column, we can combine these two rows directly without dividing by first. We subtract row 2 from row 3 to get and we can now use this to solve the system. The bottom row says that , so that . The second row says that , since , we have that , so . Finally, the first row of the augmented matrix says that . Plugging in our values for and gives . Therefore, the solution is       Non-unique solutions and inconsistent systems  It is possible that the solution of a linear system of equations is not unique, or that no solution exists. Suppose for a moment that the row echelon form we found was Then the last row gives the equation , or . That is impossible and the equations are . There is no solution to .  On the other hand, if we find a row echelon form of then there is no issue with finding solutions. In fact, we will find way too many. Let us continue with backsubstitution (subtracting 3 times the second row from the first) to find the reduced row echelon form and let’s mark the pivots. The last row is all zeros; it just says and we ignore it. The two remaining equations are Let us solve for the variables that corresponded to the pivots, that is and as there was a pivot in the first column and in the third column: The variable can be anything you wish and we still get a solution. The is called a . There are infinitely many solutions, one for every choice of . For example, if we pick , then , and give a solution. But we also get a solution by picking say , in which case and , or by picking in which case and .  The general idea is that if any row has all zeros in the columns corresponding to the variables, but a nonzero entry in the column corresponding to the right-hand side , then the system is inconsistent and has no solutions. In other words, the system is inconsistent if you find a pivot on the right side of the vertical line drawn in the augmented matrix. Otherwise, the system is consistent, and at least one solution exists.  If the system is consistent:     If every column corresponding to a variable has a pivot element, then the solution is unique.    If there are columns corresponding to variables with no pivot, then those are free variables that can be chosen arbitrarily, and there are infinitely many solutions.     Another way to interpret this idea of free variables is that at the beginning, before you look at the system of equations, all of the variables can be anything, and there are no constraints on them. The equations then give us constraints on these variables, because they give us rules that the variables must satisfy. When we have a row of the augmented matrix that becomes all zeros, it means that the equation that was there is redundant and doesn’t add any constraints to the equations. This may result in an system, which will likely have free variables.      Solve the following two systems of equations, or determine that no solution exists, using row reduction:            For the first of these systems, we will set up the augmented matrix and proceed through the process like normal. The augmented matrix is Since we already have a in the top-left corner of this matrix, we can use it to cancel the entries in the rest of column . We add one copy of row 1 to row 2, and subtract row 1 from row 3 to get the next augmented form matrix as Looking at the matrix here, we see that row 3 is times row 2. Therefore, if we add two copies of row 2 to row 3, we get the augmented matrix Therefore, we have a situation where there are only two pivot columns, and the last row is all zeros. Since there are three variables and column 3 is not a pivot column, we can take as a free variable. If we do that, the second equation tells us that , or, since we are taking as a free variable, we can write . We can then take the first equation, which says that or, by rearranging This means that for any value of , our solution is determined by The use of here is just to separate it from the variable . For example, we could pick , in which case we would get , , .  For the second version of the problem, we again set up the augmented matrix Since the left side matrix part is the same as the previous version, the process of row reducing the matrix is identical to what was done previously. When we carry out this process we get the augmented matrix In this case, we see that the last row corresponds to the equation so these equations are inconsistent and do not have a solution.    The point of the above example is to illustrate the fact that whether or not a system is inconsistent or has free variables in the solution depends on the right-hand side of the equation, even if the left-hand side has the same coefficients. We’ll see more about why this is in .  When , we have a so-called  There is no need to write an augmented matrix in this case. As the elementary operations do not do anything to a zero column, it always stays a zero column. Moreover, always has at least one solution, namely . Such a system is always consistent. It may have other solutions: If you find any free variables, then you get infinitely many solutions. As mentioned in the last section, this is directly connected to linear independence of the columns of . If there are other solutions, then there are other linear combinations that give , and so the columns of are linearly dependent. Otherwise, if there are no such solutions outside of , then the columns of are linearly independent.  How would we determine this fact? We don’t need to include the zero column on the far right, but we can apply the same operations to the matrix alone. In this case, we either get a pivot column in every column for the row echelon form, in which case the only solution is , or we get at least one non-pivot column, which means that there are free variables, implying that non-zero solutions exist. This leads to a first equivalence statement we can make about the solution to homogeneous matrix equations.   Let be a matrix. The following statements are equivalent (meaning if any one of them is true, so are all of the other ones):     The only solution to the matrix equation is .    The row echelon form of has a pivot element in every column.    The reduced row echelon form of is an identity matrix, potentially with rows of zero on the bottom.    The columns of are linearly independent.     The set of solutions of comes up quite often so people give it a name. It is called the or the of . One place where the kernel comes up is invertibility of a square matrix . If the kernel of contains a nonzero vector, then it contains infinitely many vectors (there was a free variable). But then it is impossible to invert , since infinitely many vectors go to , so there is no unique vector that takes to . So if the kernel is nontrivial, that is, if there are any nonzero vectors, in other words, if there are any free variables, or in yet other words, if the row echelon form of has columns without pivots, then is not invertible. We will return to this idea later.    Exercises     Compute the reduced row echelon form for the following matrices:   (4)            a)  b)  c)  d)  e)  f)  g)  h)        Compute the reduced row echelon form for the following matrices:   (4)              Solve (find all solutions), or show no solution exists   (2)        a)  , b)  , . c)  , , , any real d)  No solution      Solve (find all solutions), or show no solution exists   (2)          Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Assume that you are solving a three component linear system of equations via row reduction of an augmented matrix and reach the matrix What does this mean about the solution to this system of equations?      Assume that you are solving a three component linear system of equations via row reduction of an augmented matrix and reach the matrix What does this mean about the solution to this system of equations?      Assume that you are solving a four component linear system of equations via row reduction of an augmented matrix and reach the matrix What is the next step in reducing this matrix? Carry out the rest of this problem to solve the corresponding system of equations.    Swap rows 2 and 3, then cancel down. , , ,       Assume that someone else has provided you the solution to an augmented matrix reduction for solving a system of equations given below Is this work correct? If so, what does this say about the solution(s) to the system? If not, correct the work to solve the system.      Find the row echelon form of the matrix given below. What does this tell you about the solutions to the equation ?     There are infinitely many solutions.      Find the row echelon form of the matrix given below. What does this tell you about the solutions to the equation ?     There is only one solution, .     "
},
{
  "id": "row-echelon-form-and-elementary-operations-10",
  "level": "2",
  "url": "elim-section.html#row-echelon-form-and-elementary-operations-10",
  "type": "Example",
  "number": "3.3.1",
  "title": ".",
  "body": "    The following matrices are in row echelon form. The leading entries are marked: Note that the definition applies to matrices of any size. None of the matrices above are in reduced row echelon form. For example, in the first matrix none of the entries above the second and third leading entries are zero; they are 9, 3, and 5.  The following matrices are in reduced row echelon form. The leading entries are marked:    "
},
{
  "id": "row-echelon-form-and-elementary-operations-19",
  "level": "2",
  "url": "elim-section.html#row-echelon-form-and-elementary-operations-19",
  "type": "Example",
  "number": "3.3.2",
  "title": ".",
  "body": "    Solve the following system of equations using row reduction:     In order to solve this problem, we need to set up the augmented matrix for this system, which is   To carry out the process, we need to get a 1 in the top left corner, then work from there. We multiply the first row by -1 to get   Next, we want to use row 1 to cancel out the and in column 1. To do this, we add three copies of row 1 to row 2, and two copies of row 1 to row 3 to get the augmented matrix   Normally, the next step would be to divide the second row by in order to put a in that pivot spot. However, since both the second and third rows have a in the second column, we can combine these two rows directly without dividing by first. We subtract row 2 from row 3 to get and we can now use this to solve the system. The bottom row says that , so that . The second row says that , since , we have that , so . Finally, the first row of the augmented matrix says that . Plugging in our values for and gives . Therefore, the solution is    "
},
{
  "id": "non-unique-solutions-and-inconsistent-systems-8",
  "level": "2",
  "url": "elim-section.html#non-unique-solutions-and-inconsistent-systems-8",
  "type": "Example",
  "number": "3.3.3",
  "title": ".",
  "body": "    Solve the following two systems of equations, or determine that no solution exists, using row reduction:            For the first of these systems, we will set up the augmented matrix and proceed through the process like normal. The augmented matrix is Since we already have a in the top-left corner of this matrix, we can use it to cancel the entries in the rest of column . We add one copy of row 1 to row 2, and subtract row 1 from row 3 to get the next augmented form matrix as Looking at the matrix here, we see that row 3 is times row 2. Therefore, if we add two copies of row 2 to row 3, we get the augmented matrix Therefore, we have a situation where there are only two pivot columns, and the last row is all zeros. Since there are three variables and column 3 is not a pivot column, we can take as a free variable. If we do that, the second equation tells us that , or, since we are taking as a free variable, we can write . We can then take the first equation, which says that or, by rearranging This means that for any value of , our solution is determined by The use of here is just to separate it from the variable . For example, we could pick , in which case we would get , , .  For the second version of the problem, we again set up the augmented matrix Since the left side matrix part is the same as the previous version, the process of row reducing the matrix is identical to what was done previously. When we carry out this process we get the augmented matrix In this case, we see that the last row corresponds to the equation so these equations are inconsistent and do not have a solution.   "
},
{
  "id": "elim-section-5-2",
  "level": "2",
  "url": "elim-section.html#elim-section-5-2",
  "type": "Exercise",
  "number": "3.3.4.1",
  "title": "",
  "body": "  Compute the reduced row echelon form for the following matrices:   (4)            a)  b)  c)  d)  e)  f)  g)  h)     "
},
{
  "id": "elim-section-5-3",
  "level": "2",
  "url": "elim-section.html#elim-section-5-3",
  "type": "Exercise",
  "number": "3.3.4.2",
  "title": "",
  "body": "  Compute the reduced row echelon form for the following matrices:   (4)           "
},
{
  "id": "elim-section-5-4",
  "level": "2",
  "url": "elim-section.html#elim-section-5-4",
  "type": "Exercise",
  "number": "3.3.4.3",
  "title": "",
  "body": "  Solve (find all solutions), or show no solution exists   (2)        a)  , b)  , . c)  , , , any real d)  No solution   "
},
{
  "id": "elim-section-5-5",
  "level": "2",
  "url": "elim-section.html#elim-section-5-5",
  "type": "Exercise",
  "number": "3.3.4.4",
  "title": "",
  "body": "  Solve (find all solutions), or show no solution exists   (2)       "
},
{
  "id": "elim-section-5-6",
  "level": "2",
  "url": "elim-section.html#elim-section-5-6",
  "type": "Exercise",
  "number": "3.3.4.5",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "elim-section-5-7",
  "level": "2",
  "url": "elim-section.html#elim-section-5-7",
  "type": "Exercise",
  "number": "3.3.4.6",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "elim-section-5-8",
  "level": "2",
  "url": "elim-section.html#elim-section-5-8",
  "type": "Exercise",
  "number": "3.3.4.7",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "elim-section-5-9",
  "level": "2",
  "url": "elim-section.html#elim-section-5-9",
  "type": "Exercise",
  "number": "3.3.4.8",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "elim-section-5-10",
  "level": "2",
  "url": "elim-section.html#elim-section-5-10",
  "type": "Exercise",
  "number": "3.3.4.9",
  "title": "",
  "body": "  Assume that you are solving a three component linear system of equations via row reduction of an augmented matrix and reach the matrix What does this mean about the solution to this system of equations?   "
},
{
  "id": "elim-section-5-11",
  "level": "2",
  "url": "elim-section.html#elim-section-5-11",
  "type": "Exercise",
  "number": "3.3.4.10",
  "title": "",
  "body": "  Assume that you are solving a three component linear system of equations via row reduction of an augmented matrix and reach the matrix What does this mean about the solution to this system of equations?   "
},
{
  "id": "elim-section-5-12",
  "level": "2",
  "url": "elim-section.html#elim-section-5-12",
  "type": "Exercise",
  "number": "3.3.4.11",
  "title": "",
  "body": "  Assume that you are solving a four component linear system of equations via row reduction of an augmented matrix and reach the matrix What is the next step in reducing this matrix? Carry out the rest of this problem to solve the corresponding system of equations.    Swap rows 2 and 3, then cancel down. , , ,    "
},
{
  "id": "elim-section-5-13",
  "level": "2",
  "url": "elim-section.html#elim-section-5-13",
  "type": "Exercise",
  "number": "3.3.4.12",
  "title": "",
  "body": "  Assume that someone else has provided you the solution to an augmented matrix reduction for solving a system of equations given below Is this work correct? If so, what does this say about the solution(s) to the system? If not, correct the work to solve the system.   "
},
{
  "id": "elim-section-5-14",
  "level": "2",
  "url": "elim-section.html#elim-section-5-14",
  "type": "Exercise",
  "number": "3.3.4.13",
  "title": "",
  "body": "  Find the row echelon form of the matrix given below. What does this tell you about the solutions to the equation ?     There are infinitely many solutions.   "
},
{
  "id": "elim-section-5-15",
  "level": "2",
  "url": "elim-section.html#elim-section-5-15",
  "type": "Exercise",
  "number": "3.3.4.14",
  "title": "",
  "body": "  Find the row echelon form of the matrix given below. What does this tell you about the solutions to the equation ?     There is only one solution, .   "
},
{
  "id": "det-section",
  "level": "1",
  "url": "det-section.html",
  "type": "Section",
  "number": "3.4",
  "title": "Determinant",
  "body": " Determinant  For square matrices we define a useful quantity called the . We define the determinant of a matrix as the value of its only entry For a matrix we define   Before defining the determinant for larger matrices, we note the meaning of the determinant. An matrix gives a mapping of the -dimensional euclidean space to itself. In particular, a matrix is a mapping of the plane to itself. The determinant of is the factor by which the area of objects changes. If we take the unit square (square of side 1) in the plane, then takes the square to a parallelogram of area . The sign of denotes a change of orientation (negative if the axes get flipped). For example, let Then . Let us see where sends the unit square with vertices , , , and . The point gets sent to . The image of the square is another square with vertices , , , and . The image square has a side of length and is therefore of area 2. See .    In general the image of a square is going to be a . In high school geometry, you may have seen a formula for computing the area of a with vertices , , and . The area is The vertical lines above mean absolute value. The matrix carries the unit square to the given parallelogram.  There are a number of ways to define the determinant for an matrix. Let us use the so-called . We define as the matrix with the row and the column deleted. For example, We now define the determinant recursively or in other words For a matrix, we get . For example,   It turns out that we did not have to necessarily use the first row. That is for any , It is sometimes useful to use a row other than the first. In the following example it is more convenient to expand along the second row. Notice that for the second row we are starting with a negative sign. Let us check if it is really the same as expanding along the first row,   In computing the determinant, we alternately add and subtract the determinants of the submatrices multiplied by for a fixed and all . The numbers are called cofactors of the matrix. And that is why this method of computing the determinant is called the cofactor expansion .  Similarly we do not need to expand along a row, we can expand along a column. For any  A related fact is that   Recall that a matrix is if all elements below the main diagonal are 0. For example, is upper triangular. Similarly a matrix is one where everything above the diagonal is zero. For example,   The determinant for triangular matrices is very simple to compute. Consider the lower triangular matrix. If we expand along the first row, we find that the determinant is 1 times the determinant of the lower triangular matrix . So the deteriminant is just the product of the diagonal entries: Similarly for upper triangular matrices In general, if is triangular, then   If is diagonal, then it is also triangular (upper and lower), so same formula applies. For example,   In particular, the identity matrix is diagonal, and the diagonal entries are all 1. Thus,   Another way that we can compute determinants is by using row reduction. Since the row echelon form is a diagonal matrix, this will make it easy to compute the determinant using the product of the diagonal entries. However, we need to know how the determinant is affected by elementary row operations.   Properties of the Determinant Let be a square matrix.    If obtained from by interchanging two rows (or two columns) of , then .    If is obtained from by multiplying a row of column by the number , then .    If is obtained from by multiplying a row (or column) by a non-zero number and adding the result to another row, then .      Proof. The proof of each of these facts comes from the cofactor expansion of the determinant.    Assume that is obtained by interchanging the first and second row of . We will use cofactor expansion along the first row to find the determinant of , and the second row for the determinant of . We get that and However, since the second row of is the first row of , we know that for all . In addition, this swap means that we also have that for each of the cofactors in this expansion. All of these cofactor matrices are made up of the second through last rows of , with the appropriate columns removed at each step.  Therefore, the only difference between these two formulas is that the formula starts with and the formula starts with . Thus, will have an additional factor of in it, giving the desired result.  The exact same process works for swapping any two adjacent rows of the matrix, giving that this also provides a in the computation of the determinant. For non-adjacent rows, we use the fact that to any swap of non-adjacent rows of a matrix requires an odd number of adjacent row swaps. For example, if we want to swap rows and , we can swap row 1 with row 2, then row 2 with row 3, and finally swap row 1 with row 2 again. This will put the first row in the third spot and the third row up in the first slot. Since each of these adjacent switches adds a minus sign, doing an odd number of switches still results in adding a single minus sign to the computation of the determinant.    Assume that we want to multiply the th row of by the number to get . We use cofactor expansion along this same th row to find the determinant of each matrix. We get that and However, the minor ignores the th row of the matrix , so the minors are identical to those of . Thus, we have that     Assume that is formed by adding copies of the th row of to the th row. Since the th row is the one being changed, we will use cofactor expansion there to compute each determinant. We get that and where we have replaced the minors of by the minors of because they ignore the th row, which is the only thing that has changed. We can now split the determinant of into two parts The first of these is the determinant of the matrix . The second is the determinant of a new matrix that we will call . is the same as the matrix , except that we have replaced the th row of by times the th row of . Thus, the th row of this matrix is a multiple of the th row. This means that the rows of are not linearly independent. By coming up later (don’t worry, it does not depend on this result), this tells us that the determinant of is zero. Therefore so this operation does not change the determinant of the matrix.     ◻  These correspond to the three elementary row operations that we use to row reduce matrices. In order to use this to compute determinants, we need to keep track of each of these operations and how the determinant changes at each step.      Compute the determinant of the matrix using row reduction.    We will go through the process of row reduction to find the determinant. We need to keep track of each time that we swap rows (to add a minus sign) and that we multiply a row by a constant (to factor in that constant). Throughout this process, we will use to refer to the initial matrix and will refer to wherever we are in the process. So we will start by dividing the first row of the matrix by  Since we divided by , tells us that The next step of row reduction will be to use the 1 in the top left to cancel out the and below it. Part (c) in says that this doesn’t change the determinant. Therefore, the row reduction gives and we still have that Next, we will multiply row by , which gives Adding this in to our previous steps using , we get that Finally, we add two copies of row 2 to row 3, which does not change the determinant and gives the matrix with We can rearrange this expression to say that and we can easily compute that by multiplying the diagonal entries. Thus, we have that .      Compute using cofactor expansion and show that you get the same answer.    The determinant is telling you how geometric objects scale. If doubles the sizes of geometric objects and triples them, then (which applies to an object and then it applies ) should make size go up by a factor of . This is true in general:        This property is one of the most useful, and it is employed often to actually compute determinants. A particularly interesting consequence is to note what it means for existence of inverses. Take and to be inverses, that is . Then Neither nor can be zero. This fact is an extremely useful property of the determinant, and one which is used often in this book:   An matrix is invertible if and only if .  In fact, says that So we know what the determinant of is without computing .  Let us return to the formula for the inverse of a matrix: Notice the determinant of the matrix in the denominator of the fraction. The formula only works if the determinant is nonzero, otherwise we are dividing by zero.  A common notation for the determinant is a pair of vertical lines: Personally, I find this notation confusing as vertical lines usually mean a positive quantity, while determinants can be negative. Also think about how to write the absolute value of a determinant. This notation is not used in this book.  With this discussion of determinants complete, we can now state a major theorem from linear algebra that will help us here and when we get back to solving differential equations using this linear algebra. In a full course on linear algebra, this theorem would be covered in full detail, including all of the proofs. For this introduction, we give some idea as to why everything is true here, but not all of the details.   Note: This is an example of an equivalence theorem, which is fairly common in mathematics. It means that if any one of the statements are true, then we know that all of the others are true as well. It means it’s harder to prove, but once we have such a theorem, it is very powerful in how we can use it going forward.   Let be an matrix. The following are equivalent:     is invertible.     .    There is a unique solution to for every vector .    The only solution to is .    The reduced row echelon form of is , the identity matrix.    The columns of are linearly independent.      Proof. Why is all of this true? For (a) and (b), we have Theorem to say that they are equivalent. For (c), if is invertible, then the unique solution to is . If we take here, we get (d), that the solution is . This means that reducing the system of equations gives , , ..., , which means the reduced row echelon form of is just the identity matrix, which is (e). Finally, this means that every column is a pivot column, so that all of the columns are linearly independent, giving (f). ◻  This is a massive theorem that forms most of the backbone of linear algebra. We will only be using a few parts of it later and we can also add some other parts to it with different definitions from linear algebra, but since we have seen all of these components, it is nice to see them all put together into one complete statement.   Exercises    Compute the determinant of the following matrices:   (4)            a)  3 b)  -5 c)  0 d) 24 e) 12 f)  85 g) 84 h) -3      Compute the determinant of the following matrices:   (4)              For which are the following matrices singular (not invertible).   (4)        a)  b)  c)  d)        For which are the following matrices singular (not invertible).   (4)          Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 2. Compute the determinant using row reduction.      Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 3. Compute the determinant using row reduction.      Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 4. Compute the determinant using row reduction.      Is the matrix below invertible? How do you know?     Yes      Compute the determinant of the matrix using row reduction. What does this say about the solutions to ?      Compute the determinant of the matrix using row reduction. What does this say about the columns of ?      Compute the determinant of the matrix using row reduction. What does this say about the solutions to .      Compute without computing the inverse.           Compute without computing the inverse.      Suppose Let . Compute in a simple way, without computing what is . Hint: First read off and .           Consider the linear mapping from to given by the matrix for some number . You wish to make such that it doubles the area of every geometric figure. What are the possibilities for (there are two answers).           Consider the matrix as a function of the variable .   Find all the so that and the matrix inverse have only integer entries (no fractions). Note that there are two answers. Find all the so that the matrix inverse has only integer entries (no fractions). (You should get more answers here than the previous part.)      Suppose and are matrices, and is invertible. Suppose that . Compute and . Justify your answer using the theorems in this section.    3      Let be an matrix such that . Compute given a number . [2] Hint: First try computing , then note that .          "
},
{
  "id": "det-section-20",
  "level": "2",
  "url": "det-section.html#det-section-20",
  "type": "Example",
  "number": "3.4.1",
  "title": ".",
  "body": "    Compute the determinant of the matrix using row reduction.    We will go through the process of row reduction to find the determinant. We need to keep track of each time that we swap rows (to add a minus sign) and that we multiply a row by a constant (to factor in that constant). Throughout this process, we will use to refer to the initial matrix and will refer to wherever we are in the process. So we will start by dividing the first row of the matrix by  Since we divided by , tells us that The next step of row reduction will be to use the 1 in the top left to cancel out the and below it. Part (c) in says that this doesn’t change the determinant. Therefore, the row reduction gives and we still have that Next, we will multiply row by , which gives Adding this in to our previous steps using , we get that Finally, we add two copies of row 2 to row 3, which does not change the determinant and gives the matrix with We can rearrange this expression to say that and we can easily compute that by multiplying the diagonal entries. Thus, we have that .   "
},
{
  "id": "det-section-21",
  "level": "2",
  "url": "det-section.html#det-section-21",
  "type": "Checkpoint",
  "number": "3.4.2",
  "title": "",
  "body": "  Compute using cofactor expansion and show that you get the same answer.    The determinant is telling you how geometric objects scale. If doubles the sizes of geometric objects and triples them, then (which applies to an object and then it applies ) should make size go up by a factor of . This is true in general:   "
},
{
  "id": "det-section-34-2",
  "level": "2",
  "url": "det-section.html#det-section-34-2",
  "type": "Exercise",
  "number": "3.4.1",
  "title": "",
  "body": "  Compute the determinant of the following matrices:   (4)            a)  3 b)  -5 c)  0 d) 24 e) 12 f)  85 g) 84 h) -3   "
},
{
  "id": "det-section-34-3",
  "level": "2",
  "url": "det-section.html#det-section-34-3",
  "type": "Exercise",
  "number": "3.4.2",
  "title": "",
  "body": "  Compute the determinant of the following matrices:   (4)           "
},
{
  "id": "det-section-34-4",
  "level": "2",
  "url": "det-section.html#det-section-34-4",
  "type": "Exercise",
  "number": "3.4.3",
  "title": "",
  "body": "  For which are the following matrices singular (not invertible).   (4)        a)  b)  c)  d)     "
},
{
  "id": "det-section-34-5",
  "level": "2",
  "url": "det-section.html#det-section-34-5",
  "type": "Exercise",
  "number": "3.4.4",
  "title": "",
  "body": "  For which are the following matrices singular (not invertible).   (4)       "
},
{
  "id": "det-section-34-6",
  "level": "2",
  "url": "det-section.html#det-section-34-6",
  "type": "Exercise",
  "number": "3.4.5",
  "title": "",
  "body": "  Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 2. Compute the determinant using row reduction.   "
},
{
  "id": "det-section-34-7",
  "level": "2",
  "url": "det-section.html#det-section-34-7",
  "type": "Exercise",
  "number": "3.4.6",
  "title": "",
  "body": "  Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 3. Compute the determinant using row reduction.   "
},
{
  "id": "det-section-34-8",
  "level": "2",
  "url": "det-section.html#det-section-34-8",
  "type": "Exercise",
  "number": "3.4.7",
  "title": "",
  "body": "  Consider the matrix    Compute the determinant of using cofactor expansion along row 1. Compute the determinant of using cofactor expansion along column 4. Compute the determinant using row reduction.   "
},
{
  "id": "det-section-34-9",
  "level": "2",
  "url": "det-section.html#det-section-34-9",
  "type": "Exercise",
  "number": "3.4.8",
  "title": "",
  "body": "  Is the matrix below invertible? How do you know?     Yes   "
},
{
  "id": "det-section-34-10",
  "level": "2",
  "url": "det-section.html#det-section-34-10",
  "type": "Exercise",
  "number": "3.4.9",
  "title": "",
  "body": "  Compute the determinant of the matrix using row reduction. What does this say about the solutions to ?   "
},
{
  "id": "det-section-34-11",
  "level": "2",
  "url": "det-section.html#det-section-34-11",
  "type": "Exercise",
  "number": "3.4.10",
  "title": "",
  "body": "  Compute the determinant of the matrix using row reduction. What does this say about the columns of ?   "
},
{
  "id": "det-section-34-12",
  "level": "2",
  "url": "det-section.html#det-section-34-12",
  "type": "Exercise",
  "number": "3.4.11",
  "title": "",
  "body": "  Compute the determinant of the matrix using row reduction. What does this say about the solutions to .   "
},
{
  "id": "det-section-34-13",
  "level": "2",
  "url": "det-section.html#det-section-34-13",
  "type": "Exercise",
  "number": "3.4.12",
  "title": "",
  "body": "  Compute without computing the inverse.        "
},
{
  "id": "det-section-34-14",
  "level": "2",
  "url": "det-section.html#det-section-34-14",
  "type": "Exercise",
  "number": "3.4.13",
  "title": "",
  "body": "  Compute without computing the inverse.   "
},
{
  "id": "det-section-34-15",
  "level": "2",
  "url": "det-section.html#det-section-34-15",
  "type": "Exercise",
  "number": "3.4.14",
  "title": "",
  "body": "  Suppose Let . Compute in a simple way, without computing what is . Hint: First read off and .        "
},
{
  "id": "det-section-34-16",
  "level": "2",
  "url": "det-section.html#det-section-34-16",
  "type": "Exercise",
  "number": "3.4.15",
  "title": "",
  "body": "  Consider the linear mapping from to given by the matrix for some number . You wish to make such that it doubles the area of every geometric figure. What are the possibilities for (there are two answers).        "
},
{
  "id": "det-section-34-17",
  "level": "2",
  "url": "det-section.html#det-section-34-17",
  "type": "Exercise",
  "number": "3.4.16",
  "title": "",
  "body": "  Consider the matrix as a function of the variable .   Find all the so that and the matrix inverse have only integer entries (no fractions). Note that there are two answers. Find all the so that the matrix inverse has only integer entries (no fractions). (You should get more answers here than the previous part.)   "
},
{
  "id": "det-section-34-18",
  "level": "2",
  "url": "det-section.html#det-section-34-18",
  "type": "Exercise",
  "number": "3.4.17",
  "title": "",
  "body": "  Suppose and are matrices, and is invertible. Suppose that . Compute and . Justify your answer using the theorems in this section.    3   "
},
{
  "id": "det-section-34-19",
  "level": "2",
  "url": "det-section.html#det-section-34-19",
  "type": "Exercise",
  "number": "3.4.18",
  "title": "",
  "body": "  Let be an matrix such that . Compute given a number . [2] Hint: First try computing , then note that .        "
},
{
  "id": "eig-section",
  "level": "1",
  "url": "eig-section.html",
  "type": "Section",
  "number": "3.5",
  "title": "Eigenvalues and Eigenvectors",
  "body": " Eigenvalues and Eigenvectors   Consider the matrix We can compute a few operations with this matrix. For instance and This last computation is fairly interesting, because the result we get is the same as 3 times the original vector. However, the matrix does not multiply every vector by 3, as seen in the first example and the fact that so actually preserves this vector, multiplying it by 1. So, these vectors, and , and numbers, and , are somehow special for this matrix . With this information, we want to define these vectors as and numbers as of the matrix .   For a square matrix , we say that non-zero vector is an eigenvector of the matrix if there exists a number so that In this case, we say that is an eigenvalue of and it is the corresponding eigenvalue for the eigenvector .  Thus, we can say that, for the matrix we see that is an eigenvector with corresponding eigenvalue , and that is an eigenvector with corresponding eigenvalue .  Why are these important? It turns out that these eigenvalues and eigenvectors characterize the behavior of the matrix . For example, if we wanted to figure out what happens when is applied to the vector , we can figure this out as   In addition, eigenvectors determine directions in which multiplying by the matrix behaves just like scalar multiplication. This idea will be very important for our understanding of systems of differential equations, because we have already seen how to solve a scalar first order equation way back in and .    Finding Eigenvalues and Eigenvectors  Since eigenvalues and eigenvectors are so important, we want to know how to find them. To do this, we are looking for a number and a non-zero vector so that We can rewrite this as or, using the identity matrix, This means that we are looking for a non-zero solution to a homogeneous vector equation of the form . This is where all of our linear algebra theory comes into play.  Theorem tells us that, combining parts (b) and (d), that there is a non-zero solution to if and only if the determinant of the matrix is zero. Therefore, we can compute this determinant, find the values of so that , and these will give us our eigenvalues. Let’s see an example of what this looks like.      Compute for the matrix     For this matrix, we have that Thus   If we were looking for eigenvalues here, we could then set this equal to zero, getting that so that the eigenvalues are and .    In this case, we saw that computing for this case, we ended up with a quadratic polynomial, so it was easy to find the eigenvalues. Thankfully, no matter the size of the matrix, we will always get a polynomial here.   For a matrix , the expression is called the of the matrix. It will always be a polynomial, and for an matrix, it will be a degree polynomial.  This explains why we got a quadratic polynomial for the matrix . Therefore, for a matrix , the roots of the characteristic polynomial are the eigenvalues of .  Once we have the eigenvalues, we can use them to find the eigenvectors. As with how we started this discussion, we are looking for a non-zero vector so that and we know the value of . Therefore, we can set up a system of equations that correponds to and solve it for the components of the eigenvector.      Find the eigenvalues and eigenvectors of the matrix     The previous example shows that the eigenvalues for this matrix are and . For the eigenvalue , we want to find a non-zero solution to , which means we want to solve for   Writing the vector as , this system of equations becomes   Since the second equation is two times the first one, these equations are redundant, so we only need to satisfy . We can do this by choosing and , which gives that for , a corresponding eigenvector is .  We can follow the same process for the eigenvalue . For this, we want to find a non-zero solution to , which means that we want to solve   Writing the vector as , we get the two equations As before, these two equations are the same, since they are both a multiple of . Therefore, we just need to find a solution to that previous equation, which can be done with and . Therefore, an eigenvector for eigenvalue is .    This example illustrates the standard process that is always used to find eigenvalues and eigenvectors of matrices: find the characteristic polynomial, get the roots of this polynomial, and use each of these eigenvalues to set up a system of equations for the components of each eigenvector. In addition, the equations that we get from this system will always be redundant if we have found the eigenvalue correctly. Since , we know that the rows of the matrix are not linearly independent, and so the row-echelon form of must have a zero row in it. This process works for any size matrix, but it becomes harder to find the roots of this polynomial when it is higher degree.      Find the eigenvalues and eigenvectors of the matrix     We start by hunting for eigenvalues by taking the determinant of , which will require the cofactor expansion in order to solve.     We need to look for the roots of this polynomial. There’s no nice way to factor this right away, so we need to start guessing roots. We know that the root must be a factor of 6. If we try , we get so that one doesn’t work. Plugging in , we get so this is a root, meaing that is a factor of the characteristic polynomial. We can then use polynomial long division to get that and the quadratic term here factors as . Thus, the characteristic polynomial of this matrix is so the eigenvalues are , , and .  For the eigenvalue , the eigenvector must satisfy which we can write as   To solve this, we row-reduce the coefficient matrix.   Therefore, the eigenvector must satsify and . We need to pick any non-zero set of numbers that solves these equations. For example, we could pick to get that we need and . This gives an eigenvector of   For the eigenvalue , the eigenvector must satisfy   Row reduction gives which means that the eigenvector must satisfy and . Again, choosing gives that we want and . Therefore, a corresponding eigenvector here is   For the eigenvalue , the eigenvector must satisfy where we can row reduce the coefficient matrix.     Therefore, the eigenvector must satisfy and . Picking again gives that we want and . Therefore, an eigenvector with eigenvalue is       Real Eigenvalues  Since eigenvalues come from finding the roots of a polynomial, there are a few different situations that can arise in terms of these eigenvalues. If we take a quadratic polynomial, there are three options for the two roots.    Two real and different roots,    Two complex roots in a conjugate pair, or    One double (repeated) root.    The same is true for eigenvalues, they are either all real and distinct, there are some that appear in complex conjugate pairs, or there are some repeated eigenvalues. The easiest of these cases is when the characteristic polynomial has all real and distinct eigenvalues.  In this case, we get a very nice result. We know that for each eigenvalue, there will always be at least one eigenvector, otherwise it wouldn’t be an eigenvalue. If the matrix is an matrix, then the characteristic polynomial is a degree polynomial, which will have distinct roots by our assumption. Each of these will have a corresponding eigenvector, giving us eigenvectors as well. A more involved result tells us that eigenvectors for different eigenvalues are always linearly independent. Therefore, we get vectors in , that are linearly independent, and so they are a basis. This gives the following result.   Let be an matrix. Assume that the characteristic polynomial of has all real and distinct roots, namely that for the distinct real eigenvalues. Then there exist vectors , ..., such that is an eigenvector for eigenvalue and form a basis of .  To reference, look at the previous example. We found three distinct real eigenvalues of , , and . For these eigenvalues, we had eigenvectors These three vectors are linearly independent (check this!) and since they are three component vectors, the space has dimension 3, and so 3 linearly independent vectors must make up a basis. This is useful to know for now, but will be critical when we want to use this information to solve systems of differential equations later.    Complex Eigenvalues  When the matrix has complex eigenvalues, the process is very similar to before. However, the eigenvector will necessarily also be complex, that is, some of the components of this vector will be complex numbers. Let’s illustrate this with an example.      Find the eigenvalues and eigenvectors of the matrix     We first look for the eigenvalues using the characteristic polynomial of .   This quadratic does not factor, so we use the quadratic formula to find that so that we have complex eigenvalues.  We now look for the eigenvectors in the same way as in the real case. If we take the eigenvalue , then such an eigenvector must satisfy This means that   These two equations should be redundant, and to verify that, we will multiply the top row by in row reduction to get and from this, we can see that the top row is 8 times the bottom one, so they are redundant. Thus, an eigenvector must satisfy and we can pick any non-zero numbers that satisfy this. One simple way to do this is by switching the coefficients, so that and . Therefore, an eigenvector that we get is   Now, we can take the other eigenvalue, . The process is the same, so that the vector must satisfy   To check redundancy again, we multiply the top row by to get and again, the first equation is 8 times the second one. Thus, the eigenvector will need to satisfy which can be done by picking and , giving an eigenvector of     The process here is the same as it was in the real case, except that now all of the equations are complex equations. In particular, the redundancy that we expect to see between the equations will likely be via a complex multiple. The easiest way to verify that these equations are redundant is by multiplying the first entry in each row by its complex conjugate. This is because, if we have the complex number , multiplying this by gives which is now a real number. This will make it easier to compare the two equations to make sure that they are redundant, and that the eigenvalue was found correctly.      Find the eigenvalues and eigenvectors of the matrix     We first look for eigenvalues, like always. We get these by computing   We will compute this by cofactor expansion along the second row. so that one eigenvalue is at . For the other two, we use the quadratic formula to obtain Thus, we have one real eigenvalue and two complex eigenvalues.  For , we know that the eigenvector must satisfy Row reduction will reduce this matrix to ( Check this! ) so that the eigenvector in this case is   For the eigenvalue , we get that the eigenvector must satisfy We now want to row reduce the coefficient matrix. To do so, we start by dividing the first row by 3 then multiplying by . We could divide the first row by 2 to get to a 1 in the top-right entry, but we’ll wait on that in order to avoid fractions. To row reduce the rest of the matrix, we will divide each of the remaining two rows by 3, and then multiply the second by , just like we did to the first row.   which illlustrates that the last two rows are redundant. Thus, the reduced form of the matrix that we have (which is not quite a row echelon form, but it is enough to back-solve for the eigenvector) is This means that the eigenvector must satisfy We can satisfy the second of these equations by choosing and . Plugging these values into the first equation gives that Therefore, we need to take , giving that the eigenvector is   A very similar computation following the same set of steps (or just using the remark below) for the eigenvalue gives that this corresponding eigenvector is     One fact that comes out of those examples is that the eigenvectors for conjugate eigenvalues are also complex conjugates. This comes from the fact that is a real matrix, which means that if and we take the complex conjugate of both sides, we get that so that is an eigenvector for . This means that, when solving these types of problems, we only need to find one of the complex eigenvectors and can get the other by taking the complex conjugate.    Repeated Eigenvalues  Distinct and complex eigenvalues all work out nicely and in pretty much the same manner. For repeated eigenvalues, the issues get more significant.      Find the eigenvalues and eigenvectors of the matrices     For the matrix , we can compute the characteristic polynomial   Therefore, we have a double root at for this matrix. Therefore, the only eigenvalue we get is . When we look to find the eigenvectors, we get so that this matrix multiplied by any vector is zero. Therefore, we can use both and as eigenvectors.  On the other hand, the matrix has a characteristic polynomial so again, we have a double root at . However, when we go to find the eigenvectors, we get that which gives that an eigenvector must satisfy so works.    There is a big difference between these two examples. Both had the same characteristic polynomial of , but for , we could find two linearly independent eigenvectors, but for , we could only find 1. This seems like it might be a problem, since we would like to get to two eigenvectors like we did for both of the previous two cases. This leads us to define the following for and matrix and an eigenvalue of .     The algebraic multiplicity of is the power of in the characteristic polynomial if .    The geometric multiplicity of is the number of linearly independent eigenvectors of with eigenvalue .    The defect of is the difference between the algebraic multiplicity and the geometric multiplicity of .    We say that an eigenvalue is defective if the defect is at least 1.    For the previous example, the algebraic multiplicity of for both and was 2, but the geometric multiplictiy of for is 2, and for is it only . Therefore has a defect of and has a defect of , so is a defective eigenvalue for matrix .  In terms of these multiplicities, there are two facts that are known to be true.    If is an eigenvalue, then both the algebraic and geometric multiplicity are at least 1.    The algebraic multiplicity of any eigenvalue is always greater than or equal to the geometric multiplicity.    This tells us that in the case of real and distinct eigenvalues, every eigenvalue has multiplicity 1. Since the geometric multiplicity is also , this means that none of these eigenvalues are defective. This was great, because it let us get to eigenvectors for an matrix, and these generated a basis of .  Why is a defective eigenvalue a problem? When we go solve differential equations using the method in , having a full set of eigenvectors, or eigenvectors for an matrix, will be very important. When we have a defective eigenvalue, we can’t get there. Since the degree of the characteristic polynomial is , the only way we get to eigenvectors is if every eigenvalue has a number of linearly independent eigenvectors equal to the algebraic multiplicity, which means they are not defective.  So how can we fix this? Well, there’s not really much we can do in the way of finding more eigenvectors, because they don’t exist. The replacement that we have is, in linear algebra contexts, called a generalized eigenvector . We will see this idea come back up in in a more natural way. The rest of this section contains a more detailed definition of generalized eigenvectors. You are welcome to skip this part on a first reading and come back after you are more comfortable with eigenvalues and eigenvectors, or when the material comes back around again in .  If is an defective eigenvalue of the matrix with eigenvector , a of is a vector so that . This is the same as the normal eigenvector equation with on the right-hand side instead of . Since , this also means that More generally, a generalized eigenvector is a vector where there is a power so that   It might seems strange where this comes from, but we will see why this formula makes more sense once we try to solve differential equations using matrices in .      Find a generalized eigenvector of eigenvalue for the matrix     Previously, we found that is an eigenvector for with eigenvalue . To find a generalized eigenvector, we need a vector so that   Plugging in the matrix for gives that we need Both of the rows of this matrix becomes the equation There are many values of and that make this work. We can pick and . This will give a generalized eigenvector of . We could also pick and , to get a generalized eigenvector as . Any of these choices work as a generalized eigenvector.        Find the eigenvalues and eigenvectors (and generalized eigenvectors if needed) of the matrix     We start by looking for the eigenvalues through the characteristic polynomial. To compute this determinant, we will expand along column 2, because it only has one non-zero entry. This gives so we have an eigenvalue at and a double eigenvalue at .  First, let’s look for the eigenvector for eigenvalue . In this case, we know that the eigenvector must satisfy Row reducing the coefficient matrix will give so that a corresponding eigenvector is since we know that and .  For , we see that an eigenvector must satisfy We now look to row reduce this coefficient matrix. Therefore, we know that If we pick , then we know that and , so the only eigenvector we get for is   Since we only found one eigenvector for and was squared in the characteristic polynomial, this is a defective eigenvalue. Thus, we can look for a generalized eigenvalue here, which means that we need to solve for a vector with We can then row reduce the augmented matrix to see what we can pick for . Thus, the generalized eigenvector must satisfy We can pick any non-zero numbers to do this, so we can take , and . Thus, the generalized eigenvector here is       Exercises    Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and corresponding eigenvectors of the matrix       Find the eigenvalues and eigenvectors for the matrix below. Compute generalized eigenvectors if needed to get to a total of two vectors.       Find the eigenvalues and eigenvectors for the matrix below. Compute generalized eigenvectors if needed to get to a total of two vectors.       This exercise will work through the process of finding the eigenvalues and corresponding eigenvectors of the matrix    Find the characteristic polynomial of this matrix by computing using any method from this section. This polynomial can be rewritten as where and are the eigenvalues of . What are the eigenvalues? What is each of their algebraic multiplicity? (Hint: One of these roots is ) Find an eigenvector for eigenvalue above. What is the geometric multiplicity of this eigenvalue? Find an eigenvector for eigenvalue . What is the geometric multiplicity of this eigenvalue? There is only one possible eigenvector for , which means it is defective. Find a solution to the equation , where is the eigenvector you found in the previous part. This is the generalized eigenvector for .      We say that a matrix is if there exist matrices and so that . This really means that can be represented by a diagonal matrix in a different basis (as opposed to the standard basis). One way this can be done is with eigenvalues.   Consider the matrix given by Find the eigenvalues and corresponding eigenvectors of this matrix. Form two matrices, , a diagonal matrix with the eigenvalues of on the diagonal, and , a matrix whose columns are the eigenvectors of in the same order as the eigenvalues were put into . Write out these matrices. Compute . Work out the products and . What do you notice here?  This shows that, in the case of a matrix, if we have two distinct real eigenvalues, that matrix is diagonalizable, using the eigenvectors.    a)  , . , b)  , c)  d)  ,       Follow the process outlined in Exercise to attempt to diagonalize the matrix Hint: 1 is an eigenvalue.     ,       The diagonalization process decribed in Exercise works for any case where there are real and distinct eigenvalues, as well as complex eigenvalues (but the algebra with the complex numbers gets complicated). It may or may not work in the case of repeated eigenvalues, and it fails whenever there are defective eigenvalues. Consider the matrix    Find the eigenvalue(s) of this matrix, and see that we have a repeated eigenvalue. Find the eigenvector for that eigenvalue, as well as a generalized eigenvector. Build a matrix like before, but this time put the eigenvector in the first column and the generalized eigenvector in the second. Compute . Find the product . Before, this gave us a diagonal matrix, but what do we get now?  The matrix we get here is almost diagonal, but not quite. It turns out that this is the best we can do for matrices with defective eigenvalues. This matrix is often called and is the Jordan Form of the matrix .    a)  3 repeated b)  Eigenvector , Generalized c)  , d)        Follow the process in Exercise to find the Jordan Form of the matrix     "
},
{
  "id": "finding-eigenvalues-and-eigenvectors-4",
  "level": "2",
  "url": "eig-section.html#finding-eigenvalues-and-eigenvectors-4",
  "type": "Example",
  "number": "3.5.1",
  "title": ".",
  "body": "    Compute for the matrix     For this matrix, we have that Thus   If we were looking for eigenvalues here, we could then set this equal to zero, getting that so that the eigenvalues are and .   "
},
{
  "id": "finding-eigenvalues-and-eigenvectors-9",
  "level": "2",
  "url": "eig-section.html#finding-eigenvalues-and-eigenvectors-9",
  "type": "Example",
  "number": "3.5.2",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors of the matrix     The previous example shows that the eigenvalues for this matrix are and . For the eigenvalue , we want to find a non-zero solution to , which means we want to solve for   Writing the vector as , this system of equations becomes   Since the second equation is two times the first one, these equations are redundant, so we only need to satisfy . We can do this by choosing and , which gives that for , a corresponding eigenvector is .  We can follow the same process for the eigenvalue . For this, we want to find a non-zero solution to , which means that we want to solve   Writing the vector as , we get the two equations As before, these two equations are the same, since they are both a multiple of . Therefore, we just need to find a solution to that previous equation, which can be done with and . Therefore, an eigenvector for eigenvalue is .   "
},
{
  "id": "finding-eigenvalues-and-eigenvectors-11",
  "level": "2",
  "url": "eig-section.html#finding-eigenvalues-and-eigenvectors-11",
  "type": "Example",
  "number": "3.5.3",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors of the matrix     We start by hunting for eigenvalues by taking the determinant of , which will require the cofactor expansion in order to solve.     We need to look for the roots of this polynomial. There’s no nice way to factor this right away, so we need to start guessing roots. We know that the root must be a factor of 6. If we try , we get so that one doesn’t work. Plugging in , we get so this is a root, meaing that is a factor of the characteristic polynomial. We can then use polynomial long division to get that and the quadratic term here factors as . Thus, the characteristic polynomial of this matrix is so the eigenvalues are , , and .  For the eigenvalue , the eigenvector must satisfy which we can write as   To solve this, we row-reduce the coefficient matrix.   Therefore, the eigenvector must satsify and . We need to pick any non-zero set of numbers that solves these equations. For example, we could pick to get that we need and . This gives an eigenvector of   For the eigenvalue , the eigenvector must satisfy   Row reduction gives which means that the eigenvector must satisfy and . Again, choosing gives that we want and . Therefore, a corresponding eigenvector here is   For the eigenvalue , the eigenvector must satisfy where we can row reduce the coefficient matrix.     Therefore, the eigenvector must satisfy and . Picking again gives that we want and . Therefore, an eigenvector with eigenvalue is    "
},
{
  "id": "complex-eigenvalues-3",
  "level": "2",
  "url": "eig-section.html#complex-eigenvalues-3",
  "type": "Example",
  "number": "3.5.4",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors of the matrix     We first look for the eigenvalues using the characteristic polynomial of .   This quadratic does not factor, so we use the quadratic formula to find that so that we have complex eigenvalues.  We now look for the eigenvectors in the same way as in the real case. If we take the eigenvalue , then such an eigenvector must satisfy This means that   These two equations should be redundant, and to verify that, we will multiply the top row by in row reduction to get and from this, we can see that the top row is 8 times the bottom one, so they are redundant. Thus, an eigenvector must satisfy and we can pick any non-zero numbers that satisfy this. One simple way to do this is by switching the coefficients, so that and . Therefore, an eigenvector that we get is   Now, we can take the other eigenvalue, . The process is the same, so that the vector must satisfy   To check redundancy again, we multiply the top row by to get and again, the first equation is 8 times the second one. Thus, the eigenvector will need to satisfy which can be done by picking and , giving an eigenvector of    "
},
{
  "id": "complex-eigenvalues-5",
  "level": "2",
  "url": "eig-section.html#complex-eigenvalues-5",
  "type": "Example",
  "number": "3.5.5",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors of the matrix     We first look for eigenvalues, like always. We get these by computing   We will compute this by cofactor expansion along the second row. so that one eigenvalue is at . For the other two, we use the quadratic formula to obtain Thus, we have one real eigenvalue and two complex eigenvalues.  For , we know that the eigenvector must satisfy Row reduction will reduce this matrix to ( Check this! ) so that the eigenvector in this case is   For the eigenvalue , we get that the eigenvector must satisfy We now want to row reduce the coefficient matrix. To do so, we start by dividing the first row by 3 then multiplying by . We could divide the first row by 2 to get to a 1 in the top-right entry, but we’ll wait on that in order to avoid fractions. To row reduce the rest of the matrix, we will divide each of the remaining two rows by 3, and then multiply the second by , just like we did to the first row.   which illlustrates that the last two rows are redundant. Thus, the reduced form of the matrix that we have (which is not quite a row echelon form, but it is enough to back-solve for the eigenvector) is This means that the eigenvector must satisfy We can satisfy the second of these equations by choosing and . Plugging these values into the first equation gives that Therefore, we need to take , giving that the eigenvector is   A very similar computation following the same set of steps (or just using the remark below) for the eigenvalue gives that this corresponding eigenvector is    "
},
{
  "id": "repeated-eigenvalues-3",
  "level": "2",
  "url": "eig-section.html#repeated-eigenvalues-3",
  "type": "Example",
  "number": "3.5.6",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors of the matrices     For the matrix , we can compute the characteristic polynomial   Therefore, we have a double root at for this matrix. Therefore, the only eigenvalue we get is . When we look to find the eigenvectors, we get so that this matrix multiplied by any vector is zero. Therefore, we can use both and as eigenvectors.  On the other hand, the matrix has a characteristic polynomial so again, we have a double root at . However, when we go to find the eigenvectors, we get that which gives that an eigenvector must satisfy so works.   "
},
{
  "id": "repeated-eigenvalues-14",
  "level": "2",
  "url": "eig-section.html#repeated-eigenvalues-14",
  "type": "Example",
  "number": "3.5.7",
  "title": ".",
  "body": "    Find a generalized eigenvector of eigenvalue for the matrix     Previously, we found that is an eigenvector for with eigenvalue . To find a generalized eigenvector, we need a vector so that   Plugging in the matrix for gives that we need Both of the rows of this matrix becomes the equation There are many values of and that make this work. We can pick and . This will give a generalized eigenvector of . We could also pick and , to get a generalized eigenvector as . Any of these choices work as a generalized eigenvector.   "
},
{
  "id": "repeated-eigenvalues-15",
  "level": "2",
  "url": "eig-section.html#repeated-eigenvalues-15",
  "type": "Example",
  "number": "3.5.8",
  "title": ".",
  "body": "    Find the eigenvalues and eigenvectors (and generalized eigenvectors if needed) of the matrix     We start by looking for the eigenvalues through the characteristic polynomial. To compute this determinant, we will expand along column 2, because it only has one non-zero entry. This gives so we have an eigenvalue at and a double eigenvalue at .  First, let’s look for the eigenvector for eigenvalue . In this case, we know that the eigenvector must satisfy Row reducing the coefficient matrix will give so that a corresponding eigenvector is since we know that and .  For , we see that an eigenvector must satisfy We now look to row reduce this coefficient matrix. Therefore, we know that If we pick , then we know that and , so the only eigenvector we get for is   Since we only found one eigenvector for and was squared in the characteristic polynomial, this is a defective eigenvalue. Thus, we can look for a generalized eigenvalue here, which means that we need to solve for a vector with We can then row reduce the augmented matrix to see what we can pick for . Thus, the generalized eigenvector must satisfy We can pick any non-zero numbers to do this, so we can take , and . Thus, the generalized eigenvector here is    "
},
{
  "id": "eig-section-7-2",
  "level": "2",
  "url": "eig-section.html#eig-section-7-2",
  "type": "Exercise",
  "number": "3.5.5.1",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-3",
  "level": "2",
  "url": "eig-section.html#eig-section-7-3",
  "type": "Exercise",
  "number": "3.5.5.2",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-4",
  "level": "2",
  "url": "eig-section.html#eig-section-7-4",
  "type": "Exercise",
  "number": "3.5.5.3",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-5",
  "level": "2",
  "url": "eig-section.html#eig-section-7-5",
  "type": "Exercise",
  "number": "3.5.5.4",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-6",
  "level": "2",
  "url": "eig-section.html#eig-section-7-6",
  "type": "Exercise",
  "number": "3.5.5.5",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-7",
  "level": "2",
  "url": "eig-section.html#eig-section-7-7",
  "type": "Exercise",
  "number": "3.5.5.6",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-8",
  "level": "2",
  "url": "eig-section.html#eig-section-7-8",
  "type": "Exercise",
  "number": "3.5.5.7",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-9",
  "level": "2",
  "url": "eig-section.html#eig-section-7-9",
  "type": "Exercise",
  "number": "3.5.5.8",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-10",
  "level": "2",
  "url": "eig-section.html#eig-section-7-10",
  "type": "Exercise",
  "number": "3.5.5.9",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-11",
  "level": "2",
  "url": "eig-section.html#eig-section-7-11",
  "type": "Exercise",
  "number": "3.5.5.10",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-12",
  "level": "2",
  "url": "eig-section.html#eig-section-7-12",
  "type": "Exercise",
  "number": "3.5.5.11",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-13",
  "level": "2",
  "url": "eig-section.html#eig-section-7-13",
  "type": "Exercise",
  "number": "3.5.5.12",
  "title": "",
  "body": "  Find the eigenvalues and corresponding eigenvectors of the matrix    "
},
{
  "id": "eig-section-7-14",
  "level": "2",
  "url": "eig-section.html#eig-section-7-14",
  "type": "Exercise",
  "number": "3.5.5.13",
  "title": "",
  "body": "  Find the eigenvalues and eigenvectors for the matrix below. Compute generalized eigenvectors if needed to get to a total of two vectors.    "
},
{
  "id": "eig-section-7-15",
  "level": "2",
  "url": "eig-section.html#eig-section-7-15",
  "type": "Exercise",
  "number": "3.5.5.14",
  "title": "",
  "body": "  Find the eigenvalues and eigenvectors for the matrix below. Compute generalized eigenvectors if needed to get to a total of two vectors.    "
},
{
  "id": "eig-section-7-16",
  "level": "2",
  "url": "eig-section.html#eig-section-7-16",
  "type": "Exercise",
  "number": "3.5.5.15",
  "title": "",
  "body": "  This exercise will work through the process of finding the eigenvalues and corresponding eigenvectors of the matrix    Find the characteristic polynomial of this matrix by computing using any method from this section. This polynomial can be rewritten as where and are the eigenvalues of . What are the eigenvalues? What is each of their algebraic multiplicity? (Hint: One of these roots is ) Find an eigenvector for eigenvalue above. What is the geometric multiplicity of this eigenvalue? Find an eigenvector for eigenvalue . What is the geometric multiplicity of this eigenvalue? There is only one possible eigenvector for , which means it is defective. Find a solution to the equation , where is the eigenvector you found in the previous part. This is the generalized eigenvector for .   "
},
{
  "id": "eig-section-7-17",
  "level": "2",
  "url": "eig-section.html#eig-section-7-17",
  "type": "Exercise",
  "number": "3.5.5.16",
  "title": "",
  "body": "  We say that a matrix is if there exist matrices and so that . This really means that can be represented by a diagonal matrix in a different basis (as opposed to the standard basis). One way this can be done is with eigenvalues.   Consider the matrix given by Find the eigenvalues and corresponding eigenvectors of this matrix. Form two matrices, , a diagonal matrix with the eigenvalues of on the diagonal, and , a matrix whose columns are the eigenvectors of in the same order as the eigenvalues were put into . Write out these matrices. Compute . Work out the products and . What do you notice here?  This shows that, in the case of a matrix, if we have two distinct real eigenvalues, that matrix is diagonalizable, using the eigenvectors.    a)  , . , b)  , c)  d)  ,    "
},
{
  "id": "eig-section-7-18",
  "level": "2",
  "url": "eig-section.html#eig-section-7-18",
  "type": "Exercise",
  "number": "3.5.5.17",
  "title": "",
  "body": "  Follow the process outlined in Exercise to attempt to diagonalize the matrix Hint: 1 is an eigenvalue.     ,    "
},
{
  "id": "eig-section-7-19",
  "level": "2",
  "url": "eig-section.html#eig-section-7-19",
  "type": "Exercise",
  "number": "3.5.5.18",
  "title": "",
  "body": "  The diagonalization process decribed in Exercise works for any case where there are real and distinct eigenvalues, as well as complex eigenvalues (but the algebra with the complex numbers gets complicated). It may or may not work in the case of repeated eigenvalues, and it fails whenever there are defective eigenvalues. Consider the matrix    Find the eigenvalue(s) of this matrix, and see that we have a repeated eigenvalue. Find the eigenvector for that eigenvalue, as well as a generalized eigenvector. Build a matrix like before, but this time put the eigenvector in the first column and the generalized eigenvector in the second. Compute . Find the product . Before, this gave us a diagonal matrix, but what do we get now?  The matrix we get here is almost diagonal, but not quite. It turns out that this is the best we can do for matrices with defective eigenvalues. This matrix is often called and is the Jordan Form of the matrix .    a)  3 repeated b)  Eigenvector , Generalized c)  , d)     "
},
{
  "id": "eig-section-7-20",
  "level": "2",
  "url": "eig-section.html#eig-section-7-20",
  "type": "Exercise",
  "number": "3.5.5.19",
  "title": "",
  "body": "  Follow the process in Exercise to find the Jordan Form of the matrix    "
},
{
  "id": "sec-kernel",
  "level": "1",
  "url": "sec-kernel.html",
  "type": "Section",
  "number": "3.6",
  "title": "Related Topics in Linear Algebra",
  "body": " Related Topics in Linear Algebra   Subspaces and span  Assume that we find two vectors that solve . What other vectors also solve this equation? In our discussion of linear combinations, we saw that if and solve , then so does for any constants and . Thus, all linear combinations will also solve the equation. This leads to the definition of the span of a set of vectors.   The set of all linear combinations of a set of vectors is called their .   Thus, if two vectors solve a homogeneous equation, so does everything in the span of those two vectors. The span of a collection of vectors is an example of a subspace, which is a common object in linear algebra. We say that a set of vectors in is a if whenever and are members of and is a scalar, then are also members of . That is, we can add and multiply by scalars and we still land in . So every linear combination of vectors of is still in . That is really what a subspace is. It is a subset where we can take linear combinations and still end up being in the subset.      If we let , then this is a subspace of . Adding any two vectors in gets a vector in , and so does multiplying by scalars.  The set , that is, the set of the zero vector by itself, is also a subspace of . There is only one vector in this subspace, so we only need to check for that one vector, and everything checks out: and .  The set of all the vectors of the form for any real number , such as , , or is a subspace of . Adding two such vectors, say again gets a vector of the same form, and so does multiplying by a scalar, say .    We can apply these ideas to the vectors that live inside a matrix. The span of the rows of a matrix is called the . The row space of and the row space of the row echelon form of are the same, because reducing the matrix to its row echelon form involves taking linear combinations, which will preserve the span. In the example,   Similarly to row space, the span of columns is called the .   In particular, to find a set of linearly independent columns we need to look at where the pivots were. If you recall above, when solving the key was finding the pivots, any non-pivot columns corresponded to free variables. That means we can solve for the non-pivot columns in terms of the pivot columns. Let’s see an example.      Find the linearly independent columns of the matrix     We find a pivot and reduce the rows below: We find the next pivot, make it one, and rinse and repeat: The final matrix is the row echelon form of the matrix. Consider the pivots that we marked. The pivot columns are the first and the third column. All other columns correspond to free variables when solving , so all other columns can be solved in terms of the first and the third column. In other words     We could perhaps use another pair of columns to get the same span, but the first and the third are guaranteed to work because they are pivot columns.  In the previous example, this means that only the first and third colums are important in the sense of generating the full column space as a span. We would like to have a way to talk about what these first and third columns do.   Let be a subspace of a vector space. The set is a for the subspace if each of these vectors are in and the span of is equal to .  In the context of the previous example, for the matrix we know that This means that both are spanning sets for this column space.  The idea also works in reverse. Suppose we have a bunch of column vectors and we just need to find a linearly independent set. For example, suppose we started with the vectors These vectors are not linearly independent as we saw above. In particular, the span and is the same as the span of all four of the vectors. So and can both be written as linear combinations of and . A common thing that comes up in practice is that one gets a set of vectors whose span is the set of solutions of some problem. But perhaps we get way too many vectors, we want to simplify. For example above, all vectors in the span of can be written for some numbers . But it is also true that every such vector can be written as for two numbers and . And one has to admit, that looks much simpler. Moreover, these numbers and are unique. More on that later in this section.  To find this linearly independent set we simply take our vectors and form the matrix , that is, the matrix We crank up the row-reduction machine, feed this matrix into it, and find the pivot columns and pick those. In this case, and .    Basis and dimension  At this point, we have talked about subspaces, and two other properties of sets of vectors: linear independence and being a spanning set for a subspace. In some sense, these two properties are in opposition to each other. If I add more vectors to a set, I am more likely to become a spanning set (because I have more options for adding to get other vectors), but less likely to be independent (because there are more possibilities for a linear combination to be zero). Similarly, the reverse is true; removing vectors means the set is more likely to be linearly independent, but less likely to span a given subspace. The question then becomes if there is a sweet spot where both things are true, and that leads to the definition of a basis.   If is a subspace and we can find linearly independent vectors in  such that every other vector in is a linear combination of , then the set is called a of . In other words, is the span of . We say that has  , and we write   The next theorem illustrates the main properties and classification of a basis of a vector space.   If is a subspace and is not the trivial subspace , then there exists a unique positive integer (the dimension) and a (not unique) basis , such that every in can be uniquely represented by for some scalars , , …, .  We should reiterate that while is unique (a subspace cannot have two different dimensions), the set of basis vectors is not at all unique. There are lots of different bases for any given subspace. Finding just the right basis for a subspace is a large part of what one does in linear algebra. In fact, that is what we spend a lot of time on in linear differential equations, although at first glance it may not seem like that is what we are doing.      The standard basis is a basis of (hence the name). So as expected   On the other hand the subspace is of dimension .  The subspace from a previous example, that is, the set of vectors is of dimension 1. One possible basis is simply , the single vector : every vector in can be represented by . Similarly another possible basis would be . Then the vector would be represented as . In this case, the subspace has many different bases, two of which are and , and the vector has a different representation (different constant) for the different bases.    Row and column spaces of a matrix are also examples of subspaces, as they are given as the span of vectors. We can use what we know about row spaces and column spaces from the previous section to find a basis.      Earlier, we considered the matrix Using row reduction to find the pivot columns, we found What we did was we found the basis of the column space. The basis has two elements, and so the column space of is two dimensional.    We would have followed the same procedure if we wanted to find the basis of the subspace spanned by We would have simply formed the matrix with these vectors as columns and repeated the computation above. The subspace is then the column space of .      Consider the matrix Conveniently, the matrix is in reduced row echelon form. The column space is the span of the pivot columns, because the pivot columns always form a basis for the column space of a matrix. It is the 3-dimensional space The row space is the 3-dimensional space As these vectors have 5 components, we think of the row space of as a subspace of .      Rank  In that last example, we noticed that the dimension of the row space and the column space were the same. It turns out that this is not a coincidence. In order to describe this in more detail, we need to define one more term.   Given a matrix , the maximal number of linearly independent rows is called the of , and we write for the rank.  For example, The second and third row are multiples of the first one. We cannot choose more than one row and still have a linearly independent set. But what is That seems to be a tougher question to answer. The first two rows are linearly independent, so the rank is at least two. If we would set up the equations for the , , and , we would find a system with infinitely many solutions. One solution is So the set of all three rows is linearly dependent, the rank cannot be 3. Therefore the rank is 2.  But how can we do this in a more systematic way? We find the row echelon form! The elementary row operations do not change the set of linear combinations of the rows (that was one of the main reasons for defining them as they were). In other words, the span of the rows of the is the same as the span of the rows of the row echelon form of . In particular, the number of linearly independent rows is the same. And in the row echelon form, all nonzero rows are linearly independent. This is not hard to see. Consider the two nonzero rows in the example above. Suppose we tried to solve for the and in Since the first column of the row echelon matrix has zeros except in the first row means that . For the same reason, is zero. We only have two nonzero rows, and they are linearly independent, so the rank of the matrix is 2. This also tells us that if we were trying to solve the system of equations we would get that one row of the reduced augmented matrix has all zeros on the left side, and so this system either has a free variable or is inconsistent, because only two equations here are relevant.  Referring back to the examples from earlier in this section, we could carry out the same calculations to say that and   We know how to find the set of linearly independent rows, but sometimes it may also be useful to find the linearly independent columns as well. It is a tremendously useful fact that the number of linearly independent columns is always the same as the number of linearly independent rows:      Or, in the context of the row and column spaces that we have already discussed:   Rank The dimension of the column space and the dimension of the row space of a matrix are both equal to the rank of .  This relates to the statement at the start of this section; since the number of vectors that we needed to take to get a basis of linearly independent columns was always the same as the number of pivots, and the number of pivots is the rank, we get that above theorem.    Kernel  The set of solutions of a linear equation , the kernel of , is a subspace: If and are solutions, then So and are solutions. The dimension of the kernel is called the of the matrix.  The same sort of idea governs the solutions of linear differential equations. We try to describe the kernel of a linear differential operator, and as it is a subspace, we look for a basis of this kernel. Much of this book is dedicated to finding such bases.  The kernel of a matrix is the same as the kernel of its reduced row echelon form. For a matrix in reduced row echelon form, the kernel is rather easy to find. If a vector is applied to a matrix , then each entry in corresponds to a column of , the column that the entry multiplies. To find the kernel, pick a non-pivot column make a vector that has a in the entry corresponding to this non-pivot column and zeros at all the other entries corresponding to the other non-pivot columns. Then for all the entries corresponding to pivot columns make it precisely the value in the corresponding row of the non-pivot column to make the vector be a solution to . This procedure is best understood by example.      Consider This matrix is in reduced row echelon form, the pivots are marked. There are two non-pivot columns, so the kernel has dimension 2, that is, it is the span of 2 vectors. Let us find the first vector. We look at the first non-pivot column, the column, and we put a in the entry of our vector. We put a in the entry as the column is also a non-pivot column: Let us fill the rest. When this vector hits the first row, we get a and times whatever the first question mark is. So make the first question mark . For the second and third rows, it is sufficient to make it the question marks zero. We are really filling in the non-pivot column into the remaining entries. Let us check while marking which numbers went where: Yay! How about the second vector. We start with We set the first question mark to 3, the second to 4, and the third to 5. Let us check, marking things as previously, There are two non-pivot columns, so we only need two vectors. We have found the basis of the kernel. So,     What we did in finding a basis of the kernel is we expressed all solutions of as a linear combination of some given vectors.  The procedure to find the basis of the kernel of a matrix :     Find the reduced row echelon form of .    Write down the basis of the kernel as above, one vector for each non-pivot column.     The rank of a matrix is the dimension of the column space, and that is the span of the pivot columns, while the kernel is the span of vectors in the non-pivot columns. So the two numbers must add to the number of columns.   Rank–Nullity If a matrix has columns, rank , and nullity (dimension of the kernel), then   The theorem is immensely useful in applications. It allows one to compute the rank if one knows the nullity and vice versa, without doing any extra work.  Let us consider an example application, a simple version of the so-called . A similar result is true for differential equations. Consider where is a square matrix. There are then two mutually exclusive possibilities:     A nonzero solution to exists.    The equation has a unique solution for every .     How does the Rank–Nullity theorem come into the picture? Well, if has a nonzero solution to , then the nullity is positive. But then the rank must be less than . In particular it means that the column space of is of dimension less than , so it is a subspace that does not include everything in . So has to contain some vector not in the column space of . In fact, most vectors in are not in the column space of .  The idea of a kernel also comes up when defining and discussing eigenvectors. In order to find this vector, we are looking for a vector so that This means that we are looking for a vector that is in the kernel of the matrix . Since the kernel is also a subspace, this means that the set of all eigenvectors of a matrix with a certain eigenvalue is a subspace, so it has a dimension. This dimension is number of linearly independent eigenvectors with that eigenvalue, so it is the geometric multiplicity of this eigenvalue. This also motivates why this is sometimes called the eigenspace for a given eigenvalue. Finding a basis of this subspace (which is also finding the kernel of the matrix ) is the exact same as the process of finding the eigenvectors of the matrix .    Computing the inverse  If the matrix is square and there exists a unique solution to for any (there are no free variables), then is invertible.  In particular, if then . Now we just need to compute what is. We can surely do elimination every time we want to find , but that would be ridiculous. The mapping is linear and hence given by a matrix, and we have seen that to figure out the matrix we just need to find where does take the standard basis vectors , , …, .  That is, to find the first column of we solve , because then . To find the second column of we solve . And so on. It is really just eliminations that we need to do. But it gets even easier. If you think about it, the elimination is the same for everything on the left side of the augmented matrix. Doing eliminations separately we would redo most of the computations. Best is to do all at once.  Therefore, to find the inverse of , we write an augmented matrix , where is the identity matrix, whose columns are precisely the standard basis vectors. We then perform row reduction until we arrive at the reduced row echelon form. If is invertible, then pivots can be found in every column of , and so the reduced row echelon form of looks like . We then just read off the inverse . If you do not find a pivot in every one of the first columns of the augmented matrix, then is not invertible.  This is best seen by example.      Find the inverse of the matrix     We write the augmented matrix and we start reducing: So     Not too terrible, no? Perhaps harder than inverting a matrix for which we had a formula, but not too bad. Really in practice this is done efficiently by a computer.    Trace and Determinant of Matrices  The next thing to add into our toolbox of matrices is the idea of the trace of a matrix, and how it and the determinant relate to the eigenvalues of said matrix.   Let be an square matrix. The of is the sum of all diagonal entries of .  For example, if we have the matrix the trace is .  The trace is important in our context because it also tells us something about the eigenvalues of a matrix. To work this out, let’s consider the generic matrix and how we would find the eigenvalues. If we have a matrix of the form we can write out the expression in order to find the eigenvalues. In this case, we would get   However, the coefficients in this polynomial look familiar. is just the determinant of the matrix , and is the trace. Therefore, for any matrix, we could write the as where is the trace of the matrix and is the determinant. On the other hand, assume that and are the two eigenvalues of this matrix (whether they be real, complex, or repeated). In that case, we know that this polynomial has and as roots. Therefore, it is equal to   Matching up the coefficient of and the constant term in and gives the relation that that is, the trace of the matrix is the sum of the eigenvalues, and the determinant of the matrix is the product of the eigenvalues. We only showed this fact for matrices, but it does hold for matrices of all sizes, giving us the following theorem.   Let be an square matrix with eigenvalues , written with multiplicity if needed. Then     The trace of is .    The determinant of is .     From the above statement, we note that if any of the eigenvalues is zero, the product of all eigenvalues will be zero, and so the matrix will have zero determinant. This gives an extra follow-up fact, and addition to .   A matrix is invertible if and only if all of it’s eigenvalues are non-zero.      Use the facts above to analyze the eigenvalues of the matrix     From the matrix , we can compute that the trace of is , and the determinant is . Based on the theorem above, we know that the two eigenvalues of this matrix must add to and multiply to . While you could probably guess the numbers here, the important take-aways from this example are what we can learn.  The main fact to point out is that this is enough information, in the case, to tell us that the eigenvalues have to be real and distinct. Since their product is a negative number, we can eliminate the other two options. If we have two complex roots, they must be of the form and , and so the product is which is always positive, no matter what and are. Similarly, if we have a repeated eigvalue, the product will be that number squared, which is also positive. Therefore, if the determinant of a matrix is negative, the eigenvalues must be real and distinct, with one being positive and one negative (otherwise the product can not be negative). These facts will be important when we start to analyze the solutions to systems of differential equations in .        What can be said about the eigenvalues of the matrix     We can find the same information as the previous example. The trace of is , and the determinant, by cofactor expansion along column 3, is . Therefore, the sum of the three eigenvalues is , and the product of them is . We don’t actually have enough information here to determine what the eigenvalues are. The issue is that with three eigenvalues, there are many different ways to get to a product being negative. There could be three negative eigenvalues, two positive and one negative, or one negative real with two complex eigenvalues. However, the one thing we do know for sure is that there must be one negative real eigenvalue. For this particular example, we can compute that the eigenvalues are , , and , so we did end up in the complex case.      Imagine that we have a matrix with a positive determinant (it doesn’t matter what the trace is). Think about all the scenarios and verify that at least one eigenvalue must be real and positive for this to happen.      Extension of Previous Theorem  With all of the new definitions and properties that have been stated, we can add a few more equivalent statements to .   Let be an matrix. The following are equivalent:      is invertible.     .    The rank of is .    The rows of are linearly independent.    The nullity of the matrix is .    None of the eigenvalues of are , or equivalently, the product of the eigenvalues of is non-zero.    The columns of are a basis of .    The rows of are a basis of .       Proof. Most of these follow from the components of . If is invertible, then we know that the columns are linearly independent. But there are columns, so that number must be the rank. This implies that the rows are linearly independent, and if the rank plus the nullity must be , we must have the nullity equal to zero. On that same train of thought, if we have linearly independent vectors in , then they must be a basis, giving (k) and (l). Finally, since the determinant is the product of the eigenvalues, if the determinant is non-zero, that implies fact (j). ◻    Exercises    For the following matrices, find a basis for the kernel (nullspace).   (4)        a)  b)  c)  d)        For the following matrices, find a basis for the kernel (nullspace).   (4)          Suppose a matrix has rank 3. What is the nullity?    2      Consider a square matrix , and suppose that is a nonzero vector such that . What does the Fredholm alternative say about invertibility of ?     must be non-invertible.      Compute the rank of the matrix below. What does this tell you about the invertibility of ? How about the solutions to ?      Compute the rank of the matrix below. What does this tell you about the invertibility of ? How about the solutions to ?      Consider If the nullity of this matrix is 2, fill in the question marks. Hint: What is the rank?           Suppose the column space of a matrix of dimension 3. Find   (2) Rank of . Nullity of . Dimension of the row space of . Dimension of the nullspace of . Size of the maximum subset of linearly independent rows of .      Compute the rank of the given matrices   (3)       a)  2 b)  3 c)  1      Compute the rank of the given matrices   (3)         For the matrices in , find a linearly independent set of row vectors that span the row space (they don’t need to be rows of the matrix).    a)  b)  c)        For the matrices in , find a linearly independent set of columns that span the column space. That is, find the pivot columns of the matrices.    a)  b)  c)        For the matrices in , find a linearly independent set of row vectors that span the row space (they don’t need to be rows of the matrix).      For the matrices in , find a linearly independent set of columns that span the column space. That is, find the pivot columns of the matrices.      Compute the rank of the matrix       Compute the rank of the matrix       Find a linearly independent subset of the following vectors that has the same span.            Find a linearly independent subset of the following vectors that has the same span.       For the following sets of vectors, determine if the set is linearly independent. Then find a basis for the subspace spanned by the vectors, and find the dimension of the subspace.   (3)          a) No, , Dimension 1 b) No, , Dimension 2 c) Yes, All 3, Dimension 3 d) No, , Dimension 2 e) No, , Dimension 2 f)  Yes, All 3, Dimension 3      For the following sets of vectors, determine if the set is linearly independent. Then find a basis for the subspace spanned by the vectors, and find the dimension of the subspace.   (3)            Suppose that is the set of all the vectors of whose third component is zero. Is a subspace? And if so, find a basis and the dimension.    Yes. Basis: Dimension 2      Consider a set of 3 component vectors.   How can it be shown if these vectors are linearly independent? Can a set of 4 of these 3 component vectors be linearly independent? Explain your answer. Can a set of 2 of these 3 component vectors be linearly independent? Explain. How would it be shown if these vectors make up a spanning set for all 3 component vectors? Can 4 vectors be a spanning set? Explain. Can 2 vectors be a spanning set? Explain.      Consider the vectors Let be the matrix with these vectors as columns and the vector .   Compute the rank of to determine how many of these vectors are linearly independent. Determine if is in the span of the given vectors by using row reduction to try to solve . Look at the columns of the row-reduced form of . Is in the span of those vectors? What do these last two parts tell you about the span of the columns of a matrix, and the span of the columns of the row-reduced matrix? Now, build a matrix with these vectors as rows. Row-reduce this matrix to get a matrix . Is in the span of the rows of ? You can’t check this in using the matrix form; instead, just brute force it based on the form of . What does this potentially say about the span of the rows of and the rows of ?      Complete with     a)  3 b) No c)  Yes d) They are not the same e)  f)  No      Compute the inverse of the given matrices   (3)       a)  b)  c)        Compute the inverse of the given matrices   (3)         By computing the inverse, solve the following systems for .   (2)      a)  b)        By computing the inverse, solve the following systems for .   (2)        For each of the following matrices below:   Compute the trace and determinant of the matrix, and Find the eigenvalues of the matrix and verify that the trace is the sum of the eigenvalues and the determinant is the product.         For each of the following matrices below:   Compute the trace and determinant of the matrix, and Find the eigenvalues of the matrix and verify that the trace is the sum of the eigenvalues and the determinant is the product.        "
},
{
  "id": "subspaces-and-span-5",
  "level": "2",
  "url": "sec-kernel.html#subspaces-and-span-5",
  "type": "Example",
  "number": "3.6.1",
  "title": ".",
  "body": "    If we let , then this is a subspace of . Adding any two vectors in gets a vector in , and so does multiplying by scalars.  The set , that is, the set of the zero vector by itself, is also a subspace of . There is only one vector in this subspace, so we only need to check for that one vector, and everything checks out: and .  The set of all the vectors of the form for any real number , such as , , or is a subspace of . Adding two such vectors, say again gets a vector of the same form, and so does multiplying by a scalar, say .   "
},
{
  "id": "subspaces-and-span-9",
  "level": "2",
  "url": "sec-kernel.html#subspaces-and-span-9",
  "type": "Example",
  "number": "3.6.2",
  "title": ".",
  "body": "    Find the linearly independent columns of the matrix     We find a pivot and reduce the rows below: We find the next pivot, make it one, and rinse and repeat: The final matrix is the row echelon form of the matrix. Consider the pivots that we marked. The pivot columns are the first and the third column. All other columns correspond to free variables when solving , so all other columns can be solved in terms of the first and the third column. In other words    "
},
{
  "id": "basis-and-dimension-7",
  "level": "2",
  "url": "sec-kernel.html#basis-and-dimension-7",
  "type": "Example",
  "number": "3.6.3",
  "title": ".",
  "body": "    The standard basis is a basis of (hence the name). So as expected   On the other hand the subspace is of dimension .  The subspace from a previous example, that is, the set of vectors is of dimension 1. One possible basis is simply , the single vector : every vector in can be represented by . Similarly another possible basis would be . Then the vector would be represented as . In this case, the subspace has many different bases, two of which are and , and the vector has a different representation (different constant) for the different bases.   "
},
{
  "id": "basis-and-dimension-9",
  "level": "2",
  "url": "sec-kernel.html#basis-and-dimension-9",
  "type": "Example",
  "number": "3.6.4",
  "title": ".",
  "body": "    Earlier, we considered the matrix Using row reduction to find the pivot columns, we found What we did was we found the basis of the column space. The basis has two elements, and so the column space of is two dimensional.   "
},
{
  "id": "basis-and-dimension-11",
  "level": "2",
  "url": "sec-kernel.html#basis-and-dimension-11",
  "type": "Example",
  "number": "3.6.5",
  "title": ".",
  "body": "    Consider the matrix Conveniently, the matrix is in reduced row echelon form. The column space is the span of the pivot columns, because the pivot columns always form a basis for the column space of a matrix. It is the 3-dimensional space The row space is the 3-dimensional space As these vectors have 5 components, we think of the row space of as a subspace of .   "
},
{
  "id": "kernel-5",
  "level": "2",
  "url": "sec-kernel.html#kernel-5",
  "type": "Example",
  "number": "3.6.6",
  "title": ".",
  "body": "    Consider This matrix is in reduced row echelon form, the pivots are marked. There are two non-pivot columns, so the kernel has dimension 2, that is, it is the span of 2 vectors. Let us find the first vector. We look at the first non-pivot column, the column, and we put a in the entry of our vector. We put a in the entry as the column is also a non-pivot column: Let us fill the rest. When this vector hits the first row, we get a and times whatever the first question mark is. So make the first question mark . For the second and third rows, it is sufficient to make it the question marks zero. We are really filling in the non-pivot column into the remaining entries. Let us check while marking which numbers went where: Yay! How about the second vector. We start with We set the first question mark to 3, the second to 4, and the third to 5. Let us check, marking things as previously, There are two non-pivot columns, so we only need two vectors. We have found the basis of the kernel. So,    "
},
{
  "id": "computing-the-inverse-7",
  "level": "2",
  "url": "sec-kernel.html#computing-the-inverse-7",
  "type": "Example",
  "number": "3.6.7",
  "title": ".",
  "body": "    Find the inverse of the matrix     We write the augmented matrix and we start reducing: So    "
},
{
  "id": "trace-and-determinant-of-matrices-12",
  "level": "2",
  "url": "sec-kernel.html#trace-and-determinant-of-matrices-12",
  "type": "Example",
  "number": "3.6.8",
  "title": ".",
  "body": "    Use the facts above to analyze the eigenvalues of the matrix     From the matrix , we can compute that the trace of is , and the determinant is . Based on the theorem above, we know that the two eigenvalues of this matrix must add to and multiply to . While you could probably guess the numbers here, the important take-aways from this example are what we can learn.  The main fact to point out is that this is enough information, in the case, to tell us that the eigenvalues have to be real and distinct. Since their product is a negative number, we can eliminate the other two options. If we have two complex roots, they must be of the form and , and so the product is which is always positive, no matter what and are. Similarly, if we have a repeated eigvalue, the product will be that number squared, which is also positive. Therefore, if the determinant of a matrix is negative, the eigenvalues must be real and distinct, with one being positive and one negative (otherwise the product can not be negative). These facts will be important when we start to analyze the solutions to systems of differential equations in .   "
},
{
  "id": "trace-and-determinant-of-matrices-13",
  "level": "2",
  "url": "sec-kernel.html#trace-and-determinant-of-matrices-13",
  "type": "Example",
  "number": "3.6.9",
  "title": ".",
  "body": "    What can be said about the eigenvalues of the matrix     We can find the same information as the previous example. The trace of is , and the determinant, by cofactor expansion along column 3, is . Therefore, the sum of the three eigenvalues is , and the product of them is . We don’t actually have enough information here to determine what the eigenvalues are. The issue is that with three eigenvalues, there are many different ways to get to a product being negative. There could be three negative eigenvalues, two positive and one negative, or one negative real with two complex eigenvalues. However, the one thing we do know for sure is that there must be one negative real eigenvalue. For this particular example, we can compute that the eigenvalues are , , and , so we did end up in the complex case.   "
},
{
  "id": "trace-and-determinant-of-matrices-14",
  "level": "2",
  "url": "sec-kernel.html#trace-and-determinant-of-matrices-14",
  "type": "Checkpoint",
  "number": "3.6.10",
  "title": "",
  "body": "  Imagine that we have a matrix with a positive determinant (it doesn’t matter what the trace is). Think about all the scenarios and verify that at least one eigenvalue must be real and positive for this to happen.   "
},
{
  "id": "sec-kernel-9-2",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-2",
  "type": "Exercise",
  "number": "3.6.8.1",
  "title": "",
  "body": "  For the following matrices, find a basis for the kernel (nullspace).   (4)        a)  b)  c)  d)     "
},
{
  "id": "sec-kernel-9-3",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-3",
  "type": "Exercise",
  "number": "3.6.8.2",
  "title": "",
  "body": "  For the following matrices, find a basis for the kernel (nullspace).   (4)       "
},
{
  "id": "sec-kernel-9-4",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-4",
  "type": "Exercise",
  "number": "3.6.8.3",
  "title": "",
  "body": "  Suppose a matrix has rank 3. What is the nullity?    2   "
},
{
  "id": "sec-kernel-9-5",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-5",
  "type": "Exercise",
  "number": "3.6.8.4",
  "title": "",
  "body": "  Consider a square matrix , and suppose that is a nonzero vector such that . What does the Fredholm alternative say about invertibility of ?     must be non-invertible.   "
},
{
  "id": "sec-kernel-9-6",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-6",
  "type": "Exercise",
  "number": "3.6.8.5",
  "title": "",
  "body": "  Compute the rank of the matrix below. What does this tell you about the invertibility of ? How about the solutions to ?   "
},
{
  "id": "sec-kernel-9-7",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-7",
  "type": "Exercise",
  "number": "3.6.8.6",
  "title": "",
  "body": "  Compute the rank of the matrix below. What does this tell you about the invertibility of ? How about the solutions to ?   "
},
{
  "id": "sec-kernel-9-8",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-8",
  "type": "Exercise",
  "number": "3.6.8.7",
  "title": "",
  "body": "  Consider If the nullity of this matrix is 2, fill in the question marks. Hint: What is the rank?        "
},
{
  "id": "sec-kernel-9-9",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-9",
  "type": "Exercise",
  "number": "3.6.8.8",
  "title": "",
  "body": "  Suppose the column space of a matrix of dimension 3. Find   (2) Rank of . Nullity of . Dimension of the row space of . Dimension of the nullspace of . Size of the maximum subset of linearly independent rows of .   "
},
{
  "id": "sec-kernel-9-10",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-10",
  "type": "Exercise",
  "number": "3.6.8.9",
  "title": "",
  "body": "  Compute the rank of the given matrices   (3)       a)  2 b)  3 c)  1   "
},
{
  "id": "sec-kernel-9-11",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-11",
  "type": "Exercise",
  "number": "3.6.8.10",
  "title": "",
  "body": "  Compute the rank of the given matrices   (3)      "
},
{
  "id": "sec-kernel-9-12",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-12",
  "type": "Exercise",
  "number": "3.6.8.11",
  "title": "",
  "body": "  For the matrices in , find a linearly independent set of row vectors that span the row space (they don’t need to be rows of the matrix).    a)  b)  c)     "
},
{
  "id": "sec-kernel-9-13",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-13",
  "type": "Exercise",
  "number": "3.6.8.12",
  "title": "",
  "body": "  For the matrices in , find a linearly independent set of columns that span the column space. That is, find the pivot columns of the matrices.    a)  b)  c)     "
},
{
  "id": "sec-kernel-9-14",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-14",
  "type": "Exercise",
  "number": "3.6.8.13",
  "title": "",
  "body": "  For the matrices in , find a linearly independent set of row vectors that span the row space (they don’t need to be rows of the matrix).   "
},
{
  "id": "sec-kernel-9-15",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-15",
  "type": "Exercise",
  "number": "3.6.8.14",
  "title": "",
  "body": "  For the matrices in , find a linearly independent set of columns that span the column space. That is, find the pivot columns of the matrices.   "
},
{
  "id": "sec-kernel-9-16",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-16",
  "type": "Exercise",
  "number": "3.6.8.15",
  "title": "",
  "body": "  Compute the rank of the matrix    "
},
{
  "id": "sec-kernel-9-17",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-17",
  "type": "Exercise",
  "number": "3.6.8.16",
  "title": "",
  "body": "  Compute the rank of the matrix    "
},
{
  "id": "sec-kernel-9-18",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-18",
  "type": "Exercise",
  "number": "3.6.8.17",
  "title": "",
  "body": "  Find a linearly independent subset of the following vectors that has the same span.         "
},
{
  "id": "sec-kernel-9-19",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-19",
  "type": "Exercise",
  "number": "3.6.8.18",
  "title": "",
  "body": "  Find a linearly independent subset of the following vectors that has the same span.    "
},
{
  "id": "sec-kernel-9-20",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-20",
  "type": "Exercise",
  "number": "3.6.8.19",
  "title": "",
  "body": "  For the following sets of vectors, determine if the set is linearly independent. Then find a basis for the subspace spanned by the vectors, and find the dimension of the subspace.   (3)          a) No, , Dimension 1 b) No, , Dimension 2 c) Yes, All 3, Dimension 3 d) No, , Dimension 2 e) No, , Dimension 2 f)  Yes, All 3, Dimension 3   "
},
{
  "id": "sec-kernel-9-21",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-21",
  "type": "Exercise",
  "number": "3.6.8.20",
  "title": "",
  "body": "  For the following sets of vectors, determine if the set is linearly independent. Then find a basis for the subspace spanned by the vectors, and find the dimension of the subspace.   (3)         "
},
{
  "id": "sec-kernel-9-22",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-22",
  "type": "Exercise",
  "number": "3.6.8.21",
  "title": "",
  "body": "  Suppose that is the set of all the vectors of whose third component is zero. Is a subspace? And if so, find a basis and the dimension.    Yes. Basis: Dimension 2   "
},
{
  "id": "sec-kernel-9-23",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-23",
  "type": "Exercise",
  "number": "3.6.8.22",
  "title": "",
  "body": "  Consider a set of 3 component vectors.   How can it be shown if these vectors are linearly independent? Can a set of 4 of these 3 component vectors be linearly independent? Explain your answer. Can a set of 2 of these 3 component vectors be linearly independent? Explain. How would it be shown if these vectors make up a spanning set for all 3 component vectors? Can 4 vectors be a spanning set? Explain. Can 2 vectors be a spanning set? Explain.   "
},
{
  "id": "sec-kernel-9-24",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-24",
  "type": "Exercise",
  "number": "3.6.8.23",
  "title": "",
  "body": "  Consider the vectors Let be the matrix with these vectors as columns and the vector .   Compute the rank of to determine how many of these vectors are linearly independent. Determine if is in the span of the given vectors by using row reduction to try to solve . Look at the columns of the row-reduced form of . Is in the span of those vectors? What do these last two parts tell you about the span of the columns of a matrix, and the span of the columns of the row-reduced matrix? Now, build a matrix with these vectors as rows. Row-reduce this matrix to get a matrix . Is in the span of the rows of ? You can’t check this in using the matrix form; instead, just brute force it based on the form of . What does this potentially say about the span of the rows of and the rows of ?   "
},
{
  "id": "sec-kernel-9-25",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-25",
  "type": "Exercise",
  "number": "3.6.8.24",
  "title": "",
  "body": "  Complete with     a)  3 b) No c)  Yes d) They are not the same e)  f)  No   "
},
{
  "id": "sec-kernel-9-26",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-26",
  "type": "Exercise",
  "number": "3.6.8.25",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (3)       a)  b)  c)     "
},
{
  "id": "sec-kernel-9-27",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-27",
  "type": "Exercise",
  "number": "3.6.8.26",
  "title": "",
  "body": "  Compute the inverse of the given matrices   (3)      "
},
{
  "id": "sec-kernel-9-28",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-28",
  "type": "Exercise",
  "number": "3.6.8.27",
  "title": "",
  "body": "  By computing the inverse, solve the following systems for .   (2)      a)  b)     "
},
{
  "id": "sec-kernel-9-29",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-29",
  "type": "Exercise",
  "number": "3.6.8.28",
  "title": "",
  "body": "  By computing the inverse, solve the following systems for .   (2)     "
},
{
  "id": "sec-kernel-9-30",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-30",
  "type": "Exercise",
  "number": "3.6.8.29",
  "title": "",
  "body": "  For each of the following matrices below:   Compute the trace and determinant of the matrix, and Find the eigenvalues of the matrix and verify that the trace is the sum of the eigenvalues and the determinant is the product.      "
},
{
  "id": "sec-kernel-9-31",
  "level": "2",
  "url": "sec-kernel.html#sec-kernel-9-31",
  "type": "Exercise",
  "number": "3.6.8.30",
  "title": "",
  "body": "  For each of the following matrices below:   Compute the trace and determinant of the matrix, and Find the eigenvalues of the matrix and verify that the trace is the sum of the eigenvalues and the determinant is the product.      "
},
{
  "id": "sec-introtosys",
  "level": "1",
  "url": "sec-introtosys.html",
  "type": "Section",
  "number": "4.1",
  "title": "Introduction to systems of ODEs",
  "body": " Introduction to systems of ODEs   Systems  Often we do not have just one dependent variable and one equation. For instance, we may be looking at multiple populations that are changing over time, or watching how the amount of support for multiple candidates develops leading up to an election. And as we will see, we may end up with systems of several equations and several dependent variables even if we start with a single equation.  If we have several dependent variables, suppose , , …, , then we can have a differential equation involving all of them and their derivatives with respect to one independent variable . For example, . Usually, when we have two dependent variables we have two equations such as for some functions and . We call the above a . More precisely, the above is a of ODEs as second order derivatives appear. The system is a , where are the dependent variables, and is the independent variable.  The terminology for systems is essentially the same as for single equations. For the system above, a solution is a set of three functions , , , such that   In order to verify that something is a solution, we plug the different components into the solution to see that all of the equations are satisfied; if any one of the equations is not satisfied, then this set of functions is not a solution. We usually also have an initial condition . Just like for single equations we specify , , and for some fixed . For example, , , for some constants , , and . For the second order system we would also specify the first derivatives at that same initial time point. And if we find a solution with constants in it, where by solving for the constants we find a solution for any initial condition, we call this solution the general solution . Best to look at a simple example.      Sometimes a system is easy to solve by solving for one variable and then for the second variable. Take the first order system with , as the dependent variables and as the independent variable. Consider initial conditions , and solve the initial value problem.    We note that is the general solution of the first equation, which we can get because this equation does not involve at all and we can get a solution via our normal first order equation methods. We then plug this into the second equation and get the equation , which is a linear first order equation that is easily solved for . By the method of integrating factor we get or . The general solution to the system is, therefore, We solve for and given the initial conditions. We substitute and find that and . Thus the solution is , and .    Generally, we will not be so lucky to be able to solve for each variable separately as in the example above, and we will have to solve for all variables at once. While we won’t generally be able to solve for one variable and then the next, we will try to salvage as much as possible from this technique. It will turn out that in a certain sense we will still (try to) solve a bunch of single equations and put their solutions together. Let’s not worry right now about how to solve systems yet.  We will mostly consider . The example above is an example of a . It is linear as none of the dependent variables or their derivatives appear in nonlinear functions or with powers higher than one ( , , and , constants, and functions of can appear, but not or or ). A more complicated example of a second order linear system is     Applications  Let us consider some simple applications of systems and how to set up the equations.      First, we consider salt and brine tanks, but this time water flows from one to the other and back. We again consider that the tanks are well-mixed.    Suppose we have two tanks, each containing volume liters of salt brine. The amount of salt in the first tank is grams, and the amount of salt in the second tank is grams. The liquid is perfectly mixed and flows at the rate liters per second out of each tank into the other. See .    The rate of change of , that is , is the rate of salt coming in minus the rate going out. The rate coming in is the density of the salt in tank 2, that is , times the rate . The rate coming out is the density of the salt in tank 1, that is , times the rate . In other words it is Similarly we find the rate , where the roles of and are reversed. All in all, the system of ODEs for this problem is In this system we cannot solve for or separately. We must solve for both and at once, which is intuitively clear since the amount of salt in one tank affects the amount in the other. We can’t know before we know , and vice versa.  We don’t yet know how to find all the solutions, but intuitively we can at least find some solutions. Suppose we know that initially the tanks have the same amount of salt. That is, we have an initial condition such as . Then clearly the amount of salt coming and out of each tank is the same, so the amounts are not changing. In other words, and (the constant functions) is a solution: , and , so the equations are satisfied.  Let us think about the setup a little bit more without solving it. Suppose the initial conditions are and , for two different constants and . Since no salt is coming in or out of this closed system, the total amount of salt is constant. That is, is constant, and so it equals . Intuitively if is bigger than , then more salt will flow out of tank one than into it. Eventually, after a long time we would then expect the amount of salt in each tank to equalize. In other words, the solutions of both and should tend towards . Once you know how to solve systems you will find out that this really is so.        Another example that showcases how systems work is different ways that populations of animals can interact. There are two main interactions that we will consider. The first of these is of two competing species. The idea here is that there are two species that are trying to coexist in a given area. On their own (without the other species), each one would grow exponentially, but any interaction between the two species is negative for both of them, because they share the types of food and other resources that they need to survive and grow. This gives rise to a system of differential equations of the form   In the system here, the coefficient represents the growth rate of species 1 on it’s own, represents the amount to which the competition for resources affects the growth rate of species 1, represents the growth rate of species 2, and represents the magnitude of how the competition affects the growth of species 2. This type of system can also be written to contain logistic growth terms for the two species, resulting in   The other main population model to consider is a predator-prey interaction. The key components of this model are that the prey population will grow on it’s own and the interaction between the two populations is negative, because the presence of predator population will cause the prey population to decrease. On the other hand, the predator population will die off on it’s own (without a food source) but the interaction with the prey population causes the predator population to increase. This gives rise to the system of differential equations where is the prey population and is the predator population. We will take another look at both of these examples in once we have more terminology and techniques to discuss them.        Let us look at a second order example. We return to the mass and spring setup, but this time we consider two masses.   2.0in2.3in  Consider one spring with constant and two masses and . Think of the masses as carts that ride along a straight track with no friction. Let be the displacement of the first cart and be the displacement of the second cart. That is, we put the two carts somewhere with no tension on the spring, and we mark the position of the first and second cart and call those the zero positions. Then measures how far the first cart is from its zero position, and measures how far the second cart is from its zero position. The force exerted by the spring on the first cart is , since is how far the string is stretched (or compressed) from the rest position. The force exerted on the second cart is the opposite, thus the same thing with a negative sign. states that force equals mass times acceleration. So the system of equations is   Again, we cannot solve for the or variable separately. That we must solve for both and at once is intuitively clear, since where the first cart goes depends on exactly where the second cart goes and vice versa.      Changing to first order  Before we talk about how to handle systems, let us note that in some sense we need only consider first order systems. Let us take an order differential equation that we would like to convert into a first order system. To do this, we first consider what a first order system would look like. A first order system consists of a set of equations involving the derivative of each of our variables. Let’s start with the first variable . What is the derivative of ? Well, it’s , and we don’t have a way to represent this in terms of our variables ( ) without any derivatives. So, we add a new variable that we define to be , which makes the first equation in our system .  Well, now we have and we need to determine what its derivative is. Since , . If the order of the equation is 2, we then have an equation to define what is in terms of , , and , which are , , and in our new system. If that’s the case, we’re done, and if not, we need to define a new variable so that . We can continue this process over and over again.  When do we stop? As illustrated in the previous example with , we stop when our derivative is the th derivative of . This works because our equation tells us exactly what is in terms of lower order terms, which we have already defined variables for. Thus, we define new variables and write the system We solve this system for , , …, . Once we have solved for the ’s, we can discard through and let . This solves the original equation.      Take . Convert this equation into a first order system.    Letting , , , we find the system: Since this is a linear system, we can also write this in matrix-vector form, which will be useful for systems that we will analyze later. To do this, we define a vector as Then, we know that We want to rewrite this equation using the vector and a matrix. We can rewrite this last vector as and the right-hand side of this equation can be written as (Verify that the matrix multiplication works out here!) Therefore, we can write this first order system as     Note that if the equation above was non-linear, it would not be possible to write the system version in an appropriate matrix form. It is also important to know how to take initial conditions into account with these problems.      Convert the initial value problem into a system of first order equations. Simplify the expression as much as possible.    We follow the same procedure as the previous example. We define variables , , as so that we have the differential equations which we can write in vector form as We would now want to try to convert this into matrix form. However, the matrix that we come up with should not depend on at all. In this case, it would mean that we want to write this equation as since the extra term needs to be everything that does not depend on . However, while we can determine the first two rows of the matrix, we can not determine the last row. There is no way to pick terms independent of to fill in the three stars in the bottom row in order to make the bottom term in the matrix-vector product to equal . The issue here is that the equation is non-linear; the term and the term can not be written in this way. Therefore, the best we can do is the vector form, and it can’t be written in matrix form.  The last thing we need to deal with is the initial conditions. Since the conditions say that and we have that , this means that the initial condition should be or Thus, the full way to write this initial value problem in system form is     A similar process can be followed for a system of higher order differential equations. For example, a system of differential equations in unknowns, all of order , can be transformed into a first order system of equations and unknowns.      Consider the system from the carts example, Let , , , . The second order system becomes the first order system         The idea works in reverse as well. Consider the system where the independent variable is . We wish to solve for the initial conditions , .    If we differentiate the second equation, we get . We know what is in terms of and , and we know that . So, We now have the equation . We know how to solve this equation and we find that . Once we have , we use the equation to get . We solve for the initial conditions and . Hence, and . So and . Our solution is       Plug in and check that this really is the solution.    It is useful to go back and forth between systems and higher order equations for other reasons. For example, software for solving ODE numerically (approximation) is generally for first order systems. So to use it, you have to take whatever ODE you want to solve and convert it to a first order system. In fact, it is not very hard to adapt computer code for the Euler or Runge–Kutta method for first order equations to handle first order systems. We essentially just treat the dependent variable not as a number but as a vector. In many mathematical computer languages there is almost no distinction in syntax.      Autonomous systems and vector fields  A system where the equations do not depend on the independent variable is called an . For example the system , is autonomous as is the independent variable but does not appear in the equations.  For autonomous systems we can draw the so-called or , a plot similar to a slope field, but instead of giving a slope at each point, we give a direction (and a magnitude). The previous example, , , says that at the point the direction in which we should travel to satisfy the equations should be the direction of the vector with the speed equal to the magnitude of this vector. So we draw the vector at the point and we do this for many points on the -plane. For example, at the point we draw the vector , a vector pointing to the right and a little bit up, while at the point we draw the vector a vector that points straight up. When drawing the vectors, we will scale down their size to fit many of them on the same direction field. We are mostly interested in their direction and relative size. See .  We can draw a path of the solution in the plane. Suppose the solution is given by , . We pick an interval of (say for our example) and plot all the points for in the selected range. The resulting picture is called the (or ). The particular curve obtained is called the or . See an example plot in . In the figure the solution starts at and travels along the vector field for a distance of 2 units of . We solved this system precisely, so we compute and to find and . This point corresponds to the top right end of the plotted solution curve in the figure.    Notice the similarity to the diagrams we drew for autonomous systems in one dimension. But note how much more complicated things become when we allow just one extra dimension.  We can draw phase portraits and trajectories in the -plane even if the system is not autonomous. In this case however we cannot draw the direction field, since the field changes as changes. For each we would get a different direction field.    Picard’s theorem  Perhaps before going further, let us mention that Picard’s theorem on existence and uniqueness still holds for systems of ODE. Let us restate this theorem in the setting of systems. A general first order system is of the form    Picard’s theorem on existence and uniqueness for systems If for every and every each is continuous and the derivative exists and is continuous near some , then a solution to subject to the initial condition , , …, exists (at least for some small interval of ’s) and is unique.  That is, a unique solution exists for any initial condition given that the system is reasonable ( and its partial derivatives in the variables are continuous). As for single equations we may not have a solution for all time , but at least for some short period of time.  As we can change any th order ODE into a first order system, then we notice that this theorem provides also the existence and uniqueness of solutions for higher order equations that we have until now not stated explicitly.    Exercises    Verify that , solves the system , .    It works      Verify that , solves the system , .    It works      Find the general solution of , .     ,       Find the general solution of , .     ,       Find the general solution to , , .      Solve , , , .      Write as a first order system of ODEs.           Write , as a first order system of ODEs.           Write as a first order system.      Write , as a first order system.      Write as a first order system.           Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem.     ,       Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem. Can this be written in matrix form? Why or why not?     , . Non-linear.      Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem.     , .      Suppose two masses on carts on frictionless surface are at displacements and as in . Suppose that a rocket applies force in the positive direction on cart . Set up the system of equations.           Suppose two masses on carts on frictionless surface are at displacements and as in . Suppose initial displacement is , and initial velocity is for some number . Use your intuition to solve the system, explain your reasoning.      Suppose the tanks are as in , starting both at volume , but now the rate of flow from tank 1 to tank 2 is , and rate of flow from tank 2 to tank 1 is . In particular, the volumes will now be changing. Set up the system of equations.     ,        Suppose the tanks are as in except that clean water flows in at the rate liters per second into tank 1, and brine flows out of tank 2 and into the sewer also at the rate of liters per second. We also adjust the flow rate of the line from tank 1 to tank 2 to be liters per second.   Draw the picture. Set up the system of equations. Intuitively, what happens as goes to infinity, explain.      Match the systems of differential equations below to their corresponding slope fields. Justify.    (3)    image     image     image       Match the systems of differential equations below to their corresponding slope fields. Justify.    (3)    image     image     image     "
},
{
  "id": "systems-6",
  "level": "2",
  "url": "sec-introtosys.html#systems-6",
  "type": "Example",
  "number": "4.1.1",
  "title": ".",
  "body": "    Sometimes a system is easy to solve by solving for one variable and then for the second variable. Take the first order system with , as the dependent variables and as the independent variable. Consider initial conditions , and solve the initial value problem.    We note that is the general solution of the first equation, which we can get because this equation does not involve at all and we can get a solution via our normal first order equation methods. We then plug this into the second equation and get the equation , which is a linear first order equation that is easily solved for . By the method of integrating factor we get or . The general solution to the system is, therefore, We solve for and given the initial conditions. We substitute and find that and . Thus the solution is , and .   "
},
{
  "id": "applications-3",
  "level": "2",
  "url": "sec-introtosys.html#applications-3",
  "type": "Example",
  "number": "4.1.2",
  "title": ".",
  "body": "    First, we consider salt and brine tanks, but this time water flows from one to the other and back. We again consider that the tanks are well-mixed.    Suppose we have two tanks, each containing volume liters of salt brine. The amount of salt in the first tank is grams, and the amount of salt in the second tank is grams. The liquid is perfectly mixed and flows at the rate liters per second out of each tank into the other. See .    The rate of change of , that is , is the rate of salt coming in minus the rate going out. The rate coming in is the density of the salt in tank 2, that is , times the rate . The rate coming out is the density of the salt in tank 1, that is , times the rate . In other words it is Similarly we find the rate , where the roles of and are reversed. All in all, the system of ODEs for this problem is In this system we cannot solve for or separately. We must solve for both and at once, which is intuitively clear since the amount of salt in one tank affects the amount in the other. We can’t know before we know , and vice versa.  We don’t yet know how to find all the solutions, but intuitively we can at least find some solutions. Suppose we know that initially the tanks have the same amount of salt. That is, we have an initial condition such as . Then clearly the amount of salt coming and out of each tank is the same, so the amounts are not changing. In other words, and (the constant functions) is a solution: , and , so the equations are satisfied.  Let us think about the setup a little bit more without solving it. Suppose the initial conditions are and , for two different constants and . Since no salt is coming in or out of this closed system, the total amount of salt is constant. That is, is constant, and so it equals . Intuitively if is bigger than , then more salt will flow out of tank one than into it. Eventually, after a long time we would then expect the amount of salt in each tank to equalize. In other words, the solutions of both and should tend towards . Once you know how to solve systems you will find out that this really is so.   "
},
{
  "id": "applications-4",
  "level": "2",
  "url": "sec-introtosys.html#applications-4",
  "type": "Example",
  "number": "4.1.3",
  "title": ".",
  "body": "    Another example that showcases how systems work is different ways that populations of animals can interact. There are two main interactions that we will consider. The first of these is of two competing species. The idea here is that there are two species that are trying to coexist in a given area. On their own (without the other species), each one would grow exponentially, but any interaction between the two species is negative for both of them, because they share the types of food and other resources that they need to survive and grow. This gives rise to a system of differential equations of the form   In the system here, the coefficient represents the growth rate of species 1 on it’s own, represents the amount to which the competition for resources affects the growth rate of species 1, represents the growth rate of species 2, and represents the magnitude of how the competition affects the growth of species 2. This type of system can also be written to contain logistic growth terms for the two species, resulting in   The other main population model to consider is a predator-prey interaction. The key components of this model are that the prey population will grow on it’s own and the interaction between the two populations is negative, because the presence of predator population will cause the prey population to decrease. On the other hand, the predator population will die off on it’s own (without a food source) but the interaction with the prey population causes the predator population to increase. This gives rise to the system of differential equations where is the prey population and is the predator population. We will take another look at both of these examples in once we have more terminology and techniques to discuss them.   "
},
{
  "id": "applications-5",
  "level": "2",
  "url": "sec-introtosys.html#applications-5",
  "type": "Example",
  "number": "4.1.4",
  "title": ".",
  "body": "    Let us look at a second order example. We return to the mass and spring setup, but this time we consider two masses.   2.0in2.3in  Consider one spring with constant and two masses and . Think of the masses as carts that ride along a straight track with no friction. Let be the displacement of the first cart and be the displacement of the second cart. That is, we put the two carts somewhere with no tension on the spring, and we mark the position of the first and second cart and call those the zero positions. Then measures how far the first cart is from its zero position, and measures how far the second cart is from its zero position. The force exerted by the spring on the first cart is , since is how far the string is stretched (or compressed) from the rest position. The force exerted on the second cart is the opposite, thus the same thing with a negative sign. states that force equals mass times acceleration. So the system of equations is   Again, we cannot solve for the or variable separately. That we must solve for both and at once is intuitively clear, since where the first cart goes depends on exactly where the second cart goes and vice versa.   "
},
{
  "id": "changing-to-first-order-5",
  "level": "2",
  "url": "sec-introtosys.html#changing-to-first-order-5",
  "type": "Example",
  "number": "4.1.5",
  "title": ".",
  "body": "    Take . Convert this equation into a first order system.    Letting , , , we find the system: Since this is a linear system, we can also write this in matrix-vector form, which will be useful for systems that we will analyze later. To do this, we define a vector as Then, we know that We want to rewrite this equation using the vector and a matrix. We can rewrite this last vector as and the right-hand side of this equation can be written as (Verify that the matrix multiplication works out here!) Therefore, we can write this first order system as    "
},
{
  "id": "changing-to-first-order-7",
  "level": "2",
  "url": "sec-introtosys.html#changing-to-first-order-7",
  "type": "Example",
  "number": "4.1.6",
  "title": ".",
  "body": "    Convert the initial value problem into a system of first order equations. Simplify the expression as much as possible.    We follow the same procedure as the previous example. We define variables , , as so that we have the differential equations which we can write in vector form as We would now want to try to convert this into matrix form. However, the matrix that we come up with should not depend on at all. In this case, it would mean that we want to write this equation as since the extra term needs to be everything that does not depend on . However, while we can determine the first two rows of the matrix, we can not determine the last row. There is no way to pick terms independent of to fill in the three stars in the bottom row in order to make the bottom term in the matrix-vector product to equal . The issue here is that the equation is non-linear; the term and the term can not be written in this way. Therefore, the best we can do is the vector form, and it can’t be written in matrix form.  The last thing we need to deal with is the initial conditions. Since the conditions say that and we have that , this means that the initial condition should be or Thus, the full way to write this initial value problem in system form is    "
},
{
  "id": "changing-to-first-order-9",
  "level": "2",
  "url": "sec-introtosys.html#changing-to-first-order-9",
  "type": "Example",
  "number": "4.1.7",
  "title": ".",
  "body": "    Consider the system from the carts example, Let , , , . The second order system becomes the first order system    "
},
{
  "id": "changing-to-first-order-10",
  "level": "2",
  "url": "sec-introtosys.html#changing-to-first-order-10",
  "type": "Example",
  "number": "4.1.8",
  "title": ".",
  "body": "    The idea works in reverse as well. Consider the system where the independent variable is . We wish to solve for the initial conditions , .    If we differentiate the second equation, we get . We know what is in terms of and , and we know that . So, We now have the equation . We know how to solve this equation and we find that . Once we have , we use the equation to get . We solve for the initial conditions and . Hence, and . So and . Our solution is    "
},
{
  "id": "changing-to-first-order-11",
  "level": "2",
  "url": "sec-introtosys.html#changing-to-first-order-11",
  "type": "Checkpoint",
  "number": "4.1.9",
  "title": "",
  "body": "  Plug in and check that this really is the solution.    It is useful to go back and forth between systems and higher order equations for other reasons. For example, software for solving ODE numerically (approximation) is generally for first order systems. So to use it, you have to take whatever ODE you want to solve and convert it to a first order system. In fact, it is not very hard to adapt computer code for the Euler or Runge–Kutta method for first order equations to handle first order systems. We essentially just treat the dependent variable not as a number but as a vector. In many mathematical computer languages there is almost no distinction in syntax.   "
},
{
  "id": "sec-introtosys-7-2",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-2",
  "type": "Exercise",
  "number": "4.1.6.1",
  "title": "",
  "body": "  Verify that , solves the system , .    It works   "
},
{
  "id": "sec-introtosys-7-3",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-3",
  "type": "Exercise",
  "number": "4.1.6.2",
  "title": "",
  "body": "  Verify that , solves the system , .    It works   "
},
{
  "id": "sec-introtosys-7-4",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-4",
  "type": "Exercise",
  "number": "4.1.6.3",
  "title": "",
  "body": "  Find the general solution of , .     ,    "
},
{
  "id": "sec-introtosys-7-5",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-5",
  "type": "Exercise",
  "number": "4.1.6.4",
  "title": "",
  "body": "  Find the general solution of , .     ,    "
},
{
  "id": "sec-introtosys-7-6",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-6",
  "type": "Exercise",
  "number": "4.1.6.5",
  "title": "",
  "body": "  Find the general solution to , , .   "
},
{
  "id": "sec-introtosys-7-7",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-7",
  "type": "Exercise",
  "number": "4.1.6.6",
  "title": "",
  "body": "  Solve , , , .   "
},
{
  "id": "sec-introtosys-7-8",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-8",
  "type": "Exercise",
  "number": "4.1.6.7",
  "title": "",
  "body": "  Write as a first order system of ODEs.        "
},
{
  "id": "sec-introtosys-7-9",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-9",
  "type": "Exercise",
  "number": "4.1.6.8",
  "title": "",
  "body": "  Write , as a first order system of ODEs.        "
},
{
  "id": "sec-introtosys-7-10",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-10",
  "type": "Exercise",
  "number": "4.1.6.9",
  "title": "",
  "body": "  Write as a first order system.   "
},
{
  "id": "sec-introtosys-7-11",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-11",
  "type": "Exercise",
  "number": "4.1.6.10",
  "title": "",
  "body": "  Write , as a first order system.   "
},
{
  "id": "sec-introtosys-7-12",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-12",
  "type": "Exercise",
  "number": "4.1.6.11",
  "title": "",
  "body": "  Write as a first order system.        "
},
{
  "id": "sec-introtosys-7-13",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-13",
  "type": "Exercise",
  "number": "4.1.6.12",
  "title": "",
  "body": "  Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem.     ,    "
},
{
  "id": "sec-introtosys-7-14",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-14",
  "type": "Exercise",
  "number": "4.1.6.13",
  "title": "",
  "body": "  Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem. Can this be written in matrix form? Why or why not?     , . Non-linear.   "
},
{
  "id": "sec-introtosys-7-15",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-15",
  "type": "Exercise",
  "number": "4.1.6.14",
  "title": "",
  "body": "  Write the initial value problem as an initial value problem for a first order system of ODEs. Make sure to indicate how the initial condition appears as a part of this problem.     , .   "
},
{
  "id": "sec-introtosys-7-16",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-16",
  "type": "Exercise",
  "number": "4.1.6.15",
  "title": "",
  "body": "  Suppose two masses on carts on frictionless surface are at displacements and as in . Suppose that a rocket applies force in the positive direction on cart . Set up the system of equations.        "
},
{
  "id": "sec-introtosys-7-17",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-17",
  "type": "Exercise",
  "number": "4.1.6.16",
  "title": "",
  "body": "  Suppose two masses on carts on frictionless surface are at displacements and as in . Suppose initial displacement is , and initial velocity is for some number . Use your intuition to solve the system, explain your reasoning.   "
},
{
  "id": "sec-introtosys-7-18",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-18",
  "type": "Exercise",
  "number": "4.1.6.17",
  "title": "",
  "body": "  Suppose the tanks are as in , starting both at volume , but now the rate of flow from tank 1 to tank 2 is , and rate of flow from tank 2 to tank 1 is . In particular, the volumes will now be changing. Set up the system of equations.     ,     "
},
{
  "id": "sec-introtosys-7-19",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-19",
  "type": "Exercise",
  "number": "4.1.6.18",
  "title": "",
  "body": "  Suppose the tanks are as in except that clean water flows in at the rate liters per second into tank 1, and brine flows out of tank 2 and into the sewer also at the rate of liters per second. We also adjust the flow rate of the line from tank 1 to tank 2 to be liters per second.   Draw the picture. Set up the system of equations. Intuitively, what happens as goes to infinity, explain.   "
},
{
  "id": "sec-introtosys-7-20",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-20",
  "type": "Exercise",
  "number": "4.1.6.19",
  "title": "",
  "body": "  Match the systems of differential equations below to their corresponding slope fields. Justify.    (3)    image     image     image    "
},
{
  "id": "sec-introtosys-7-21",
  "level": "2",
  "url": "sec-introtosys.html#sec-introtosys-7-21",
  "type": "Exercise",
  "number": "4.1.6.20",
  "title": "",
  "body": "  Match the systems of differential equations below to their corresponding slope fields. Justify.    (3)    image     image     image    "
},
{
  "id": "sec-matrix",
  "level": "1",
  "url": "sec-matrix.html",
  "type": "Section",
  "number": "4.2",
  "title": "Matrices and linear systems",
  "body": " Matrices and linear systems   This section is meant to summarize the parts of linear algebra that will be necessary in the process of developing and solving linear systems of differential equations. All of this information is covered in more detail in , so you can find more information there. If you went through that chapter already, this section will serve as a review.    Matrices and vectors  Before we start talking about linear systems of ODEs, we need to talk about matrices, so let us review these briefly. A is an array of numbers ( rows and columns). For example, we denote a matrix as follows The numbers are called elements or entries .  By a we usually mean a , that is an matrix. If we mean a , we will explicitly say so (a row vector is a matrix). We usually denote matrices by upper case letters and vectors by lower case letters with an arrow such as or . By we mean the vector of all zeros.  We define some operations on matrices. We want matrices to really act like numbers, so our operations have to be compatible with this viewpoint.  First, we can multiply a matrix by a (a number). We simply multiply each entry in the matrix by the scalar. For example, Matrix addition is also easy. We add matrices element by element. For example, If the sizes do not match, then addition is not defined.  If we denote by 0 the matrix with all zero entries, by , scalars, and by , , matrices, we have the following familiar rules:   Another useful operation for matrices is the so-called . This operation just swaps rows and columns of a matrix. The transpose of is denoted by . Example:     Matrix multiplication  Let us now define matrix multiplication. First we define the so-called (or ) of two vectors. Usually this will be a row vector multiplied with a column vector of the same size. For the dot product we multiply each pair of entries from the first and the second vector and we sum these products. The result is a single number. For example, And similarly for larger (or smaller) vectors.  Armed with the dot product we define the . First let us denote by the row of and by the column of . For an matrix and an matrix we can define the product . We let be an matrix whose entry is the dot product Do note how the sizes match up: multiplied by is . Example:   For multiplication we want an analogue of a 1. This analogue is the so-called . The identity matrix is a square matrix with 1s on the diagonal and zeros everywhere else. It is usually denoted by . For each size we have a different identity matrix and so sometimes we may denote the size as a subscript. For example, the would be the identity matrix   We have the following rules for matrix multiplication. Suppose that , , are matrices of the correct sizes so that the following make sense. Let denote a scalar (number).   A few warnings are in order.     in general (it may be true by fluke sometimes). That is, matrices do not . For example, take and .     does not necessarily imply , even if is not 0.     does not necessarily mean that or . Try, for example, .    For the last two items to hold we would need to by a matrix. This is where the comes in. Suppose that and are matrices such that Then we call the inverse of and we denote by . If the inverse of exists, then we call  invertible . If is not invertible, we sometimes say is singular .  If is invertible, then does imply that (in particular the inverse of is unique). We just multiply both sides by (on the left) to get or or . We can also see from the definition that .    The determinant  For square matrices we define a useful quantity called the . We define the determinant of a matrix as the value of its only entry. For a matrix we define   Before trying to define the determinant for larger matrices, let us note the meaning of the determinant. Consider an matrix as a mapping of the -dimensional euclidean space to itself, where gets sent to . In particular, a matrix is a mapping of the plane to itself. The determinant of is the factor by which the area of objects changes. If we take the unit square (square of side 1) in the plane, then takes the square to a parallelogram of area . The sign of denotes changing of orientation (negative if the axes get flipped). For example, let Then . Let us see where the (unit) square with vertices , , , and gets sent. Clearly gets sent to . The image of the square is another square with vertices , , , and . The image square has a side of length and is therefore of area 2.  If you think back to high school geometry, you may have seen a formula for computing the area of a with vertices , , and . And it is precisely The vertical lines above mean absolute value. The matrix carries the unit square to the given parallelogram.  Let us look at the determinant for larger matrices. We define as the matrix with the row and the column deleted. To compute the determinant of a matrix, pick one row, say the row and compute: For the first row we get We alternately add and subtract the determinants of the submatrices multiplied by for a fixed and all . For a matrix, picking the first row, we get . For example,   The numbers are called cofactors of the matrix and this way of computing the determinant is called the . No matter which row you pick, you always get the same number. It is also possible to compute the determinant by expanding along columns (picking a column instead of a row above). It is true that .  A common notation for the determinant is a pair of vertical lines: I personally find this notation confusing as vertical lines usually mean a positive quantity, while determinants can be negative. Also think about how to write the absolute value of a determinant. I will not use this notation in this book.  Think of the determinants telling you the scaling of a mapping. If doubles the sizes of geometric objects and triples them, then (which applies to an object and then ) should make size go up by a factor of . This is true in general: This property is one of the most useful, and it is employed often to actually compute determinants. A particularly interesting consequence is to note what it means for existence of inverses. Take and to be inverses of each other, that is . Then Neither nor can be zero. Let us state this as a theorem as it will be very important in the context of this course.   An matrix is invertible if and only if .  In fact, says that . So we even know what the determinant of is before we know how to compute .  There is a simple formula for the inverse of a matrix Notice the determinant of the matrix in the denominator of the fraction. The formula only works if the determinant is nonzero, otherwise we are dividing by zero.    Solving linear systems  One application of matrices we will need is to solve systems of linear equations. This is best shown by example. Suppose that we have the following system of linear equations   Without changing the solution, we could swap equations in this system, we could multiply any of the equations by a nonzero number, and we could add a multiple of one equation to another equation. It turns out these operations always suffice to find a solution.  It is easier to write the system as a matrix equation. The system above can be written as To solve the system we put the coefficient matrix (the matrix on the left-hand side of the equation) together with the vector on the right and side and get the so-called    We apply the following three elementary operations.    Swap two rows.    Multiply a row by a nonzero number.    Add a multiple of one row to another row.    We keep doing these operations until we get into a state where it is easy to read off the answer, or until we get into a contradiction indicating no solution, for example if we come up with an equation such as .  Let us work through the example. First multiply the first row by to obtain Now subtract the first row from the second and third row. Multiply the last row by and the second row by . Swap rows 2 and 3. Subtract the last row from the first, then subtract the second row from the first. If we think about what equations this augmented matrix represents, we see that , , and . We try this solution in the original system and, voilà, it works!    Check that the solution above really solves the given equations.    We write this equation in matrix notation as where is the matrix and is the vector . The solution can also be computed via the inverse,     It is possible that the solution is not unique, or that no solution exists. It is easy to tell if a solution does not exist. If during the row reduction you come up with a row where all the entries except the last one are zero (the last entry in a row corresponds to the right-hand side of the equation), then the system is inconsistent and has no solution. For example, for a system of 3 equations and 3 unknowns, if you find a row such as in the augmented matrix, you know the system is inconsistent. That row corresponds to .  You generally try to use row operations until the following conditions are satisfied. The first (from the left) nonzero entry in each row is called the .    The leading entry in any row is strictly to the right of the leading entry of the row above.    Any zero rows are below all the nonzero rows.    All leading entries are 1.    All the entries above and below a leading entry are zero.    Such a matrix is said to be in . The variables corresponding to columns with no leading entries are said to be free variables . Free variables mean that we can pick those variables to be anything we want and then solve for the rest of the unknowns.      The following augmented matrix is in reduced row echelon form. Suppose the variables are , , and . Then is the free variable, , and .  On the other hand if during the row reduction process you come up with the matrix there is no need to go further. The last row corresponds to the equation , which is preposterous. Hence, no solution exists.      Computing the inverse  If the matrix is square and there exists a unique solution to for any (there are no free variables), then is invertible. Multiplying both sides by , you can see that . So it is useful to compute the inverse if you want to solve the equation for many different right-hand sides .  We have a formula for the inverse, but it is also not hard to compute inverses of larger matrices. While we will not have too much occasion to compute inverses for larger matrices than by hand, let us touch on how to do it. Finding the inverse of is actually just solving a bunch of linear equations. If we can solve where is the vector with all zeros except a 1 at the position, then the inverse is the matrix with the columns for (exercise: why?). Therefore, to find the inverse we write a larger augmented matrix , where is the identity matrix. We then perform row reduction. The reduced row echelon form of will be of the form if and only if is invertible. We then just read off the inverse .    Eigenvalues and eigenvectors of a matrix  Let be a constant square matrix. Suppose there is a scalar and a nonzero vector such that We call an of and we call a corresponding .      The matrix has an eigenvalue with a corresponding eigenvector as     Let us see how to compute eigenvalues for any matrix. Rewrite the equation for an eigenvalue as This equation has a nonzero solution only if is not invertible. Were it invertible, we could write , which implies . Therefore, has the eigenvalue if and only if solves the equation   Consequently, we will be able to find an eigenvalue of without finding a corresponding eigenvector. An eigenvector will have to be found later, once is known.      Find all eigenvalues of .    We write So the eigenvalues are , , and .    For an matrix, the polynomial we get by computing is of degree , and hence in general, we have eigenvalues. Some may be repeated, some may be complex.  To find an eigenvector corresponding to an eigenvalue , we write and solve for a nontrivial (nonzero) vector . If is an eigenvalue, there will be at least one free variable, and so for each distinct eigenvalue , we can always find an eigenvector.      Find an eigenvector of corresponding to the eigenvalue .    We write It is easy to solve this system of linear equations. We write down the augmented matrix and perform row operations (exercise: which ones?) until we get: The entries of have to satisfy the equations , , and is a free variable. We can pick to be arbitrary (but nonzero), let , and of course . For example, if we pick , then . Let us verify that really is an eigenvector corresponding to : Yay! It worked.      Are eigenvectors unique? Can you find a different eigenvector for in the example above? How are the two eigenvectors related?    All eigenvectors (in this case) are multiples of each other.      When the matrix is you do not need to do row operations when computing an eigenvector, you can read it off from (if you have computed the eigenvalues correctly). Can you see why? Explain. Try it for the matrix .      Exercises    Let and be the matrices below. Compute , , and .     , ,       Solve by using matrix inverse.           Compute determinant of .    6      Compute determinant of       Compute determinant of . Hint: Expand along the proper row or column to make the calculations simpler.    4      Compute inverse of .           For which is not invertible? Is there only one such ? Are there several? Infinitely many?           Find such that is not invertible.      For which is not invertible? Find all such .           Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Solve the system of equations or determine that no solution exists.      Solve .           Solve .    Infinitely many solutions for any real       Solve .      Solve .    No solution      Find 3 nonzero matrices , , and such that but .    Many examples. (Hint: What do you know has to be true about ?) , ,       Suppose are nonzero numbers. Let , .   (2) Compute . Compute .      Let be a matrix with an eigenvalue of 3 and a corresponding eigenvector . Find .           Find the eigenvalues and eigenvectors for the matrix       Find the eigenvalues and eigenvectors for the matrix       Find the eigenvalues and eigenvectors for the matrix     "
},
{
  "id": "solving-linear-systems-9",
  "level": "2",
  "url": "sec-matrix.html#solving-linear-systems-9",
  "type": "Checkpoint",
  "number": "4.2.1",
  "title": "",
  "body": "  Check that the solution above really solves the given equations.    We write this equation in matrix notation as where is the matrix and is the vector . The solution can also be computed via the inverse,    "
},
{
  "id": "solving-linear-systems-14",
  "level": "2",
  "url": "sec-matrix.html#solving-linear-systems-14",
  "type": "Example",
  "number": "4.2.2",
  "title": ".",
  "body": "    The following augmented matrix is in reduced row echelon form. Suppose the variables are , , and . Then is the free variable, , and .  On the other hand if during the row reduction process you come up with the matrix there is no need to go further. The last row corresponds to the equation , which is preposterous. Hence, no solution exists.   "
},
{
  "id": "eigenvalues-and-eigenvectors-of-a-matrix-3",
  "level": "2",
  "url": "sec-matrix.html#eigenvalues-and-eigenvectors-of-a-matrix-3",
  "type": "Example",
  "number": "4.2.3",
  "title": ".",
  "body": "    The matrix has an eigenvalue with a corresponding eigenvector as    "
},
{
  "id": "eigenvalues-and-eigenvectors-of-a-matrix-6",
  "level": "2",
  "url": "sec-matrix.html#eigenvalues-and-eigenvectors-of-a-matrix-6",
  "type": "Example",
  "number": "4.2.4",
  "title": ".",
  "body": "    Find all eigenvalues of .    We write So the eigenvalues are , , and .   "
},
{
  "id": "eigenvalues-and-eigenvectors-of-a-matrix-9",
  "level": "2",
  "url": "sec-matrix.html#eigenvalues-and-eigenvectors-of-a-matrix-9",
  "type": "Example",
  "number": "4.2.5",
  "title": ".",
  "body": "    Find an eigenvector of corresponding to the eigenvalue .    We write It is easy to solve this system of linear equations. We write down the augmented matrix and perform row operations (exercise: which ones?) until we get: The entries of have to satisfy the equations , , and is a free variable. We can pick to be arbitrary (but nonzero), let , and of course . For example, if we pick , then . Let us verify that really is an eigenvector corresponding to : Yay! It worked.   "
},
{
  "id": "eigenvalues-and-eigenvectors-of-a-matrix-10",
  "level": "2",
  "url": "sec-matrix.html#eigenvalues-and-eigenvectors-of-a-matrix-10",
  "type": "Checkpoint",
  "number": "4.2.6",
  "title": "",
  "body": "  Are eigenvectors unique? Can you find a different eigenvector for in the example above? How are the two eigenvectors related?    All eigenvectors (in this case) are multiples of each other.   "
},
{
  "id": "eigenvalues-and-eigenvectors-of-a-matrix-11",
  "level": "2",
  "url": "sec-matrix.html#eigenvalues-and-eigenvectors-of-a-matrix-11",
  "type": "Checkpoint",
  "number": "4.2.7",
  "title": "",
  "body": "  When the matrix is you do not need to do row operations when computing an eigenvector, you can read it off from (if you have computed the eigenvalues correctly). Can you see why? Explain. Try it for the matrix .   "
},
{
  "id": "sec-matrix-9-2",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-2",
  "type": "Exercise",
  "number": "4.2.7.1",
  "title": "",
  "body": "  Let and be the matrices below. Compute , , and .     , ,    "
},
{
  "id": "sec-matrix-9-3",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-3",
  "type": "Exercise",
  "number": "4.2.7.2",
  "title": "",
  "body": "  Solve by using matrix inverse.        "
},
{
  "id": "sec-matrix-9-4",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-4",
  "type": "Exercise",
  "number": "4.2.7.3",
  "title": "",
  "body": "  Compute determinant of .    6   "
},
{
  "id": "sec-matrix-9-5",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-5",
  "type": "Exercise",
  "number": "4.2.7.4",
  "title": "",
  "body": "  Compute determinant of    "
},
{
  "id": "sec-matrix-9-6",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-6",
  "type": "Exercise",
  "number": "4.2.7.5",
  "title": "",
  "body": "  Compute determinant of . Hint: Expand along the proper row or column to make the calculations simpler.    4   "
},
{
  "id": "sec-matrix-9-7",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-7",
  "type": "Exercise",
  "number": "4.2.7.6",
  "title": "",
  "body": "  Compute inverse of .        "
},
{
  "id": "sec-matrix-9-8",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-8",
  "type": "Exercise",
  "number": "4.2.7.7",
  "title": "",
  "body": "  For which is not invertible? Is there only one such ? Are there several? Infinitely many?        "
},
{
  "id": "sec-matrix-9-9",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-9",
  "type": "Exercise",
  "number": "4.2.7.8",
  "title": "",
  "body": "  Find such that is not invertible.   "
},
{
  "id": "sec-matrix-9-10",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-10",
  "type": "Exercise",
  "number": "4.2.7.9",
  "title": "",
  "body": "  For which is not invertible? Find all such .        "
},
{
  "id": "sec-matrix-9-11",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-11",
  "type": "Exercise",
  "number": "4.2.7.10",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "sec-matrix-9-12",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-12",
  "type": "Exercise",
  "number": "4.2.7.11",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "sec-matrix-9-13",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-13",
  "type": "Exercise",
  "number": "4.2.7.12",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "sec-matrix-9-14",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-14",
  "type": "Exercise",
  "number": "4.2.7.13",
  "title": "",
  "body": "  Solve the system of equations or determine that no solution exists.   "
},
{
  "id": "sec-matrix-9-15",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-15",
  "type": "Exercise",
  "number": "4.2.7.14",
  "title": "",
  "body": "  Solve .        "
},
{
  "id": "sec-matrix-9-16",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-16",
  "type": "Exercise",
  "number": "4.2.7.15",
  "title": "",
  "body": "  Solve .    Infinitely many solutions for any real    "
},
{
  "id": "sec-matrix-9-17",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-17",
  "type": "Exercise",
  "number": "4.2.7.16",
  "title": "",
  "body": "  Solve .   "
},
{
  "id": "sec-matrix-9-18",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-18",
  "type": "Exercise",
  "number": "4.2.7.17",
  "title": "",
  "body": "  Solve .    No solution   "
},
{
  "id": "sec-matrix-9-19",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-19",
  "type": "Exercise",
  "number": "4.2.7.18",
  "title": "",
  "body": "  Find 3 nonzero matrices , , and such that but .    Many examples. (Hint: What do you know has to be true about ?) , ,    "
},
{
  "id": "sec-matrix-9-20",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-20",
  "type": "Exercise",
  "number": "4.2.7.19",
  "title": "",
  "body": "  Suppose are nonzero numbers. Let , .   (2) Compute . Compute .   "
},
{
  "id": "sec-matrix-9-21",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-21",
  "type": "Exercise",
  "number": "4.2.7.20",
  "title": "",
  "body": "  Let be a matrix with an eigenvalue of 3 and a corresponding eigenvector . Find .        "
},
{
  "id": "sec-matrix-9-22",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-22",
  "type": "Exercise",
  "number": "4.2.7.21",
  "title": "",
  "body": "  Find the eigenvalues and eigenvectors for the matrix    "
},
{
  "id": "sec-matrix-9-23",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-23",
  "type": "Exercise",
  "number": "4.2.7.22",
  "title": "",
  "body": "  Find the eigenvalues and eigenvectors for the matrix    "
},
{
  "id": "sec-matrix-9-24",
  "level": "2",
  "url": "sec-matrix.html#sec-matrix-9-24",
  "type": "Exercise",
  "number": "4.2.7.23",
  "title": "",
  "body": "  Find the eigenvalues and eigenvectors for the matrix    "
},
{
  "id": "linsystems-section",
  "level": "1",
  "url": "linsystems-section.html",
  "type": "Section",
  "number": "4.3",
  "title": "Linear systems of ODEs",
  "body": " Linear systems of ODEs  In order to get into the details of how to talk about and deal with linear systems of differential equations, we first need to talk about matrix- or vector-valued functions. Such a function is just a matrix or vector whose entries depend on some variable. If is the independent variable, we write a  as Similarly a  is As long as the addition of vectors is defined, we can add vector-valued functions, and as long as the addition and multiplication of matrices are defined (like if they are the right size) we can multiply matrix-valued functions. In addition, the derivative or is just the matrix-valued function whose entry is . We used this idea previously when talking about how to write first order systems from higher order equations in .  Rules of differentiation of matrix-valued functions are similar to rules for normal functions. Let and be matrix-valued functions. Let a scalar and let be a constant matrix. Then Note the order of the multiplication in the last two expressions because matrix multiplication is not commutative.  A is a system that can be written as the vector equation where is a matrix-valued function, and and are vector-valued functions. We will often suppress the dependence on and only write . A solution of the system is a vector-valued function satisfying the vector equation.  For example, the equations can be written as   We will mostly concentrate on equations that are not just linear, but are in fact equations. That is, the matrix will be constant; it will not depend on .  When (the zero vector), then we say the system is homogeneous . For homogeneous linear systems we have the principle of superposition, just like for single homogeneous equations.   Superposition Let be a linear homogeneous system of ODEs. Suppose that are solutions of the equation and are any constants, then is also a solution. Furthermore, if this is a system of equations ( is ), and are linearly independent, then every solution can be written as .  Linear independence for vector-valued functions is the same idea as for normal functions. The vector-valued functions are linearly independent if the only way to satisfy the equation is by choosing the parameters , where the equation must hold for all .      Determine if the sets and are linearly independent.    The vector functions in are linearly dependent because , and this holds for all . So , , and above will work.  On the other hand, the vector functions in are linearly independent, even though this is only a slight change from . First write and note that it has to hold for all . We get that In other words and . If we set , then the second equation becomes . But then the first equation becomes for all and so . Thus the second equation is just , which means . So is the only solution and , , and are linearly independent.    The linear combination could always be also as where is the matrix with columns , and is the column vector with entries . This is similar to the way that we could write linear combinations of vectors by putting them into a matrix, including how we talked about rank in . Assuming that are linearly independent and solutions to a given system of differential equations, the matrix-valued function is called a , or a .  To solve nonhomogeneous first order linear systems, we use the same technique as we applied to solve single linear nonhomogeneous equations.   Let be a linear system of ODEs. Suppose is one particular solution. Then every solution can be written as where is a solution to the ( ).  The procedure for systems is the same as for single equations. We find a particular solution to the nonhomogeneous equation, then we find the general solution to the associated homogeneous equation, and finally we add the two together.  Alright, suppose you have found the general solution of . Next suppose you are given an initial condition of the form for some fixed and a constant vector . Let be a fundamental matrix solution of the associated homogeneous equation (i.e. columns of are solutions). The general solution can be written as We are seeking a vector such that In other words, we are solving for in the nonhomogeneous system of linear equations       In we solved the system with initial conditions , . Let us consider this problem in the language of this section.  The system is homogeneous, so . We write the system and the initial conditions as   We found the general solution is and . Letting and , we obtain the solution . Letting and , we obtain . These two solutions are linearly independent, as can be seen by setting , and noting that the resulting constant vectors are linearly independent. In matrix notation, a fundamental matrix solution is, therefore,   To solve the initial value problem we solve for in the equation or in other words, A single elementary row operation shows . Our solution is This new solution agrees with our previous solution from .     Exercises    Write the system , in the form .     ,       Write , in matrix notation.      Consider the third order differential equation Convert this to a first order system and simplify as much as possible. Can you write this in the form ? Why or why not?    No, it is non-linear.        Verify that the system has the two solutions and . Write down the general solution. Write down the general solution in the form , (i.e. write down a formula for each element of the solution).    b)  c)        Verify that and are linearly independent. Hint: Just plug in .    Yes      Are and linearly independent? Justify.      Verify that and and are linearly independent. Hint: You must be a bit more tricky than in the previous exercises.    Yes. Write this out as three equations that all must equal zero, see what combining the first two gets you, then go from there.      Are , , and linearly independent? Justify.      Verify that and are linearly independent.    Yes, write out the equations and see when they can be zero.      Take the system , .   Write it in the form for matrices and . Compute and use that to write the system in the form .     , ,        Write , in matrix notation. Solve and write the solution in matrix notation.    "
},
{
  "id": "linsystems-section-10",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-10",
  "type": "Example",
  "number": "4.3.1",
  "title": ".",
  "body": "    Determine if the sets and are linearly independent.    The vector functions in are linearly dependent because , and this holds for all . So , , and above will work.  On the other hand, the vector functions in are linearly independent, even though this is only a slight change from . First write and note that it has to hold for all . We get that In other words and . If we set , then the second equation becomes . But then the first equation becomes for all and so . Thus the second equation is just , which means . So is the only solution and , , and are linearly independent.   "
},
{
  "id": "linsystems-section-16",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-16",
  "type": "Example",
  "number": "4.3.2",
  "title": ".",
  "body": "    In we solved the system with initial conditions , . Let us consider this problem in the language of this section.  The system is homogeneous, so . We write the system and the initial conditions as   We found the general solution is and . Letting and , we obtain the solution . Letting and , we obtain . These two solutions are linearly independent, as can be seen by setting , and noting that the resulting constant vectors are linearly independent. In matrix notation, a fundamental matrix solution is, therefore,   To solve the initial value problem we solve for in the equation or in other words, A single elementary row operation shows . Our solution is This new solution agrees with our previous solution from .   "
},
{
  "id": "linsystems-section-17-2",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-2",
  "type": "Exercise",
  "number": "4.3.1",
  "title": "",
  "body": "  Write the system , in the form .     ,    "
},
{
  "id": "linsystems-section-17-3",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-3",
  "type": "Exercise",
  "number": "4.3.2",
  "title": "",
  "body": "  Write , in matrix notation.   "
},
{
  "id": "linsystems-section-17-4",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-4",
  "type": "Exercise",
  "number": "4.3.3",
  "title": "",
  "body": "  Consider the third order differential equation Convert this to a first order system and simplify as much as possible. Can you write this in the form ? Why or why not?    No, it is non-linear.    "
},
{
  "id": "linsystems-section-17-5",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-5",
  "type": "Exercise",
  "number": "4.3.4",
  "title": "",
  "body": "   Verify that the system has the two solutions and . Write down the general solution. Write down the general solution in the form , (i.e. write down a formula for each element of the solution).    b)  c)     "
},
{
  "id": "linsystems-section-17-6",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-6",
  "type": "Exercise",
  "number": "4.3.5",
  "title": "",
  "body": "  Verify that and are linearly independent. Hint: Just plug in .    Yes   "
},
{
  "id": "linsystems-section-17-7",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-7",
  "type": "Exercise",
  "number": "4.3.6",
  "title": "",
  "body": "  Are and linearly independent? Justify.   "
},
{
  "id": "linsystems-section-17-8",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-8",
  "type": "Exercise",
  "number": "4.3.7",
  "title": "",
  "body": "  Verify that and and are linearly independent. Hint: You must be a bit more tricky than in the previous exercises.    Yes. Write this out as three equations that all must equal zero, see what combining the first two gets you, then go from there.   "
},
{
  "id": "linsystems-section-17-9",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-9",
  "type": "Exercise",
  "number": "4.3.8",
  "title": "",
  "body": "  Are , , and linearly independent? Justify.   "
},
{
  "id": "linsystems-section-17-10",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-10",
  "type": "Exercise",
  "number": "4.3.9",
  "title": "",
  "body": "  Verify that and are linearly independent.    Yes, write out the equations and see when they can be zero.   "
},
{
  "id": "linsystems-section-17-11",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-11",
  "type": "Exercise",
  "number": "4.3.10",
  "title": "",
  "body": "  Take the system , .   Write it in the form for matrices and . Compute and use that to write the system in the form .     , ,    "
},
{
  "id": "linsystems-section-17-12",
  "level": "2",
  "url": "linsystems-section.html#linsystems-section-17-12",
  "type": "Exercise",
  "number": "4.3.11",
  "title": "",
  "body": "   Write , in matrix notation. Solve and write the solution in matrix notation.   "
},
{
  "id": "eigenmethod-section",
  "level": "1",
  "url": "eigenmethod-section.html",
  "type": "Section",
  "number": "4.4",
  "title": "Eigenvalue method",
  "body": " Eigenvalue method   In this section we will learn how to solve linear homogeneous constant coefficient systems of ODEs by the eigenvalue method. Suppose we have such a system where is a constant square matrix. We wish to adapt the method for the single constant coefficient equation by trying the function . However, is a vector. So we try , where is an arbitrary constant vector. We plug this into the equation to get We divide by and notice that we are looking for a scalar and a vector that satisfy the equation   This means that we are looking for an eigenvalue with corresponding eigenvector for the matrix . When we can find these, we will get solutions to the original system of differential equations of the form We get the easiest route to solutions when the matrix has all real eigenvalues and the eigenvalues are all distinct, and can extend to deal with the complications that arise from complex and repeated eigenvalues.  Another way to view these types of solutions are as straight-line solutions. A system of differential equations of the form is an autonomous system of differential equations, because there is no explicit dependence on on the right-hand side. When we solved autonomous equations in , we started by looking for equilibrium solutions and built up from there. In this particular case, we are looking for vectors so that . As long as is invertible, the only vector that satisfies this is . So, that’s not super interesting, and doesn’t really tell us too much about the solution to the problem.   3.25in  The next more involved type of solution we could look for is a straight-line solution. The idea is that this solution will either move directly (in a straight-line) towards or away from the origin. In the first order autonomous equation case, all of our solutions did this; they either moved towards or away from these equilibrium solutions. This may not be the case for systems, but we can try to find them. If a solution is going to move directly towards or away from the origin, then the direction of change for the solution must be parallel to the position vector. In , the vectors that point in the same or opposite direction of will give rise to a straight-line solution, but vectors that do not point in this direction will give solutions that do not follow a straight-line through the origin.  This criterion means that we need to have for some constant . If this is the case, then we have and this is the equation for eigenvalues and eigenvectors of . We are back to the same type of solution that we found previously.    The eigenvalue method with distinct real eigenvalues  OK. We have the system of equations We find the eigenvalues , , …, of the matrix , and corresponding eigenvectors , , …, . Now we notice that the functions , , …, are solutions of the homogeneous system of equations and hence is a solution by superposition.   Take . If is an constant matrix that has distinct real eigenvalues , , …, , then there exist linearly independent corresponding eigenvectors , , …, , and the general solution to can be written as   The corresponding fundamental matrix solution is That is, is the matrix whose column is .      Consider the system Find the general solution.    Earlier, we found the eigenvalues are . We found the eigenvector for the eigenvalue 3. Similarly we find the eigenvector for the eigenvalue 1, and for the eigenvalue 2 (exercise: check). Hence our general solution is In terms of a fundamental matrix solution,       Check that this really solves the system.    Overall, the process for finding the solution for real and distinct eigenvalues is to first find the eigenvalues and eigenvectors of the matrix . Once we have these, we get linearly independent solutions of the form , so that the general solution is of the form Then, if we need to solve for an initial condition, we figure out the coefficients , , ..., to satisfy this condition.    Note: If we write a single homogeneous linear constant coefficient order equation as a first order system (as we did in ), then the eigenvalue equation is essentially the same as the characteristic equation we got in and . See the exercises for details about this.      Solve the initial value problem     Since we are in the case of a constant-coefficient linear system, we start by looking for the eigenvalues and eigenvectors of the coefficient matrix . To do this, we compute This polynomial factors as , and so the two eigenvalues are and .  Next, we need to find the corresponding eigenvectors. For , we get the matrix equation The two equations that you get here are redundant, which is . One way to satisfy this is , , so that the eigenvector is .  For , the matrix becomes so the eigenvector here is . Therefore, the general solution to this differential equation, by superposition, is   Finally, we have to solve the initial value problem using the initial conditions. If we plug in , we get the equation This results in needing to solve the system of equations These can be solved in any way, including row reduction. We will start by adding the two equations together, which gives , and then the first equation implies that . Therefore, the solution to the initial value problem is       Phase Portraits  Now that we have these solutions, we want to get an idea for what they look like in the plane. We spent a lot of time in first order equations looking at direction fields, as well as phase lines for autonomous equations. We want to develope the same type of intuition for two-component systems in the plane, because much intuition can be obtained by studying this simple case. Suppose we use coordinates for the plane as usual, and suppose is a matrix. Consider the system The system is autonomous (compare this section to ) and so we can draw a vector field (see the end of ). We will be able to visually tell what the vector field looks like and how the solutions behave, once we find the eigenvalues and eigenvectors of the matrix . The goal is to be able to sketch what the different trajectories of the solutions look like for a variety of initial conditions, as well as classify the general type of picture that results depending on the matrix .   Case 1. Suppose that the eigenvalues of are real and positive. We find two corresponding eigenvectors and plot them in the plane. For example, take the matrix . The eigenvalues are 1 and 2 and corresponding eigenvectors are and . See .   3.25in  Suppose the point is on the line determined by an eigenvector for an eigenvalue . That is, for some scalar . Then The derivative is a multiple of and hence points along the line determined by . As , the derivative points in the direction of when is positive and in the opposite direction when is negative. Let us draw the lines determined by the eigenvectors, and let us draw arrows on the lines to indicate the directions. See .  We fill in the rest of the arrows for the vector field and we also draw a few solutions. See . The picture looks like a source with arrows coming out from the origin. Hence we call this type of picture a or sometimes an . Notice the two eigenvectors are drawn on the entire vector field figure with arrows, and the straight-line solutions follow them.     Case 2. Suppose both eigenvalues are negative. For example, take the negation of the matrix in case 1, . The eigenvalues are and and corresponding eigenvectors are the same, and . The calculation and the picture are almost the same. The only difference is that the eigenvalues are negative and hence all arrows are reversed. We get the picture in . We call this kind of picture a or a .     Case 3. Suppose one eigenvalue is positive and one is negative. For example the matrix . The eigenvalues are 1 and and corresponding eigenvectors are and . We reverse the arrows on one line (corresponding to the negative eigenvalue) and we obtain the picture in . We call this picture a .    Exercises     Find the general solution of , using the eigenvalue method (first write the system in the form ). Solve the system by solving each equation separately and verify you get the same general solution.           Find the general solution of , using the eigenvalue method and sketch the phase portrait for this system of differential equations.           Solve , using the eigenvalue method and sketch the phase portrait for this system of differential equations.      Amino acid dating can be used by forensic scientists to determine the time of death in situations where other techniques might not work. These amino acids are sneaky, and they exist in a left-handed form (L) and a right-handed form (D), which are called enantiomers . While you’re alive, your body keeps all your amino acids in the L form. Once you die, your body no longer regulates your amino acids, and every so often they flip a coin and decide whether to switch into the opposite form. This way, when someone finds your body in a dumpster, they can pull out your teeth and measure the racemization ratio , which is the ratio of D-enantiomers to L-enantiomers.  Denote by and , respectively, the proportions of D- and L-enantiomers found in your teeth, where is measured in years after death. Since this is Math class, the proportions are governed by a system of differential equations, such as    Find the general solution to . Solve with initial conditions and , and express the solution in component form. Describe what happens to the quantities and in the long run. Given the above initial conditions, if the racemization ratio in your teeth is currently 1:3, how long ago did you die?    a)  b)  . Both go to . c)  years       Compute eigenvalues and eigenvectors of . Find the general solution of .    a)  , . , . , b)         Compute eigenvalues and eigenvectors of . Solve the system .      Let be numbers. Find the eigenvalues of .    a, d, f      Find the general solution of the system and sketch the phase portrait for this system.      Find the general solution of the system and draw a sketch for the phase portrait.      Find the general solution of the system       Find the general solution of the system       Solve the initial value problem            Solve the initial value problem            Solve the initial value problem           "
},
{
  "id": "the-eigenvalue-method-with-distinct-real-eigenvalues-5",
  "level": "2",
  "url": "eigenmethod-section.html#the-eigenvalue-method-with-distinct-real-eigenvalues-5",
  "type": "Example",
  "number": "4.4.1",
  "title": ".",
  "body": "    Consider the system Find the general solution.    Earlier, we found the eigenvalues are . We found the eigenvector for the eigenvalue 3. Similarly we find the eigenvector for the eigenvalue 1, and for the eigenvalue 2 (exercise: check). Hence our general solution is In terms of a fundamental matrix solution,    "
},
{
  "id": "the-eigenvalue-method-with-distinct-real-eigenvalues-6",
  "level": "2",
  "url": "eigenmethod-section.html#the-eigenvalue-method-with-distinct-real-eigenvalues-6",
  "type": "Checkpoint",
  "number": "4.4.2",
  "title": "",
  "body": "  Check that this really solves the system.    Overall, the process for finding the solution for real and distinct eigenvalues is to first find the eigenvalues and eigenvectors of the matrix . Once we have these, we get linearly independent solutions of the form , so that the general solution is of the form Then, if we need to solve for an initial condition, we figure out the coefficients , , ..., to satisfy this condition.   "
},
{
  "id": "the-eigenvalue-method-with-distinct-real-eigenvalues-8",
  "level": "2",
  "url": "eigenmethod-section.html#the-eigenvalue-method-with-distinct-real-eigenvalues-8",
  "type": "Example",
  "number": "4.4.3",
  "title": ".",
  "body": "    Solve the initial value problem     Since we are in the case of a constant-coefficient linear system, we start by looking for the eigenvalues and eigenvectors of the coefficient matrix . To do this, we compute This polynomial factors as , and so the two eigenvalues are and .  Next, we need to find the corresponding eigenvectors. For , we get the matrix equation The two equations that you get here are redundant, which is . One way to satisfy this is , , so that the eigenvector is .  For , the matrix becomes so the eigenvector here is . Therefore, the general solution to this differential equation, by superposition, is   Finally, we have to solve the initial value problem using the initial conditions. If we plug in , we get the equation This results in needing to solve the system of equations These can be solved in any way, including row reduction. We will start by adding the two equations together, which gives , and then the first equation implies that . Therefore, the solution to the initial value problem is    "
},
{
  "id": "eigenmethod-section-5-2",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-2",
  "type": "Exercise",
  "number": "4.4.3.1",
  "title": "",
  "body": "   Find the general solution of , using the eigenvalue method (first write the system in the form ). Solve the system by solving each equation separately and verify you get the same general solution.        "
},
{
  "id": "eigenmethod-section-5-3",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-3",
  "type": "Exercise",
  "number": "4.4.3.2",
  "title": "",
  "body": "  Find the general solution of , using the eigenvalue method and sketch the phase portrait for this system of differential equations.        "
},
{
  "id": "eigenmethod-section-5-4",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-4",
  "type": "Exercise",
  "number": "4.4.3.3",
  "title": "",
  "body": "  Solve , using the eigenvalue method and sketch the phase portrait for this system of differential equations.   "
},
{
  "id": "eigenmethod-section-5-5",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-5",
  "type": "Exercise",
  "number": "4.4.3.4",
  "title": "",
  "body": "  Amino acid dating can be used by forensic scientists to determine the time of death in situations where other techniques might not work. These amino acids are sneaky, and they exist in a left-handed form (L) and a right-handed form (D), which are called enantiomers . While you’re alive, your body keeps all your amino acids in the L form. Once you die, your body no longer regulates your amino acids, and every so often they flip a coin and decide whether to switch into the opposite form. This way, when someone finds your body in a dumpster, they can pull out your teeth and measure the racemization ratio , which is the ratio of D-enantiomers to L-enantiomers.  Denote by and , respectively, the proportions of D- and L-enantiomers found in your teeth, where is measured in years after death. Since this is Math class, the proportions are governed by a system of differential equations, such as    Find the general solution to . Solve with initial conditions and , and express the solution in component form. Describe what happens to the quantities and in the long run. Given the above initial conditions, if the racemization ratio in your teeth is currently 1:3, how long ago did you die?    a)  b)  . Both go to . c)  years   "
},
{
  "id": "eigenmethod-section-5-6",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-6",
  "type": "Exercise",
  "number": "4.4.3.5",
  "title": "",
  "body": "   Compute eigenvalues and eigenvectors of . Find the general solution of .    a)  , . , . , b)     "
},
{
  "id": "eigenmethod-section-5-7",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-7",
  "type": "Exercise",
  "number": "4.4.3.6",
  "title": "",
  "body": "   Compute eigenvalues and eigenvectors of . Solve the system .   "
},
{
  "id": "eigenmethod-section-5-8",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-8",
  "type": "Exercise",
  "number": "4.4.3.7",
  "title": "",
  "body": "  Let be numbers. Find the eigenvalues of .    a, d, f   "
},
{
  "id": "eigenmethod-section-5-9",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-9",
  "type": "Exercise",
  "number": "4.4.3.8",
  "title": "",
  "body": "  Find the general solution of the system and sketch the phase portrait for this system.   "
},
{
  "id": "eigenmethod-section-5-10",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-10",
  "type": "Exercise",
  "number": "4.4.3.9",
  "title": "",
  "body": "  Find the general solution of the system and draw a sketch for the phase portrait.   "
},
{
  "id": "eigenmethod-section-5-11",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-11",
  "type": "Exercise",
  "number": "4.4.3.10",
  "title": "",
  "body": "  Find the general solution of the system    "
},
{
  "id": "eigenmethod-section-5-12",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-12",
  "type": "Exercise",
  "number": "4.4.3.11",
  "title": "",
  "body": "  Find the general solution of the system    "
},
{
  "id": "eigenmethod-section-5-13",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-13",
  "type": "Exercise",
  "number": "4.4.3.12",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-section-5-14",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-14",
  "type": "Exercise",
  "number": "4.4.3.13",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-section-5-15",
  "level": "2",
  "url": "eigenmethod-section.html#eigenmethod-section-5-15",
  "type": "Exercise",
  "number": "4.4.3.14",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-cplx-section",
  "level": "1",
  "url": "eigenmethod-cplx-section.html",
  "type": "Section",
  "number": "4.5",
  "title": "Eigenvalue method with complex eigenvalues",
  "body": " Eigenvalue method with complex eigenvalues   eigencomplex  As we have seen previously, a matrix may very well have complex eigenvalues even if all the entries are real. However, this may seem concerning going forward into solutions to differential equations that require these complex numbers in them. We will see in this section that we can still write solutions this way, but we no longer have straight-line solutions. Take, for example, Let us compute the eigenvalues of the matrix . Thus . Corresponding eigenvectors are also complex. Start with . The equations and are multiples of each other. This may be trickier to spot than the real version, but that is because they are complex multiples of each other. If we multiply the first equation by , we get exactly the second one. So we only need to consider one of them. After picking , for example, we have an eigenvector . In similar fashion we find that is an eigenvector corresponding to the eigenvalue .  We could write the solution as We would then need to look for complex values and to solve any initial conditions. It is perhaps not completely clear that we get a real solution. After solving for and , we could use and do the whole song and dance we did before, but we will not. We will apply the formula in a smarter way first to find independent real solutions.  In this case, we only needed one of the two eigenvectors to get the general solution, which happens because the complex eigenvalues and eigenvectors always come in conjugate pairs. First a small detour. The real part of a complex number can be computed as , where the bar above means . This operation is called the . If is a real number, then . Similarly we bar whole vectors or matrices by taking the complex conjugate of every entry. Suppose a matrix is real. Then , and so . Also the complex conjugate of 0 is still 0, therefore, In other words, if is an eigenvalue, then so is . And if is an eigenvector corresponding to the eigenvalue , then is an eigenvector corresponding to the eigenvalue .  Suppose is a complex eigenvalue of , and is a corresponding eigenvector. Then is a solution (complex-valued) of . shows that , and so is also a solution. As and are solutions, the function is also a solution. And is real-valued! Similarly as is the imaginary part, we find that is also a real-valued solution. It turns out that and are linearly independent. We will use to separate out the real and imaginary part.  Returning to our problem, Then are the two real-valued linearly independent solutions we seek.    Check that these really are solutions.    This gives that we can write the general solution to this problem as This solution is real-valued for real and . We now solve for any initial conditions we may have. Notice that the has been dropped from the part of the process where we split the complex solution into real and imaginary parts. The point is that the real and imaginary parts of the solution are independently solutions to the equation, and so we can use them to form our basis of solutions with constants and in front of them. We want everything to be real, and this process allows us to do it.    Let us summarize as a theorem.   Let be a real-valued constant matrix. If has a complex eigenvalue and a corresponding eigenvector , then also has a complex eigenvalue with a corresponding eigenvector . Furthermore, has two linearly independent real-valued solutions   The main point here is that the real and imaginary parts of these complex solutions are the real-valued independent solutions that we seek. Compare this to Theorem in , where we saw that the same idea worked for second order equation with complex roots.  For each pair of complex eigenvalues and , we get two real-valued linearly independent solutions. We then go on to the next eigenvalue, which is either a real eigenvalue or another complex eigenvalue pair. If we have distinct eigenvalues (real or complex), then we end up with linearly independent solutions. If we had only two equations ( ) as in the example above, then once we found two solutions we are finished, and our general solution is       Find the solution to the initial value problem     We start by looking for the eigenvalues and eigenvectors of the coefficient matrix. This results in the polynomial This polynomial does not factor, but the quadratic formula gives that the roots are Thus, we are in the complex roots case, and can work from there. We need to find the complex eigenvector for one of these eigenvalues and then split into real and imaginary parts to get the general solution.  For the eigenvalue , the matrix equation becomes The two simultaneous equation that we need to solve for the vector are and these equations don’t appear to be redundant. However, this is because they are complex multiples of each other, not just real multiples. To see this, we can multiply the first equation by the complex conjugate of the first coefficient. The idea is that if we do so, this first coefficient will be real, and then we can compare it to the second equation. If we multiply the first equation by , since , it becomes and this is times the second equation above. Therefore, they are redundant, and we can just pick one of them in order to find possible values of and . If we divide this newest equation by , it becomes Based on this equation, we can pick and . Therefore, the eigenvector for is . This means that a complex-valued solution to this differential equation is   Now, we want to split this solution into real and imaginary parts in order to get a real-valued general solution. We apply Euler’s formula to do so: Therefore, we can take the real and imaginary parts of this solution to get a general solution as      Work out the eigenvector and general solution from eigenvalue and verify that it is an equivalent general solution to the one above.    Finally, we need to solve the initial value problem. Plugging in gives     The two equations that we get from here is and , so that and . Therefore, the solution to the initial value problem is     Phase Portraits  Similarly to the real eigenvalue situation, we have three different cases for the phase portrait when the eigenvalues of a 2x2 matrix are complex. As metioned before, our basis solutions that we are using to form the general solution are no longer just exponential terms. They involve sines and cosines, and so are not straight lines anymore. Therefore, these solutions will not have straight lines in them, but we can still uses these basis solutions to help determine and describe the overall behavior of the solutions to the system for a variety of initial conditions.   Case 1. Suppose the eigenvalues are purely imaginary. That is, suppose the eigenvalues are . For example, let . The eigenvalues turn out to be and eigenvectors are and . Consider the eigenvalue and its eigenvector . The real and imaginary parts of are We can take any linear combination of them to get other solutions, which one we take depends on the initial conditions. Now note that the real part is a parametric equation for an ellipse. Same with the imaginary part and in fact any linear combination of the two. This is what happens in general when the eigenvalues are purely imaginary. So when the eigenvalues are purely imaginary, we get ellipses for the solutions. This type of picture is sometimes called a . See .     Case 2. Now suppose the complex eigenvalues have a positive real part. That is, suppose the eigenvalues are for some . For example, let . The eigenvalues turn out to be and eigenvectors are and . We take and its eigenvector and find the real and imaginary parts of are Note the in front of the solutions. The solutions grow in magnitude while spinning around the origin. Hence we get a . See .   Case 3. Finally suppose the complex eigenvalues have a negative real part. That is, suppose the eigenvalues are for some . For example, let . The eigenvalues turn out to be and eigenvectors are and . We take and its eigenvector and find the real and imaginary parts of are Note the in front of the solutions. The solutions shrink in magnitude while spinning around the origin. Hence we get a . See .      Exercises    Find the general solution of , using the eigenvalue method. Do not use complex exponentials in your solution.           Solve , using the eigenvalue method.      A matrix has complex eigenvector corresponding to eigenvalue .   Use Euler’s Formula to find the (real-valued) general solution to the system . Sketch the phase portrait of this system.            Compute eigenvalues and eigenvectors of . Solve the system . Sketch the phase portrait for this system      Consider the system    Find the general solution. Sketch the phase portrait for this system. Solve the IVP with initial conditions , and determine the maximum -coordinate on this trajectory.    a)  b)  c)        Find the general solution of the system and sketch the phase portrait for this system.           Find the general solution of the system and sketch the phase portrait for this system.           Find the general solution of the system            Find the general solution of the system            Solve the initial value problem            Solve the initial value problem            Solve the initial value problem           "
},
{
  "id": "subsec-eigencomplex-7",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#subsec-eigencomplex-7",
  "type": "Checkpoint",
  "number": "4.5.1",
  "title": "",
  "body": "  Check that these really are solutions.    This gives that we can write the general solution to this problem as This solution is real-valued for real and . We now solve for any initial conditions we may have. Notice that the has been dropped from the part of the process where we split the complex solution into real and imaginary parts. The point is that the real and imaginary parts of the solution are independently solutions to the equation, and so we can use them to form our basis of solutions with constants and in front of them. We want everything to be real, and this process allows us to do it.   "
},
{
  "id": "subsec-eigencomplex-12",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#subsec-eigencomplex-12",
  "type": "Example",
  "number": "4.5.2",
  "title": ".",
  "body": "    Find the solution to the initial value problem     We start by looking for the eigenvalues and eigenvectors of the coefficient matrix. This results in the polynomial This polynomial does not factor, but the quadratic formula gives that the roots are Thus, we are in the complex roots case, and can work from there. We need to find the complex eigenvector for one of these eigenvalues and then split into real and imaginary parts to get the general solution.  For the eigenvalue , the matrix equation becomes The two simultaneous equation that we need to solve for the vector are and these equations don’t appear to be redundant. However, this is because they are complex multiples of each other, not just real multiples. To see this, we can multiply the first equation by the complex conjugate of the first coefficient. The idea is that if we do so, this first coefficient will be real, and then we can compare it to the second equation. If we multiply the first equation by , since , it becomes and this is times the second equation above. Therefore, they are redundant, and we can just pick one of them in order to find possible values of and . If we divide this newest equation by , it becomes Based on this equation, we can pick and . Therefore, the eigenvector for is . This means that a complex-valued solution to this differential equation is   Now, we want to split this solution into real and imaginary parts in order to get a real-valued general solution. We apply Euler’s formula to do so: Therefore, we can take the real and imaginary parts of this solution to get a general solution as    "
},
{
  "id": "subsec-eigencomplex-13",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#subsec-eigencomplex-13",
  "type": "Checkpoint",
  "number": "4.5.3",
  "title": "",
  "body": "  Work out the eigenvector and general solution from eigenvalue and verify that it is an equivalent general solution to the one above.    Finally, we need to solve the initial value problem. Plugging in gives    "
},
{
  "id": "eigenmethod-cplx-section-4-2",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-2",
  "type": "Exercise",
  "number": "4.5.3.1",
  "title": "",
  "body": "  Find the general solution of , using the eigenvalue method. Do not use complex exponentials in your solution.        "
},
{
  "id": "eigenmethod-cplx-section-4-3",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-3",
  "type": "Exercise",
  "number": "4.5.3.2",
  "title": "",
  "body": "  Solve , using the eigenvalue method.   "
},
{
  "id": "eigenmethod-cplx-section-4-4",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-4",
  "type": "Exercise",
  "number": "4.5.3.3",
  "title": "",
  "body": "  A matrix has complex eigenvector corresponding to eigenvalue .   Use Euler’s Formula to find the (real-valued) general solution to the system . Sketch the phase portrait of this system.        "
},
{
  "id": "eigenmethod-cplx-section-4-5",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-5",
  "type": "Exercise",
  "number": "4.5.3.4",
  "title": "",
  "body": "   Compute eigenvalues and eigenvectors of . Solve the system . Sketch the phase portrait for this system   "
},
{
  "id": "eigenmethod-cplx-section-4-6",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-6",
  "type": "Exercise",
  "number": "4.5.3.5",
  "title": "",
  "body": "  Consider the system    Find the general solution. Sketch the phase portrait for this system. Solve the IVP with initial conditions , and determine the maximum -coordinate on this trajectory.    a)  b)  c)     "
},
{
  "id": "eigenmethod-cplx-section-4-7",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-7",
  "type": "Exercise",
  "number": "4.5.3.6",
  "title": "",
  "body": "  Find the general solution of the system and sketch the phase portrait for this system.        "
},
{
  "id": "eigenmethod-cplx-section-4-8",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-8",
  "type": "Exercise",
  "number": "4.5.3.7",
  "title": "",
  "body": "  Find the general solution of the system and sketch the phase portrait for this system.        "
},
{
  "id": "eigenmethod-cplx-section-4-9",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-9",
  "type": "Exercise",
  "number": "4.5.3.8",
  "title": "",
  "body": "  Find the general solution of the system         "
},
{
  "id": "eigenmethod-cplx-section-4-10",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-10",
  "type": "Exercise",
  "number": "4.5.3.9",
  "title": "",
  "body": "  Find the general solution of the system         "
},
{
  "id": "eigenmethod-cplx-section-4-11",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-11",
  "type": "Exercise",
  "number": "4.5.3.10",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-cplx-section-4-12",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-12",
  "type": "Exercise",
  "number": "4.5.3.11",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-cplx-section-4-13",
  "level": "2",
  "url": "eigenmethod-cplx-section.html#eigenmethod-cplx-section-4-13",
  "type": "Exercise",
  "number": "4.5.3.12",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "eigenmethod-repeat-section",
  "level": "1",
  "url": "eigenmethod-repeat-section.html",
  "type": "Section",
  "number": "4.6",
  "title": "Eigenvalue method with repeated eigenvalues",
  "body": " Eigenvalue method with repeated eigenvalues   There is one remaining case for the two-component first-order linear system: repeated eigenvalues. As we have seen previously, it may happen that a matrix has some eigenvalues. That is, the characteristic equation may have repeated roots. This is actually unlikely to happen for a random matrix. If we take a small perturbation of (we change the entries of slightly), we get a matrix with distinct eigenvalues. As any system we want to solve in practice is an approximation to reality anyway, it is not absolutely indispensable to know how to solve these corner cases. On the other hand, these cases do come up in applications from time to time. Furthermore, if we have distinct but very close eigenvalues, the behavior is similar to that of repeated eigenvalues, and so understanding that case will give us insight into what is going on.    Geometric multiplicity  Take the diagonal matrix  has an eigenvalue 3 of multiplicity 2. We call the multiplicity of the eigenvalue in the characteristic equation the . In this case, there also exist 2 linearly independent eigenvectors, and corresponding to the eigenvalue 3. This means that the so-called of this eigenvalue is also 2. These terms have all been discussed previously in .  In all the theorems where we required a matrix to have distinct eigenvalues, we only really needed to have linearly independent eigenvectors. For example, has the general solution Let us restate the theorem about real eigenvalues. In the following theorem we will repeat eigenvalues according to (algebraic) multiplicity. So for the matrix above, we would say that it has eigenvalues 3 and 3.   Suppose the matrix has real eigenvalues (not necessarily distinct), , , …, , and there are linearly independent corresponding eigenvectors , , …, . Then the general solution to can be written as   The main difference in the statement here from the theorem in is that we are no longer assuming that we have  distinct eigenvalues. Instead, we need to assume that we end up with linearly independent eigenvectors, which we get for free if the eigenvalues are all distinct, but we might also have that if we do not have all distinct eigenvalues.  The geometric multiplicity of an eigenvalue of algebraic multiplicity is equal to the number of corresponding linearly independent eigenvectors. The geometric multiplicity is always less than or equal to the algebraic multiplicity. The theorem handles the case when these two multiplicities are equal for all eigenvalues. If for an eigenvalue the geometric multiplicity is equal to the algebraic multiplicity, then we say the eigenvalue is complete .  In other words, the hypothesis of the theorem could be stated as saying that if all the eigenvalues of are complete, then there are linearly independent eigenvectors and thus we have the given general solution.  If the geometric multiplicity of an eigenvalue is 2 or greater, then the set of linearly independent eigenvectors is not unique up to multiples as it was before. For example, for the diagonal matrix we could also pick eigenvectors and , or in fact any pair of two linearly independent vectors. The number of linearly independent eigenvectors corresponding to is the number of free variables we obtain when solving . We pick specific values for those free variables to obtain eigenvectors. If you pick different values, you may get different eigenvectors.    Defective eigenvalues  If an matrix has less than linearly independent eigenvectors, it is said to be deficient . Then there is at least one eigenvalue with an algebraic multiplicity that is higher than its geometric multiplicity. We call this eigenvalue defective and the difference between the two multiplicities we call the .      The matrix has an eigenvalue 3 of algebraic multiplicity 2. Let us try to compute eigenvectors. We must have that . Hence any eigenvector is of the form . Any two such vectors are linearly dependent, and hence the geometric multiplicity of the eigenvalue is 1. Therefore, the defect is 1, and we can no longer apply the eigenvalue method directly to a system of ODEs with such a coefficient matrix.  Roughly, the key observation is that if is an eigenvalue of of algebraic multiplicity , then we can find certain linearly independent vectors solving for various powers . We will call these .  Let us continue with the example and the equation . We found an eigenvalue of (algebraic) multiplicity 2 and defect 1. We found one eigenvector . We have one solution We are now stuck, we get no other solutions from standard eigenvectors. But we need two linearly independent solutions to find the general solution of the equation.  Let us try (in the spirit of repeated roots of the characteristic equation for a single equation) another solution of the form since our modified guess for repeated roots from second order equations was . If we plug this guess into the equation, we get that and since the right-hand side of the equation is , we need to satisfy Since there is no term on the right-hand side of the equation, we are forced to pick , and so we get the solution , which is not good. This guess did not work.  The issue here is that we didn’t have enough flexibility to actually get another solution to the differential equation, so we need something a little more complicated to make it work. To this end, we take a new guess of the form We differentiate to get As we are assuming that is a solution, must equal . So let’s compute : By looking at the coefficients of and we see and . This means that Therefore, is a solution if these two equations are satisfied. The second equation is satisfied if is an eigenvector, and we found the eigenvector above, so let . So, if we can find a that solves , then we are done. This is just a bunch of linear equations to solve and we are by now very good at that. Let us solve . Write By inspection we see that letting ( could be anything in fact) and does the job. Hence we can take . Our general solution to is Let us check that we really do have the solution. First . Good. Now . Good.    In the example, if we plug into we find Furthermore, if , then is an eigenvector, a multiple of . In this case is just the zero matrix (exercise). So any vector solves and we just need a such that . Then we could use for , and for .  Note that the system has a simpler solution since is a so-called , that is every entry below the diagonal is zero. In particular, the equation for does not depend on . Mind you, not every defective matrix is triangular.    Solve by first solving for and then for independently. Check that you got the same solution as we did above.    Let us describe the general algorithm. Suppose that is an eigenvalue of multiplicity 2, defect 1. First find an eigenvector of . That is, solves . Then, find a vector such that This gives us two linearly independent solutions and so our general solution to the differential equation is         Solve the initial value problem     First, we need to look for the eigenvalues of the coefficient matrix. These are found by Since this polynomial is , this has a double root at .  For , we can hunt for the eigenvector as solutions to These two equations are redundant, and the first equation is , which can be solved by . Therefore, and an eigenvector for is . Thus, we have a solution to this system of the form   Since we only found one eigenvector, we need to look for a generalized eigenvector as well. To do this, we want to solve the equation for the eigenvector that we found previously. This means we need to solve and both rows of the vector equation result in the equation for . We can pick any value of and to make this work. For the sake of this example, we will pick and . Then, we have that our second linearly independent solution to the differential equation is and so the general solution to this system is   Finally, we can solve the initial value problem. Plugging in gives which gives that and then , or . Therefore, the solution to the initial value problem is       We could have also chosen and for the vector . Use this to get a different looking general solution. Then solve the same initial value problem to see that you end up with the same answer at the end of the process.        Consider the system Find the general solution to this system using eigenvalues and eigenvectors.    Even though this is a three-component system, the process is exactly the same: find the eigenvalues, compute corresponding eigenvectors, then build them together into a general solution. Compute the eigenvalues, The eigenvalues are 1 and 2, where 2 has multiplicity 2. We leave it to the reader to find that is an eigenvector for the eigenvalue .  Let’s focus on . We compute eigenvectors: The first equation says that , so the last equation is . Let be the free variable to find that . Perhaps let to find an eigenvector . Problem is that setting to anything else just gets multiples of this vector and so we have a defect of 1. Let be the eigenvector and let’s look for a generalized eigenvector : or where we used , , as components of for simplicity. The first equation says so . The second equation says nothing. The last equation is , or , or . We let be the free variable and we choose . We find .  The general solution is therefore,     This machinery can also be generalized to higher multiplicities and higher defects. We will not go over this method in detail, but let us just sketch the ideas. Suppose that has an eigenvalue of multiplicity . We find vectors such that Such vectors are called (then is an eigenvector). For the eigenvector there is a chain of generalized eigenvectors through such that: Really once you find the such that but , you find the entire chain since you can compute the rest, , , etc. We form the linearly independent solutions Recall that is the factorial. If you have an eigenvalue of geometric multiplicity , you will have to find such chains (some of them might be short: just the single eigenvector equation). We go until we form linearly independent solutions where is the algebraic multiplicity. We don’t quite know which specific eigenvectors go with which chain, so start by finding first for the longest possible chain and go from there.  For example, if is an eigenvalue of of algebraic multiplicity 3 and defect 2, then solve That is, find such that , but . Then you are done as and . The 3 linearly independent solutions are   If on the other hand has an eigenvalue of algebraic multiplicity 3 and defect 1, then solve Here and are actual honest eigenvectors, and is a generalized eigenvector. So there are two chains. To solve, first find a such that , but . Then is going to be an eigenvector. Then solve for an eigenvector that is linearly independent from . You get 3 linearly independent solutions     Phase Portraits  We also want to look at the phase portraits and direction field diagrams for repeated eigenvalues. There are two different options here, depending on if there are two linearly independent eigenvectors or not.   Case 1. If we have a repeated eigenvalue with two linearly independent eigenvectors, this means that our matrix is of the form for the repeated eigenvalue . This means that for all vectors . So, every vector is part of a straight line solution, and so every solution goes either directly towards or directly away from the origin. This gives a which can be a sink or a source depending on whether the eigenvalue is positive or negative.     Case 2. If we have a repeated eigenvalue with only one linearly independent eigenvector, then we only have one straight-line solution. For instance, the matrix has only one eigenvector of for eigenvalue . Like the nodal sources and sinks, the solutions will go to zero and infinity along the straight line solutions. In this case, because there is only one straight line, the phase portrait looks somewhere between a node and a spiral. This gives an which can be a source or sink depending on the sign of the eigenvalue.      Exercises    Compute eigenvalues and eigenvectors of .     , . , two-dimensional space of eigenvectors, options:       Let . Find the general solution of and sketch the corresponding phase portrait.           Solve the initial value problem and sketch the phase portrait for this system.           Solve the initial value problem and sketch the phase portrait for this system.           Solve the initial value problem and sketch the phase portrait for this system.           Assume is a matrix. The row-reduced echelon forms of are given for three different values of :   Find the general solution of the homogeneous system .           Consider the matrix    Determine the characteristic polynomial of and give its eigenvalues. How many (linearly independent) straight-line solutions does the system have? How do you know, without solving?    a)  b) Only 1      Let .   Show directly that is an eigenvector of . All eigenvalues of are the same. Find the general solution to .    b)         Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) 3,1,1 b) No defects c)        Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .      Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of in two different ways and verify you get the same answer.    a) 2 b) Defect 1 c)        Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .      Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) -1, 3b) 3 has defect 1 c)        Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .      Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) -2 b) Defect 1 c)        Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) 2 b)  Defect of 2 c)        Suppose that is a matrix with a repeated eigenvalue . Suppose that there are two linearly independent eigenvectors. Show that .    Hint: This means everything is an eigenvector. Or, this can be set up as a system of equations.      Let , where , , and are unknowns. Suppose that is a doubled eigenvalue of defect 1, and suppose that is a corresponding eigenvector. Find and show that there is only one such matrix .      For each system, (i) classify the system according to type as one of sink\/source\/saddle\/center\/ spiral source\/spiral sink; (ii) solve the systems; (iii) sketch the phase portrait. Both real and complex eigenvalues appear.   2                Consider the second order equation given by    Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same!      Consider the second order equation given by    Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same, up to potentially needing to rename the constants ( and )      Consider the second order equation given by for and two real numbers.   Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same, up to potentially renaming the constants.     "
},
{
  "id": "defective-eigenvalues-3",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#defective-eigenvalues-3",
  "type": "Example",
  "number": "4.6.1",
  "title": ".",
  "body": "    The matrix has an eigenvalue 3 of algebraic multiplicity 2. Let us try to compute eigenvectors. We must have that . Hence any eigenvector is of the form . Any two such vectors are linearly dependent, and hence the geometric multiplicity of the eigenvalue is 1. Therefore, the defect is 1, and we can no longer apply the eigenvalue method directly to a system of ODEs with such a coefficient matrix.  Roughly, the key observation is that if is an eigenvalue of of algebraic multiplicity , then we can find certain linearly independent vectors solving for various powers . We will call these .  Let us continue with the example and the equation . We found an eigenvalue of (algebraic) multiplicity 2 and defect 1. We found one eigenvector . We have one solution We are now stuck, we get no other solutions from standard eigenvectors. But we need two linearly independent solutions to find the general solution of the equation.  Let us try (in the spirit of repeated roots of the characteristic equation for a single equation) another solution of the form since our modified guess for repeated roots from second order equations was . If we plug this guess into the equation, we get that and since the right-hand side of the equation is , we need to satisfy Since there is no term on the right-hand side of the equation, we are forced to pick , and so we get the solution , which is not good. This guess did not work.  The issue here is that we didn’t have enough flexibility to actually get another solution to the differential equation, so we need something a little more complicated to make it work. To this end, we take a new guess of the form We differentiate to get As we are assuming that is a solution, must equal . So let’s compute : By looking at the coefficients of and we see and . This means that Therefore, is a solution if these two equations are satisfied. The second equation is satisfied if is an eigenvector, and we found the eigenvector above, so let . So, if we can find a that solves , then we are done. This is just a bunch of linear equations to solve and we are by now very good at that. Let us solve . Write By inspection we see that letting ( could be anything in fact) and does the job. Hence we can take . Our general solution to is Let us check that we really do have the solution. First . Good. Now . Good.   "
},
{
  "id": "defective-eigenvalues-6",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#defective-eigenvalues-6",
  "type": "Checkpoint",
  "number": "4.6.2",
  "title": "",
  "body": "  Solve by first solving for and then for independently. Check that you got the same solution as we did above.    Let us describe the general algorithm. Suppose that is an eigenvalue of multiplicity 2, defect 1. First find an eigenvector of . That is, solves . Then, find a vector such that This gives us two linearly independent solutions and so our general solution to the differential equation is    "
},
{
  "id": "defective-eigenvalues-7",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#defective-eigenvalues-7",
  "type": "Example",
  "number": "4.6.3",
  "title": ".",
  "body": "    Solve the initial value problem     First, we need to look for the eigenvalues of the coefficient matrix. These are found by Since this polynomial is , this has a double root at .  For , we can hunt for the eigenvector as solutions to These two equations are redundant, and the first equation is , which can be solved by . Therefore, and an eigenvector for is . Thus, we have a solution to this system of the form   Since we only found one eigenvector, we need to look for a generalized eigenvector as well. To do this, we want to solve the equation for the eigenvector that we found previously. This means we need to solve and both rows of the vector equation result in the equation for . We can pick any value of and to make this work. For the sake of this example, we will pick and . Then, we have that our second linearly independent solution to the differential equation is and so the general solution to this system is   Finally, we can solve the initial value problem. Plugging in gives which gives that and then , or . Therefore, the solution to the initial value problem is    "
},
{
  "id": "defective-eigenvalues-8",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#defective-eigenvalues-8",
  "type": "Checkpoint",
  "number": "4.6.4",
  "title": "",
  "body": "  We could have also chosen and for the vector . Use this to get a different looking general solution. Then solve the same initial value problem to see that you end up with the same answer at the end of the process.   "
},
{
  "id": "defective-eigenvalues-9",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#defective-eigenvalues-9",
  "type": "Example",
  "number": "4.6.5",
  "title": ".",
  "body": "    Consider the system Find the general solution to this system using eigenvalues and eigenvectors.    Even though this is a three-component system, the process is exactly the same: find the eigenvalues, compute corresponding eigenvectors, then build them together into a general solution. Compute the eigenvalues, The eigenvalues are 1 and 2, where 2 has multiplicity 2. We leave it to the reader to find that is an eigenvector for the eigenvalue .  Let’s focus on . We compute eigenvectors: The first equation says that , so the last equation is . Let be the free variable to find that . Perhaps let to find an eigenvector . Problem is that setting to anything else just gets multiples of this vector and so we have a defect of 1. Let be the eigenvector and let’s look for a generalized eigenvector : or where we used , , as components of for simplicity. The first equation says so . The second equation says nothing. The last equation is , or , or . We let be the free variable and we choose . We find .  The general solution is therefore,    "
},
{
  "id": "eigenmethod-repeat-section-6-2",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-2",
  "type": "Exercise",
  "number": "4.6.4.1",
  "title": "",
  "body": "  Compute eigenvalues and eigenvectors of .     , . , two-dimensional space of eigenvectors, options:    "
},
{
  "id": "eigenmethod-repeat-section-6-3",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-3",
  "type": "Exercise",
  "number": "4.6.4.2",
  "title": "",
  "body": "  Let . Find the general solution of and sketch the corresponding phase portrait.        "
},
{
  "id": "eigenmethod-repeat-section-6-4",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-4",
  "type": "Exercise",
  "number": "4.6.4.3",
  "title": "",
  "body": "  Solve the initial value problem and sketch the phase portrait for this system.        "
},
{
  "id": "eigenmethod-repeat-section-6-5",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-5",
  "type": "Exercise",
  "number": "4.6.4.4",
  "title": "",
  "body": "  Solve the initial value problem and sketch the phase portrait for this system.        "
},
{
  "id": "eigenmethod-repeat-section-6-6",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-6",
  "type": "Exercise",
  "number": "4.6.4.5",
  "title": "",
  "body": "  Solve the initial value problem and sketch the phase portrait for this system.        "
},
{
  "id": "eigenmethod-repeat-section-6-7",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-7",
  "type": "Exercise",
  "number": "4.6.4.6",
  "title": "",
  "body": "  Assume is a matrix. The row-reduced echelon forms of are given for three different values of :   Find the general solution of the homogeneous system .        "
},
{
  "id": "eigenmethod-repeat-section-6-8",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-8",
  "type": "Exercise",
  "number": "4.6.4.7",
  "title": "",
  "body": "  Consider the matrix    Determine the characteristic polynomial of and give its eigenvalues. How many (linearly independent) straight-line solutions does the system have? How do you know, without solving?    a)  b) Only 1   "
},
{
  "id": "eigenmethod-repeat-section-6-9",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-9",
  "type": "Exercise",
  "number": "4.6.4.8",
  "title": "",
  "body": "  Let .   Show directly that is an eigenvector of . All eigenvalues of are the same. Find the general solution to .    b)     "
},
{
  "id": "eigenmethod-repeat-section-6-10",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-10",
  "type": "Exercise",
  "number": "4.6.4.9",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) 3,1,1 b) No defects c)     "
},
{
  "id": "eigenmethod-repeat-section-6-11",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-11",
  "type": "Exercise",
  "number": "4.6.4.10",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .   "
},
{
  "id": "eigenmethod-repeat-section-6-12",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-12",
  "type": "Exercise",
  "number": "4.6.4.11",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of in two different ways and verify you get the same answer.    a) 2 b) Defect 1 c)     "
},
{
  "id": "eigenmethod-repeat-section-6-13",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-13",
  "type": "Exercise",
  "number": "4.6.4.12",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .   "
},
{
  "id": "eigenmethod-repeat-section-6-14",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-14",
  "type": "Exercise",
  "number": "4.6.4.13",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) -1, 3b) 3 has defect 1 c)     "
},
{
  "id": "eigenmethod-repeat-section-6-15",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-15",
  "type": "Exercise",
  "number": "4.6.4.14",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .   "
},
{
  "id": "eigenmethod-repeat-section-6-16",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-16",
  "type": "Exercise",
  "number": "4.6.4.15",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) -2 b) Defect 1 c)     "
},
{
  "id": "eigenmethod-repeat-section-6-17",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-17",
  "type": "Exercise",
  "number": "4.6.4.16",
  "title": "",
  "body": "  Let .   What are the eigenvalues? What is\/are the defect(s) of the eigenvalue(s)? Find the general solution of .    a) 2 b)  Defect of 2 c)     "
},
{
  "id": "eigenmethod-repeat-section-6-18",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-18",
  "type": "Exercise",
  "number": "4.6.4.17",
  "title": "",
  "body": "  Suppose that is a matrix with a repeated eigenvalue . Suppose that there are two linearly independent eigenvectors. Show that .    Hint: This means everything is an eigenvector. Or, this can be set up as a system of equations.   "
},
{
  "id": "eigenmethod-repeat-section-6-19",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-19",
  "type": "Exercise",
  "number": "4.6.4.18",
  "title": "",
  "body": "  Let , where , , and are unknowns. Suppose that is a doubled eigenvalue of defect 1, and suppose that is a corresponding eigenvector. Find and show that there is only one such matrix .   "
},
{
  "id": "eigenmethod-repeat-section-6-20",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-20",
  "type": "Exercise",
  "number": "4.6.4.19",
  "title": "",
  "body": "  For each system, (i) classify the system according to type as one of sink\/source\/saddle\/center\/ spiral source\/spiral sink; (ii) solve the systems; (iii) sketch the phase portrait. Both real and complex eigenvalues appear.   2             "
},
{
  "id": "eigenmethod-repeat-section-6-21",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-21",
  "type": "Exercise",
  "number": "4.6.4.20",
  "title": "",
  "body": "  Consider the second order equation given by    Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same!   "
},
{
  "id": "eigenmethod-repeat-section-6-22",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-22",
  "type": "Exercise",
  "number": "4.6.4.21",
  "title": "",
  "body": "  Consider the second order equation given by    Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same, up to potentially needing to rename the constants ( and )   "
},
{
  "id": "eigenmethod-repeat-section-6-23",
  "level": "2",
  "url": "eigenmethod-repeat-section.html#eigenmethod-repeat-section-6-23",
  "type": "Exercise",
  "number": "4.6.4.22",
  "title": "",
  "body": "  Consider the second order equation given by for and two real numbers.   Find the general solution of this problem using the methods of . Convert this equation into a first order linear system using the transformation . Find the eigenvalues and eigenvalues of the coefficient matrix and use that to find the general solution to the system. Extract the first component of the general solution and compare that to the solution from part (a). How do they relate? Look back through the work. How do the equation used to find the roots in (a) and the eigenvalues in (c) relate to each other?    b)  d) It’s the same, up to potentially renaming the constants.   "
},
{
  "id": "sec-twodimaut",
  "level": "1",
  "url": "sec-twodimaut.html",
  "type": "Section",
  "number": "4.7",
  "title": "Two-dimensional systems and their vector fields",
  "body": " Two-dimensional systems and their vector fields   twodim  In the last three sections, we looked at the different options for two-component constant-coefficient systems. We want to determine a nice way to put all of this together. We summarize the behavior of linear homogeneous two-dimensional systems given by a nonsingular matrix in . Systems where one of the eigenvalues is zero (the matrix is singular) come up in practice from time to time, see , and the pictures are somewhat different (simpler in a way). See the exercises.     Summary of behavior of linear homogeneous two-dimensional systems.    Eigenvalues  Behavior    real and both positive  source \/ unstable node    real and both negative  sink \/ asymptotically stable node    real and opposite signs  saddle    purely imaginary  center point \/ ellipses    complex with positive real part  spiral source    complex with negative real part  spiral sink    repeated with two eigenvectors  proper node (asympt. stable or unstable)    repeated with one eigenvector  improper node (asympt. stable or unstable)     The sketches of all of these different behaviors and phase portraits can be found in their respective sections. Make sure that you understand the terminology, general behavior, and sketches for each of these different cases.    Trace-Determinant Analysis  One other way to interpret and analyze this information is using the trace and determinant of the matrix. Recall from that the of a matrix is the sum of the diagonal entries of the matrix and the of the matrix is computed from the entries and is a way to determine invertibility of the matrix. If we take a generic matrix and find the characteristic polynomial, we get that for the characteristic polynomial is Since the trace of the matrix is and the determinant is , we can rewrite this polynomial as which also means that we can characterize the eigenvalues of the matrix in terms of the trace and determinant. We get that the eigenvalues are   There are a few important facts we can learn from this equation.    A lot depends on the value of . If then we will have two real distinct eigenvalues. If then there is a single repeated eigenvalue, and if , we have complex eigenvalues.    If , then which means that . If we put this into , this will mean that the term that is after the will be larger than in absolute value. Therefore, the two eigenvalues will be real and have opposite signs.    If , then the sign of the eigenvalues, or the sign of the real part in the complex case, is dictated by the sign of . If , then , so that the part under the square root in is always smaller in absolute value than . Thus, both the plus and minus version will have values that are the same sign as . If the expression is complex, then the real part is exactly , which is the same sign as .    All of this means we can make a new table characterizing the eigenvalues and how they are connected to the trace and determinant.     Summary of behavior of linear homogeneous two-dimensional systems.    Eigenvalues  Trace and Determinant Classification    real and both positive  , ,    real and both negative  , ,    real and opposite signs     purely imaginary  ,    complex with positive real part  ,    complex with negative real part  ,    repeated      Since these are all based on the relation between and , we can also combine all of this into a figure to summarize the details. In , is on the horizontal axis and is the vertical axis. The graph drawn is , which is the important criteria that shows up in the table.    can be used to determine the behavior of a two-component system without actually needing to solve the differential equation. The point is that the signs and type of the eigenvalues determine the structure of the solution, and we can determine the important qualities of these using just the trace and determinant of a matrix.      Use Trace-Determinant analysis to determine the overall behavior of the system     From the matrix, we can see that the trace is and the determinant is . We see that with and . Therefore, we have , so we are above the curve on the graph, and so have a spiral. Since , this will be a spiral source.   Note: If you wanted to get a general solution or sketch a phase portrait for this differential equation, you would need to actually solve it out for that; you can not get enough information just from this image to sketch a proper phase portrait.      Compute the eigenvalues for the system above, find the general solution, and verify that this is a spiral source. The numbers here will not work out great, so having the quick analysis that it is a spiral source is nice.      Exercises    Take the equation , with , , for the mass-spring system.   Convert this to a system of first order equations. Classify for what do you get which behavior. Can you explain from physical intuition why you do not get all the different kinds of behavior here?    a)  b)  is center, is spiral sink, is improper sink, is nodal sink. c) The forced positive coefficients restricts the behavior      What happens in the case when ? In this case the eigenvalue is repeated and there is only one independent eigenvector. What picture does this look like?    Improper nodal sink      What happens in the case when ? Does this look like any of the pictures we have drawn?    It does not look like any of our previous pictures.      Describe the behavior of the following systems without solving:   (2) , . , . , . , . , .      Which behaviors are possible if is diagonal, that is ? You can assume that and are not zero.    Eigenvalues are and , so any real eigenvalue behavior is possible. Saddle, source, sink.      Suppose that where is a 2 by 2 matrix with eigenvalues . Describe the behavior.      For each of the following matrices , describe the behavior and classify the phase portrait of the system given by . Use the eigenvalues to determine this.   (2)            For each of the matrices and systems in , perform the same analysis using the trace and determinant of the matrix.      Consider the system of differential equations given by    Use trace and determinant analysis to determine the behavior of this linear system. Find the general solution to this system of differential equations and verify that it matches the analysis in (a).    Spiral sink. .      Consider the system of differential equations given by    Use trace and determinant analysis to determine the behavior of this linear system. Find the general solution to this system of differential equations and verify that it matches the analysis in (a).    Improper nodal source.       Take the system from , , . As we said, one of the eigenvalues is zero. What is the other eigenvalue, how does the picture look like and what happens when goes to infinity.    All solutions flow directly to the line .      Take . Draw the vector field and describe the behavior. Is it one of the behaviors that we have seen before?      In this exercise, we will analyze perturbations or near-by matrices to the ones that are given. This will be important later in . For each of the following matrices   Find the trace and determinant, and use them to classify the behavior of the linear system for the given matrix . Draw a sketch of the trace-determinant plane, including the curve , and plot the point corresponding to the matrix on those axes. Look at the points in a small (as small as you want) circle around the point you just drew. What does the behavior look like for systems whose matrices fall within that circle? What do these behaviors have in common with each other, and how do they differ?       "
},
{
  "id": "subsec-twodim-3",
  "level": "2",
  "url": "sec-twodimaut.html#subsec-twodim-3",
  "type": "Table",
  "number": "4.7.1",
  "title": "Summary of behavior of linear homogeneous two-dimensional systems.",
  "body": " Summary of behavior of linear homogeneous two-dimensional systems.    Eigenvalues  Behavior    real and both positive  source \/ unstable node    real and both negative  sink \/ asymptotically stable node    real and opposite signs  saddle    purely imaginary  center point \/ ellipses    complex with positive real part  spiral source    complex with negative real part  spiral sink    repeated with two eigenvectors  proper node (asympt. stable or unstable)    repeated with one eigenvector  improper node (asympt. stable or unstable)    "
},
{
  "id": "trace-determinant-analysis-6",
  "level": "2",
  "url": "sec-twodimaut.html#trace-determinant-analysis-6",
  "type": "Table",
  "number": "4.7.2",
  "title": "Summary of behavior of linear homogeneous two-dimensional systems.",
  "body": " Summary of behavior of linear homogeneous two-dimensional systems.    Eigenvalues  Trace and Determinant Classification    real and both positive  , ,    real and both negative  , ,    real and opposite signs     purely imaginary  ,    complex with positive real part  ,    complex with negative real part  ,    repeated     "
},
{
  "id": "trace-determinant-analysis-9",
  "level": "2",
  "url": "sec-twodimaut.html#trace-determinant-analysis-9",
  "type": "Example",
  "number": "4.7.3",
  "title": ".",
  "body": "    Use Trace-Determinant analysis to determine the overall behavior of the system     From the matrix, we can see that the trace is and the determinant is . We see that with and . Therefore, we have , so we are above the curve on the graph, and so have a spiral. Since , this will be a spiral source.   Note: If you wanted to get a general solution or sketch a phase portrait for this differential equation, you would need to actually solve it out for that; you can not get enough information just from this image to sketch a proper phase portrait.   "
},
{
  "id": "trace-determinant-analysis-10",
  "level": "2",
  "url": "sec-twodimaut.html#trace-determinant-analysis-10",
  "type": "Checkpoint",
  "number": "4.7.4",
  "title": "",
  "body": "  Compute the eigenvalues for the system above, find the general solution, and verify that this is a spiral source. The numbers here will not work out great, so having the quick analysis that it is a spiral source is nice.   "
},
{
  "id": "sec-twodimaut-4-2",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-2",
  "type": "Exercise",
  "number": "4.7.3.1",
  "title": "",
  "body": "  Take the equation , with , , for the mass-spring system.   Convert this to a system of first order equations. Classify for what do you get which behavior. Can you explain from physical intuition why you do not get all the different kinds of behavior here?    a)  b)  is center, is spiral sink, is improper sink, is nodal sink. c) The forced positive coefficients restricts the behavior   "
},
{
  "id": "sec-twodimaut-4-3",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-3",
  "type": "Exercise",
  "number": "4.7.3.2",
  "title": "",
  "body": "  What happens in the case when ? In this case the eigenvalue is repeated and there is only one independent eigenvector. What picture does this look like?    Improper nodal sink   "
},
{
  "id": "sec-twodimaut-4-4",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-4",
  "type": "Exercise",
  "number": "4.7.3.3",
  "title": "",
  "body": "  What happens in the case when ? Does this look like any of the pictures we have drawn?    It does not look like any of our previous pictures.   "
},
{
  "id": "sec-twodimaut-4-5",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-5",
  "type": "Exercise",
  "number": "4.7.3.4",
  "title": "",
  "body": "  Describe the behavior of the following systems without solving:   (2) , . , . , . , . , .   "
},
{
  "id": "sec-twodimaut-4-6",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-6",
  "type": "Exercise",
  "number": "4.7.3.5",
  "title": "",
  "body": "  Which behaviors are possible if is diagonal, that is ? You can assume that and are not zero.    Eigenvalues are and , so any real eigenvalue behavior is possible. Saddle, source, sink.   "
},
{
  "id": "sec-twodimaut-4-7",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-7",
  "type": "Exercise",
  "number": "4.7.3.6",
  "title": "",
  "body": "  Suppose that where is a 2 by 2 matrix with eigenvalues . Describe the behavior.   "
},
{
  "id": "sec-twodimaut-4-8",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-8",
  "type": "Exercise",
  "number": "4.7.3.7",
  "title": "",
  "body": "  For each of the following matrices , describe the behavior and classify the phase portrait of the system given by . Use the eigenvalues to determine this.   (2)         "
},
{
  "id": "sec-twodimaut-4-9",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-9",
  "type": "Exercise",
  "number": "4.7.3.8",
  "title": "",
  "body": "  For each of the matrices and systems in , perform the same analysis using the trace and determinant of the matrix.   "
},
{
  "id": "sec-twodimaut-4-10",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-10",
  "type": "Exercise",
  "number": "4.7.3.9",
  "title": "",
  "body": "  Consider the system of differential equations given by    Use trace and determinant analysis to determine the behavior of this linear system. Find the general solution to this system of differential equations and verify that it matches the analysis in (a).    Spiral sink. .   "
},
{
  "id": "sec-twodimaut-4-11",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-11",
  "type": "Exercise",
  "number": "4.7.3.10",
  "title": "",
  "body": "  Consider the system of differential equations given by    Use trace and determinant analysis to determine the behavior of this linear system. Find the general solution to this system of differential equations and verify that it matches the analysis in (a).    Improper nodal source.    "
},
{
  "id": "sec-twodimaut-4-12",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-12",
  "type": "Exercise",
  "number": "4.7.3.11",
  "title": "",
  "body": "  Take the system from , , . As we said, one of the eigenvalues is zero. What is the other eigenvalue, how does the picture look like and what happens when goes to infinity.    All solutions flow directly to the line .   "
},
{
  "id": "sec-twodimaut-4-13",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-13",
  "type": "Exercise",
  "number": "4.7.3.12",
  "title": "",
  "body": "  Take . Draw the vector field and describe the behavior. Is it one of the behaviors that we have seen before?   "
},
{
  "id": "sec-twodimaut-4-14",
  "level": "2",
  "url": "sec-twodimaut.html#sec-twodimaut-4-14",
  "type": "Exercise",
  "number": "4.7.3.13",
  "title": "",
  "body": "  In this exercise, we will analyze perturbations or near-by matrices to the ones that are given. This will be important later in . For each of the following matrices   Find the trace and determinant, and use them to classify the behavior of the linear system for the given matrix . Draw a sketch of the trace-determinant plane, including the curve , and plot the point corresponding to the matrix on those axes. Look at the points in a small (as small as you want) circle around the point you just drew. What does the behavior look like for systems whose matrices fall within that circle? What do these behaviors have in common with each other, and how do they differ?      "
},
{
  "id": "nonhomogsys-section",
  "level": "1",
  "url": "nonhomogsys-section.html",
  "type": "Section",
  "number": "4.8",
  "title": "Nonhomogeneous systems",
  "body": " Nonhomogeneous systems   Now, we want to take a look at solving non-homogeneous linear systems. As discussed previously, the process here is the same as it was for second order non-homogeneous equations. We can solve the homogeneous equation and then need one particular solution to the non-homogeneous problem. Adding these together gives the general solution to the non-homogeneous problem, where we can pick constants to meet an initial condition if it is given. This section here will focus on a variety of methods to find this particular solution.    First order constant coefficient   Diagonalization  Diagonalization is a linear algebra-based process for adjusting a matrix into one that is diagonal. In order to see why this might be helpful in the process of solving non-homogeneous systems, or generating a particular solution to the non-homogeneous system, let’s start by looking at a problem with a diagonal matrix to see how we could solve it.      Find the general solution of the non-homogeneous system     If we write this system out in components, we get or   These are two completely separated, or equations. We can solve each of these via first-order integrating factor methods. For the first, we get and for the second, we see that   Therefore, the solution to this system is or, rewriting in a different form,     Therefore, if we have a non-homogeneous system with a diagonal matrix, then we can separate the decoupled equations, solve them individually, and put them back together into a full solution. In this particular case, the eigenvectors of were and , and so the standard basis vectors were the directions in which acts like a scalar. When the eigenvectors are not the standard basis vectors, we need to take them into account in order to use this method.  Take the equation Assume has linearly independent eigenvectors with corresponding eigenvalues . Build the matrices that is, is the matrix with the eigenvectors as columns, and is a diagonal matrix with the eigenvalues on the diagonal in the same order as the eigenvectors are put into . Since we have eigenvectors, both of these are square matrices. It is a fact from linear algebra that     For the matrix compute the matrices and and verify that .    With this tool in hand, we look to approach our non-homogeneous system. We would like for the system to use the matrix instead of the matrix , because that is decoupled and we can solve it directly. To do this, we define a new unknown function by the relation . If we plug this into , we get Using the relation for and the fact that is a constant matrix, we get that If we multiply both sides of this equation by , we get and this is now a decoupled system of equations. Once we compute , we can then solve this directly because it is based on a decoupled system of differential equations to solve for the solution . Once we have , we can compute as to get our solution.        Let . Solve where for .    The first step in this process is always to find the eigenvalues and eigenvectors of the coefficient matrix. We do this in the standard way Since this factors as , the eigenvalues are and . Using these (exercise!) we can show that the corresponding eigenvectors are for and for . Therefore, the general solution to the homogeneous problem is   Now that we have this solution, we can work to solve the non-homogeneous problem. To do this, we form the matrices and, using the fact that for a matrix we can compute as   As an aside, we can check that to make sure that we did this right.     Thus, we can proceed. From the general process of diagonalization, we know that the system we need to solve is for , or defined by . Computing the non-homogenoeus term gives so that we can now decouple the system into two separate first-order equations that we can solve by normal first-order integrating factor methods. For the equation, we want to use an integrating factor of to solve it as   For the second, we need the integrating factor to solve   Therefore, we have the vector solution   To get to the actual solution , we need to multiply this solution by the matrix  which is a valid way to write the general solution. We can also write this solution in the form and we see that the general solution to the homogeneous problem shows up at the end of this solution.  Finally, we need to satisfy the initial conditions. If we plug in , we get Rearranging this expression gives the two equations which has solution and . Therefore, the solution to the initial value problem is     Another way to view this process is by thinking about it as eigenvector decomposition. (This approach is not necessary on a first reading. The next new information starts at the undetermined coefficients section.) The eigenvectors of are the directions in which the matrix basically acts like a scalar. If we can solve the differential equation in those directions, then it acts like a scalar equation, which we know how to solve. We can then reorient everything to get back to our original solution.  Again, we start with the equation and assume has linearly independent eigenvectors Write That is, we wish to write our solution as a linear combination of eigenvectors of . If we solve for the scalar functions through , we have our solution . Let us decompose in terms of the eigenvectors as well. We wish to write That is, we wish to find through that satisfy . Since all the eigenvectors are independent, the matrix is invertible. Write the equation as , where the components of are the functions through . Then . Hence it is always possible to find when there are linearly independent eigenvectors.  We plug into , and note that : If we identify the coefficients of the vectors through , we get the equations Each one of these equations is independent of the others. They are all linear first order equations and can easily be solved by the standard integrating factor method for single equations. That is, for the equation we write We use the integrating factor to find that We integrate and solve for to get If we are looking for just any particular solution, we can set to be zero. If we leave these constants in, we get the general solution. Write , and we are done.  As always, it is perhaps better to write these integrals as definite integrals. Suppose that we have an initial condition . Take to find , just like before. Then if we write we get the particular solution satisfying , because .  Let us remark that the technique we just outlined is the eigenvalue method applied to nonhomogeneous systems. If a system is homogeneous, that is, if , then the equations we get are , and so are the solutions and that’s precisely what we got in .      (Same as the previous example) Let . Solve where for .    The eigenvalues of are and 4 and corresponding eigenvectors are and respectively. We write down the matrix of the eigenvectors and compute its inverse (using the inverse formula for matrices)   We are looking for a solution of the form . We first need to write in terms of the eigenvectors. That is we wish to write . Thus So and .  We further need to write in terms of the eigenvectors. That is, we wish to write . Hence So and . We plug our into the equation and get We get the two equations We solve with integrating factor. Computation of the integral is left as an exercise to the student. You will need integration by parts.  is the constant of integration. As , then and hence . Similarly As we have and hence . The solution is That is, and .      Check that and solve the problem. Check both that they satisfy the differential equation and that they satisfy the initial conditions.      Undetermined coefficients  The method of undetermined coefficients also works for systems. The only difference is that we use unknown vectors rather than just numbers. Same caveats apply to undetermined coefficients for systems as for single equations. This method does not always work for the same reasons that the corresponding method did not work for second order equations. We need to have a right-hand side of a proper form so that we can guess a solution of the correct form for the non-homogeneous solution. Furthermore, if the right-hand side is complicated, we have to solve for lots of variables. Each element of an unknown vector is an unknown number. In system of 3 equations with say say 4 unknown vectors (this would not be uncommon), we already have 12 unknown numbers to solve for. The method can turn into a lot of work if done by hand. As the method is essentially the same as for single equations, let us just do an example.      Let . Find a particular solution of where .    Note that we can solve this system in an easier way (can you see how?), but for the purposes of the example, let us use the eigenvalue method plus undetermined coefficients. The eigenvalues of are and 1 and corresponding eigenvectors are and respectively. Hence our complementary solution is for some arbitrary constants and .  We would want to guess a particular solution of However, something of the form appears in the complementary solution. Because we do not yet know if the vector is a multiple of , we do not know if a conflict arises. It is possible that there is no conflict, but to be safe we should also try . Here we find the crux of the difference between a single equation and systems. We try both terms and in the solution, not just the term . Therefore, we try Thus we have 8 unknowns. We write , , , and . We plug into the equation. First let us compute . Now must equal , which is We identify the coefficients of , , and any constant vectors in and in to find the equations: We could write the augmented matrix and start row reduction, but it is easier to just solve the equations in an ad hoc manner. Immediately we see that , , . Plugging these back in, we get that and . The remaining equations that tell us something are So and . Finally, can be arbitrary and still satisfy the equations. We are looking for just a single solution so presumably the simplest one is when . Therefore, That is, , . We would add this to the complementary solution to get the general solution of the problem. Notice that both and were really needed.      Check that and solve the problem. Try setting and check we get a solution as well. What is the difference between the two solutions we obtained (one with and one with )?    As you can see, other than the handling of conflicts, undetermined coefficients works exactly the same as it did for single equations. However, the computations can get out of hand pretty quickly for systems. The equation we considered was pretty simple.       First order variable coefficient   Variation of parameters  Just as for a single equation, there is the method of variation of parameters. This method works for any linear system, even if it is not constant coefficient, provided we somehow solve the associated homogeneous problem.  Suppose we have the equation Further, suppose we solved the associated homogeneous equation and found a fundamental matrix solution . If we find separate, linearly independent solutions, this matrix can be generated by putting these solutions as the columns of a matrix. The general solution to the associated homogeneous equation is for a constant vector . Just like for variation of parameters for single equation we try the solution to the nonhomogeneous equation of the form where is a vector-valued function instead of a constant. We substitute into to obtain But is a fundamental matrix solution to the homogeneous problem. So , and Hence . If we compute , then . We integrate to obtain and we have the particular solution . Let us write this as a formula       Find a particular solution to given that the general solution to the homogeneous problem is     Here is most definitely not constant, so it’s a good thing that we have the general solution to this system. From this, we can build the matrix as , which is a fundamental matrix for this system and solves . Once we know the complementary solution we can find a solution to . First we find Next we know a particular solution to is Adding the complementary solution we find the general solution to :       Check that and really solve .    In the variation of parameters, we can obtain the general solution by adding in constants of integration. That is, we will add for a vector of arbitrary constants. But that is precisely the complementary solution.    To conclude this section, we will solve one example using all three methods to be able to compare and contrast them. All of them have their benefits and drawbacks, and it’s good to be able to do all three to be able to choose which to apply in a given circumstance.      Find the general solution to the system of differential equations     No matter which of the three methods we want to use to solve this problem, we always need the eigenvalues and eigenvectors of the coefficient matrix in order to find the general solution to the homogeneous problem. These are found by This polynomial factors as so the eigenvalues are and . For , the system we need to solve is which can be solved by the vector . For , the system is which can be solved by the vector . Therefore, the general solution to the homogeneous problem is   Now, we can divide into the different methods that we want to use to solve the non-homogeneous problem.    Diagonalization. For this method, we need the matrices and defined by and can then compute as We then compute which gives rise to the decoupled system where is defined by . We can solve for and using normal first-order methods:          Therefore, our solution for is and by converting back to , we get Or, rewriting in a different way, Notice how the general solution to the homogeneous equation shows up at the end of this expression.    Undetermined coefficients. Since the non-homogeneous part of our equation has terms of the form and constants, we should make a guess of the form We can plug this into our equation to get that and the right hand side of the equation is Writing out and in components will give the right-hand side as We can now set this equal to the left-hand side in to get the vector equation and we can match up the terms on the left and right sides to get a system that we need to solve: Let’s start with the equations. Rearranging these gives Subtracting two copies of the second equation from the first gives or , which gives . Next, we can solve the equations, which we can rearrange to give Subtracting two copies of the second equation from the first gives so , leading to . Therefore, a solution to the non-homogeneous problem is and so we can add in the homogeneous solution from to get the full general solution as     Variation of Parameters. For this method, we write down the fundamental matrix by combining the two basis solutions into a matrix, as and compute the inverse matrix as We can then work out the components of the method of variation of parameters. Integrating this expression gives and so the general solution to this system is Notice again that the homogeneous solution shows up at the end of these terms, so we do not need to add it in at the end.    Comparing the solutions , , and , we see that the three solutions generated by these three methods are all the same.    For this previous example, we only found the general solution. If the solution to an initial value problem was needed, we would need to wait until the very end, once we have figured out the solution to the non-homogeneous problem and added in the solution to the homogeneous problem to determine the value of the constants to meet the initial condition.     Exercises    Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.           Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.      Find the general solution to , ,   (2) using diagonalization, using undetermined coefficients.           Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.      Let . This matrix has eigenvectors and .   Find a fundamental matrix, , for the system . Use variation of parameters to solve the non-homogeneous system . If we used method of undetermined coefficients instead, what would be the appropriate guess for the form of the non-homogeneous solution?     ,       Solve , with initial conditions , , using diagonalization.      For each of the following vector functions , find the general solution to the system of differential equations given by using any of the methods described in this section. Notice the similarities and differences between using these methods for different non-homogeneous parts.   (3)          a)  b)  c)  d)  e)  f)        The variation of parameters method can also be applied to constant coefficient systems. Find the general solution of the system using   (2) diagonalization variation of parameters.  Compare and contrast these methods. You can use undetermined coefficients to check your answer.           Find the general solution to the differential equation The best option is undetermined coefficients here because of the eigenvalues of the matrix. Diagonalization can be used, but care will be needed with solving the decoupled system because the coefficients will be complex.           Find the general solution to the differential equation The best option is undetermined coefficients here because of the eigenvalues of the matrix. We can’t actually use diagonalization (try it and see why!).           Find the general solution to the differential equation            Consider the system    Rewrite in the form , where is a homogeneous system, and is a vector-valued function. Solve using Method of Undetermined Coefficients.               Use variation of parameters to solve the system . What does that solution tell you about how to set up the guess for the method of undetermined coefficients when there is a repeated eigenvalue?     .      Solve the initial value problem            Solve the initial value problem            Solve the initial value problem            Take the equation    Check that is the complementary solution. Use variation of parameters to find a particular solution.          "
},
{
  "id": "diagonalization-3",
  "level": "2",
  "url": "nonhomogsys-section.html#diagonalization-3",
  "type": "Example",
  "number": "4.8.1",
  "title": ".",
  "body": "    Find the general solution of the non-homogeneous system     If we write this system out in components, we get or   These are two completely separated, or equations. We can solve each of these via first-order integrating factor methods. For the first, we get and for the second, we see that   Therefore, the solution to this system is or, rewriting in a different form,    "
},
{
  "id": "diagonalization-6",
  "level": "2",
  "url": "nonhomogsys-section.html#diagonalization-6",
  "type": "Checkpoint",
  "number": "4.8.2",
  "title": "",
  "body": "  For the matrix compute the matrices and and verify that .    With this tool in hand, we look to approach our non-homogeneous system. We would like for the system to use the matrix instead of the matrix , because that is decoupled and we can solve it directly. To do this, we define a new unknown function by the relation . If we plug this into , we get Using the relation for and the fact that is a constant matrix, we get that If we multiply both sides of this equation by , we get and this is now a decoupled system of equations. Once we compute , we can then solve this directly because it is based on a decoupled system of differential equations to solve for the solution . Once we have , we can compute as to get our solution.   "
},
{
  "id": "diagonalization-7",
  "level": "2",
  "url": "nonhomogsys-section.html#diagonalization-7",
  "type": "Example",
  "number": "4.8.3",
  "title": ".",
  "body": "    Let . Solve where for .    The first step in this process is always to find the eigenvalues and eigenvectors of the coefficient matrix. We do this in the standard way Since this factors as , the eigenvalues are and . Using these (exercise!) we can show that the corresponding eigenvectors are for and for . Therefore, the general solution to the homogeneous problem is   Now that we have this solution, we can work to solve the non-homogeneous problem. To do this, we form the matrices and, using the fact that for a matrix we can compute as   As an aside, we can check that to make sure that we did this right.     Thus, we can proceed. From the general process of diagonalization, we know that the system we need to solve is for , or defined by . Computing the non-homogenoeus term gives so that we can now decouple the system into two separate first-order equations that we can solve by normal first-order integrating factor methods. For the equation, we want to use an integrating factor of to solve it as   For the second, we need the integrating factor to solve   Therefore, we have the vector solution   To get to the actual solution , we need to multiply this solution by the matrix  which is a valid way to write the general solution. We can also write this solution in the form and we see that the general solution to the homogeneous problem shows up at the end of this solution.  Finally, we need to satisfy the initial conditions. If we plug in , we get Rearranging this expression gives the two equations which has solution and . Therefore, the solution to the initial value problem is    "
},
{
  "id": "diagonalization-13",
  "level": "2",
  "url": "nonhomogsys-section.html#diagonalization-13",
  "type": "Example",
  "number": "4.8.4",
  "title": ".",
  "body": "    (Same as the previous example) Let . Solve where for .    The eigenvalues of are and 4 and corresponding eigenvectors are and respectively. We write down the matrix of the eigenvectors and compute its inverse (using the inverse formula for matrices)   We are looking for a solution of the form . We first need to write in terms of the eigenvectors. That is we wish to write . Thus So and .  We further need to write in terms of the eigenvectors. That is, we wish to write . Hence So and . We plug our into the equation and get We get the two equations We solve with integrating factor. Computation of the integral is left as an exercise to the student. You will need integration by parts.  is the constant of integration. As , then and hence . Similarly As we have and hence . The solution is That is, and .   "
},
{
  "id": "diagonalization-14",
  "level": "2",
  "url": "nonhomogsys-section.html#diagonalization-14",
  "type": "Checkpoint",
  "number": "4.8.5",
  "title": "",
  "body": "  Check that and solve the problem. Check both that they satisfy the differential equation and that they satisfy the initial conditions.   "
},
{
  "id": "undetermined-coefficients-3",
  "level": "2",
  "url": "nonhomogsys-section.html#undetermined-coefficients-3",
  "type": "Example",
  "number": "4.8.6",
  "title": ".",
  "body": "    Let . Find a particular solution of where .    Note that we can solve this system in an easier way (can you see how?), but for the purposes of the example, let us use the eigenvalue method plus undetermined coefficients. The eigenvalues of are and 1 and corresponding eigenvectors are and respectively. Hence our complementary solution is for some arbitrary constants and .  We would want to guess a particular solution of However, something of the form appears in the complementary solution. Because we do not yet know if the vector is a multiple of , we do not know if a conflict arises. It is possible that there is no conflict, but to be safe we should also try . Here we find the crux of the difference between a single equation and systems. We try both terms and in the solution, not just the term . Therefore, we try Thus we have 8 unknowns. We write , , , and . We plug into the equation. First let us compute . Now must equal , which is We identify the coefficients of , , and any constant vectors in and in to find the equations: We could write the augmented matrix and start row reduction, but it is easier to just solve the equations in an ad hoc manner. Immediately we see that , , . Plugging these back in, we get that and . The remaining equations that tell us something are So and . Finally, can be arbitrary and still satisfy the equations. We are looking for just a single solution so presumably the simplest one is when . Therefore, That is, , . We would add this to the complementary solution to get the general solution of the problem. Notice that both and were really needed.   "
},
{
  "id": "undetermined-coefficients-4",
  "level": "2",
  "url": "nonhomogsys-section.html#undetermined-coefficients-4",
  "type": "Checkpoint",
  "number": "4.8.7",
  "title": "",
  "body": "  Check that and solve the problem. Try setting and check we get a solution as well. What is the difference between the two solutions we obtained (one with and one with )?    As you can see, other than the handling of conflicts, undetermined coefficients works exactly the same as it did for single equations. However, the computations can get out of hand pretty quickly for systems. The equation we considered was pretty simple.   "
},
{
  "id": "variation-of-parameters-4",
  "level": "2",
  "url": "nonhomogsys-section.html#variation-of-parameters-4",
  "type": "Example",
  "number": "4.8.8",
  "title": ".",
  "body": "    Find a particular solution to given that the general solution to the homogeneous problem is     Here is most definitely not constant, so it’s a good thing that we have the general solution to this system. From this, we can build the matrix as , which is a fundamental matrix for this system and solves . Once we know the complementary solution we can find a solution to . First we find Next we know a particular solution to is Adding the complementary solution we find the general solution to :    "
},
{
  "id": "variation-of-parameters-5",
  "level": "2",
  "url": "nonhomogsys-section.html#variation-of-parameters-5",
  "type": "Checkpoint",
  "number": "4.8.9",
  "title": "",
  "body": "  Check that and really solve .    In the variation of parameters, we can obtain the general solution by adding in constants of integration. That is, we will add for a vector of arbitrary constants. But that is precisely the complementary solution.   "
},
{
  "id": "variation-of-parameters-7",
  "level": "2",
  "url": "nonhomogsys-section.html#variation-of-parameters-7",
  "type": "Example",
  "number": "4.8.10",
  "title": ".",
  "body": "    Find the general solution to the system of differential equations     No matter which of the three methods we want to use to solve this problem, we always need the eigenvalues and eigenvectors of the coefficient matrix in order to find the general solution to the homogeneous problem. These are found by This polynomial factors as so the eigenvalues are and . For , the system we need to solve is which can be solved by the vector . For , the system is which can be solved by the vector . Therefore, the general solution to the homogeneous problem is   Now, we can divide into the different methods that we want to use to solve the non-homogeneous problem.    Diagonalization. For this method, we need the matrices and defined by and can then compute as We then compute which gives rise to the decoupled system where is defined by . We can solve for and using normal first-order methods:          Therefore, our solution for is and by converting back to , we get Or, rewriting in a different way, Notice how the general solution to the homogeneous equation shows up at the end of this expression.    Undetermined coefficients. Since the non-homogeneous part of our equation has terms of the form and constants, we should make a guess of the form We can plug this into our equation to get that and the right hand side of the equation is Writing out and in components will give the right-hand side as We can now set this equal to the left-hand side in to get the vector equation and we can match up the terms on the left and right sides to get a system that we need to solve: Let’s start with the equations. Rearranging these gives Subtracting two copies of the second equation from the first gives or , which gives . Next, we can solve the equations, which we can rearrange to give Subtracting two copies of the second equation from the first gives so , leading to . Therefore, a solution to the non-homogeneous problem is and so we can add in the homogeneous solution from to get the full general solution as     Variation of Parameters. For this method, we write down the fundamental matrix by combining the two basis solutions into a matrix, as and compute the inverse matrix as We can then work out the components of the method of variation of parameters. Integrating this expression gives and so the general solution to this system is Notice again that the homogeneous solution shows up at the end of these terms, so we do not need to add it in at the end.    Comparing the solutions , , and , we see that the three solutions generated by these three methods are all the same.   "
},
{
  "id": "nonhomogsys-section-5-2",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-2",
  "type": "Exercise",
  "number": "4.8.3.1",
  "title": "",
  "body": "  Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.        "
},
{
  "id": "nonhomogsys-section-5-3",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-3",
  "type": "Exercise",
  "number": "4.8.3.2",
  "title": "",
  "body": "  Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.   "
},
{
  "id": "nonhomogsys-section-5-4",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-4",
  "type": "Exercise",
  "number": "4.8.3.3",
  "title": "",
  "body": "  Find the general solution to , ,   (2) using diagonalization, using undetermined coefficients.        "
},
{
  "id": "nonhomogsys-section-5-5",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-5",
  "type": "Exercise",
  "number": "4.8.3.4",
  "title": "",
  "body": "  Find a particular solution to , ,   (2) using diagonalization, using undetermined coefficients.   "
},
{
  "id": "nonhomogsys-section-5-6",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-6",
  "type": "Exercise",
  "number": "4.8.3.5",
  "title": "",
  "body": "  Let . This matrix has eigenvectors and .   Find a fundamental matrix, , for the system . Use variation of parameters to solve the non-homogeneous system . If we used method of undetermined coefficients instead, what would be the appropriate guess for the form of the non-homogeneous solution?     ,    "
},
{
  "id": "nonhomogsys-section-5-7",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-7",
  "type": "Exercise",
  "number": "4.8.3.6",
  "title": "",
  "body": "  Solve , with initial conditions , , using diagonalization.   "
},
{
  "id": "nonhomogsys-section-5-8",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-8",
  "type": "Exercise",
  "number": "4.8.3.7",
  "title": "",
  "body": "  For each of the following vector functions , find the general solution to the system of differential equations given by using any of the methods described in this section. Notice the similarities and differences between using these methods for different non-homogeneous parts.   (3)          a)  b)  c)  d)  e)  f)     "
},
{
  "id": "nonhomogsys-section-5-9",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-9",
  "type": "Exercise",
  "number": "4.8.3.8",
  "title": "",
  "body": "  The variation of parameters method can also be applied to constant coefficient systems. Find the general solution of the system using   (2) diagonalization variation of parameters.  Compare and contrast these methods. You can use undetermined coefficients to check your answer.        "
},
{
  "id": "nonhomogsys-section-5-10",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-10",
  "type": "Exercise",
  "number": "4.8.3.9",
  "title": "",
  "body": "  Find the general solution to the differential equation The best option is undetermined coefficients here because of the eigenvalues of the matrix. Diagonalization can be used, but care will be needed with solving the decoupled system because the coefficients will be complex.        "
},
{
  "id": "nonhomogsys-section-5-11",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-11",
  "type": "Exercise",
  "number": "4.8.3.10",
  "title": "",
  "body": "  Find the general solution to the differential equation The best option is undetermined coefficients here because of the eigenvalues of the matrix. We can’t actually use diagonalization (try it and see why!).        "
},
{
  "id": "nonhomogsys-section-5-12",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-12",
  "type": "Exercise",
  "number": "4.8.3.11",
  "title": "",
  "body": "  Find the general solution to the differential equation         "
},
{
  "id": "nonhomogsys-section-5-13",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-13",
  "type": "Exercise",
  "number": "4.8.3.12",
  "title": "",
  "body": "  Consider the system    Rewrite in the form , where is a homogeneous system, and is a vector-valued function. Solve using Method of Undetermined Coefficients.        "
},
{
  "id": "nonhomogsys-section-5-14",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-14",
  "type": "Exercise",
  "number": "4.8.3.13",
  "title": "",
  "body": "      Use variation of parameters to solve the system . What does that solution tell you about how to set up the guess for the method of undetermined coefficients when there is a repeated eigenvalue?     .   "
},
{
  "id": "nonhomogsys-section-5-15",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-15",
  "type": "Exercise",
  "number": "4.8.3.14",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "nonhomogsys-section-5-16",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-16",
  "type": "Exercise",
  "number": "4.8.3.15",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "nonhomogsys-section-5-17",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-17",
  "type": "Exercise",
  "number": "4.8.3.16",
  "title": "",
  "body": "  Solve the initial value problem         "
},
{
  "id": "nonhomogsys-section-5-18",
  "level": "2",
  "url": "nonhomogsys-section.html#nonhomogsys-section-5-18",
  "type": "Exercise",
  "number": "4.8.3.17",
  "title": "",
  "body": "  Take the equation    Check that is the complementary solution. Use variation of parameters to find a particular solution.        "
},
{
  "id": "sol-section",
  "level": "1",
  "url": "sol-section.html",
  "type": "Section",
  "number": "4.9",
  "title": "Second order systems and applications",
  "body": " Second order systems and applications   Undamped mass-spring systems  While we did say that we will usually only look at first order systems, it is sometimes more convenient to study the system in the way it arises naturally. For example, suppose we have 3 masses connected by springs between two walls. We could pick any higher number, and the math would be essentially the same, but for simplicity we pick 3 right now. Let us also assume no friction, that is, the system is undamped. The masses are , , and and the spring constants are , , , and . Let be the displacement from rest position of the first mass, and and the displacement of the second and third mass. We make, as usual, positive values go right (as grows, the first mass is moving right). See .    This simple system turns up in unexpected places. For example, our world really consists of many small particles of matter interacting together. When we try the system above with many more masses, we obtain a good approximation to how an elastic material behaves.  Let us set up the equations for the . By , the force acting on the mass equals the spring compression times the spring constant. By , force is mass times acceleration. So if we sum the forces acting on each mass, put the right sign in front of each term, depending on the direction in which it is acting, and set this equal to mass times the acceleration, we end up with the desired system of equations. We define the matrices We write the equation simply as At this point we could introduce 3 new variables and write out a system of 6 first order equations. We claim this simple setup is easier to handle as a second order system. We call the , the , and the .    Repeat this setup for 4 masses (find the matrices and ). Do it for 5 masses. Can you find a prescription to do it for masses?    As with a single equation we want to This means computing the inverse of . The masses are all nonzero and is a diagonal matrix, so computing the inverse is easy: This fact follows readily by how we multiply diagonal matrices. As an exercise, you should verify that .    Let . We look at the system , or Many real world systems can be modeled by this equation. For simplicity, we will only talk about the given masses-and-springs problem. We try a solution of the form We compute that for this guess, . We plug our guess into the equation and get We divide by to arrive at . Hence if is an eigenvalue of and is a corresponding eigenvector, we have found a solution.  In our example, and in other common applications, has only real negative eigenvalues (and possibly a zero eigenvalue). So we study only this case. When an eigenvalue is negative, it means that is negative. Hence there is some real number such that . Then . The solution we guessed was By taking the real and imaginary parts (note that is real), we find that and are linearly independent solutions.  If an eigenvalue is zero, it turns out that both and are solutions, where is an eigenvector corresponding to the eigenvalue 0.    Show that if has a zero eigenvalue and is a corresponding eigenvector, then is a solution of for arbitrary constants and .     Let be a real matrix with distinct real negative (or zero) eigenvalues we denote by , and corresponding eigenvectors by , , …, . If is invertible (that is, if ), then is the general solution of for some arbitrary constants and . If has a zero eigenvalue, that is , and all other eigenvalues are distinct and negative, then the general solution can be written as   We use this solution and the setup from the introduction of this section even when some of the masses and springs are missing. For example, when there are only 2 masses and only 2 springs, simply take only the equations for the two masses and set all the spring constants for the springs that are missing to zero.    Examples      Consider the setup in , with , , , and .      The equations we write down are or   We find the eigenvalues of to be (exercise). We find corresponding eigenvectors to be and respectively (exercise).  We check the theorem and note that and . Hence the general solution is   The two terms in the solution represent the two so-called natural or normal modes of oscillation . And the two (angular) frequencies are the natural frequencies . The first natural frequency is 1, and second natural frequency is 2. The two modes are plotted in .    Let us write the solution as The first term, corresponds to the mode where the masses move synchronously in the same direction.  The second term, corresponds to the mode where the masses move synchronously but in opposite directions.  The general solution is a combination of the two modes. That is, the initial conditions determine the amplitude and phase shift of each mode. As an example, suppose we have initial conditions We use the constants to solve for initial conditions. First We solve (exercise) to find , . To find the and , we differentiate first: Now we solve: Again solve (exercise) to find , . So our solution is The graphs of the two displacements, and of the two carts is in .          We have two toy rail cars. Car 1 of mass kg is traveling at towards the second rail car of mass kg. There is a bumper on the second rail car that engages at the moment the cars hit (it connects to two cars) and does not let go. The bumper acts like a spring of spring constant . The second car is 10 meters from a wall. See .    We want to ask several questions. At what time after the cars link does impact with the wall happen? What is the speed of car 2 when it hits the wall?    OK, let us first set the system up. Let be the time when the two cars link up. Let be the displacement of the first car from the position at , and let be the displacement of the second car from its original location. Then the time when is exactly the time when impact with wall occurs. For this , is the speed at impact. This system acts just like the system of the previous example but without . Hence the equation is or   We compute the eigenvalues of . It is not hard to see that the eigenvalues are 0 and (exercise). Furthermore, eigenvectors are and respectively (exercise). Then , , and by the second part of the theorem the general solution is   We now apply the initial conditions. First the cars start at position 0 so and . The first car is traveling at , so and the second car starts at rest, so . The first conditions says It is not hard to see that . We set and in and differentiate to get So Solving these two equations we find and . Hence the position of our cars is (until the impact with the wall) Note how the presence of the zero eigenvalue resulted in a term containing . This means that the cars will be traveling in the positive direction as time grows, which is what we expect.  What we are really interested in is the second expression, the one for . We have . See for the plot of versus time.  Just from the graph we can see that time of impact will be a little more than 5 seconds from time zero. For this we have to solve the equation . Using a computer (or even a graphing calculator) we find that seconds.   3.25in  The speed of the second car is . At the time of impact (5.22 seconds from ) we get . The maximum speed is the maximum of , which is 4. We are traveling at almost the maximum speed when we hit the wall.  Suppose that Bob is a tiny person sitting on car 2. Bob has a Martini in his hand and would like not to spill it. Let us suppose Bob would not spill his Martini when the first car links up with car 2, but if car 2 hits the wall at any speed greater than zero, Bob will spill his drink. Suppose Bob can move car 2 a few meters towards or away from the wall (he cannot go all the way to the wall, nor can he get out of the way of the first car). Is there a distance for him to be at? A distance such that the impact with the wall is at zero speed?  The answer is yes. Looking at , we note the between and . There is a point where the speed is zero. To find it we solve . This is when or in other words when and so on. We plug in the first value to obtain . So a distance is about 7 and a quarter meters from the wall.  Alternatively Bob could move away from the wall towards the incoming car 2, where another safe distance is and so on. We can use all the different such that . Of course is also a solution, corresponding to , but that means standing right at the wall.      Forced oscillations  Finally we move to forced oscillations. Suppose that now our system is That is, we are adding periodic forcing to the system in the direction of the vector .  As before, this system just requires us to find one particular solution , add it to the general solution of the associated homogeneous system , and we will have the general solution to . Let us suppose that is not one of the natural frequencies of , then we can guess where is an unknown constant vector. Note that we do not need to use sine since there are only second derivatives. We solve for to find . This is really just the method of undetermined coefficients for systems. Let us differentiate twice to get Plug and into equation : We cancel out the cosine and rearrange the equation to obtain So Of course this is possible only if is invertible. That matrix is invertible if and only if is not an eigenvalue of . That is true if and only if is not a natural frequency of the system.  We simplified things a little bit. If we wish to have the forcing term to be in the units of force, say Newtons, then we must write If we then write things in terms of , we have where .      Let us take the example in with the same parameters as before: , , , and . Now suppose that there is a force acting on the second cart.    The equation is We solved the associated homogeneous equation before and found the complementary solution to be   The natural frequencies are 1 and 2. As 3 is not a natural frequency, we try . We invert : Hence,   Combining with the general solution of the associated homogeneous problem, we get that the general solution to is We then solve for the constants , , , and using any initial conditions we are given.    Note that given force , we write the equation as to get the units right. Then we write . The term in is in units of force per unit mass.  If is a natural frequency of the system, may occur, because we will have to try a particular solution of the form That is assuming that the eigenvalues of the coefficient matrix are distinct. Next, note that the amplitude of this solution grows without bound as grows.    Non-Homogeneous Solutions   Undetermined coefficients  Let the equation be where is a constant matrix. If is of the form , then as two derivatives of cosine is again cosine we can try a solution of the form and we do not need to introduce sines.  If the is a sum of cosines, note that we still have the superposition principle. If , then we would try for the problem , and we would try for the problem . Then we sum the solutions.  However, if there is duplication with the complementary solution, or the equation is of the form , then we need to do the same thing as we do for first order systems.  You will never go wrong with putting in more terms than needed into your guess. You will find that the extra coefficients will turn out to be zero. But it is useful to save some time and effort.    Eigenvector decomposition  If we have the system we can do , just like for first order systems.  Let be the eigenvalues and be eigenvectors. Again form the matrix . Write Decompose in terms of the eigenvectors where, again, .  We plug in, and as before we obtain We identify the coefficients of the eigenvectors to get the equations Each one of these equations is independent of the others. We solve each equation using the methods of . We write , and we are done; we have a particular solution. We find the general solutions for through , and again is the general solution (and not just a particular solution).      Let us do the same example from before using this method.    The equation is The eigenvalues are and , with eigenvectors and . Therefore and . Therefore, So after the whole song and dance of plugging in, the equations we get are For each equation we use the method of undetermined coefficients. We try for the first equation and for the second equation. We plug in to get We solve each of these equations separately. We get and . And hence and . So our particular solution is This solution matches what we got previously.       Exercises    Find a particular solution to            Find the general solution to .      Let us take the example in with the same parameters as before: , , and , except for , which is unknown. Suppose that there is a force acting on the first mass. Find an such that there exists a particular solution where the first mass does not move.  Note: This idea is called . In practice there will be a small amount of damping and so any transient solution will disappear and after long enough time, the first mass will always come to a stop.           Let us take the , but that at time of impact, car 2 is moving to the left at the speed of .   Find the behavior of the system after linkup. Will the second car hit the wall, or will it be moving away from the wall as time goes on? At what speed would the first car have to be traveling for the system to essentially stay in place after linkup?    a)  b) It will hit the wall. c)  m\/s to the right      Let us take the example in with parameters , . Does there exist a set of initial conditions for which the first cart moves but the second cart does not? If so, find those conditions. If not, argue why not.    No      Suppose there are three carts of equal mass and connected by two springs of constant (and no connections to walls). Set up the system and find its general solution.      Suppose a cart of mass kg is attached by a spring of constant to a cart of mass kg, which is attached to the wall by a spring also of constant . Suppose that the initial position of the first cart is 1 meter in the positive direction from the rest position, and the second mass starts at the rest position. The masses are not moving and are let go. Find the position of the second mass as a function of time.      Find the general solution to , ,   (2) using eigenvector decomposition, using undetermined coefficients.           Find the general solution to , ,   (2) using eigenvector decomposition, using undetermined coefficients.           Solve , with initial conditions , , , , using eigenvector decomposition.    "
},
{
  "id": "undamped-mass-spring-systems-5",
  "level": "2",
  "url": "sol-section.html#undamped-mass-spring-systems-5",
  "type": "Checkpoint",
  "number": "4.9.1",
  "title": "",
  "body": "  Repeat this setup for 4 masses (find the matrices and ). Do it for 5 masses. Can you find a prescription to do it for masses?    As with a single equation we want to This means computing the inverse of . The masses are all nonzero and is a diagonal matrix, so computing the inverse is easy: This fact follows readily by how we multiply diagonal matrices. As an exercise, you should verify that .   "
},
{
  "id": "undamped-mass-spring-systems-9",
  "level": "2",
  "url": "sol-section.html#undamped-mass-spring-systems-9",
  "type": "Checkpoint",
  "number": "4.9.2",
  "title": "",
  "body": "  Show that if has a zero eigenvalue and is a corresponding eigenvector, then is a solution of for arbitrary constants and .   "
},
{
  "id": "examples-2",
  "level": "2",
  "url": "sol-section.html#examples-2",
  "type": "Example",
  "number": "4.9.3",
  "title": ".",
  "body": "    Consider the setup in , with , , , and .      The equations we write down are or   We find the eigenvalues of to be (exercise). We find corresponding eigenvectors to be and respectively (exercise).  We check the theorem and note that and . Hence the general solution is   The two terms in the solution represent the two so-called natural or normal modes of oscillation . And the two (angular) frequencies are the natural frequencies . The first natural frequency is 1, and second natural frequency is 2. The two modes are plotted in .    Let us write the solution as The first term, corresponds to the mode where the masses move synchronously in the same direction.  The second term, corresponds to the mode where the masses move synchronously but in opposite directions.  The general solution is a combination of the two modes. That is, the initial conditions determine the amplitude and phase shift of each mode. As an example, suppose we have initial conditions We use the constants to solve for initial conditions. First We solve (exercise) to find , . To find the and , we differentiate first: Now we solve: Again solve (exercise) to find , . So our solution is The graphs of the two displacements, and of the two carts is in .     "
},
{
  "id": "examples-3",
  "level": "2",
  "url": "sol-section.html#examples-3",
  "type": "Example",
  "number": "4.9.4",
  "title": ".",
  "body": "    We have two toy rail cars. Car 1 of mass kg is traveling at towards the second rail car of mass kg. There is a bumper on the second rail car that engages at the moment the cars hit (it connects to two cars) and does not let go. The bumper acts like a spring of spring constant . The second car is 10 meters from a wall. See .    We want to ask several questions. At what time after the cars link does impact with the wall happen? What is the speed of car 2 when it hits the wall?    OK, let us first set the system up. Let be the time when the two cars link up. Let be the displacement of the first car from the position at , and let be the displacement of the second car from its original location. Then the time when is exactly the time when impact with wall occurs. For this , is the speed at impact. This system acts just like the system of the previous example but without . Hence the equation is or   We compute the eigenvalues of . It is not hard to see that the eigenvalues are 0 and (exercise). Furthermore, eigenvectors are and respectively (exercise). Then , , and by the second part of the theorem the general solution is   We now apply the initial conditions. First the cars start at position 0 so and . The first car is traveling at , so and the second car starts at rest, so . The first conditions says It is not hard to see that . We set and in and differentiate to get So Solving these two equations we find and . Hence the position of our cars is (until the impact with the wall) Note how the presence of the zero eigenvalue resulted in a term containing . This means that the cars will be traveling in the positive direction as time grows, which is what we expect.  What we are really interested in is the second expression, the one for . We have . See for the plot of versus time.  Just from the graph we can see that time of impact will be a little more than 5 seconds from time zero. For this we have to solve the equation . Using a computer (or even a graphing calculator) we find that seconds.   3.25in  The speed of the second car is . At the time of impact (5.22 seconds from ) we get . The maximum speed is the maximum of , which is 4. We are traveling at almost the maximum speed when we hit the wall.  Suppose that Bob is a tiny person sitting on car 2. Bob has a Martini in his hand and would like not to spill it. Let us suppose Bob would not spill his Martini when the first car links up with car 2, but if car 2 hits the wall at any speed greater than zero, Bob will spill his drink. Suppose Bob can move car 2 a few meters towards or away from the wall (he cannot go all the way to the wall, nor can he get out of the way of the first car). Is there a distance for him to be at? A distance such that the impact with the wall is at zero speed?  The answer is yes. Looking at , we note the between and . There is a point where the speed is zero. To find it we solve . This is when or in other words when and so on. We plug in the first value to obtain . So a distance is about 7 and a quarter meters from the wall.  Alternatively Bob could move away from the wall towards the incoming car 2, where another safe distance is and so on. We can use all the different such that . Of course is also a solution, corresponding to , but that means standing right at the wall.   "
},
{
  "id": "forced-oscillations-5",
  "level": "2",
  "url": "sol-section.html#forced-oscillations-5",
  "type": "Example",
  "number": "4.9.5",
  "title": ".",
  "body": "    Let us take the example in with the same parameters as before: , , , and . Now suppose that there is a force acting on the second cart.    The equation is We solved the associated homogeneous equation before and found the complementary solution to be   The natural frequencies are 1 and 2. As 3 is not a natural frequency, we try . We invert : Hence,   Combining with the general solution of the associated homogeneous problem, we get that the general solution to is We then solve for the constants , , , and using any initial conditions we are given.   "
},
{
  "id": "eigenvector-decomposition-5",
  "level": "2",
  "url": "sol-section.html#eigenvector-decomposition-5",
  "type": "Example",
  "number": "4.9.6",
  "title": ".",
  "body": "    Let us do the same example from before using this method.    The equation is The eigenvalues are and , with eigenvectors and . Therefore and . Therefore, So after the whole song and dance of plugging in, the equations we get are For each equation we use the method of undetermined coefficients. We try for the first equation and for the second equation. We plug in to get We solve each of these equations separately. We get and . And hence and . So our particular solution is This solution matches what we got previously.   "
},
{
  "id": "sol-section-6-2",
  "level": "2",
  "url": "sol-section.html#sol-section-6-2",
  "type": "Exercise",
  "number": "4.9.5.1",
  "title": "",
  "body": "  Find a particular solution to         "
},
{
  "id": "sol-section-6-3",
  "level": "2",
  "url": "sol-section.html#sol-section-6-3",
  "type": "Exercise",
  "number": "4.9.5.2",
  "title": "",
  "body": "  Find the general solution to .   "
},
{
  "id": "sol-section-6-4",
  "level": "2",
  "url": "sol-section.html#sol-section-6-4",
  "type": "Exercise",
  "number": "4.9.5.3",
  "title": "",
  "body": "  Let us take the example in with the same parameters as before: , , and , except for , which is unknown. Suppose that there is a force acting on the first mass. Find an such that there exists a particular solution where the first mass does not move.  Note: This idea is called . In practice there will be a small amount of damping and so any transient solution will disappear and after long enough time, the first mass will always come to a stop.        "
},
{
  "id": "sol-section-6-5",
  "level": "2",
  "url": "sol-section.html#sol-section-6-5",
  "type": "Exercise",
  "number": "4.9.5.4",
  "title": "",
  "body": "  Let us take the , but that at time of impact, car 2 is moving to the left at the speed of .   Find the behavior of the system after linkup. Will the second car hit the wall, or will it be moving away from the wall as time goes on? At what speed would the first car have to be traveling for the system to essentially stay in place after linkup?    a)  b) It will hit the wall. c)  m\/s to the right   "
},
{
  "id": "sol-section-6-6",
  "level": "2",
  "url": "sol-section.html#sol-section-6-6",
  "type": "Exercise",
  "number": "4.9.5.5",
  "title": "",
  "body": "  Let us take the example in with parameters , . Does there exist a set of initial conditions for which the first cart moves but the second cart does not? If so, find those conditions. If not, argue why not.    No   "
},
{
  "id": "sol-section-6-7",
  "level": "2",
  "url": "sol-section.html#sol-section-6-7",
  "type": "Exercise",
  "number": "4.9.5.6",
  "title": "",
  "body": "  Suppose there are three carts of equal mass and connected by two springs of constant (and no connections to walls). Set up the system and find its general solution.   "
},
{
  "id": "sol-section-6-8",
  "level": "2",
  "url": "sol-section.html#sol-section-6-8",
  "type": "Exercise",
  "number": "4.9.5.7",
  "title": "",
  "body": "  Suppose a cart of mass kg is attached by a spring of constant to a cart of mass kg, which is attached to the wall by a spring also of constant . Suppose that the initial position of the first cart is 1 meter in the positive direction from the rest position, and the second mass starts at the rest position. The masses are not moving and are let go. Find the position of the second mass as a function of time.   "
},
{
  "id": "sol-section-6-9",
  "level": "2",
  "url": "sol-section.html#sol-section-6-9",
  "type": "Exercise",
  "number": "4.9.5.8",
  "title": "",
  "body": "  Find the general solution to , ,   (2) using eigenvector decomposition, using undetermined coefficients.        "
},
{
  "id": "sol-section-6-10",
  "level": "2",
  "url": "sol-section.html#sol-section-6-10",
  "type": "Exercise",
  "number": "4.9.5.9",
  "title": "",
  "body": "  Find the general solution to , ,   (2) using eigenvector decomposition, using undetermined coefficients.        "
},
{
  "id": "sol-section-6-11",
  "level": "2",
  "url": "sol-section.html#sol-section-6-11",
  "type": "Exercise",
  "number": "4.9.5.10",
  "title": "",
  "body": "  Solve , with initial conditions , , , , using eigenvector decomposition.   "
},
{
  "id": "sec-matexp",
  "level": "1",
  "url": "sec-matexp.html",
  "type": "Section",
  "number": "4.10",
  "title": "Matrix exponentials",
  "body": " Matrix exponentials   Definition  There is another way of finding a fundamental matrix solution of a system. Consider the constant coefficient equation If this would be just one equation (when is a number or a matrix), then the solution would be That doesn’t make sense if is a larger matrix, but essentially the same computation that led to the above works for matrices when we define properly. First let us write down the Taylor series for for some number : Recall is the factorial, and . We differentiate this series term by term Maybe we can try the same trick with matrices.   For an matrix we define the as   Let us not worry about convergence. The series really does always converge. We usually write as by convention when is a matrix. With this small change and by the exact same calculation as above we have that Now and hence is an matrix. What we are looking for is a vector. In the case we would at this point multiply by an arbitrary constant to get the general solution. In the matrix case we multiply by a column vector .   Let be an matrix. Then the general solution to is where is an arbitrary constant vector. In fact, .  Let us check:   Hence is a of the homogeneous system. So if we can compute the matrix exponential, we have another method of solving constant coefficient homogeneous systems. It also makes it easy to solve for initial conditions. To solve , , we take the solution This equation follows because , so .  We mention a drawback of matrix exponentials. In general . The trouble is that matrices do not commute, that is, in general . If you try to prove using the Taylor series, you will see why the lack of commutativity becomes a problem. However, it is still true that if , that is, if and commute, then . We will find this fact useful. Let us restate this as a theorem to make a point.   If , then . Otherwise, in general.    Simple cases  In some instances it may work to just plug into the series definition. Suppose the matrix is diagonal. For example, . Then and So by this rationale   This makes exponentials of certain other matrices easy to compute. For example, the matrix can be written as where . Notice that . So for all . Therefore, . Suppose we actually want to compute . The matrices and commute (exercise: check this) and , since . We write We found a fundamental matrix solution for the system . Note that this matrix has a repeated eigenvalue with a defect; there is only one eigenvector for the eigenvalue 3. So we found a perhaps easier way to handle this case. In fact, if a matrix is and has an eigenvalue of multiplicity 2, then either , or where . This is a good exercise.    Suppose that is and is the only eigenvalue. Show that , and therefore that we can write , where (and possibly ). Hint: First write down what does it mean for the eigenvalue to be of multiplicity 2. You will get an equation for the entries. Now compute the square of .    Matrices such that for some are called . Computation of the matrix exponential for nilpotent matrices is easy by just writing down the first terms of the Taylor series.      General matrices  In general, the exponential is not as easy to compute as above. We usually cannot write a matrix as a sum of commuting matrices where the exponential is simple for each one. But fear not, it is still not too difficult provided we can find enough eigenvectors. First we need the following interesting result about matrix exponentials. For two square matrices and , with invertible, we have This can be seen by writing down the Taylor series. First And by the same reasoning . Now write the Taylor series for :   Given a square matrix , we can usually write , where is diagonal and invertible. This procedure is called . If we can do that, the computation of the exponential becomes easy as is just taking the exponential of the entries on the diagonal. Adding into the mix, we can then compute the exponential   To diagonalize we need linearly independent eigenvectors of . Otherwise, this method of computing the exponential does not work and we need to be trickier, but we will not get into such details. Let be the matrix with the eigenvectors as columns. Let , , …, be the eigenvalues and let , , …, be the eigenvectors, then . Make a diagonal matrix with the eigenvalues on the diagonal: We compute The columns of are linearly independent as these are linearly independent eigenvectors of . Hence is invertible. Since , we multiply on the right by and we get This means that . Multiplying the matrix by we obtain The formula , therefore, gives the formula for computing a fundamental matrix solution for the system , in the case where we have linearly independent eigenvectors.  This computation still works when the eigenvalues and eigenvectors are complex, though then you have to compute with complex numbers. It is clear from the definition that if is real, then is real. So you will only need complex numbers in the computation and not for the result. You may need to apply to simplify the result. If simplified properly, the final matrix will not have any complex numbers in it.      Compute a fundamental matrix solution using the matrix exponential for the system Then compute the particular solution for the initial conditions and .  Let be the coefficient matrix . We first compute (exercise) that the eigenvalues are 3 and and corresponding eigenvectors are and . Hence the diagonalization of is We write   The initial conditions are and . Hence, by the property that we find that the particular solution we are looking for is where is . Then the particular solution we are looking for is       Fundamental matrix solutions  We note that if you can compute a fundamental matrix solution in a different way, you can use this to find the matrix exponential . A fundamental matrix solution of a system of ODEs is not unique. The exponential is the fundamental matrix solution with the property that for we get the identity matrix. So we must find the right fundamental matrix solution. Let be any fundamental matrix solution to . Then we claim Clearly, if we plug into we get the identity. We can multiply a fundamental matrix solution on the right by any constant invertible matrix and we still get a fundamental matrix solution. All we are doing is changing what are the arbitrary constants in the general solution .    Approximations  If you think about it, the computation of any fundamental matrix solution using the eigenvalue method is just as difficult as the computation of . So perhaps we did not gain much by this new tool. However, the Taylor series expansion actually gives us a way to approximate solutions, which the eigenvalue method did not.  The simplest thing we can do is to just compute the series up to a certain number of terms. There are better ways to approximate the exponential C. Moler and C.F. Van Loan, Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later , SIAM Review 45 (1), 2003, 3–49 . In many cases however, few terms of the Taylor series give a reasonable approximation for the exponential and may suffice for the application. For example, let us compute the first 4 terms of the series for the matrix . Just like the scalar version of the Taylor series approximation, the approximation will be better for small and worse for larger . For larger , we will generally have to compute more terms. Let us see how we stack up against the real solution with . The approximate solution is approximately (rounded to 8 decimal places) And plugging into the real solution (rounded to 8 decimal places) we get Not bad at all! Although if we take the same approximation for we get while the real value is (again rounded to 8 decimal places) So the approximation is not very good once we get up to . To get a good approximation at (say up to 2 decimal places) we would need to go up to the power (exercise).    Non-Homogeneous Systems   Integrating factor  Now that we have matrix exponentials, we can try to use them to help us solve non-homogeneous systems of differential equations. First, let’s recall what we did for first order equations. If we have an equation of the form where will assume that is constant (even though it doesn’t have to be). We would go about solving this problem by multiplying both sides of the equation by , writing the left-hand side as a product rule, integrating both sides, and solving.  With matrix exponentials, we can do exactly the same thing with first order systems. Let us focus on the nonhomogeneous first order equation where is a constant matrix. The method we look at here is the integrating factor method . For simplicity we rewrite the equation as where . We multiply both sides of the equation by (being mindful that we are dealing with matrices that may not commute) to obtain We notice that . This fact follows by writing down the series definition of : So . The product rule says and so We can now integrate. That is, we integrate each component of the vector separately In , you will compute and verify that . Therefore, we obtain   Perhaps it is better understood as a definite integral. In this case it will be easy to also solve for the initial conditions. Consider the equation with initial conditions The solution can then be written as Again, the integration means that each component of the vector is integrated separately. It is not hard to see that really does satisfy the initial condition .       Suppose that we have the system with initial conditions .    Let us write the system as The matrix has a doubled eigenvalue 2 with defect 1, and we leave it as an exercise to double check we computed correctly. Once we have , we find , simply by negating . Instead of computing the whole formula at once, let us do it in stages. First Then Phew!  Let us check that this really works. Similarly (exercise) . The initial conditions are also satisfied (exercise).    For systems, the integrating factor method only works if does not depend on , that is, is constant. The problem is that in general because matrix multiplication is not commutative.     Exercises    Using the matrix exponential, find a fundamental matrix solution for the system , .           Find for the matrix .           Compute where .      Compute where .       (2) Compute where . Solve for .      Find a fundamental matrix solution for the system , , . Then find the solution that satisfies .     ,       Compute the matrix exponential for .           Suppose . Show that under this assumption, .    Hint: Consider the equation . Show that both of the above solve this equation using that if then commutes with and vice versa.      Use to show that . In particular this means that is invertible even if is not.    Hint: commutes with .      Let be a matrix with eigenvalues , , and corresponding eigenvectors , .   Find matrix with these properties. Find a fundamental matrix solution to . Solve the system in with initial conditions .    a)  b)  c)        Suppose that is an matrix with a repeated eigenvalue of multiplicity . Suppose that there are linearly independent eigenvectors. Show that the matrix is diagonal, in particular . Hint: Use diagonalization and the fact that the identity matrix commutes with every other matrix.    Hint: If there are linearly independent eigenvectors, then it can be diagonalized. What does look like?      Let .   (2) Find . Solve , .    a)  b)        Let . Approximate by expanding the power series up to the third order.           Compute the first 3 terms (up to the second degree) of the Taylor expansion of where (Write as a single matrix). Then use it to approximate .      For any positive integer , find a formula (or a recipe) for for the following matrices:   (4)        a)  b)  c)  , , for all d)        For any positive integer , find a formula (or a recipe) for for the following matrices:   (3)         Solve the initial value problem using matrix exponentials.           Solve the initial value problem using matrix exponentials.          "
},
{
  "id": "simple-cases-4",
  "level": "2",
  "url": "sec-matexp.html#simple-cases-4",
  "type": "Checkpoint",
  "number": "4.10.1",
  "title": "",
  "body": "  Suppose that is and is the only eigenvalue. Show that , and therefore that we can write , where (and possibly ). Hint: First write down what does it mean for the eigenvalue to be of multiplicity 2. You will get an equation for the entries. Now compute the square of .    Matrices such that for some are called . Computation of the matrix exponential for nilpotent matrices is easy by just writing down the first terms of the Taylor series.   "
},
{
  "id": "general-matrices-6",
  "level": "2",
  "url": "sec-matexp.html#general-matrices-6",
  "type": "Example",
  "number": "4.10.2",
  "title": ".",
  "body": "    Compute a fundamental matrix solution using the matrix exponential for the system Then compute the particular solution for the initial conditions and .  Let be the coefficient matrix . We first compute (exercise) that the eigenvalues are 3 and and corresponding eigenvectors are and . Hence the diagonalization of is We write   The initial conditions are and . Hence, by the property that we find that the particular solution we are looking for is where is . Then the particular solution we are looking for is    "
},
{
  "id": "integrating-factor-5",
  "level": "2",
  "url": "sec-matexp.html#integrating-factor-5",
  "type": "Example",
  "number": "4.10.3",
  "title": ".",
  "body": "    Suppose that we have the system with initial conditions .    Let us write the system as The matrix has a doubled eigenvalue 2 with defect 1, and we leave it as an exercise to double check we computed correctly. Once we have , we find , simply by negating . Instead of computing the whole formula at once, let us do it in stages. First Then Phew!  Let us check that this really works. Similarly (exercise) . The initial conditions are also satisfied (exercise).   "
},
{
  "id": "sec-matexp-8-2",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-2",
  "type": "Exercise",
  "number": "4.10.7.1",
  "title": "",
  "body": "  Using the matrix exponential, find a fundamental matrix solution for the system , .        "
},
{
  "id": "sec-matexp-8-3",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-3",
  "type": "Exercise",
  "number": "4.10.7.2",
  "title": "",
  "body": "  Find for the matrix .        "
},
{
  "id": "sec-matexp-8-4",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-4",
  "type": "Exercise",
  "number": "4.10.7.3",
  "title": "",
  "body": "  Compute where .   "
},
{
  "id": "sec-matexp-8-5",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-5",
  "type": "Exercise",
  "number": "4.10.7.4",
  "title": "",
  "body": "  Compute where .   "
},
{
  "id": "sec-matexp-8-6",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-6",
  "type": "Exercise",
  "number": "4.10.7.5",
  "title": "",
  "body": "   (2) Compute where . Solve for .   "
},
{
  "id": "sec-matexp-8-7",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-7",
  "type": "Exercise",
  "number": "4.10.7.6",
  "title": "",
  "body": "  Find a fundamental matrix solution for the system , , . Then find the solution that satisfies .     ,    "
},
{
  "id": "sec-matexp-8-8",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-8",
  "type": "Exercise",
  "number": "4.10.7.7",
  "title": "",
  "body": "  Compute the matrix exponential for .        "
},
{
  "id": "sec-matexp-8-9",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-9",
  "type": "Exercise",
  "number": "4.10.7.8",
  "title": "",
  "body": "  Suppose . Show that under this assumption, .    Hint: Consider the equation . Show that both of the above solve this equation using that if then commutes with and vice versa.   "
},
{
  "id": "sec-matexp-8-10",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-10",
  "type": "Exercise",
  "number": "4.10.7.9",
  "title": "",
  "body": "  Use to show that . In particular this means that is invertible even if is not.    Hint: commutes with .   "
},
{
  "id": "sec-matexp-8-11",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-11",
  "type": "Exercise",
  "number": "4.10.7.10",
  "title": "",
  "body": "  Let be a matrix with eigenvalues , , and corresponding eigenvectors , .   Find matrix with these properties. Find a fundamental matrix solution to . Solve the system in with initial conditions .    a)  b)  c)     "
},
{
  "id": "sec-matexp-8-12",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-12",
  "type": "Exercise",
  "number": "4.10.7.11",
  "title": "",
  "body": "  Suppose that is an matrix with a repeated eigenvalue of multiplicity . Suppose that there are linearly independent eigenvectors. Show that the matrix is diagonal, in particular . Hint: Use diagonalization and the fact that the identity matrix commutes with every other matrix.    Hint: If there are linearly independent eigenvectors, then it can be diagonalized. What does look like?   "
},
{
  "id": "sec-matexp-8-13",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-13",
  "type": "Exercise",
  "number": "4.10.7.12",
  "title": "",
  "body": "  Let .   (2) Find . Solve , .    a)  b)     "
},
{
  "id": "sec-matexp-8-14",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-14",
  "type": "Exercise",
  "number": "4.10.7.13",
  "title": "",
  "body": "  Let . Approximate by expanding the power series up to the third order.        "
},
{
  "id": "sec-matexp-8-15",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-15",
  "type": "Exercise",
  "number": "4.10.7.14",
  "title": "",
  "body": "  Compute the first 3 terms (up to the second degree) of the Taylor expansion of where (Write as a single matrix). Then use it to approximate .   "
},
{
  "id": "sec-matexp-8-16",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-16",
  "type": "Exercise",
  "number": "4.10.7.15",
  "title": "",
  "body": "  For any positive integer , find a formula (or a recipe) for for the following matrices:   (4)        a)  b)  c)  , , for all d)     "
},
{
  "id": "sec-matexp-8-17",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-17",
  "type": "Exercise",
  "number": "4.10.7.16",
  "title": "",
  "body": "  For any positive integer , find a formula (or a recipe) for for the following matrices:   (3)      "
},
{
  "id": "sec-matexp-8-18",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-18",
  "type": "Exercise",
  "number": "4.10.7.17",
  "title": "",
  "body": "  Solve the initial value problem using matrix exponentials.        "
},
{
  "id": "sec-matexp-8-19",
  "level": "2",
  "url": "sec-matexp.html#sec-matexp-8-19",
  "type": "Exercise",
  "number": "4.10.7.18",
  "title": "",
  "body": "  Solve the initial value problem using matrix exponentials.        "
},
{
  "id": "linearization-section",
  "level": "1",
  "url": "linearization-section.html",
  "type": "Section",
  "number": "5.1",
  "title": "Linearization, critical points, and stability",
  "body": " Linearization, critical points, and stability   Except for a few brief detours in , we considered mostly linear equations. Linear equations suffice in many applications, but in reality most phenomena require nonlinear equations. Nonlinear equations, however, are notoriously more difficult to understand than linear ones, and many strange new phenomena appear when we allow our equations to be nonlinear.  Not to worry, we did not waste all this time studying linear equations. Nonlinear equations can often be approximated by linear ones if we only need a solution for example, only for a short period of time, or only for certain parameters. Understanding specific linear equations can also give us qualitative understanding about a more general nonlinear problem. The idea is similar to what you did in calculus in trying to approximate a function by a line with the right slope.   1.45in1.75in  In we looked at the pendulum of length . The goal was to solve for the angle as a function of the time . The equation for the setup is the nonlinear equation Instead of solving this equation, we solved the rather easier linear equation While the solution to the linear equation is not exactly what we were looking for, it is rather close to the original, as long as the angle is small and the time period involved is short.  You might ask: Why don’t we just solve the nonlinear problem? Well, it might be very difficult, impractical, or impossible to solve analytically, depending on the equation in question. We may not even be interested in the actual solution, we might only be interested in some qualitative idea of what the solution is doing. For example, what happens as time goes to infinity?    Autonomous systems and phase plane analysis  We restrict our attention to a two-dimensional autonomous system where and are functions of two variables, and the derivatives are taken with respect to time . Solutions are functions and such that The way we will analyze the system is very similar to , where we studied a single autonomous equation. The ideas in two dimensions are the same, but the behavior can be far more complicated.  It may be best to think of the system of equations as the single vector equation As in we draw the (or ), where each point corresponds to a specific state of the system. We draw the given at each point by the vector . And as before if we find solutions, we draw the trajectories by plotting all points for a certain range of .      Consider the second order equation . Write this equation as a first order nonlinear system The phase portrait with some trajectories is drawn in .    From the phase portrait it should be clear that even this simple system has fairly complicated behavior. Some trajectories keep oscillating around the origin, and some go off towards infinity. We will return to this example often, and analyze it completely in this (and the next) section.    If we zoom into the diagram near a point where is not zero, then nearby the arrows point generally in essentially that same direction and have essentially the same magnitude. In other words the behavior is not that interesting near such a point. We are of course assuming that and are continuous.  Let us concentrate on those points in the phase diagram above where the trajectories seem to start, end, or go around. We see two such points: and . The trajectories seem to go around the point , and they seem to either go in or out of the point . These points are precisely those points where the derivatives of both and are zero.   The critical points of a system of differential equations are the points such that In other words, these are the points where both and .  The critical points are where the behavior of the system is in some sense the most complicated. If is zero, then nearby, the vector can point in any direction whatsoever. Also, the trajectories are either going towards, away from, or around these points, so if we are looking for long-term qualitative behavior of the system, we should look at what is happening near the critical points.  Critical points are also sometimes called equilibria , since we have so-called equilibrium solutions at critical points. If is a critical point, then we have the solutions In , there are two equilibrium solutions: The discussion here should seem a bit familiar; it is the same as how we formulated equilibrium solutions to autonomous differential equations in in .    Linearization  How do linear systems fit into this approach? For a linear, homogeneous system of two variables defined by where is an invertible matrix, the only critical point is the origin . Since is invertible, the only vector that satisfies is , see . (This also applies beyond two variables, but we’ll stick to that for simplicity.) In we studied the behavior of a homogeneous linear system of two equations near a critical point. Let us put the understanding we gained in that section to good use understanding what happens near critical points of nonlinear systems.  In calculus we learned to estimate a function by taking its derivative and linearizing. We work similarly with nonlinear systems of ODE. Suppose is a critical point. In order to linearize the system of differential equations, we want to linearize the two functions and that define this system. To do so, we will replace and by the tangent plane approximation to the functions. That is, if we set , the tangent plane is given by Since is a critical point, we know that , so the tangent plane is given by Similarly, the tangent plane for near the critical point is given by   The idea of linearization in calculus was that we could use the tangent line or tangent plane to approximate a function near to a given point. For systems of differential equations, the idea is that we can approximate the solutions to the system of differential equations by the solutions to the linearized systems as long as we stay near the critical point. That means that we can approximate the solution to near the critical point by the solution to the system   Next, change variables to , so that corresponds to . That is, which is not going to affect our differential equations because and are constant.  Since and , we can rewrite the approximation system as   In multivariable calculus you may have seen that the several variables version of the derivative is the  Named for the German mathematician Carl Gustav Jacob Jacobi (1804–1851). . The Jacobian matrix of the vector-valued function at is This matrix gives the best linear approximation as and (and therefore and ) vary.   The of the equation as the linear system       Determine the linearization of the system of differential equations in : , at all of its critical points.    There are two critical points, and . The Jacobian matrix at any point is Therefore at , we have and , and the linearization is   At the point , we have and , and the linearization is   The phase diagrams of the two linearizations at the point and are given in . Note that the variables are now and . Compare with , and look especially at the behavior near the critical points.        Isolated critical points and almost linear systems  The next step in this process is to try to figure out a way to analyze what is happening to a non-linear system of differential equations near equilibrium solutions without using a slope field\/phase portrait. We would like to be able to determine this from the equations alone, not any of the pictures that come from them. Thankfully, our ability to analyze linear systems helps us accomplish this goal.   A critical point is isolated if it is the only critical point in some small of the point.  That is, if we zoom in far enough it is the only critical point we see. In the example above, the critical point was isolated. If on the other hand there would be a whole curve of critical points, then it would not be isolated. For example, the system has the entire line as critical points. Therefore, these are not isolated.   A system is called at a critical point , if the critical point is isolated and the Jacobian matrix at the point is invertible, or equivalently if the linearized system has an isolated critical point.  This is also equivalent to zero not being an eigenvalue of the Jacobian matrix at the critical point. In such a case, the nonlinear terms are very small and the system behaves like its linearization, at least if we are close to the critical point.  For example, the system in Examples  and has two isolated critical points and , and is almost linear at both critical points as the Jacobian matrices at both points, and , are invertible.  On the other hand, the system , has an isolated critical point at , however the Jacobian matrix is zero when . So the system is not almost linear. Even a worse example is the system , , which does not have isolated critical points; and are both zero whenever , that is, the entire -axis.  Fortunately, most often critical points are isolated, and the system is almost linear at the critical points. So if we learn what happens there, we will have figured out the majority of situations that arise in applications.    Stability and classification of isolated critical points  Once we have an isolated critical point, the system is almost linear at that critical point, and we computed the associated linearized system, we can classify what happens to the solutions. The classifications for linear two-variable systems from are generally the same as what we use here, with one minor caveat. Let us list the behaviors depending on the eigenvalues of the Jacobian matrix at the critical point in . This table is very similar to , with the exception of missing points. The repeated eigenvalue cases are also missing. They behave similarly to the real eigenvalue descriptions in the table below, but similar to centers, the behavior can change slightly. It can behave like either a spiral or a node, but will be either a source or sink based on the sign of the repeated eigenvalue. We will discuss centers later, as they are more complicated.     Behavior of an almost linear system near an isolated critical point.    Eigenvalues of the Jacobian matrix  Behavior  Stability    real and both positive  source \/ unstable node  unstable    real and both negative  sink \/ stable node  asymptotically stable    real and opposite signs  saddle  unstable    complex with positive real part  spiral source  unstable    complex with negative real part  spiral sink  asymptotically stable     In the third column, we mark points as asymptotically stable or unstable .   Let be a critical point for a non-linear system of two differential equations.     We say that the critical point is a if, given any small distance to , and any initial condition within a perhaps smaller radius around , the trajectory of the system never goes further away from than .    The critical point is an if it is not stable; that is, there are trajectories that start within a distance of and end up farther than from that point.    The critical point is called if given any initial condition sufficiently close to and any solution satisfying that condition, then      Informally, a point is stable if we start close to a critical point and follow a trajectory we either go towards, or at least not away from, this critical point. If the point is asymptotically stable, then any trajectory for a sufficiently close initial condition goes towards the critical point , and unstable means that, in general, trajectories move away from the critical point.      Find and analyze the critical points of , .    See for the phase diagram. Let us find the critical points. These are the points where and . The first equation means , and so . Plugging into the second equation we obtain . Factoring we obtain . Since we are looking only for real solutions we get either or . Solving for the corresponding using , we get two critical points, one being and the other being . Clearly the critical points are isolated.    Let us compute the Jacobian matrix: At the point we get the matrix and so the two eigenvalues are and . As the matrix is invertible, the system is almost linear at . As the eigenvalues are real and of opposite signs, we get a saddle point, which is an unstable equilibrium point. Looking at the phase portrait, we can see trajectories that would start near and end up farther away from . These trajectories may end up at , but that is away from .  At the point we get the matrix and computing the eigenvalues we get , . The matrix is invertible, and so the system is almost linear at . As we have real eigenvalues and both negative, the critical point is a sink, and therefore an asymptotically stable equilibrium point. That is, if we start with any point close to as an initial condition and plot a trajectory, it approaches . In other words, As you can see from the diagram, this behavior is true even for some initial points quite far from , but it is definitely not true for all initial points.        Find and analyze the critical points of , .    First let us find the critical points. These are the points where and . Simplifying we get . So the critical points are and , and hence are isolated. Let us compute the Jacobian matrix:   At the point we get the matrix and so the two eigenvalues are and . As the matrix is invertible, the system is almost linear at . And, as the eigenvalues are real and of opposite signs, we get a saddle point, which is an unstable equilibrium point.  At the point we get the matrix whose eigenvalues are . The matrix is invertible, and so the system is almost linear at . As we have complex eigenvalues with positive real part, the critical point is a spiral source, and therefore an unstable equilibrium point.    See for the phase diagram. Notice the two critical points, and the behavior of the arrows in the vector field around these points.      The trouble with centers  Recall, a linear system with a center means that trajectories travel in closed elliptical orbits in some direction around the critical point. Such a critical point we call a or a . It is not an asymptotically stable critical point, as the trajectories never approach the critical point, but at least if you start sufficiently close to the critical point, you stay close to the critical point. The simplest example of such behavior is the linear system with a center. Another example is the critical point in .  The trouble with a center in a nonlinear system is that whether the trajectory goes towards or away from the critical point is governed by the sign of the real part of the eigenvalues of the Jacobian matrix, and the Jacobian matrix in a nonlinear system changes from point to point. Since this real part is zero at the critical point itself, it can have either sign nearby, meaning the trajectory could be pulled towards or away from the critical point.      Find and analyze the critical point(s) of .    The only critical point is the origin . The Jacobian matrix is At the Jacobian matrix is , which has eigenvalues . So the linearization has a center.  Using the quadratic equation, the eigenvalues of the Jacobian matrix at any point are At any point where (so at most points near the origin), the eigenvalues have a positive real part ( can never be negative). This positive real part pulls the trajectory away from the origin. A sample trajectory for an initial condition near the origin is given in .      The same process could be carried out with the system . This one will also have a center as the linearization at the origin, but the non-linear system will have a spiral sink at the origin. The moral of the example is that further analysis is needed when the linearization has a center. The analysis will in general be more complicated than in the example above, and is more likely to involve case-by-case consideration. Such a complication should not be surprising to you. By now in your mathematical career, you have seen many places where a simple test is inconclusive, recall for example the second derivative test for maxima or minima, and requires more careful, and perhaps ad hoc analysis of the situation.    Exercises    Sketch the phase plane vector field for:   (3) , , , , , .    a)       image   b)     image   c)     image      Match systems to the vector fields below. Justify.   (3)    image     image     image     a)  (ii) b) (i) c) (iii)      Match systems to the vector fields below. Justify.   (3)    image     image     image       Find the critical points and linearizations of the following systems.   (2) , , , , , .    a)  Critical points: . At , linearization matrix is . At , linearization matrix is . At , linearization matrix is . At , linearization matrix is . b) Critical point: , linearization matrix c) Critical points: and . At , linearization matrix is . At , linearization matrix is .      Find the critical points and linearizations of the following systems.   (2) , , , , , .      For the following systems, verify they have critical point at , and find the linearization at .   (2) ,  ,  , , where , , and all first partial derivatives of and are also zero at , that is, .    a)  b)  c)  .      Take the system ,   .   Find all critical points. Determine the linearization of this system around each of the critical points. For each of the critical points, determine the behavior and classify the type of solution that the linearized system will have around that critical point.     , , Nodal sink.  , , Saddle.   , , Saddle.  , , Nodal source.      Take the system ,   .   Find all critical points. Determine the linearization of this system around each of the critical points. For each of the critical points, determine the behavior and classify the type of solution that the linearized system will have around that critical point.     , , Nodal sink.  , , Nodal source.  , , Saddle.  , , Nodal Source.  , , Saddle.  , , Saddle.      Take , .   Find the set of critical points. Sketch a phase diagram and describe the behavior near the critical point(s). Find the linearization. Is it helpful in understanding the system?    a) (0,0) b) Solutions move away from 0, generally above the line c) No. Linearization is 0.      Take , .   Find the set of critical points. Sketch a phase diagram and describe the behavior near the critical point(s). Find the linearization. Is it helpful in understanding the system?    a)  for any . b) Generally curving upward as gets bigger c) No. Linearization is zero at any critical point.       The idea of critical points and linearization works in higher dimensions as well. You simply make the Jacobian matrix bigger by adding more functions and more variables. For the following system of 3 equations find the critical points and their linearizations:       Any two-dimensional non-autonomous system , can be written as a three-dimensional autonomous system (three equations). Write down this autonomous system using the variables , , .      For the systems below, find and classify the critical points, also indicate if the equilibria are stable, asymptotically stable, or unstable.   (2)  ,  ,     a)  nodal sink, asymptotically stable. saddle, unstable. b)  saddle, unstable. center, unknown, maybe stable. c)  spiral source, unstable.      For the systems below, find and classify the critical points.   (3) ,  ,  ,       Find and classify all critical points of the system      , improper nodal source, unstable. , saddle, unstable.      Find and classify all critical points of the system      , improper nodal sink, asymptotically stable. , spiral sink, asymptotically stable. , saddle, unstable. , nodal source, unstable.      Find and classify the critical point(s) of , .     Unstable. Everything moves downward, so if either component is negative, the solution converges away from .       Suppose , .   Show there are two spiral sinks at and . For any initial point of the form , find the trajectory. Can a trajectory starting at where spiral into the critical point at ? Why or why not?    b) The solution will converge (exponentially) to . c)  No, it can not cross another solution curve.      In the example , show that for any trajectory, the distance from the origin is an increasing function. Conclude that the origin behaves like is a spiral source. Hint: Consider and show it has positive derivative.           Find and analyze all critical points of the system , . Use the ideas from to show that the solutions to this problem move towards the origin as grows.           Derive an analogous classification of critical points for equations in one dimension, such as based on the derivative. A point is critical when and almost linear if in addition . Figure out if the critical point is stable or unstable depending on the sign of . Explain. Hint: see .     "
},
{
  "id": "autonomous-systems-and-phase-plane-analysis-4",
  "level": "2",
  "url": "linearization-section.html#autonomous-systems-and-phase-plane-analysis-4",
  "type": "Example",
  "number": "5.1.1",
  "title": ".",
  "body": "    Consider the second order equation . Write this equation as a first order nonlinear system The phase portrait with some trajectories is drawn in .    From the phase portrait it should be clear that even this simple system has fairly complicated behavior. Some trajectories keep oscillating around the origin, and some go off towards infinity. We will return to this example often, and analyze it completely in this (and the next) section.   "
},
{
  "id": "linearization-9",
  "level": "2",
  "url": "linearization-section.html#linearization-9",
  "type": "Example",
  "number": "5.1.2",
  "title": ".",
  "body": "    Determine the linearization of the system of differential equations in : , at all of its critical points.    There are two critical points, and . The Jacobian matrix at any point is Therefore at , we have and , and the linearization is   At the point , we have and , and the linearization is   The phase diagrams of the two linearizations at the point and are given in . Note that the variables are now and . Compare with , and look especially at the behavior near the critical points.     "
},
{
  "id": "stability-and-classification-of-isolated-critical-points-3",
  "level": "2",
  "url": "linearization-section.html#stability-and-classification-of-isolated-critical-points-3",
  "type": "Table",
  "number": "5.1.3",
  "title": "Behavior of an almost linear system near an isolated critical point.",
  "body": " Behavior of an almost linear system near an isolated critical point.    Eigenvalues of the Jacobian matrix  Behavior  Stability    real and both positive  source \/ unstable node  unstable    real and both negative  sink \/ stable node  asymptotically stable    real and opposite signs  saddle  unstable    complex with positive real part  spiral source  unstable    complex with negative real part  spiral sink  asymptotically stable    "
},
{
  "id": "stability-and-classification-of-isolated-critical-points-8",
  "level": "2",
  "url": "linearization-section.html#stability-and-classification-of-isolated-critical-points-8",
  "type": "Example",
  "number": "5.1.4",
  "title": ".",
  "body": "    Find and analyze the critical points of , .    See for the phase diagram. Let us find the critical points. These are the points where and . The first equation means , and so . Plugging into the second equation we obtain . Factoring we obtain . Since we are looking only for real solutions we get either or . Solving for the corresponding using , we get two critical points, one being and the other being . Clearly the critical points are isolated.    Let us compute the Jacobian matrix: At the point we get the matrix and so the two eigenvalues are and . As the matrix is invertible, the system is almost linear at . As the eigenvalues are real and of opposite signs, we get a saddle point, which is an unstable equilibrium point. Looking at the phase portrait, we can see trajectories that would start near and end up farther away from . These trajectories may end up at , but that is away from .  At the point we get the matrix and computing the eigenvalues we get , . The matrix is invertible, and so the system is almost linear at . As we have real eigenvalues and both negative, the critical point is a sink, and therefore an asymptotically stable equilibrium point. That is, if we start with any point close to as an initial condition and plot a trajectory, it approaches . In other words, As you can see from the diagram, this behavior is true even for some initial points quite far from , but it is definitely not true for all initial points.   "
},
{
  "id": "stability-and-classification-of-isolated-critical-points-9",
  "level": "2",
  "url": "linearization-section.html#stability-and-classification-of-isolated-critical-points-9",
  "type": "Example",
  "number": "5.1.5",
  "title": ".",
  "body": "    Find and analyze the critical points of , .    First let us find the critical points. These are the points where and . Simplifying we get . So the critical points are and , and hence are isolated. Let us compute the Jacobian matrix:   At the point we get the matrix and so the two eigenvalues are and . As the matrix is invertible, the system is almost linear at . And, as the eigenvalues are real and of opposite signs, we get a saddle point, which is an unstable equilibrium point.  At the point we get the matrix whose eigenvalues are . The matrix is invertible, and so the system is almost linear at . As we have complex eigenvalues with positive real part, the critical point is a spiral source, and therefore an unstable equilibrium point.    See for the phase diagram. Notice the two critical points, and the behavior of the arrows in the vector field around these points.   "
},
{
  "id": "the-trouble-with-centers-4",
  "level": "2",
  "url": "linearization-section.html#the-trouble-with-centers-4",
  "type": "Example",
  "number": "5.1.6",
  "title": ".",
  "body": "    Find and analyze the critical point(s) of .    The only critical point is the origin . The Jacobian matrix is At the Jacobian matrix is , which has eigenvalues . So the linearization has a center.  Using the quadratic equation, the eigenvalues of the Jacobian matrix at any point are At any point where (so at most points near the origin), the eigenvalues have a positive real part ( can never be negative). This positive real part pulls the trajectory away from the origin. A sample trajectory for an initial condition near the origin is given in .     "
},
{
  "id": "linearization-section-8-2",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-2",
  "type": "Exercise",
  "number": "5.1.6.1",
  "title": "",
  "body": "  Sketch the phase plane vector field for:   (3) , , , , , .    a)    "
},
{
  "id": "linearization-section-8-3",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-3",
  "type": "Figure",
  "number": "5.1.7",
  "title": "",
  "body": "  image  "
},
{
  "id": "linearization-section-8-5",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-5",
  "type": "Figure",
  "number": "5.1.8",
  "title": "",
  "body": "  image  "
},
{
  "id": "linearization-section-8-7",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-7",
  "type": "Figure",
  "number": "5.1.9",
  "title": "",
  "body": "  image  "
},
{
  "id": "linearization-section-8-8",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-8",
  "type": "Exercise",
  "number": "5.1.6.2",
  "title": "",
  "body": "  Match systems to the vector fields below. Justify.   (3)    image     image     image     a)  (ii) b) (i) c) (iii)   "
},
{
  "id": "linearization-section-8-9",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-9",
  "type": "Exercise",
  "number": "5.1.6.3",
  "title": "",
  "body": "  Match systems to the vector fields below. Justify.   (3)    image     image     image    "
},
{
  "id": "linearization-section-8-10",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-10",
  "type": "Exercise",
  "number": "5.1.6.4",
  "title": "",
  "body": "  Find the critical points and linearizations of the following systems.   (2) , , , , , .    a)  Critical points: . At , linearization matrix is . At , linearization matrix is . At , linearization matrix is . At , linearization matrix is . b) Critical point: , linearization matrix c) Critical points: and . At , linearization matrix is . At , linearization matrix is .   "
},
{
  "id": "linearization-section-8-11",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-11",
  "type": "Exercise",
  "number": "5.1.6.5",
  "title": "",
  "body": "  Find the critical points and linearizations of the following systems.   (2) , , , , , .   "
},
{
  "id": "linearization-section-8-12",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-12",
  "type": "Exercise",
  "number": "5.1.6.6",
  "title": "",
  "body": "  For the following systems, verify they have critical point at , and find the linearization at .   (2) ,  ,  , , where , , and all first partial derivatives of and are also zero at , that is, .    a)  b)  c)  .   "
},
{
  "id": "linearization-section-8-13",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-13",
  "type": "Exercise",
  "number": "5.1.6.7",
  "title": "",
  "body": "  Take the system ,   .   Find all critical points. Determine the linearization of this system around each of the critical points. For each of the critical points, determine the behavior and classify the type of solution that the linearized system will have around that critical point.     , , Nodal sink.  , , Saddle.   , , Saddle.  , , Nodal source.   "
},
{
  "id": "linearization-section-8-14",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-14",
  "type": "Exercise",
  "number": "5.1.6.8",
  "title": "",
  "body": "  Take the system ,   .   Find all critical points. Determine the linearization of this system around each of the critical points. For each of the critical points, determine the behavior and classify the type of solution that the linearized system will have around that critical point.     , , Nodal sink.  , , Nodal source.  , , Saddle.  , , Nodal Source.  , , Saddle.  , , Saddle.   "
},
{
  "id": "linearization-section-8-15",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-15",
  "type": "Exercise",
  "number": "5.1.6.9",
  "title": "",
  "body": "  Take , .   Find the set of critical points. Sketch a phase diagram and describe the behavior near the critical point(s). Find the linearization. Is it helpful in understanding the system?    a) (0,0) b) Solutions move away from 0, generally above the line c) No. Linearization is 0.   "
},
{
  "id": "linearization-section-8-16",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-16",
  "type": "Exercise",
  "number": "5.1.6.10",
  "title": "",
  "body": "  Take , .   Find the set of critical points. Sketch a phase diagram and describe the behavior near the critical point(s). Find the linearization. Is it helpful in understanding the system?    a)  for any . b) Generally curving upward as gets bigger c) No. Linearization is zero at any critical point.   "
},
{
  "id": "linearization-section-8-17",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-17",
  "type": "Exercise",
  "number": "5.1.6.11",
  "title": "",
  "body": "  The idea of critical points and linearization works in higher dimensions as well. You simply make the Jacobian matrix bigger by adding more functions and more variables. For the following system of 3 equations find the critical points and their linearizations:    "
},
{
  "id": "linearization-section-8-18",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-18",
  "type": "Exercise",
  "number": "5.1.6.12",
  "title": "",
  "body": "  Any two-dimensional non-autonomous system , can be written as a three-dimensional autonomous system (three equations). Write down this autonomous system using the variables , , .   "
},
{
  "id": "linearization-section-8-19",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-19",
  "type": "Exercise",
  "number": "5.1.6.13",
  "title": "",
  "body": "  For the systems below, find and classify the critical points, also indicate if the equilibria are stable, asymptotically stable, or unstable.   (2)  ,  ,     a)  nodal sink, asymptotically stable. saddle, unstable. b)  saddle, unstable. center, unknown, maybe stable. c)  spiral source, unstable.   "
},
{
  "id": "linearization-section-8-20",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-20",
  "type": "Exercise",
  "number": "5.1.6.14",
  "title": "",
  "body": "  For the systems below, find and classify the critical points.   (3) ,  ,  ,    "
},
{
  "id": "linearization-section-8-21",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-21",
  "type": "Exercise",
  "number": "5.1.6.15",
  "title": "",
  "body": "  Find and classify all critical points of the system      , improper nodal source, unstable. , saddle, unstable.   "
},
{
  "id": "linearization-section-8-22",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-22",
  "type": "Exercise",
  "number": "5.1.6.16",
  "title": "",
  "body": "  Find and classify all critical points of the system      , improper nodal sink, asymptotically stable. , spiral sink, asymptotically stable. , saddle, unstable. , nodal source, unstable.   "
},
{
  "id": "linearization-section-8-23",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-23",
  "type": "Exercise",
  "number": "5.1.6.17",
  "title": "",
  "body": "  Find and classify the critical point(s) of , .     Unstable. Everything moves downward, so if either component is negative, the solution converges away from .   "
},
{
  "id": "linearization-section-8-24",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-24",
  "type": "Exercise",
  "number": "5.1.6.18",
  "title": "",
  "body": "  Suppose , .   Show there are two spiral sinks at and . For any initial point of the form , find the trajectory. Can a trajectory starting at where spiral into the critical point at ? Why or why not?    b) The solution will converge (exponentially) to . c)  No, it can not cross another solution curve.   "
},
{
  "id": "linearization-section-8-25",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-25",
  "type": "Exercise",
  "number": "5.1.6.19",
  "title": "",
  "body": "  In the example , show that for any trajectory, the distance from the origin is an increasing function. Conclude that the origin behaves like is a spiral source. Hint: Consider and show it has positive derivative.        "
},
{
  "id": "linearization-section-8-26",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-26",
  "type": "Exercise",
  "number": "5.1.6.20",
  "title": "",
  "body": "  Find and analyze all critical points of the system , . Use the ideas from to show that the solutions to this problem move towards the origin as grows.        "
},
{
  "id": "linearization-section-8-27",
  "level": "2",
  "url": "linearization-section.html#linearization-section-8-27",
  "type": "Exercise",
  "number": "5.1.6.21",
  "title": "",
  "body": "  Derive an analogous classification of critical points for equations in one dimension, such as based on the derivative. A point is critical when and almost linear if in addition . Figure out if the critical point is stable or unstable depending on the sign of . Explain. Hint: see .   "
},
{
  "id": "nlinHamiltonian-section",
  "level": "1",
  "url": "nlinHamiltonian-section.html",
  "type": "Section",
  "number": "5.2",
  "title": "Behavior of non-linear systems",
  "body": " Behavior of non-linear systems   Conservative equations  An equation of the form for an arbitrary function is called a . For example the pendulum equation is a conservative equation. The equations are conservative as there is no friction in the system so the energy in the system is Let us write this equation as a system of nonlinear ODE. These types of equations have the advantage that we can solve for their trajectories easily.   Assume that we have an autonomous system of differential equations defining and , A for this system is a curve in the -plane that the solution curve will stay on for all . This curve will generally be given with as a function of , or the level curve of some function .  For conservative equations, we want to first think of as a function of for a moment. Then use the chain rule where the prime indicates a derivative with respect to . We obtain . We integrate with respect to to get . In other words We obtained an implicit equation for the trajectories, with different giving different trajectories. The value of is conserved on any trajectory. This expression is sometimes called the or the energy of the system. If you look back to , you will notice that is an exact equation, and we just found a potential function.  Another approach we could use in this case is separable equations, if it works out. The idea is that we have the system and want to develop a differential equation for in terms of . We can write this differential equation using some principles from implicit differentiation and parametric equations as which, for this case, is This equation is separable as and we can get to the same implicit equation for the trajectories as before.      Find the trajectories for the equation , which is the equation from .    The corresponding first order system is Trajectories satisfy We solve for    Plotting these graphs we get exactly the trajectories in . In particular we notice that near the origin the trajectories are : they keep going around the origin, never spiraling in or out. Therefore we discovered a way to verify that the critical point at is a stable center. The critical point at is a saddle as we already noticed. This example is typical for conservative equations.    Consider an arbitrary conservative equation . All critical points occur when (the -axis), that is when . The critical points are those points on the -axis where . The trajectories are given by So all trajectories are mirrored across the -axis. In particular, there can be no spiral sources nor sinks. The Jacobian matrix is The critical point is almost linear if at the critical point. Let denote the Jacobian matrix. The eigenvalues of are solutions to Therefore . In other words, either we get real eigenvalues of opposite signs (if ), or we get purely imaginary eigenvalues (if ). There are only two possibilities for critical points, either an unstable saddle point , or a stable center . There are never any sinks or sources.    Hamiltonian Systems  A generalization of conservative equations to systems is a system. This type of system has all of the nice properties of conservative equations when converted into systems, but allows for more general interactions between and . For these systems, the point is that the equation has a conserved quantity called a Hamiltonian, which does not change as the system evolves in time, which generally represents the energy of the system. Calling this function , this means that By the chain rule, this is equivalent to   One way to satisfy this is with   and this gives the definition of a Hamiltonian system .   The system is Hamiltonian if there is a function so that and .  For solving these sorts of systems, we know that since that’s how we defined the system. This means that the trajectories of this system are given by for a constant determined by initial conditions. So if we can find the function that expresses the system in the form , then we are done.  Finding this is a lot similar to finding solutions to exact equations in . First, we need to determine if the system is Hamiltonian. Since we want to have that we know that which shows that This is what we can use to check if a system is Hamiltonian; compare to Theorem for exact equations.  Once we know that a system is Hamiltonian, we can integrate the different components of the equation to find the function . Since , then we can write where is an unknown function, which can be determined by differentiating this in and setting equal to .      Consider the system of differential equations given by Determine if this system is Hamiltonian and, if so, find the trajectories of the solution.    We first check if to see if the system is Hamiltonian. Since and , this means we have a Hamiltonian system. In order to find the function , we use that Integrating both sides in gives that for an unknown function . Differentiating this in gives which we want to equal . This gives that so . Thus, the Hamiltonian is given by so that the trajectories are defined by for any constant . These are sketched in .    Note that this system is linear and autonomous. Therefore, we could have solved this using those methods as well. For this, we have the coefficient matrix and we can find the eigenvalues of this matrix as the roots of whose roots are which have opposite signs. Therefore, this will be a saddle point, which we see represented in the plot in .      Separatrices and Basins of Attractions  If we have an asymptotically stable critical point for an autonomous system of differential equation, we know that solutions that start near this point will converge to it as . That’s what it means for the point to be asymptotically stable. However, for applications, it may be important to know exactly which initial conditions will end up converging to . This can be particularly relevant when there are multiple asymptotically stable equilibrium solutions and we need to determine which one a given initial condition will converge to.   Let be an asymptotically stable equilibrium solution for the autonomous system . The for is the set of all points where the solution to converges to as .  In general, the basin of attraction for an asymptotically stable critical point is difficult, if not impossible, to find analytically. The main approach here is to use a direction field to approximate the basin of attraction.      Find all asymptotically stable critical points for the autonomous system and determine an approximate basin of attraction for each.    We want to start by finding the critical points for this system, classifying them to determine if they are asymptotically stable, and then use a slope field to try to find the basin of attraction. In order to have a critical point, we need to have both and equal to zero. This means that we need This results in the points , , , and . In order to classify each of these critical points, we need to find the Jacobian matrix for this system, which is and then we want to plug each critical point into this matrix in turn.  Plugging in gives , which has eigenvalues of and , and so is a nodal source, which is unstable. Plugging in gives , which has eigenvalues of and , which is a nodal sink, and so asymptotically stable. Plugging in gives , which has eigenvalues at and , giving an asymptotically stable nodal sink. The last point at gives , which is not triangular, and so does not have easily identifiable eigenvalues. We could use trace-determinant analysis to classify () or we can just compute the eigenvalues. Those are found by the roots of and since the last term is negative, we know we are going to get roots of opposite signs, so this is an unstable saddle point. The actual eigenvalues are   So, this means we have two asymptotically stable critical points, and . We need to look at a slope field to determine the approximate basin of attraction for each of these points.    From , we can see that there is a sort of dividing line between the two nodal sinks. If the solution starts on one side of the line, it funnels into one critical point, and on the other side, it heads to the other one. This dividing line also seems to pass through the saddle point at , which is not a coincidence, as we will see later.    Another interesting feature of these regions is the boundary of them. This is a curve that separates solutions that converge to the asymptotically stable equilibrium solution and those that don’t. This leads to another definition.   Consider the autonomous system . A (plural separatrices) is a curve in the plane that separates trajectories that have different long-term behaviors of solutions to .  The boundary of a basin of attraction is a separatrix because the long-term behavior inside the curve (converging to the asymptotically stable critical point) is different from the behavior outside the curve (going somewhere else). These dividing curves also show up in other contexts.      Analyze the system in the context of separatrices.    This is a linear, homogeneous system, so we can analyze it via that approach. For the coefficient matrix , we have eigenvalues as the roots of , or . Therefore, the eigenvalues here are and . For we have eigenvector and for , an eigenvector is . We can see what this looks like on a slope field in .   3.3in  There are no asymptotically stable critical points here, so there are no basins of attraction. However, there are two distinct behaviors of the solution curve. It is going away from the origin, but it could go to the top left, or to the bottom right. Both of those make sense based on the slope field here. So how do we know which way it goes? The line drawn on the right side of seems to divide these two regions up. If the solution starts above the line, it goes to the top left, otherwise, it goes to the bottom right. This is the separatrix for this saddle point.  But what is that line? If we inspect the graph more closely, the separatrix here is the straight-line solution that converges to zero over time; the one particular solution that does not go off to infinity because it only has the term in it. So the straight-line solutions that flow into saddle points divide what happens on the two sides of it. This is a very common fact in looking at separatrices: if they go through a critical point, they generally do so as the in-flowing solution from a saddle point. All of the examples we have seen so far with separatrices have done exactly this.      Nullclines  When trying to find critical points for a non-linear, autonomous system, we need all (both, in the case of two component systems) of the equations to be zero. What happens if only one of the equations is zero? This is a lot easier to find, and can also give us a fair bit of information.   Consider the autonomous two-component system A for this system is a curve where either or . We can also be more specific and use the term x-nullcline for the curve(s) where and y-nullcline for where .  The way we can use these nullclines is to know in general which direction the solution curve will move in different regions of the plane. Assuming that all of the functions involved are continuous, if we know that the solution at a given point will move to the right, that is, if , then we know that the solution will continue to move to the right until we cross an -nullcline. If the solution starts going back to the left, this means that becomes negative, and so must cross zero, which is where a nullcline is.  In addition, we know that along an -nullcline, , so the solution can only be moving in the direction, that is, vertically. If we can determine in which direction the solution graph will cross the nullclines, this can also be helpful and useful. It doesn’t give as much information as a full slope field or trajectory plot, but it can give a general idea of what is going to happen to the solution over time.      Use a nullcline analysis to determine the overall behavior of solutions to the system     We can get the equations for nullclines from the factors of each of the differential equations here. For -nullclines, we get and , and for -nullclines, we get and . Once we have these lines, we need to determine what happens within each of the regions on the resulting graph. For example, if we look in the region above , above and right of , we can plug in, for example . At this point and . Therefore, the solution here moves up and to the left. We can fill in all of the other regions in a similar manner. This is shown on the left of .    Based on the nullcline diagram here, we can see that there seems to be some sort of spiraling behavior around both and , which we know are critical points because the two different nullclines intersect there. From this alone, we can’t really tell if they are sources, sinks, or centers, but we do get a general idea of the behavior. We also see what looks like saddles at and , since these critical points have two opposite arrows pointing towards this point (corresponding to the negative eigenvalue of the linearized system), and two opposite arrows pointing away from the point (corresponding to the positive eigenvalue. The slope field seems to validate all of these general discussions from the nullcline diagram.        Use a nullcline analysis to determine the overall behavior of solutions to the system     As with the previous example, we can find the nullcline equations from the factors above. The -nullclines are at and , and the -nullclines are at and . We can plug in points to fill in the nullcline diagram like before, and compare to the slope field, shown in .    In this diagram, we see some of the other types of critical points and what they look like through nullclines. The point at looks like a nodal source, because all of the arrows point away from that point, and looks like a nodal source. Finally, we see a potential saddle at because of the patterns of the arrows, all of which are also shown in the slope field for this system.  An extra point with this type of result is that we know we can not cross the nullclines at and . For instance, the line is an -nullcline. This means that the solution must cross the line moving vertically. However, it is a vertical line, and there is no way to cross a vertical line moving vertically. The same argument applies to . We can also see this by the fact that the arrows on either side of the line both point into or away from these nullclines.      Exercises    Find the implicit equations of the trajectories of the following conservative systems. Next find their critical points (if any) and classify them.   (2)        a)  . is a center. b)  . is a saddle if is even, and a center if is odd. c)  , is a center, is a saddle. d)  , no critical points.      Find the implicit equations of the trajectories of the following conservative systems. Next find their critical points (if any) and classify them.   (3)         The conservative system is not almost linear. Classify its critical point(s) nonetheless.      Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.            Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.     No      Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.            Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories. Afterwards, do the same but with the system noticing that this is the same as the first system with each equation divided by .    First is not Hamiltonian. Second is with .      Consider a generic thing on a spring, with displacement and velocity . Assume that where and are some positive constants.   Rewrite this equation as a first-order system in and . Find a Hamiltonian function for this system (in terms of and ). What shapes are the level curves of the Hamiltonian function? Does this system have a basin of attraction ? Explain briefly.    a)  , b)  c)  Ellipses d)  No      Suppose is always positive. Find the trajectories of . Are there any critical points?    No.      Suppose that , . Suppose that for all and . Are there any critical points? What can we say about the trajectories at goes to infinity?    All will have . No critical points.      Here is the direction field for the system . The critical points are , and . Draw the nullclines on the plot. What do the nullclines tell us about the critical points?     image       image     Nullclines apply to linear systems as well, although since we can often solve those explicitly they’re less necessary. Construct the nullcline diagram for the system , , and use it to classify (by type) the equilibrium point at the origin. What is the linearization of this system at ?    Saddle      Consider the system .   Find all equilibrium solutions. Sketch all nullclines for this system on a single diagram. Label each region, and use these results to classify each equilibrium point.     and .      Nullclines need not be lines. Consider the system    Find all critical points of this system. Sketch the nullcline diagram and label all regions DL, DR, UL, or UR. Classify (according to type) any critical point(s) that can be classified using this analysis. Two critical points cannot be classified using the nullcline analysis. Classify these (again according to type) using the Jacobian.     2 a)  , , , b)  is a saddle, is a saddle. c)  is a spiral sink, is a spiral source.    image     Consider the system    Find all critical points of . Create the nullcline diagram for the system, labelling each region as one of UL, UR, DL, or DR. Use this information to classify two critical points according to type. Use the Jacobian matrix to classify any remaining critical points. Is there a conserved quantity (Hamiltonian function) for this system? If so, find one. If not, explain why not.     2 a)  , , , b)  is a saddle, is a saddle. c)  is a spiral sink, is a spiral source. d)  No, can not have sources or sinks.    image     For a conflict between two armies, Lanchester’s Law asserts that and , where and are the two populations, and and are some positive constants.   Find a Hamiltonian function for this system satisfying . Classify the critical point at the origin according to type and stability. Assume that we are just looking at the first quadrant, since the populations are non-negative. Find the curve along which the Hamiltonian function is zero, and explain its significance in terms of who wins the conflict.    a)  b) Saddle, these are hyperbolas. c)  , dividing line deciding who wins      Consider the non-linear system     has a critical point at the origin. What is the linearization of at the origin? Demonstrate that is locally linear in a neighborhood of the origin. Classify the origin according to its type and stability .    a) Spiral Source b) Matrix is invertible c) Unstable spiral source      Consider the system of differential equations which has slope field sketched below.     image    Find and classify all critical points of the system . Draw any separatrices that you can spot on the slope field. Do any of these critical points have a basin of attraction? If so, sketch out what regions of the plane correspond to a basin of attraction for those critical points.     2 Nodal sink, Nodal source, Nodal source, Nodal sink, Saddle. c)  Yes, bottom right goes to , top left goes to .    image     Consider the system of differential equations which has slope field sketched below.     image    Find and classify all critical points of the system . Draw any separatrices that you can spot on the slope field. Do any of these critical points have a basin of attraction? If so, sketch out what regions of the plane correspond to a basin of attraction for those critical points.     2 saddle, saddle, saddle, saddle, nodal source. c)  No.    image    "
},
{
  "id": "conservative-equations-6",
  "level": "2",
  "url": "nlinHamiltonian-section.html#conservative-equations-6",
  "type": "Example",
  "number": "5.2.1",
  "title": ".",
  "body": "    Find the trajectories for the equation , which is the equation from .    The corresponding first order system is Trajectories satisfy We solve for    Plotting these graphs we get exactly the trajectories in . In particular we notice that near the origin the trajectories are : they keep going around the origin, never spiraling in or out. Therefore we discovered a way to verify that the critical point at is a stable center. The critical point at is a saddle as we already noticed. This example is typical for conservative equations.   "
},
{
  "id": "hamiltonian-systems-9",
  "level": "2",
  "url": "nlinHamiltonian-section.html#hamiltonian-systems-9",
  "type": "Example",
  "number": "5.2.2",
  "title": ".",
  "body": "    Consider the system of differential equations given by Determine if this system is Hamiltonian and, if so, find the trajectories of the solution.    We first check if to see if the system is Hamiltonian. Since and , this means we have a Hamiltonian system. In order to find the function , we use that Integrating both sides in gives that for an unknown function . Differentiating this in gives which we want to equal . This gives that so . Thus, the Hamiltonian is given by so that the trajectories are defined by for any constant . These are sketched in .    Note that this system is linear and autonomous. Therefore, we could have solved this using those methods as well. For this, we have the coefficient matrix and we can find the eigenvalues of this matrix as the roots of whose roots are which have opposite signs. Therefore, this will be a saddle point, which we see represented in the plot in .   "
},
{
  "id": "separatrices-and-basins-of-attractions-5",
  "level": "2",
  "url": "nlinHamiltonian-section.html#separatrices-and-basins-of-attractions-5",
  "type": "Example",
  "number": "5.2.3",
  "title": ".",
  "body": "    Find all asymptotically stable critical points for the autonomous system and determine an approximate basin of attraction for each.    We want to start by finding the critical points for this system, classifying them to determine if they are asymptotically stable, and then use a slope field to try to find the basin of attraction. In order to have a critical point, we need to have both and equal to zero. This means that we need This results in the points , , , and . In order to classify each of these critical points, we need to find the Jacobian matrix for this system, which is and then we want to plug each critical point into this matrix in turn.  Plugging in gives , which has eigenvalues of and , and so is a nodal source, which is unstable. Plugging in gives , which has eigenvalues of and , which is a nodal sink, and so asymptotically stable. Plugging in gives , which has eigenvalues at and , giving an asymptotically stable nodal sink. The last point at gives , which is not triangular, and so does not have easily identifiable eigenvalues. We could use trace-determinant analysis to classify () or we can just compute the eigenvalues. Those are found by the roots of and since the last term is negative, we know we are going to get roots of opposite signs, so this is an unstable saddle point. The actual eigenvalues are   So, this means we have two asymptotically stable critical points, and . We need to look at a slope field to determine the approximate basin of attraction for each of these points.    From , we can see that there is a sort of dividing line between the two nodal sinks. If the solution starts on one side of the line, it funnels into one critical point, and on the other side, it heads to the other one. This dividing line also seems to pass through the saddle point at , which is not a coincidence, as we will see later.   "
},
{
  "id": "separatrices-and-basins-of-attractions-9",
  "level": "2",
  "url": "nlinHamiltonian-section.html#separatrices-and-basins-of-attractions-9",
  "type": "Example",
  "number": "5.2.4",
  "title": ".",
  "body": "    Analyze the system in the context of separatrices.    This is a linear, homogeneous system, so we can analyze it via that approach. For the coefficient matrix , we have eigenvalues as the roots of , or . Therefore, the eigenvalues here are and . For we have eigenvector and for , an eigenvector is . We can see what this looks like on a slope field in .   3.3in  There are no asymptotically stable critical points here, so there are no basins of attraction. However, there are two distinct behaviors of the solution curve. It is going away from the origin, but it could go to the top left, or to the bottom right. Both of those make sense based on the slope field here. So how do we know which way it goes? The line drawn on the right side of seems to divide these two regions up. If the solution starts above the line, it goes to the top left, otherwise, it goes to the bottom right. This is the separatrix for this saddle point.  But what is that line? If we inspect the graph more closely, the separatrix here is the straight-line solution that converges to zero over time; the one particular solution that does not go off to infinity because it only has the term in it. So the straight-line solutions that flow into saddle points divide what happens on the two sides of it. This is a very common fact in looking at separatrices: if they go through a critical point, they generally do so as the in-flowing solution from a saddle point. All of the examples we have seen so far with separatrices have done exactly this.   "
},
{
  "id": "nullclines-6",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nullclines-6",
  "type": "Example",
  "number": "5.2.5",
  "title": ".",
  "body": "    Use a nullcline analysis to determine the overall behavior of solutions to the system     We can get the equations for nullclines from the factors of each of the differential equations here. For -nullclines, we get and , and for -nullclines, we get and . Once we have these lines, we need to determine what happens within each of the regions on the resulting graph. For example, if we look in the region above , above and right of , we can plug in, for example . At this point and . Therefore, the solution here moves up and to the left. We can fill in all of the other regions in a similar manner. This is shown on the left of .    Based on the nullcline diagram here, we can see that there seems to be some sort of spiraling behavior around both and , which we know are critical points because the two different nullclines intersect there. From this alone, we can’t really tell if they are sources, sinks, or centers, but we do get a general idea of the behavior. We also see what looks like saddles at and , since these critical points have two opposite arrows pointing towards this point (corresponding to the negative eigenvalue of the linearized system), and two opposite arrows pointing away from the point (corresponding to the positive eigenvalue. The slope field seems to validate all of these general discussions from the nullcline diagram.   "
},
{
  "id": "nullclines-7",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nullclines-7",
  "type": "Example",
  "number": "5.2.6",
  "title": ".",
  "body": "    Use a nullcline analysis to determine the overall behavior of solutions to the system     As with the previous example, we can find the nullcline equations from the factors above. The -nullclines are at and , and the -nullclines are at and . We can plug in points to fill in the nullcline diagram like before, and compare to the slope field, shown in .    In this diagram, we see some of the other types of critical points and what they look like through nullclines. The point at looks like a nodal source, because all of the arrows point away from that point, and looks like a nodal source. Finally, we see a potential saddle at because of the patterns of the arrows, all of which are also shown in the slope field for this system.  An extra point with this type of result is that we know we can not cross the nullclines at and . For instance, the line is an -nullcline. This means that the solution must cross the line moving vertically. However, it is a vertical line, and there is no way to cross a vertical line moving vertically. The same argument applies to . We can also see this by the fact that the arrows on either side of the line both point into or away from these nullclines.   "
},
{
  "id": "nlinHamiltonian-section-6-2",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-2",
  "type": "Exercise",
  "number": "5.2.5.1",
  "title": "",
  "body": "  Find the implicit equations of the trajectories of the following conservative systems. Next find their critical points (if any) and classify them.   (2)        a)  . is a center. b)  . is a saddle if is even, and a center if is odd. c)  , is a center, is a saddle. d)  , no critical points.   "
},
{
  "id": "nlinHamiltonian-section-6-3",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-3",
  "type": "Exercise",
  "number": "5.2.5.2",
  "title": "",
  "body": "  Find the implicit equations of the trajectories of the following conservative systems. Next find their critical points (if any) and classify them.   (3)      "
},
{
  "id": "nlinHamiltonian-section-6-4",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-4",
  "type": "Exercise",
  "number": "5.2.5.3",
  "title": "",
  "body": "  The conservative system is not almost linear. Classify its critical point(s) nonetheless.   "
},
{
  "id": "nlinHamiltonian-section-6-5",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-5",
  "type": "Exercise",
  "number": "5.2.5.4",
  "title": "",
  "body": "  Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.         "
},
{
  "id": "nlinHamiltonian-section-6-6",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-6",
  "type": "Exercise",
  "number": "5.2.5.5",
  "title": "",
  "body": "  Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.     No   "
},
{
  "id": "nlinHamiltonian-section-6-7",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-7",
  "type": "Exercise",
  "number": "5.2.5.6",
  "title": "",
  "body": "  Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories.         "
},
{
  "id": "nlinHamiltonian-section-6-8",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-8",
  "type": "Exercise",
  "number": "5.2.5.7",
  "title": "",
  "body": "  Determine if the following system is Hamiltonian. If it is, find the general solution in the form and sketch some of the trajectories. Afterwards, do the same but with the system noticing that this is the same as the first system with each equation divided by .    First is not Hamiltonian. Second is with .   "
},
{
  "id": "nlinHamiltonian-section-6-9",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-9",
  "type": "Exercise",
  "number": "5.2.5.8",
  "title": "",
  "body": "  Consider a generic thing on a spring, with displacement and velocity . Assume that where and are some positive constants.   Rewrite this equation as a first-order system in and . Find a Hamiltonian function for this system (in terms of and ). What shapes are the level curves of the Hamiltonian function? Does this system have a basin of attraction ? Explain briefly.    a)  , b)  c)  Ellipses d)  No   "
},
{
  "id": "nlinHamiltonian-section-6-10",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-10",
  "type": "Exercise",
  "number": "5.2.5.9",
  "title": "",
  "body": "  Suppose is always positive. Find the trajectories of . Are there any critical points?    No.   "
},
{
  "id": "nlinHamiltonian-section-6-11",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-11",
  "type": "Exercise",
  "number": "5.2.5.10",
  "title": "",
  "body": "  Suppose that , . Suppose that for all and . Are there any critical points? What can we say about the trajectories at goes to infinity?    All will have . No critical points.   "
},
{
  "id": "nlinHamiltonian-section-6-12",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-12",
  "type": "Exercise",
  "number": "5.2.5.11",
  "title": "",
  "body": "  Here is the direction field for the system . The critical points are , and . Draw the nullclines on the plot. What do the nullclines tell us about the critical points?     image    "
},
{
  "id": "nlinHamiltonian-section-6-13",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-13",
  "type": "Figure",
  "number": "5.2.8",
  "title": "",
  "body": "  image  "
},
{
  "id": "nlinHamiltonian-section-6-14",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-14",
  "type": "Exercise",
  "number": "5.2.5.12",
  "title": "",
  "body": "  Nullclines apply to linear systems as well, although since we can often solve those explicitly they’re less necessary. Construct the nullcline diagram for the system , , and use it to classify (by type) the equilibrium point at the origin. What is the linearization of this system at ?    Saddle   "
},
{
  "id": "nlinHamiltonian-section-6-15",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-15",
  "type": "Exercise",
  "number": "5.2.5.13",
  "title": "",
  "body": "  Consider the system .   Find all equilibrium solutions. Sketch all nullclines for this system on a single diagram. Label each region, and use these results to classify each equilibrium point.     and .   "
},
{
  "id": "nlinHamiltonian-section-6-16",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-16",
  "type": "Exercise",
  "number": "5.2.5.14",
  "title": "",
  "body": "  Nullclines need not be lines. Consider the system    Find all critical points of this system. Sketch the nullcline diagram and label all regions DL, DR, UL, or UR. Classify (according to type) any critical point(s) that can be classified using this analysis. Two critical points cannot be classified using the nullcline analysis. Classify these (again according to type) using the Jacobian.   "
},
{
  "id": "nlinHamiltonian-section-6-18",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-18",
  "type": "Figure",
  "number": "5.2.9",
  "title": "",
  "body": "  image  "
},
{
  "id": "nlinHamiltonian-section-6-19",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-19",
  "type": "Exercise",
  "number": "5.2.5.15",
  "title": "",
  "body": "  Consider the system    Find all critical points of . Create the nullcline diagram for the system, labelling each region as one of UL, UR, DL, or DR. Use this information to classify two critical points according to type. Use the Jacobian matrix to classify any remaining critical points. Is there a conserved quantity (Hamiltonian function) for this system? If so, find one. If not, explain why not.   "
},
{
  "id": "nlinHamiltonian-section-6-21",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-21",
  "type": "Figure",
  "number": "5.2.10",
  "title": "",
  "body": "  image  "
},
{
  "id": "nlinHamiltonian-section-6-22",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-22",
  "type": "Exercise",
  "number": "5.2.5.16",
  "title": "",
  "body": "  For a conflict between two armies, Lanchester’s Law asserts that and , where and are the two populations, and and are some positive constants.   Find a Hamiltonian function for this system satisfying . Classify the critical point at the origin according to type and stability. Assume that we are just looking at the first quadrant, since the populations are non-negative. Find the curve along which the Hamiltonian function is zero, and explain its significance in terms of who wins the conflict.    a)  b) Saddle, these are hyperbolas. c)  , dividing line deciding who wins   "
},
{
  "id": "nlinHamiltonian-section-6-23",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-23",
  "type": "Exercise",
  "number": "5.2.5.17",
  "title": "",
  "body": "  Consider the non-linear system     has a critical point at the origin. What is the linearization of at the origin? Demonstrate that is locally linear in a neighborhood of the origin. Classify the origin according to its type and stability .    a) Spiral Source b) Matrix is invertible c) Unstable spiral source   "
},
{
  "id": "nlinHamiltonian-section-6-24",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-24",
  "type": "Exercise",
  "number": "5.2.5.18",
  "title": "",
  "body": "  Consider the system of differential equations which has slope field sketched below.     image    Find and classify all critical points of the system . Draw any separatrices that you can spot on the slope field. Do any of these critical points have a basin of attraction? If so, sketch out what regions of the plane correspond to a basin of attraction for those critical points.   "
},
{
  "id": "nlinHamiltonian-section-6-26",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-26",
  "type": "Figure",
  "number": "5.2.12",
  "title": "",
  "body": "  image  "
},
{
  "id": "nlinHamiltonian-section-6-27",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-27",
  "type": "Exercise",
  "number": "5.2.5.19",
  "title": "",
  "body": "  Consider the system of differential equations which has slope field sketched below.     image    Find and classify all critical points of the system . Draw any separatrices that you can spot on the slope field. Do any of these critical points have a basin of attraction? If so, sketch out what regions of the plane correspond to a basin of attraction for those critical points.   "
},
{
  "id": "nlinHamiltonian-section-6-29",
  "level": "2",
  "url": "nlinHamiltonian-section.html#nlinHamiltonian-section-6-29",
  "type": "Figure",
  "number": "5.2.14",
  "title": "",
  "body": "  image  "
},
{
  "id": "nlinapps-section",
  "level": "1",
  "url": "nlinapps-section.html",
  "type": "Section",
  "number": "5.3",
  "title": "Applications of nonlinear systems",
  "body": " Applications of nonlinear systems   In this section we study two very standard examples of nonlinear systems. First, we look at the nonlinear pendulum equation. We saw the pendulum equation’s linearization before, but we noted it was only valid for small angles and short times. Now we find out what happens for large angles. Next, we look at the predator-prey equation, which finds various applications in modeling problems in biology, chemistry, economics, and elsewhere.    Pendulum  The first example we study is the pendulum equation . Here, is the angular displacement, is the gravitational acceleration, and is the length of the pendulum. In this equation we disregard friction, so we are talking about an idealized pendulum.   1.45in1.75in  This equation is a conservative equation, so we can use our analysis of conservative equations from the previous section. Let us change the equation to a two-dimensional system in variables by introducing the new variable : The critical points of this system are when and , or in other words if . So the critical points are when and is a multiple of . That is, the points are . While there are infinitely many critical points, they are all isolated. Let us compute the Jacobian matrix:   For conservative equations, there are two types of critical points. Either stable centers, or saddle points. The eigenvalues of the Jacobian matrix are .  The eigenvalues are going to be real when . This happens at the odd multiples of . The eigenvalues are going to be purely imaginary when . This happens at the even multiples of . Therefore the system has a stable center at the points , and it has an unstable saddle at the points . Look at the phase diagram in , where for simplicity we let .    Since this is a pendulum without friction, we can characterize the two differnet types of trajectories here. There are the curves running along the top and bottom of the phase portrait that look somewhat like sine waves. These graphs never cross the -axis, which is the line . Therefore, these are trajectories where the pendulum never stops moving; it just keeps spinning around in full circles forever, crossing through all possible values of . The other type of trajectory are the ellipses around each of the stable equilibrium solutions. In these cases, the graph only spans a specific range of values, represented by the reduced range of the ellipse, and cycles there forever. This represents a pendulum that does not have enough energy to make a full circle, and just oscillates back-and-forth to a fixed height forever.  In the linearized equation we have only a single critical point, the center at . Now we see more clearly what we meant when we said the linearization is good for small angles. The horizontal axis is the deflection angle. The vertical axis is the angular velocity of the pendulum. Suppose we start at (no deflection), and we start with a small angular velocity . Then the trajectory keeps going around the critical point in an approximate circle. This corresponds to short swings of the pendulum back and forth. When stays small, the trajectories really look like circles and hence are very close to our linearization.  When we give the pendulum a big enough push, it goes across the top and keeps spinning about its axis. This behavior corresponds to the wavy curves that do not cross the horizontal axis in the phase diagram. Let us suppose we look at the top curves, when the angular velocity is large and positive. Then the pendulum is going around and around its axis. The velocity is going to be large when the pendulum is near the bottom, and the velocity is the smallest when the pendulum is close to the top of its loop.  At each critical point, there is an equilibrium solution. Consider the solution ; the pendulum is not moving and is hanging straight down. This is a stable place for the pendulum to be, hence this is a stable equilibrium.  The other type of equilibrium solution is at the unstable point, for example . Here the pendulum is upside down. Sure you can balance the pendulum this way and it will stay, but this is an unstable equilibrium. Even the tiniest push will make the pendulum start swinging wildly.  See for a diagram. The first picture is the stable equilibrium . The second picture corresponds to those in the phase diagram around when the angular velocity is small. The next picture is the unstable equilibrium . The last picture corresponds to the wavy lines for large angular velocities.    The quantity is conserved by any solution. This is the energy or the Hamiltonian of the system.  We have a conservative equation and so (exercise) the trajectories are given by for various values of . Let us look at the initial condition of , that is, we take the pendulum to angle , and just let it go (initial angular velocity 0). We plug the initial conditions into the above and solve for to obtain Thus the expression for the trajectory is   Let us figure out the period. That is, the time it takes for the pendulum to swing back and forth. We notice that the trajectory about the origin in the phase plane is symmetric about both the and the -axis. That is, in terms of , the time it takes from to is the same as it takes from back to . Furthermore, the time it takes from to is the same as to go from to . Therefore, let us find how long it takes for the pendulum to go from angle 0 to angle , which is a quarter of the full oscillation and then multiply by 4.  We figure out this time by finding and integrating from to . The period is four times this integral. Let us stay in the region where is positive. Since , inverting we get Therefore the period is given by The integral is an improper integral, and we cannot in general evaluate it symbolically. We must resort to numerical approximation if we want to compute a particular .  Recall from , the linearized equation has period We plot , , and the relative error in . The relative error says how far is our approximation from the real period percentage-wise. Note that is simply a constant, it does not change with the initial angle . The actual period gets larger and larger as gets larger. Notice how the relative error is small when is small. It is still only when , that is, a 90 degree angle. The error is when starting at , a 45 degree angle. At a 5 degree initial angle, the error is only .    While it is not immediately obvious from the formula, it is true that That is, the period goes to infinity as the initial angle approaches the unstable equilibrium point. So if we put the pendulum almost upside down it may take a very long time before it gets down. This is consistent with the limiting behavior, where the exactly upside down pendulum never makes an oscillation, so we could think of that as infinite period.    Predator-prey or Lotka–Volterra systems  One of the most common simple applications of nonlinear systems are the so-called or  Named for the American mathematician, chemist, and statistician Alfred James Lotka (1880–1949) and the Italian mathematician and physicist Vito Volterra (1860–1940). systems. For example, these systems arise when two species interact, one as the prey and one as the predator. It is then no surprise that the equations also see applications in economics. The system also arises in chemical reactions. In biology, this system of equations explains the natural periodic variations of populations of different species in nature. Before the application of differential equations, these periodic variations in the population baffled biologists.  We keep with the classical example of hares and foxes in a forest, it is the easiest to understand. When there are a lot of hares, there is plenty of food for the foxes, so the fox population grows. However, when the fox population grows, the foxes eat more hares, so when there are lots of foxes, the hare population should go down, and vice versa. The Lotka–Volterra model proposes that this behavior is described by the system of equations where are some parameters that describe the interaction of the foxes and hares This interaction does not end well for the hare. . In this model, these are all positive numbers.  Let us analyze the idea behind this model. The model is a slightly more complicated idea based on the exponential population model. First expand, The hares are expected to simply grow exponentially in the absence of foxes, that is where the term comes in, the growth in population is proportional to the population itself. We are assuming the hares always find enough food and have enough space to reproduce. However, there is another component , that is, the population also is decreasing proportionally to the number of foxes. Together we can write the equation as , so it is like exponential growth or decay but the constant depends on the number of foxes.  The equation for foxes is very similar, expand again The foxes need food (hares) to reproduce: the more food, the bigger the rate of growth, hence the term. On the other hand, there are natural deaths in the fox population, and hence the term.  Without further delay, let us start with an explicit example. Suppose the equations are See for the phase portrait. In this example it makes sense to also plot and as graphs with respect to time. Therefore the second graph in is the graph of and on the vertical axis (the prey is the thinner blue line with taller peaks), against time on the horizontal axis. The particular solution graphed was with initial conditions of 20 foxes and 50 hares.    Let us analyze what we see on the graphs. We work in the general setting rather than putting in specific numbers. We start with finding the critical points. Set , and . The first equation is satisfied if either or . If , the second equation implies . If , the second equation implies . There are two equilibria: at when there are no animals at all, and at . In our specific example , and . This is the point where there are 100 hares and 40 foxes.  We compute the Jacobian matrix: At the origin we get the matrix , so the eigenvalues are and , hence real and of opposite signs. So the critical point at the origin is a saddle. This makes sense. If you started with some foxes but no hares, then the foxes would go extinct, that is, you would approach the origin. If you started with no foxes and a few hares, then the hares would keep multiplying without check, and so you would go away from the origin.  OK, how about the other critical point at . Here the Jacobian matrix becomes The eigenvalues satisfy . In other words, . The eigenvalues being purely imaginary, we are in the case where we cannot quite decide using only linearization. We could have a stable center, spiral sink, or a spiral source. That is, the equilibrium could be asymptotically stable, stable, or unstable. Of course I gave you a picture above that seems to imply it is a stable center. But never trust a picture only. Perhaps the oscillations are getting larger and larger, but only very slowly. Of course this would be bad as it would imply something will go wrong with our population sooner or later. And I only graphed a very specific example with very specific trajectories.  How can we be sure we are in the stable situation? As we said before, in the case of purely imaginary eigenvalues, we have to do a bit more work. The main approach that can be used here is to directly solve for the trajectories. We can determine a differential equation that relates to by writing This is a separable first order equation, which we can rewrite as After simplifying the fractions, we can integrate this to obtain the implicit solution or Since we ended up finding a trajectory here that sketches out a closed curve, and we know that our solutions must lie on these trajectories, that tells us that, for a fact, we do have closed loops here, and the critical point is stable.  However, we can go a bit farther than this with our discussion here. If we let in , we can rearrange the expression to get that and based on how our trajectory setup works, we know that this will be conserved along the flow of the solution. That is, if the initial condition has a specific value of , the solution will continue to have that same value for all . This idea came up before in the idea of conservative or Hamiltonian systems in . Such a quantity is called the , and this forces the trajectory to go in closed loops. Let us check really is a constant of motion. How do we check, you say? Well, a constant is something that does not change with time, so let us compute the derivative with respect to time: Our equations give us what and are so let us plug those in: So along the trajectories is constant. In fact, the expression gives us an implicit equation for the trajectories. In any case, once we have found this constant of motion, it must be true that the trajectories are simple curves, that is, the level curves of . It turns out, the critical point at is a maximum for (left as an exercise). So is a stable equilibrium point, and we do not have to worry about the foxes and hares going extinct or their populations exploding.  One blemish on this wonderful model is that the number of foxes and hares are discrete quantities and we are modeling with continuous variables. Our model has no problem with there being 0.1 fox in the forest for example, while in reality that makes no sense. The approximation is a reasonable one as long as the number of foxes and hares are large, but it does not make much sense for small numbers. One must be careful in interpreting any results from such a model.  An interesting consequence (perhaps counterintuitive) of this model is that adding animals to the forest might lead to extinction, because the variations will get too big, and one of the populations will get close to zero. For example, suppose there are 20 foxes and 50 hares as before, but now we bring in more foxes, bringing their number to 200. If we run the computation, we find the number of hares will plummet to just slightly more than 1 hare in the whole forest. In reality that most likely means the hares die out, and then the foxes will die out as well as they will have nothing to eat.      Consider the system This fits the description of a predator-prey model. Which species is the predator? Find and analyze the critical points of this system, and draw a sketch of the phase portrait, with arrows to indicate the direction of flow around this portrait.    If we expand out the equations in the model, we get These equations show that, if , would decay away in time, and if , would grow indefinitely. This means that is the predator and is the prey in this relationship. For critical points, we can look back at the factored version of the equations to see that we get one critical point at and one critical point at . Since this is a predator-prey model, we know that we will have cycles around the critical point at .  The direction of these cycles is determined by the predator-prey relationship. If we start with large (greater than 2) and small (less than 3), then there are a lot of predators and few prey. This implies that the next thing to happen is that the predator population will decrease because there is not enough prey. We can also see this from the equations; if and , then both and will be negative. Similarly, if is large and is small, there are a lot of prey and few predators, so the prey population will continue to grow, while the predators also grow because of the excess of food. This means that the populations will follow these trajectories in a clockwise direction.  For the actual trajectories, we can solve for them in the same way as the calculations before this example. We can rewrite this system to give a differential equation for the trajectories as which can be rearranged as a separable equation to Solving this gives or This will be used to draw the trajectories in .  This can also be seen using a nullcline analysis. The nullclines we need to draw are , , and . Our discussion previously shows that the arrow in the bottom-right quadrant should point to the lower left, and the arrow in the top left should point up and right. We can fill in the other two quadrants to see that the solution should move around the circle in a clockwise direction. shows the nullcline image and trajectory curves for this example.        Competing Species systems  Another application of non-linear systems that also works with population models is a competing species interaction. The setup is that there are two species that live in the same environment, and need to compete over resources. This means that both species will grow on their own, but when the two species interact, it is negative for both species. This gives rise to a system of differential equations of the form if both populations grow exponentially, or if both species grow logistically. The numbers here are all positive constants that explain how the different populations affect growth rates. For the logistic model, let’s look at the equilibrium solutions. For this, we need which gives equilibrium solutions at , , and , all of which result in one (or both) of the species being extinct. The other equilibrium solution is more interesting, because it involves both species coexisting. This happens when Solving this gives a critical point with and .  The Jacobian matrix for this system is   Unlike the predator-prey system that always had the same type of equilibriums solution every time, there are multiple options for how this system can behave based on the values of , and . It is possible that the coexistence equilibrium solution will be a nodal sink, so that all nearby solutions will converge to it over time, and the species will continue to exist in harmony. However, it is also possible that the coexistence solution is a saddle and the solutions at and are sinks. This means that coexistence is unstable, and that over time, the populations will converge to one of the other two equilibrium solutions, meaning that one of the species will die out as time goes on. Determining which will survive will require a numerical model since these equations can not be solved analytically.      Analyze the competing species model given by the system of differential equations Is the coexistence solution stable or unstable? What will happen to the populations over time?    Solving for the equilibrium solutions gives , , , and the coexistence solution where Simplifying this gives or . The second equation then implies that .  The Jacobian for this system is   Evaluating this matrix at the point gives which we need to find the eigenvalues to classify what type of linearized solution we have here. These are determined by Thus, the eigenvalues are given by which will be real with opposite signs. Therefore, this equilibrium solution is a saddle, and unstable. To confirm this, we can also check the equilibrium solutions at and . For , we get the matrix which is a nodal sink. For , we get which is also a nodal sink. Thus, we see that the coexistence equilibrium solution is unstable, and both of the equilibrium solutions with one species extinct are stable. Therefore, over time, one of the two species will die off depending on the initial population.    Showing that a system of equations has a stable solution can be a very difficult problem. When Isaac Newton put forth his laws of planetary motions, he proved that a single planet orbiting a single sun is a stable system. But any solar system with more than 1 planet proved very difficult indeed. In fact, such a system behaves chaotically (see ), meaning small changes in initial conditions lead to very different long-term outcomes. From numerical experimentation and measurements, we know the earth will not fly out into the empty space or crash into the sun, for at least some millions of years or so. But we do not know what happens beyond that.    Exercises    Take the  for some (that is, there is some friction).   Suppose and for simplicity, find and classify the critical points. Do the same for any and any and , but such that the damping is small, in particular, . Explain what your findings mean, and if it agrees with what you expect in reality.    a)  , is odd is a saddle, is even is a spiral sink. b) Same is true under those conditions. c)  Oscillates decaying to , which makes sense.      Take the damped nonlinear pendulum equation for some (that is, there is friction). Suppose the friction is large, in particular .   Find and classify the critical points. Explain what your findings mean, and if it agrees with what you expect in reality.      Suppose the hares do not grow exponentially, but logistically. In particular consider For the following two values of , find and classify all the critical points in the positive quadrant, that is, for and . Then sketch the phase diagram. Discuss the implication for the long term behavior of the population.   (2) , .    a)  saddle, saddle, spiral sink. Both species survive. b)  saddle, nodal sink. Foxes die out.      Suppose we have the system predator-prey system where the foxes are also killed at a constant rate ( foxes killed per unit time):  .   Find the critical points and the Jacobian matrices of the system. Put in the constants , , , , . Analyze the critical points. What do you think it says about the forest?      Suppose the foxes never die. That is, we have the system  . Find the critical points and notice they are not isolated. What will happen to the population in the forest if it starts at some positive numbers. Hint: Think of the constant of motion.      The following system of differential equations models a pair of populations interacting.    Does this system of differential equations represent a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. If this depends on the initial condition, say so.    a) Predator-prey, is prey b)  is a center c) Oscillates around this point      The following system of differential equations models a pair of populations interacting.    Does this system of differential equations better fit with a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. It this depends on the initial condition, say so.    a) Competing Speciesb)  is a saddle c) One of the two species will die off eventually, depending on the initial condition      The following system of differential equations models a pair of populations interacting.    Does this system of differential equations better fit with a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. It this depends on the initial condition, say so.    a) Competing Speciesb)  is a nodal sink c) Tends towards coexistence equilibrium at        Suppose and are positive variables. Show attains a maximum at . Suppose are positive constants, and also suppose and are positive variables. Show attains a maximum at .    Hint: Look at where the gradient is zero for the critical point, and look at the eigenvalues of the Hessian to determine if it is a maximum. Two negative eigenvalues means it is a maximum.      Suppose that for the pendulum equation we take a trajectory giving the spinning-around motion, for example . This is the trajectory where the lowest angular velocity is . Find an integral expression for how long it takes the pendulum to go all the way around.           Consider a predator-prey interaction where humans have gotten involved. The idea is that at least one of the species is valuable for food or another resource, and the two species still intact in their normal predator-prey manner. The first version of this will deal with constant effort harvesting, which means that humans will remove animals from the populations are a rate proportional to the population. This results in equations of the form where and denote the amount of harvesting done.   There is a single equilibrium solution with and in the case of no harvesting, that is, . Find this equilibrium solution. Without doing any mathematical work, what do you think will happen to the equilibrium solution if just the prey is harvested? What if just the predator is harvested? What if both are harvested? Find the location of the equilibrium system in each of the three cases in the previous part. Do this in terms of the constants and for all three cases.    a) b) It will change the effective values of and . c)        The second version of this will deal with constant yield harvesting, which means that humans will remove animals from the populations at a fixed rate, no matter their population. This results in equations of the form where and denote the amount of harvesting done.   There is a single equilibrium solution with and in the case of no harvesting, that is, . Find this equilibrium solution. Without doing any mathematical work, what do you think will happen to the equilibrium solution if just the prey is harvested? What if just the predator is harvested? What if both are harvested? Find the location of the equilibrium system in each of the three cases in the previous part. Do this in terms of the constants and for all three cases.    a) b) Any harvesting should increase the value and decrease the value. c)        The general competing species model has the form where indicates the growth rate, is related to the carrying capacity, and is connected to the interaction term. Assume that this model is being used to represent species A and B of fish living in a pond at time , which is initially stocked with both species of fish. We want to analyze the behavior of this equation under different sets of coefficients.   If and , show that the only equilibrium populations in the pond are no fish, no fish of species A, or no fish of species B. What happens for large values of ? If and , show that the only equilibrium populations in the pond are no fish, no fish of species A, or no fish of species B. What happens for large values of ? Suppose that and . Show that there is a stable equilibrium where both species coexist.    Hint: Solve for the critical point with neither population zero in terms of all of the parameters. Then, you want to classify the critical points at this non-zero value, as well as at and for the appropriate values of and . This should give you enough to know what happens over time. For c), think about what these two inequalities tell you about .      Take the pendulum, suppose the initial position is .   Find the expression for giving the trajectory with initial condition . Hint: Figure out what should be in terms of . Find the crucial angular velocity , such that for any higher initial angular velocity, the pendulum will keep going around its axis, and for any lower initial angular velocity, the pendulum will simply swing back and forth. Hint: When the pendulum doesn’t go over the top the expression for will be undefined for some s. What do you think happens if the initial condition is , that is, the initial angle is 0, and the initial angular velocity is exactly .    a)  b)  c) It stops at the top.     "
},
{
  "id": "predator-prey-or-lotkavolterra-systems-14",
  "level": "2",
  "url": "nlinapps-section.html#predator-prey-or-lotkavolterra-systems-14",
  "type": "Example",
  "number": "5.3.1",
  "title": ".",
  "body": "    Consider the system This fits the description of a predator-prey model. Which species is the predator? Find and analyze the critical points of this system, and draw a sketch of the phase portrait, with arrows to indicate the direction of flow around this portrait.    If we expand out the equations in the model, we get These equations show that, if , would decay away in time, and if , would grow indefinitely. This means that is the predator and is the prey in this relationship. For critical points, we can look back at the factored version of the equations to see that we get one critical point at and one critical point at . Since this is a predator-prey model, we know that we will have cycles around the critical point at .  The direction of these cycles is determined by the predator-prey relationship. If we start with large (greater than 2) and small (less than 3), then there are a lot of predators and few prey. This implies that the next thing to happen is that the predator population will decrease because there is not enough prey. We can also see this from the equations; if and , then both and will be negative. Similarly, if is large and is small, there are a lot of prey and few predators, so the prey population will continue to grow, while the predators also grow because of the excess of food. This means that the populations will follow these trajectories in a clockwise direction.  For the actual trajectories, we can solve for them in the same way as the calculations before this example. We can rewrite this system to give a differential equation for the trajectories as which can be rearranged as a separable equation to Solving this gives or This will be used to draw the trajectories in .  This can also be seen using a nullcline analysis. The nullclines we need to draw are , , and . Our discussion previously shows that the arrow in the bottom-right quadrant should point to the lower left, and the arrow in the top left should point up and right. We can fill in the other two quadrants to see that the solution should move around the circle in a clockwise direction. shows the nullcline image and trajectory curves for this example.   "
},
{
  "id": "competing-species-systems-5",
  "level": "2",
  "url": "nlinapps-section.html#competing-species-systems-5",
  "type": "Example",
  "number": "5.3.2",
  "title": ".",
  "body": "    Analyze the competing species model given by the system of differential equations Is the coexistence solution stable or unstable? What will happen to the populations over time?    Solving for the equilibrium solutions gives , , , and the coexistence solution where Simplifying this gives or . The second equation then implies that .  The Jacobian for this system is   Evaluating this matrix at the point gives which we need to find the eigenvalues to classify what type of linearized solution we have here. These are determined by Thus, the eigenvalues are given by which will be real with opposite signs. Therefore, this equilibrium solution is a saddle, and unstable. To confirm this, we can also check the equilibrium solutions at and . For , we get the matrix which is a nodal sink. For , we get which is also a nodal sink. Thus, we see that the coexistence equilibrium solution is unstable, and both of the equilibrium solutions with one species extinct are stable. Therefore, over time, one of the two species will die off depending on the initial population.   "
},
{
  "id": "nlinapps-section-6-2",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-2",
  "type": "Exercise",
  "number": "5.3.4.1",
  "title": "",
  "body": "  Take the  for some (that is, there is some friction).   Suppose and for simplicity, find and classify the critical points. Do the same for any and any and , but such that the damping is small, in particular, . Explain what your findings mean, and if it agrees with what you expect in reality.    a)  , is odd is a saddle, is even is a spiral sink. b) Same is true under those conditions. c)  Oscillates decaying to , which makes sense.   "
},
{
  "id": "nlinapps-section-6-3",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-3",
  "type": "Exercise",
  "number": "5.3.4.2",
  "title": "",
  "body": "  Take the damped nonlinear pendulum equation for some (that is, there is friction). Suppose the friction is large, in particular .   Find and classify the critical points. Explain what your findings mean, and if it agrees with what you expect in reality.   "
},
{
  "id": "nlinapps-section-6-4",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-4",
  "type": "Exercise",
  "number": "5.3.4.3",
  "title": "",
  "body": "  Suppose the hares do not grow exponentially, but logistically. In particular consider For the following two values of , find and classify all the critical points in the positive quadrant, that is, for and . Then sketch the phase diagram. Discuss the implication for the long term behavior of the population.   (2) , .    a)  saddle, saddle, spiral sink. Both species survive. b)  saddle, nodal sink. Foxes die out.   "
},
{
  "id": "nlinapps-section-6-5",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-5",
  "type": "Exercise",
  "number": "5.3.4.4",
  "title": "",
  "body": "  Suppose we have the system predator-prey system where the foxes are also killed at a constant rate ( foxes killed per unit time):  .   Find the critical points and the Jacobian matrices of the system. Put in the constants , , , , . Analyze the critical points. What do you think it says about the forest?   "
},
{
  "id": "nlinapps-section-6-6",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-6",
  "type": "Exercise",
  "number": "5.3.4.5",
  "title": "",
  "body": "  Suppose the foxes never die. That is, we have the system  . Find the critical points and notice they are not isolated. What will happen to the population in the forest if it starts at some positive numbers. Hint: Think of the constant of motion.   "
},
{
  "id": "nlinapps-section-6-7",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-7",
  "type": "Exercise",
  "number": "5.3.4.6",
  "title": "",
  "body": "  The following system of differential equations models a pair of populations interacting.    Does this system of differential equations represent a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. If this depends on the initial condition, say so.    a) Predator-prey, is prey b)  is a center c) Oscillates around this point   "
},
{
  "id": "nlinapps-section-6-8",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-8",
  "type": "Exercise",
  "number": "5.3.4.7",
  "title": "",
  "body": "  The following system of differential equations models a pair of populations interacting.    Does this system of differential equations better fit with a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. It this depends on the initial condition, say so.    a) Competing Speciesb)  is a saddle c) One of the two species will die off eventually, depending on the initial condition   "
},
{
  "id": "nlinapps-section-6-9",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-9",
  "type": "Exercise",
  "number": "5.3.4.8",
  "title": "",
  "body": "  The following system of differential equations models a pair of populations interacting.    Does this system of differential equations better fit with a competing species model or a predator-prey model? If it is predator-prey, which species is the predator? Find and classify the critical point (if it exists) with both and . Describe what is going to happen to the population of these species over time. It this depends on the initial condition, say so.    a) Competing Speciesb)  is a nodal sink c) Tends towards coexistence equilibrium at    "
},
{
  "id": "nlinapps-section-6-10",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-10",
  "type": "Exercise",
  "number": "5.3.4.9",
  "title": "",
  "body": "   Suppose and are positive variables. Show attains a maximum at . Suppose are positive constants, and also suppose and are positive variables. Show attains a maximum at .    Hint: Look at where the gradient is zero for the critical point, and look at the eigenvalues of the Hessian to determine if it is a maximum. Two negative eigenvalues means it is a maximum.   "
},
{
  "id": "nlinapps-section-6-11",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-11",
  "type": "Exercise",
  "number": "5.3.4.10",
  "title": "",
  "body": "  Suppose that for the pendulum equation we take a trajectory giving the spinning-around motion, for example . This is the trajectory where the lowest angular velocity is . Find an integral expression for how long it takes the pendulum to go all the way around.        "
},
{
  "id": "nlinapps-section-6-12",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-12",
  "type": "Exercise",
  "number": "5.3.4.11",
  "title": "",
  "body": "  Consider a predator-prey interaction where humans have gotten involved. The idea is that at least one of the species is valuable for food or another resource, and the two species still intact in their normal predator-prey manner. The first version of this will deal with constant effort harvesting, which means that humans will remove animals from the populations are a rate proportional to the population. This results in equations of the form where and denote the amount of harvesting done.   There is a single equilibrium solution with and in the case of no harvesting, that is, . Find this equilibrium solution. Without doing any mathematical work, what do you think will happen to the equilibrium solution if just the prey is harvested? What if just the predator is harvested? What if both are harvested? Find the location of the equilibrium system in each of the three cases in the previous part. Do this in terms of the constants and for all three cases.    a) b) It will change the effective values of and . c)     "
},
{
  "id": "nlinapps-section-6-13",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-13",
  "type": "Exercise",
  "number": "5.3.4.12",
  "title": "",
  "body": "  The second version of this will deal with constant yield harvesting, which means that humans will remove animals from the populations at a fixed rate, no matter their population. This results in equations of the form where and denote the amount of harvesting done.   There is a single equilibrium solution with and in the case of no harvesting, that is, . Find this equilibrium solution. Without doing any mathematical work, what do you think will happen to the equilibrium solution if just the prey is harvested? What if just the predator is harvested? What if both are harvested? Find the location of the equilibrium system in each of the three cases in the previous part. Do this in terms of the constants and for all three cases.    a) b) Any harvesting should increase the value and decrease the value. c)     "
},
{
  "id": "nlinapps-section-6-14",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-14",
  "type": "Exercise",
  "number": "5.3.4.13",
  "title": "",
  "body": "  The general competing species model has the form where indicates the growth rate, is related to the carrying capacity, and is connected to the interaction term. Assume that this model is being used to represent species A and B of fish living in a pond at time , which is initially stocked with both species of fish. We want to analyze the behavior of this equation under different sets of coefficients.   If and , show that the only equilibrium populations in the pond are no fish, no fish of species A, or no fish of species B. What happens for large values of ? If and , show that the only equilibrium populations in the pond are no fish, no fish of species A, or no fish of species B. What happens for large values of ? Suppose that and . Show that there is a stable equilibrium where both species coexist.    Hint: Solve for the critical point with neither population zero in terms of all of the parameters. Then, you want to classify the critical points at this non-zero value, as well as at and for the appropriate values of and . This should give you enough to know what happens over time. For c), think about what these two inequalities tell you about .   "
},
{
  "id": "nlinapps-section-6-15",
  "level": "2",
  "url": "nlinapps-section.html#nlinapps-section-6-15",
  "type": "Exercise",
  "number": "5.3.4.14",
  "title": "",
  "body": "  Take the pendulum, suppose the initial position is .   Find the expression for giving the trajectory with initial condition . Hint: Figure out what should be in terms of . Find the crucial angular velocity , such that for any higher initial angular velocity, the pendulum will keep going around its axis, and for any lower initial angular velocity, the pendulum will simply swing back and forth. Hint: When the pendulum doesn’t go over the top the expression for will be undefined for some s. What do you think happens if the initial condition is , that is, the initial angle is 0, and the initial angular velocity is exactly .    a)  b)  c) It stops at the top.   "
},
{
  "id": "limitcycles-section",
  "level": "1",
  "url": "limitcycles-section.html",
  "type": "Section",
  "number": "5.4",
  "title": "Limit cycles",
  "body": " Limit cycles  For nonlinear systems, trajectories do not simply need to approach or leave a single point. They may in fact approach a larger set, such as a circle or another closed curve.      The Named for the Dutch physicist Balthasar van der Pol (1889–1959). is the following equation where is some positive constant. The Van der Pol oscillator originated with electrical circuits, but finds applications in diverse fields such as biology, seismology, and other physical sciences.  For simplicity, let us use . A phase diagram is given in the left-hand plot in . Notice how the trajectories seem to very quickly settle on a closed curve. On the right-hand side is the plot of a single solution for to with initial conditions and . The solution quickly tends to a periodic solution.    The Van der Pol oscillator is an example of so-called . The word relaxation comes from the sudden jump (the very steep part of the solution). For larger the steep part becomes even more pronounced, for small the limit cycle looks more like a circle. In fact, setting , we get , which is a linear system with a center and all trajectories become circles.    What we see in this example is a curve to which many solution seem to head towards as gets larger. This motivates the following definition.      A trajectory in the phase portrait that is a closed curve (a curve that is a loop) is called a .    A is a closed trajectory such that at least one other trajectory spirals into it.    If all trajectories that start near the limit cycle spiral into it, the limit cycle is called asymptotically stable .     For example, the closed curve in the phase portrait for the Van der Pol equation is a limit cycle, and the limit cycle in the Van der Pol oscillator is asymptotically stable.  Given a closed trajectory on an autonomous system, any solution that starts on it is periodic. Such a curve is called a . More precisely, if is a solution such that for some the point lies on a periodic orbit, then both and are periodic functions (with the same period). That is, there is some number such that and .  We would like to be able to identify when these sorts of periodic orbits can or can’t happen to understand more about these systems. Thankfully, we have a theorem that gives us some help here.   Poincaré–Bendixson Consider the system where the functions and have continuous derivatives in some region in the plane.  Suppose is a closed bounded region (a region in the plane that includes its boundary and does not have points arbitrarily far from the origin). Suppose is a solution of in that exists for all . Then either the solution is a periodic function, or the solution tends towards a periodic solution in .  The main point of the theorem  Ivar Otto Bendixson (1861–1935) was a Swedish mathematician. is that if you find one solution that exists for all large enough (that is, as goes to infinity) and stays within a bounded region, then you have found either a periodic orbit, or a solution that spirals towards a limit cycle or tends to a critical point. That is, in the long term, the behavior is very close to a periodic function. Note that a constant solution at a critical point is periodic (with any period). The theorem is more a qualitative statement rather than something to help us in computations. In practice it is hard to find analytic solutions and so hard to show rigorously that they exist for all time. But if we think the solution exists we numerically solve for a large time to approximate the limit cycle. Another caveat is that the theorem only works in two dimensions. In three dimensions and higher, there is simply too much room.  The theorem applies to all solutions in the Van der Pol oscillator. Solutions that start at any point except the origin will tend to the periodic solution around the limit cycle, and if the initial condition of will lead to the constant solution , .      Consider A vector field along with solutions with initial conditions , , and are drawn in . Analyze this system to determine what will happen to the solution for a variety of initial conditions.      Notice that points on the unit circle (distance one from the origin) satisfy . And , is a solution of the system. Therefore we have a closed trajectory. For points off the unit circle, the second term in pushes the solution further away from the -axis than the system , , and pushes the solution further away from the -axis than the linear system , . In other words for all other initial conditions the trajectory will spiral out.  This means that for initial conditions inside the unit circle, the solution spirals out towards the periodic solution on the unit circle, and for initial conditions outside the unit circle the solutions spiral off towards infinity. Therefore the unit circle is a limit cycle, but not an asymptotically stable one. In relation to the terms used for autonomous equations in , we could refer to this as a semistable limit cycle, since on one side (inside) the solutions spiral towards the periodic orbit, while on the other side (outside) the solutions move away. The Poincaré–Bendixson Theorem applies to the initial points inside the unit circle, as those solutions stay bounded, but not to those outside, as those solutions go off to infinity.    A very similar analysis applies to the system We still obtain a closed trajectory on the unit circle, and points outside the unit circle spiral out to infinity, but now points inside the unit circle spiral towards the critical point at the origin. So this system does not have a limit cycle, even though it has a closed trajectory.  One way to see this more explicitly is by trying to write this all in terms of For simplicity here, we will determine everything in terms of because as long as , and always have the same behavior (in terms of increasing and decreasing), and it is easier to compute with .  Using the first example we see that   Thus, we are left with the equation which is an autonomous first-order equation that we can analyze. We have two equilibrium solutions in terms of at , which corresponds to the origin, and , which corresponds to the unit circle. We can then plug in values to see that for , , so that the solutions will increase out to the unit circle. For , as well, so solutions move away from the circle outside it. This is the same as the result we obtained in the first example.  For the second example, we end up with the autonomous equation which is negative for and positive for , giving that solutions that start inside the unit circle will converge to the origin, and solutions that start outside the circle will move away from it.  Due to the Picard theorem () we find that no matter where we are in the plane we can always find a solution a little bit further in time, as long as and have continuous derivatives. So if we find a closed trajectory in an autonomous system, then for every initial point inside the closed trajectory, the solution will exist for all time and it will stay bounded (it will stay inside the closed trajectory). Since the closed trajectory is a solution, we can not cross it (by Picard theorem), and so we have to stay trapped inside. So the moment we found the solution above going around the unit circle, we knew that for every initial point inside the circle, the solution exists for all time and the Poincaré–Bendixson theorem applies.  Let us next look for conditions when limit cycles (or periodic orbits) do not exist. We assume the equation is defined on a , that is, a region with no holes we can go around. For example the entire plane is a simply connected region, and so is the inside of the unit disc. However, the entire plane minus a point is not a simply connected domain as it has a at the origin.   Bendixson–Dulac Suppose is a simply connected region, and the expression Usually the expression in the Bendixson–Dulac Theorem is for some continuously differentiable function . For simplicity, let us just consider the case .  is either always positive or always negative on (except perhaps a small set such as on isolated points or curves) then the system has no closed trajectory inside .  The theorem  Henri Dulac (1870–1955) was a French mathematician. gives us a way of ruling out the existence of a closed trajectory, and hence a way of ruling out limit cycles. The exception about points or curves means that we can allow the expression to be zero at a few points, or perhaps on a curve, but not on any larger set.      Let us look at , in the entire plane (see ) and try to apply .    The entire plane is simply connected and so we can apply the theorem. We compute . The function is always positive except on the line . Therefore, via the theorem, the system has no closed trajectories.    In some books (or the internet) the theorem is not stated carefully and it concludes there are no periodic solutions. That is not quite right. The example above has two critical points and hence it has constant solutions, and constant functions are periodic. The conclusion of the theorem should be that there exist no trajectories that form closed curves. Another way to state the conclusion of the theorem would be to say that there exist no nonconstant periodic solutions that stay in .  Let us look at a somewhat more complicated example.      Take the system , (see ) and look at how works here.    We compute . This expression takes on both signs, so if we are talking about the whole plane we cannot simply apply the theorem. However, we could apply it on the set where . Via the theorem, there is no closed trajectory in that set. Similarly, there is no closed trajectory in the set . We cannot conclude (yet) that there is no closed trajectory in the entire plane. Perhaps half of it is in the set where and the other half is in the set where .  The key is to look at the line where , or . On this line and . In particular, when then . That means that the arrows, the vectors , always point into the set where . There is no way we can start in the set where and go into the set where . Once we are in the set where , we stay there. So no closed trajectory can have points in both sets.        Consider , , and consider the region given by . That is, is the region outside a circle of radius centered at the origin. Then there is a closed trajectory in , namely , . Furthermore, which is always positive on . So what is going on? The Bendixson–Dulac theorem does not apply since the region is not simply connected—it has a hole, the circle we cut out!     Exercises    Consider the two-dimensional system of differential equation written in polar coordinates as Determine all limit cycles, periodic solutions, and classify the stability of each of these solutions.     is asymptotically stable, is a periodic solution, but not a limit cycle, is unstable, is semistable, limit cycle from the inside.      Consider the two-dimensional system of differential equation written in polar coordinates as Determine all limit cycles, periodic solutions, and classify the stability of each of these solutions.     asymptoticallys table, semistable limit cycle, periodic solution, unstable.      Consider the system of differential equation given by Find and classify all limit cycles by converting to an autonomous equation in or .      Consider the system of differential equation given by Find and classify all limit cycles by converting to an autonomous equation in or .      Consider the system    Use polar coordinates to write as a function of . Draw the phase line of the DE , where is the function from part a. Does the system have a limit cycle? If so, find it. If not, explain why not. For each positive root of , decide whether the corresponding trajectory one is stable, unstable, or semistable.    a)  c) Limit cycle at , it is semistable.      Show that the following systems have no closed trajectories.   (2) , , .    a)  b)  , c)        Show that the following systems have no closed trajectories.   (2) , , .      Suppose an autonomous system in the plane has a solution , . What can you say about the system (in particular about limit cycles and periodic solutions)?      Formulate a condition for a 2-by-2 linear system to not be a center using the Bendixson–Dulac theorem. That is, the theorem says something about certain elements of .           Explain why the Bendixson–Dulac Theorem does not apply for any conservative system .     , , so it’s always zero.      A system such as has solutions that exist for all time , yet there are no closed trajectories. Explain why the Poincaré–Bendixson Theorem does not apply.    The solutions are not bounded.      Show that the limit cycle of the Van der Pol oscillator (for ) must not lie completely in the set where . Compare with .      Differential equations can also be given in different coordinate systems. Suppose we have the system , given in polar coordinates. Find all the closed trajectories and check if they are limit cycles and if so, if they are asymptotically stable or not.     is unstable, is asymptotically stable limit cycle      Suppose we have the system , given in polar coordinates. Find all the closed trajectories.     "
},
{
  "id": "limitcycles-section-3",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-3",
  "type": "Example",
  "number": "5.4.1",
  "title": ".",
  "body": "    The Named for the Dutch physicist Balthasar van der Pol (1889–1959). is the following equation where is some positive constant. The Van der Pol oscillator originated with electrical circuits, but finds applications in diverse fields such as biology, seismology, and other physical sciences.  For simplicity, let us use . A phase diagram is given in the left-hand plot in . Notice how the trajectories seem to very quickly settle on a closed curve. On the right-hand side is the plot of a single solution for to with initial conditions and . The solution quickly tends to a periodic solution.    The Van der Pol oscillator is an example of so-called . The word relaxation comes from the sudden jump (the very steep part of the solution). For larger the steep part becomes even more pronounced, for small the limit cycle looks more like a circle. In fact, setting , we get , which is a linear system with a center and all trajectories become circles.   "
},
{
  "id": "limitcycles-section-13",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-13",
  "type": "Example",
  "number": "5.4.2",
  "title": ".",
  "body": "    Consider A vector field along with solutions with initial conditions , , and are drawn in . Analyze this system to determine what will happen to the solution for a variety of initial conditions.      Notice that points on the unit circle (distance one from the origin) satisfy . And , is a solution of the system. Therefore we have a closed trajectory. For points off the unit circle, the second term in pushes the solution further away from the -axis than the system , , and pushes the solution further away from the -axis than the linear system , . In other words for all other initial conditions the trajectory will spiral out.  This means that for initial conditions inside the unit circle, the solution spirals out towards the periodic solution on the unit circle, and for initial conditions outside the unit circle the solutions spiral off towards infinity. Therefore the unit circle is a limit cycle, but not an asymptotically stable one. In relation to the terms used for autonomous equations in , we could refer to this as a semistable limit cycle, since on one side (inside) the solutions spiral towards the periodic orbit, while on the other side (outside) the solutions move away. The Poincaré–Bendixson Theorem applies to the initial points inside the unit circle, as those solutions stay bounded, but not to those outside, as those solutions go off to infinity.   "
},
{
  "id": "limitcycles-section-23",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-23",
  "type": "Example",
  "number": "5.4.3",
  "title": ".",
  "body": "    Let us look at , in the entire plane (see ) and try to apply .    The entire plane is simply connected and so we can apply the theorem. We compute . The function is always positive except on the line . Therefore, via the theorem, the system has no closed trajectories.   "
},
{
  "id": "limitcycles-section-26",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-26",
  "type": "Example",
  "number": "5.4.4",
  "title": ".",
  "body": "    Take the system , (see ) and look at how works here.    We compute . This expression takes on both signs, so if we are talking about the whole plane we cannot simply apply the theorem. However, we could apply it on the set where . Via the theorem, there is no closed trajectory in that set. Similarly, there is no closed trajectory in the set . We cannot conclude (yet) that there is no closed trajectory in the entire plane. Perhaps half of it is in the set where and the other half is in the set where .  The key is to look at the line where , or . On this line and . In particular, when then . That means that the arrows, the vectors , always point into the set where . There is no way we can start in the set where and go into the set where . Once we are in the set where , we stay there. So no closed trajectory can have points in both sets.   "
},
{
  "id": "limitcycles-section-27",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-27",
  "type": "Example",
  "number": "5.4.5",
  "title": ".",
  "body": "    Consider , , and consider the region given by . That is, is the region outside a circle of radius centered at the origin. Then there is a closed trajectory in , namely , . Furthermore, which is always positive on . So what is going on? The Bendixson–Dulac theorem does not apply since the region is not simply connected—it has a hole, the circle we cut out!   "
},
{
  "id": "limitcycles-section-28-2",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-2",
  "type": "Exercise",
  "number": "5.4.1",
  "title": "",
  "body": "  Consider the two-dimensional system of differential equation written in polar coordinates as Determine all limit cycles, periodic solutions, and classify the stability of each of these solutions.     is asymptotically stable, is a periodic solution, but not a limit cycle, is unstable, is semistable, limit cycle from the inside.   "
},
{
  "id": "limitcycles-section-28-3",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-3",
  "type": "Exercise",
  "number": "5.4.2",
  "title": "",
  "body": "  Consider the two-dimensional system of differential equation written in polar coordinates as Determine all limit cycles, periodic solutions, and classify the stability of each of these solutions.     asymptoticallys table, semistable limit cycle, periodic solution, unstable.   "
},
{
  "id": "limitcycles-section-28-4",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-4",
  "type": "Exercise",
  "number": "5.4.3",
  "title": "",
  "body": "  Consider the system of differential equation given by Find and classify all limit cycles by converting to an autonomous equation in or .   "
},
{
  "id": "limitcycles-section-28-5",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-5",
  "type": "Exercise",
  "number": "5.4.4",
  "title": "",
  "body": "  Consider the system of differential equation given by Find and classify all limit cycles by converting to an autonomous equation in or .   "
},
{
  "id": "limitcycles-section-28-6",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-6",
  "type": "Exercise",
  "number": "5.4.5",
  "title": "",
  "body": "  Consider the system    Use polar coordinates to write as a function of . Draw the phase line of the DE , where is the function from part a. Does the system have a limit cycle? If so, find it. If not, explain why not. For each positive root of , decide whether the corresponding trajectory one is stable, unstable, or semistable.    a)  c) Limit cycle at , it is semistable.   "
},
{
  "id": "limitcycles-section-28-7",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-7",
  "type": "Exercise",
  "number": "5.4.6",
  "title": "",
  "body": "  Show that the following systems have no closed trajectories.   (2) , , .    a)  b)  , c)     "
},
{
  "id": "limitcycles-section-28-8",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-8",
  "type": "Exercise",
  "number": "5.4.7",
  "title": "",
  "body": "  Show that the following systems have no closed trajectories.   (2) , , .   "
},
{
  "id": "limitcycles-section-28-9",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-9",
  "type": "Exercise",
  "number": "5.4.8",
  "title": "",
  "body": "  Suppose an autonomous system in the plane has a solution , . What can you say about the system (in particular about limit cycles and periodic solutions)?   "
},
{
  "id": "limitcycles-section-28-10",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-10",
  "type": "Exercise",
  "number": "5.4.9",
  "title": "",
  "body": "  Formulate a condition for a 2-by-2 linear system to not be a center using the Bendixson–Dulac theorem. That is, the theorem says something about certain elements of .        "
},
{
  "id": "limitcycles-section-28-11",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-11",
  "type": "Exercise",
  "number": "5.4.10",
  "title": "",
  "body": "  Explain why the Bendixson–Dulac Theorem does not apply for any conservative system .     , , so it’s always zero.   "
},
{
  "id": "limitcycles-section-28-12",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-12",
  "type": "Exercise",
  "number": "5.4.11",
  "title": "",
  "body": "  A system such as has solutions that exist for all time , yet there are no closed trajectories. Explain why the Poincaré–Bendixson Theorem does not apply.    The solutions are not bounded.   "
},
{
  "id": "limitcycles-section-28-13",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-13",
  "type": "Exercise",
  "number": "5.4.12",
  "title": "",
  "body": "  Show that the limit cycle of the Van der Pol oscillator (for ) must not lie completely in the set where . Compare with .   "
},
{
  "id": "limitcycles-section-28-14",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-14",
  "type": "Exercise",
  "number": "5.4.13",
  "title": "",
  "body": "  Differential equations can also be given in different coordinate systems. Suppose we have the system , given in polar coordinates. Find all the closed trajectories and check if they are limit cycles and if so, if they are asymptotically stable or not.     is unstable, is asymptotically stable limit cycle   "
},
{
  "id": "limitcycles-section-28-15",
  "level": "2",
  "url": "limitcycles-section.html#limitcycles-section-28-15",
  "type": "Exercise",
  "number": "5.4.14",
  "title": "",
  "body": "  Suppose we have the system , given in polar coordinates. Find all the closed trajectories.   "
},
{
  "id": "sec-chaos",
  "level": "1",
  "url": "sec-chaos.html",
  "type": "Section",
  "number": "5.5",
  "title": "Chaos",
  "body": " Chaos   chaosintro  You have surely heard the idea of the butterfly effect, that the flap of a butterfly wing in the Amazon can cause hurricanes in the North Atlantic. In a prior section, we mentioned that a small change in initial conditions of the planets can lead to very different configuration of the planets in the long term. These are examples of . Mathematical chaos is not really chaos, there is precise order behind the scenes. Everything is still deterministic. However a chaotic system is extremely sensitive to initial conditions. This also means even small errors induced via numerical approximation create large errors very quickly, so it is almost impossible to numerically approximate for long times. This is a large part of the trouble, as chaotic systems cannot be in general solved analytically.  Take the weather, the most well-known chaotic system. A small change in the initial conditions (the temperature at every point of the atmosphere for example) produces drastically different predictions in relatively short time, and so we cannot accurately predict weather. And we do not actually know the exact initial conditions. We measure temperatures at a few points with some error, and then we somehow estimate what is in between. There is no way we can accurately measure the effects of every butterfly wing. Then we solve the equations numerically introducing new errors. You should not trust weather prediction more than a few days out.  Chaotic behavior was first noticed by Edward Lorenz  Edward Norton Lorenz (1917–2008) was an American mathematician and meteorologist. in the 1960s when trying to model thermally induced air convection (movement). Lorentz was looking at the relatively simple system: A small change in the initial conditions yields a very different solution after a reasonably short time.   0.95in1.25in  A simple example the reader can experiment with, and which displays chaotic behavior, is a double pendulum. The equations for this setup are somewhat complicated, and their derivation is quite , so we will not bother to write them down. The idea is to put a pendulum on the end of another pendulum. The movement of the bottom mass will appear chaotic. This type of chaotic system is a basis for a whole number of office novelty desk toys. It is simple to build a version. Take a piece of a string. Tie two heavy nuts at different points of the string; one at the end, and one a bit above. Now give the bottom nut a little push. As long as the swings are not too big and the string stays tight, you have a double pendulum system.    Duffing equation and strange attractors  Let us study the so-called : Here , , , , and are constants. Except for the term, this equation looks like a forced mass-spring system. The means the spring does not exactly obey Hooke’s law (which no real-world spring actually does obey exactly). When is not zero, the equation does not have a closed form solution, so we must resort to numerical solutions, as is usual for nonlinear systems. Not all choices of constants and initial conditions exhibit chaotic behavior. Let us study   The equation is not autonomous, so we cannot draw the vector field in the phase plane. We can still draw the trajectories. In we plot trajectories for going from 0 to 15, for two very close initial conditions and , and also the solutions in the space. The two trajectories are close at first, but after a while diverge significantly. This sensitivity to initial conditions is precisely what we mean by the system behaving chaotically.      Let us see the long term behavior. In , we plot the behavior of the system for initial conditions for a longer period of time. It is hard to see any particular pattern in the shape of the solution except that it seems to oscillate, but each oscillation appears quite unique. The oscillation is expected due to the forcing term. We mention that to produce the picture accurately, a ridiculously large number of steps In fact for reference, 30,000 steps were used with the Runge–Kutta algorithm, see exercises in . had to be used in the numerical algorithm, as even small errors quickly propagate in a chaotic system.  It is very difficult to analyze chaotic systems, or to find the order behind the madness, but let us try to do something that we did for the standard mass-spring system. One way we analyzed the system is that we figured out what was the long term behavior (not dependent on initial conditions). From the figure above, it is clear that we will not get a nice exact description of the long term behavior for this chaotic system, but perhaps we can find some order to what happens on each and what do these oscillations have in common.  The concept we explore is that of a  Named for the French polymath Jules Henri Poincaré (1854–1912). . Instead of looking at in a certain interval, we look at where the system is at a certain sequence of points in time. Imagine flashing a strobe at a fixed frequency and drawing the points where the solution is during the flashes. The right strobing frequency depends on the system in question. The correct frequency for the forced Duffing equation (and other similar systems) is the frequency of the forcing term. For the Duffing equation above, find a solution , and look at the points As we are really not interested in the transient part of the solution, that is, the part of the solution that depends on the initial condition, we skip some number of steps in the beginning. For example, we might skip the first 100 such steps and start plotting points at , that is The plot of these points is the Poincaré section. After plotting enough points, a curious pattern emerges in (the left-hand picture), a so-called .    Given a sequence of points, an is a set towards which the points in the sequence eventually get closer and closer to, that is, they are attracted. The Poincaré section is not really the attractor itself, but as the points are very close to it, we see its shape. The strange attractor is a very complicated set. It has fractal structure, that is, if you zoom in as far as you want, you keep seeing the same complicated structure.  The initial condition makes no difference. If we start with a different initial condition, the points eventually gravitate towards the attractor, and so as long as we throw away the first few points, we get the same picture. Similarly small errors in the numerical approximations do not matter here.  An amazing thing is that a chaotic system such as the Duffing equation is not random at all. There is a very complicated order to it, and the strange attractor says something about this order. We cannot quite say what state the system will be in eventually, but given the fixed strobing frequency we narrow it down to the points on the attractor.  If we use a phase shift, for example , and look at the times we obtain a slightly different attractor. The picture is the right-hand side of . It is as if we had rotated, moved, and slightly distorted the original. For each phase shift you can find the set of points towards which the system periodically keeps coming back to.  Study the pictures and notice especially the scales—where are these attractors located in the phase plane. Notice the regions where the strange attractor lives and compare it to the plot of the trajectories in .  Let us compare this section to the discussion in about forced oscillations. Take the equation This is like the Duffing equation, but with no term. The steady periodic solution is of the form Strobing using the frequency , we obtain a single point in the phase space. The attractor in this setting is a single point—an expected result as the system is not chaotic. It was the opposite of chaotic: Any difference induced by the initial conditions dies away very quickly, and we settle into always the same steady periodic motion.    The Lorenz system  In two dimensions to find chaotic behavior, we must study forced, or non-autonomous, systems such as the Duffing equation. The Poincaré–Bendixson Theorem says that a solution to an autonomous two-dimensional system that exists for all time in the future and does not go towards infinity is periodic or tends towards a periodic solution. Hardly the chaotic behavior we are looking for.  In three dimensions even autonomous systems can be chaotic. Let us very briefly return to the The Lorenz system is an autonomous system in three dimensions exhibiting chaotic behavior. See the for a sample trajectory, which is now a curve in three-dimensional space.    The solutions tend to an attractor in space, the so-called . In this case no strobing is necessary. Again we cannot quite see the attractor itself, but if we try to follow a solution for long enough, as in the figure, we get a pretty good picture of what the attractor looks like. The Lorenz attractor is also a strange attractor and has a complicated fractal structure. And, just as for the Duffing equation, what we want to draw is not the whole trajectory, but start drawing the trajectory after a while, once it is close to the attractor.  The path of the trajectory is not simply a repeating figure-eight. The trajectory spins some seemingly random number of times on the left, then spins a number of times on the right, and so on. As this system arose in weather prediction, one can perhaps imagine a few days of warm weather and then a few days of cold weather, where it is not easy to predict when the weather will change, just as it is not really easy to predict far in advance when the solution will jump onto the other side. See for a plot of the component of the solution drawn above. A negative corresponds to the left and a positive corresponds to the right .  Most of the mathematics we studied in this book is quite classical and well understood. On the other hand, chaos, including the Lorenz system, continues to be the subject of current research. Furthermore, chaos has found applications not just in the sciences, but also in art.      Exercises    Find critical points of the Lorenz system and the associated linearizations.      For the non-chaotic equation , suppose we strobe with frequency as we mentioned above. Use the known steady periodic solution to find precisely the point which is the attractor for the Poincaré section.     for , or       Construct the double pendulum described in the text with a string and two nuts (or heavy beads). Play around with the position of the middle nut, and perhaps use different weight nuts. Describe what you find.       A simple fractal attractor can be drawn via the following chaos game. Draw the three vertices of a triangle and label them, say , and . Draw some random point (it does not have to be one of the three points above). Roll a die to pick of the , , or randomly (for example 1 and 4 mean , 2 and 5 mean , and 3 and 6 mean ). Suppose we picked , then let be the point exactly halfway between and . Draw this point and let now refer to this new point . Rinse, repeat. Try to be precise and draw as many iterations as possible. Your points will be attracted to the so-called . A computer was used to run the game for 10,000 iterations to obtain the picture in .        Use a computer software (such as Matlab, Octave, or perhaps even a spreadsheet), plot the solution of the given forced Duffing equation with Euler’s method. Plotting the solution for from 0 to 100 with several different (small) step sizes. Discuss.    You should get very different behavior for similar (small) step sizes becasue the equation is chaotic.     "
},
{
  "id": "sec-chaos-5-2",
  "level": "2",
  "url": "sec-chaos.html#sec-chaos-5-2",
  "type": "Exercise",
  "number": "5.5.4.1",
  "title": "",
  "body": "  Find critical points of the Lorenz system and the associated linearizations.   "
},
{
  "id": "sec-chaos-5-3",
  "level": "2",
  "url": "sec-chaos.html#sec-chaos-5-3",
  "type": "Exercise",
  "number": "5.5.4.2",
  "title": "",
  "body": "  For the non-chaotic equation , suppose we strobe with frequency as we mentioned above. Use the known steady periodic solution to find precisely the point which is the attractor for the Poincaré section.     for , or    "
},
{
  "id": "sec-chaos-5-4",
  "level": "2",
  "url": "sec-chaos.html#sec-chaos-5-4",
  "type": "Exercise",
  "number": "5.5.4.3",
  "title": "",
  "body": "  Construct the double pendulum described in the text with a string and two nuts (or heavy beads). Play around with the position of the middle nut, and perhaps use different weight nuts. Describe what you find.   "
},
{
  "id": "sec-chaos-5-5",
  "level": "2",
  "url": "sec-chaos.html#sec-chaos-5-5",
  "type": "Exercise",
  "number": "5.5.4.4",
  "title": "",
  "body": "  A simple fractal attractor can be drawn via the following chaos game. Draw the three vertices of a triangle and label them, say , and . Draw some random point (it does not have to be one of the three points above). Roll a die to pick of the , , or randomly (for example 1 and 4 mean , 2 and 5 mean , and 3 and 6 mean ). Suppose we picked , then let be the point exactly halfway between and . Draw this point and let now refer to this new point . Rinse, repeat. Try to be precise and draw as many iterations as possible. Your points will be attracted to the so-called . A computer was used to run the game for 10,000 iterations to obtain the picture in .   "
},
{
  "id": "sec-chaos-5-6",
  "level": "2",
  "url": "sec-chaos.html#sec-chaos-5-6",
  "type": "Exercise",
  "number": "5.5.4.5",
  "title": "",
  "body": "  Use a computer software (such as Matlab, Octave, or perhaps even a spreadsheet), plot the solution of the given forced Duffing equation with Euler’s method. Plotting the solution for from 0 to 100 with several different (small) step sizes. Discuss.    You should get very different behavior for similar (small) step sizes becasue the equation is chaotic.   "
},
{
  "id": "the-matlab-interface",
  "level": "1",
  "url": "the-matlab-interface.html",
  "type": "Section",
  "number": "6.1",
  "title": "The MATLAB Interface",
  "body": " The MATLAB Interface  There are many components to the MATLAB interface, and the way that the window is organized can be fully customized. There are four main components of this interface.    Current Folder window. This shows the current folder in which MATLAB is running. This determines what files that MATLAB currently has access to and what functions and methods can be called.    Editor window. This is the main code-editing window, where script files can be written, edited, saved, and run.    Command window. This is where individual lines of code can be entered to see how they work.    Workspace window. This shows a list of all variables that currently exist, as well as their values or sizes.    All four of these components are very useful in organizing thoughts and programming practices while using MATLAB. Both the Default layout and Two-Column layout (as of MATLAB R2019b) contain all four of these windows in different locations. Either of these will work for programming in MATLAB, as well as any modifications of them. The current format can be saved using Layout - Save Layout if needed.  "
},
{
  "id": "file-structure",
  "level": "1",
  "url": "file-structure.html",
  "type": "Section",
  "number": "6.2",
  "title": "File Structure",
  "body": " File Structure  The main type of file used in MATLAB is the Script file. These are saved as *.m files and can represent both stand-alone executable files and functions that can be called from other scripts. For running simple, one-line expressions or debugging code, the Command Window and the command line prompt can be useful. However, for anything more involved and complicated than that, the script editor should be used instead.  In writing a script file or using the Command window, the Current Folder window shows all of the files in the current directory. These are all of the files that MATLAB has access to while running a MATLAB file that it saved in that folder. This means that if a script wants to call a method, it either needs to be a built-in method or a function file that is contained within the same script file or the Current Folder. For more information about writing functions, see Section .  To use script files, multiple lines of code can be entered in a row, and MATLAB will execute them in sequence when the Run button is clicked. This button is in the Editor tab at the top of the screen.  MATLAB Live Scripts can also be used to do very similar things, with some additional benefits. These allow the MATLAB code to be viewed side-by-side with the output, as well as an easy export to PDF functionality. These are saved as *.mlx files. These work the same way as scripts in terms of how code is written, and allow the user to mix between text (which can be resized and formatted) and code. For more information on Live Scripts, see the website https:\/\/www.mathworks.com\/help\/matlab\/matlab_prog\/what-is-a-live-script-or-function.html .  Live Scripts also have the ability to put section breaks between different pieces of code and then run individual sections using the “Run Section\" button at the top of the editor. With Live Scripts, it is necessary to run the entire code (by clicking the run button) before exporting as a PDF in order to get the correct images and outputs in the final PDF. To export, go to Save at the top of the screen, click the down arrow under it, and select Export to PDF  after running the code to regenerate all of the images.  "
},
{
  "id": "file-structure-6",
  "level": "2",
  "url": "file-structure.html#file-structure-6",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "after "
},
{
  "id": "computation-in-matlab",
  "level": "1",
  "url": "computation-in-matlab.html",
  "type": "Section",
  "number": "6.3",
  "title": "Computation in MATLAB",
  "body": " Computation in MATLAB  MATLAB can do many of the simple computational operations that would be expected from a calculator. It is easiest to see these operations by using the Command Window, but they can also be implemented in scripts if desired. Addition and subtraction work in standard ways. In the command line, typing   2 + 3  and pressing ENTER will give an output of   ans = 5  showing the answer of this computation. For any computation or line of code, putting a semi-colon (;) at the end will suppress the output, in that typing   2 + 3;  will not show any output. However, MATLAB did do the computation, which can be shown by storing this output in a variable and doing something with it later.  Multiplication and division, and by extension powers, can work differently in MATLAB. As MATLAB is built around using matrices for calculations and is optimized for this approach, the program interprets all multiplication, division, and exponentiation in terms of matrices as a default. Both components of the multiplication are simple scalars (numbers), then this is fine. The * symbol works for multiplication in this context:   >> 4*6 ans = 24  as well as using \/ for division and ^ for exponentiation. Issues may arise when the code wants to compute products or powers of multiple values at the same time. Many MATLAB built-in functions will automatically combine multiple of the same type of calculation into a vectorized calculation, where if the code wanted to compute the sum of two numbers a bunch of times, it would put all of these numbers into arrays and then add the two vectors together. This completes the task of adding all of the different pairs of numbers together, but saves time by not doing them all individually. This works great for addition and subtraction, because addition and subtraction of arrays or matrices is done element-wise, which is the exact operation we wanted to compute in the first place.  However, mutliplication is different. Matrix multiplication is a different operation that, in particular, is not element-wise multiplication. Beyond that, even if two matrices are the same size, it is possible that their product, in the normal matrix sense, is not defined. In MATLAB, the product   * [4 3 2];  will return an error because the matrices are not the correct size. From a human point of view, the output desired from this code was likely [4 6 6] , the product of each term individually. To obtain this in MATLAB, we need the elementwise operations .* , .\/ and .^ for multipication, division, and exponentiation, respectively. Thus, the following computations can be made in MATLAB   >> [1 2 3] .* [4 3 2] ans = [4 6 6] >> [1 4 6].^2 ans = [1 16 36] >> [5 4 2] .\/ [10 2 6] ans = [0.5 2 0.3333]  There are many built-in functions in MATLAB that can help with computation and algebra.     sqrt(x) will compute the square root of a number .     exp(x) will compute for the base of the natural logarithm, and any number. Note that MATLAB does not know the definition of built-in, so it will either need to be defined (using exp(1) ) or just use exp() whenever it is needed.     abs(x) computes the absolute value of a number .     log(x) computes the natural logarithm of a number . The functions log2 and log10 compute the log base 2 and log base 10 respectively.    Trigonometric functions can also be computed with sin(x) , cos(x) , and tan(x) .    "
},
{
  "id": "variables-and-arrays",
  "level": "1",
  "url": "variables-and-arrays.html",
  "type": "Section",
  "number": "6.4",
  "title": "Variables and Arrays",
  "body": " Variables and Arrays  As with other programming languages, MATLAB utilizes variables to store information and use it later. The name of variables in MATLAB must start with a letter, but the rest of the name can consist of letters, digits, or underscores. Variables should be named suggestively corresponding to what this information is or the way it will be used. Variables do not need to be created in advance, they are created when something is stored in the variable by putting the name on the left side of an equals sign, with the computation that gives rise to that variable on the right. Even though the output is suppressed, the line   val = 2+3;  will store the value 5 in the variable val , where it can be used later. For example,   >> val * 4 ans = 20  >> val^2 + 2 ans = 27  However, trying to use a variable name without defining it first will cause MATLAB to give an error:   >> r Undefined function or variable ’r’.  As variables do not need to be created or instantiated before they are used, any variable can store any type of information. Two of the most common ones are numbers (double precision) or strings.   numVar = sqrt(15); strVar = Hello World! ;  Strings can be stored using either single or double quotes. Strings also have a lot of useful operations that can be used to make some MATLAB programs run more simply, but they are beyond the scope of this introduction. For information about what can be done with strings, see the MATLAB documentation https:\/\/www.mathworks.com\/help\/matlab\/ref\/string.html .  Another common variable data type that MATLAB is very comfortable with is arrays. As described previously, MATLAB defaults to matrices when considering multiplication and exponentiation operations. Arrays can be created using square brackets, with either spaces or commas between the entries.   A = [2,4,6]; B = [1 3 5];  These create horizontal arrays. Vertical arrays can also be created using semi-colons between each entry, and these can be combined with horizontal arrays to create a matrix, or rectangular array of values.   C = [5;7;8]; M = [1,2,3;5,6,7];  In these examples, and will be row arrays (or row vectors) with 3 elements, will be a column vector with elements, and will be a matrix with two rows and three columns. For most situations that don’t involve matrices, row and column vectors will work equivalently, so either one can be used. Once matrices are involved, it matters which one is chosen, because MATLAB will multiply matrices and vectors in the same way that would be carried out mathematically, which means the dimensions need to match.  To access elements of a matrix, parentheses are used. Unlike other programming languages, MATLAB starts indexing elements at 1, not zero. That is, with the above variables C(2) = 7 , since is the second element of the array . In terms of accessing elements of matrices, the first index is the row and the second is the column.   >> M = [1,2,3;5,6,7]; >> M(1,1) ans = 1  >> M(1,3) ans = 3  >> M(2,1) ans = 5  The matrix (and vectors) do have limits on how big they are, and attempting to access an element outside of that range will cause MATLAB to give an error.   >> M(3,1) Index in position 1 exceeds array bounds (must not exceed 2).  Among many other possible variables, another type that can be stored is a handle to a function. How to use functions will be described in Section . The fact that all of these different data types can be stored in variables, with no real indication as to which type a given variable is, means it is critical to name variables carefully with what they correspond to.  "
},
{
  "id": "funMat-section",
  "level": "1",
  "url": "funMat-section.html",
  "type": "Section",
  "number": "6.5",
  "title": "Functions and Anonymous Functions",
  "body": " Functions and Anonymous Functions  A key component to programming in MATLAB is the idea of functions. These are programming objects that will accept a number of inputs (called arguments ) and perform a given set of operations on those arguments, returning some set of ouputs back to the main program. These are mainly used to group code together that has a given purpose and can be called to carry out that purpose on a variety of outputs. An example of a built-in function like this is sum(V) . This function takes in a linear array and will return the number that is the sum of all of the elements in the array (if the array is multi-dimensional, it will only sum along one dimension). This is a piece of code that could be written fairly easily; it would just involve taking the array, looping through it and adding up the value at each index. However, putting it into a function allows it to be called more simply in one line, allowing the main script to focus on the task at hand.  There are two main ways that functions can be written in MATLAB. Functions can either be written at the bottom of the MATLAB script where they will be used or they can be written in their own separate script file. If written in a separate file, there can only be one function in each file, and the name of the file (once saved) must match the name given to the function. To write a function, the reserved word function is used:   function [a,b] = testFunction(x, y, z) end   Note: If this is done in a script by itself, the function line must be the first line of the code. There can be no code or comments above this line.  In this case, the function takes in three inputs and returns two outputs. When writing the code inside the function, the three inputs will be called x, y, and z, and in order to tell the program what to send back to wherever this function was called, those outputs should be stored in variables a and b. For example, a function that takes in three numbers and returns their sum in the first output and the product in the second would look like   function [a,b] = testFunction(x, y, z) a = x+y+z; b = x*y*z; end  and that would work just fine. However, if any other MATLAB methods were going to use this function, there is a chance they would try to pass in array inputs. If so, then there would be an error in computing b , because those products would not be defined. The easiest way to fix this would be to use element-wise products, giving a function that looks like   function [a,b] = testFunction(x, y, z) a = x+y+z; b = x.*y.*z; end  These functions can be as complicated as necessary, including graphs, loops, calls to other functions, and many different components. However, if the function needed is a simple mathematical function, then this can be written in an shorter way with anonymous functions. For example, if the function needed to be coded, it could be written as   f = @(x,y) x.^2 + 4.*x.*y + y.^2;  and this will now make f a handle to the function that does exactly what is desired. If a later line of code is   >> f(2,1) ans = 13  the function value will be computed at the desired point. Notice the use of element-wise operations again in this function definition to ensure that it will also work on array inputs. This works for these simple kinds of functions, and can be easier than adding an entire new function to the script file.  Overall, the following two function definitions are almost equivalent.   fShort = @(x,y) x.^2 + y.^2;   function z = fLong(x,y) z = x.^2 + y.^2; end  The only difference arises when trying to use these functions in built-in or written methods that require a handle to a function. The @ symbol at the beginning of the anonymous function indicates that the thing being defined ( fShort ) is a handle to a function that takes two inputs and computes an output from it. On the other hand, the definition of fLong is a function that does this, and is not a handle to that function. To fix this, an @ symbol needs to be put in-front of fLong before using it in one of these methods. As an example ode45 is a method that numerically computes the solution to a differential equation, and it requires a function handle in the first argument. So, the code   ode45(fShort, [0, 3], 1)  runs fine. However,   ode45(fLong, [0, 3], 1)  throws an error about there being not enough inputs for fLong . This is because whenever MATLAB sees fLong , it is expecting to see two inputs next to it. This is not the case for fShort because of the way it was defined. To remedy this, the code needs to be written   ode45(@fLong, [0, 3], 1)  and then it will execute the same as the first line.  With any of these functions, it is possible to restrict variables and get new functions. This can be fairly easily done with the same setup as for anonymous functions. The line of code   fNew = @(y) fShort(1,y)  will create a new handle for a function of one variable that is fShort when the value is fixed to be 1. The exact same code will work for fLong as you are giving it two inputs.  "
},
{
  "id": "funMat-section-5",
  "level": "2",
  "url": "funMat-section.html#funMat-section-5",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Note: "
},
{
  "id": "loops-and-branching-statements",
  "level": "1",
  "url": "loops-and-branching-statements.html",
  "type": "Section",
  "number": "6.6",
  "title": "Loops and Branching Statements",
  "body": " Loops and Branching Statements   The code written in a MATLAB script will always proceed in order from one line to the next unless there is some alteration to the flow using loops or branching (if) statements.    For Loops  For loops are a form of iterative programming, where MATLAB will run the same bit of code multiple times with an iterative parameter that can change certain things about the code. If there is an element of the program that needs to carry out a process several times in a row, particularly using the previous step to compute the one after it, a for loop might be the best structure to use. A sample for loop has the following form:   for counter = 1:1:10 end  In this line, counter is the variable that is getting incremented over the list. The rest of that line says that counter starts at 1, increments by 1 each loop, and stops after 10. A line of the form counter = 2:5:34 will start at 2, increment by 5 each loop, and stop once the counter gets above 34, so after the iteration when counter = 32 .  In order to loop through an array of values, it is useful to figure out the size of the array and use that to determine how many times the loop should be run. This sort of programming will allow your code to work for a variety of different inputs, no matter the size. This can be done with code like this.   v = [1,2,3,4,5]; for counter = 1:1:length(v) x = v(counter)^2 end  To find how many elements are in an array, the length function will work for a linear array. If the array is more complicated, the size function can be used. This will give a list of values saying how large the array is in each dimension.  MATLAB also has while loops, which allow a loop to run up until a condition becomes false. This is better than for loops in specific situations, but either one can be used. For the code developed here, for loops will be just as easy to write as while loops.    If Statements  If statements, or conditional statements, allow certain parts of code to be executed only if a certain condition is met. For instance, something like   if counter < 5 end  will only execute if the counter is less than 5, and   if mod(counter,2) == 0 end  will only run if counter is even, that is, if the remainder when dividing counter by 2 is zero. Notice that == is used for comparison here to check if two things are equal, while = is used for variable assignment. The condition part of an if statement can be anything that gives back a true or false result. For math operations, these can be any inequalities ( ) or == for testing inequality. The operator is used for not , in that will be true if is not equal to , and false if they are the same. Outside of numbers, there are other MATLAB methods that will give true or false answers. These can be things like comparing strings, but this is beyond the code developed here.   "
},
{
  "id": "plotting-in-matlab",
  "level": "1",
  "url": "plotting-in-matlab.html",
  "type": "Section",
  "number": "6.7",
  "title": "Plotting in MATLAB",
  "body": " Plotting in MATLAB  Graphing in MATLAB always involves plotting a set of points, but these can be fairly easily generated from functions as well. For example   xPts = [1,2,3,4,5]; fx = @(x) x.^2 + 2; yPts = [2,3,2,3,1]; figure(1); plot(xPts, yPts); figure(2); plot(xPts, fx(xPts));  will generate two figures, referred to by the lines figure(1) and figure(2) , and allow the two graphs to be simultaneously drawn without overlapping each other. Any time MATLAB draws a plot (with the plot command) it will overwrite any plot that is already on the target figure. In order to put multiple plots on the same figure, the hold on; and hold off; commands can be used.   xPts = linspace(1,5,100); fx = @(x) x.^2 + 2; gx = @(x) x.^2 - 3*x + 7; figure(1); hold on; plot(xPts, fx(xPts)); plot(xPts, gx(xPts)); hold off;  The linspace generates a list of 100 equally spaced values between 1 and 5 for plotting purposes. It gives an easy way to generate a lot of input values for plotting a smooth-looking graph. It also emphasizes the need to use the element-wise operations in these functions to make sure they all compute correctly.  There are many additional options that can be passed to the plot method in order to change the color, shape, and size of the plot. For these options, refer to the MATLAB documentation on the plot function at https:\/\/www.mathworks.com\/help\/matlab\/ref\/plot.html .  "
},
{
  "id": "supplemental-code-files",
  "level": "1",
  "url": "supplemental-code-files.html",
  "type": "Section",
  "number": "6.8",
  "title": "Supplemental Code Files",
  "body": " Supplemental Code Files  There are eleven supplemental code files provided. In order to use these files in a script or a Live Script, they must be placed in the same folder as the script file, so that the Current Folder window contains both the file being executed and all of these function files. Another option would be to store all of these function files in a single folder, navigating to that folder in the MATLAB Current Folder window, right-clicking on the folder, and selecting Add to Path. The first of these is more recommended, but the second can also work if there is a common repository to store all of the users custom MATLAB functions. The function headers are given below along with a brief description of their use.   function quiver244(f, t_min, t_max, y_min, y_max, col)  The main point of this function is to simplify the process of drawing quiver plots. The code here takes care of the difficulties that arise from the built-in quiver function in MATLAB and allows the user to input the right-hand side of a first order ODE and generate quiver plots. It will draw a quiver plot in the first figure, and a normalized quiver plot (all vectors the same length) in the second figure. It can sometimes be easier to see the general trajectory of solutions from the normalized figure, so both graphs are provided. All of the plotting commands use the hold commands so that they will not overwrite anything on the desired figures. This allows the overlaying of multiple plots, but means that the code calling this method must clear the figure if it needs to be cleared.  This code can be used as   f = @(t,y) t - exp(y); quiver244(f, 0, 5, -6, 6, ’b’);   quiver244(@f2, 0, 5, -6, 6, ’b’);  function z = f2(t,y) z = t - exp(y); end  In each case, the ‘b’ indicates that the quiver plot will be drawn in blue, and the 1 before that indicates that the two plots will be drawn on figures 1 and 2.   function samplePlots244(f, t_min, t_max, y_min, y_max, t_0, y_0, col)  This function follows the same setup as quiver244 , but draws sample trajectories of the solution instead of the quiver plot. It will take initial conditions as . For a single , a vector of initial values can be passed in and the function will work correctly. This function can be used as   f = @(t,y) y.*(y-5).*(y+6); samplePlots244(f, -1, 6, -7, 6, 0, [-1,0.5,4,5], ’r’)  The ‘r’ here indicates that this plot will be drawn in red and put on figure 2. If this is combined with the quiver244 method, then it will overlay these red curves on top of the quiver plot drawn on figure 2.   function bifDiag244(f, a_min, a_max, y_min, y_max)  This function will draw a bifurcation diagram for the given differential equation. Note: This function will need the optimization tool-box add-on for MATLAB in order to run correctly. As with the previous methods, it will not overwrite the figure. Example implementation:   f = @(a,y) y.^2 - a.^2; bifDiag244(f, -3, 3, -5, 5, 3);   function quiver2D244(f,g, x_min, x_max, y_min, y_max, col)  This function does the same concept as quiver244 but for the autonomous system of differential equations Example implementation:   f = @(x,y) 3.*x - 2.*x.*y; g = @(x,y) 2.*y - 3.*x.*y; quiver2D244(f,g, 0, 5, 0, 5, ’g’);   function phaseLine(f, ymin, ymax)  This function draws a representation of the phase line for an autonomous first order differential equation from to . Example implementation:   f = @(y) y.*(y-3).*(y+2); phaseLine(f, -4, 5);   function phasePortrait244(F, G, xmin, xmax, ymin, ymax, tmin, tmax, x0, y0)  This function draws a phase portrait for the two-component autonomous system and . The axes are fixed at and . Solution curves are drawn starting at the (potential list of) points and , and will assume these happen at . The curves are drawn from to , and there will be a black dot plotted at to indicate the direction of flow. Example implementation:   f = @(x,y) 2.*x - 3.* y; g = @(x,y) -3.*x + y; phasePortrait244(f, g, -3, 3, -3, 3, -2, 2, [1, 0, -1, 1, 0, -1], [1,1,1,-1,-1,-1]);   function [t, y] = rungeKuttaMethod(f, dt, Tf, T0, y0)   function [t,y] = rungeKuttaSystemMethod(f, T0, Tf, dt, y0)  These two methods use the Runge-Kutta method to numerically solve the differential equation or the system . It will return the list of and values that are generated by this method.   function [S,I,R] = SIRModel_244(r, c, ICs, Tf)   function [S,I,Q,R,D] = SIRQModel_244(alpha, beta, gamma, delta, eta, rho, ICs, Tf)   function [S,I,Q,R,D] = SIRQVModel_244(alpha, beta, gamma, delta, eta, rho, zeta, ICs, Tf)  Each of these last three methods use the Runge Kutta method to numerical solve a disease modeling problem with their respective equations. The shared arguments are the initial conditions, which are a three or five component vector depending on the problem type, and the final time . The step-size used is one day, and the method will return the list of time-stepped values for each population (every day) from to . For , the equations are For SIRQ, the equations are and for SIRQV, it is An example implementation is   = SIRModel_244(0.1, 0.2, [0.99; 0.01; 0], 400); [S,I,Q,R,D] = SIRQModel_244(0.15, 0.08, 0.02, 0.03, 0.01, 0.04, [0.95; 0.05; 0; 0; 0], 400); [S,I,Q,R,D] = SIRQVModel_244(0.15, 0.08, 0.02, 0.03, 0.01, 0.04,0.2, [0.95; 0.05; 0; 0; 0], 400);  "
},
{
  "id": "supplemental-code-files-15",
  "level": "2",
  "url": "supplemental-code-files.html#supplemental-code-files-15",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Note: "
},
{
  "id": "sec-polys",
  "level": "1",
  "url": "sec-polys.html",
  "type": "Section",
  "number": "7.1",
  "title": "Polynomials and Factoring",
  "body": " Polynomials and Factoring   There are several components of differential equations, particularly higher order equations and systems, that involve dealing with and finding roots of polynomials, using these results to generate solutions to differential equations. This appendix will review some properties of and techniques related to polynomials.    Definitions and Operations  First we start with the definition of a polynomial. A polynomial is a sum of terms each of which is a real number or a real number multiplied by one or more variables to natural number powers. Some examples of polynomials are , and . Things like , and are not polynomials. Below, we review some terminology about polynomials.      Terms in polynomials without variables are called constant terms.    In non-constant terms, the real number factor in the expression is called the coefficient of the term.    The degree of a non-constant term is the sum of the exponents on the variables in the term; non-zero constant terms are defined to have degree . The degree of a polynomial is the highest degree of the nonzero terms.    Terms in a polynomial are called like terms if they have the same variables each with the same corresponding exponents.    A polynomial is said to be simplified if all arithmetic operations have been completed and there are no longer any like terms.    A simplified polynomial is called a      monomial if it has exactly one nonzero term     binomial if it has exactly two nonzero terms     trinomial if it has exactly three nonzero terms        For example, is a trinomial of degree . The coefficient of is and the constant term is . The polynomial is a binomial of degree ( ) with constant term .  The concept of like terms really amounts to finding terms which can be combined using the Distributive Property. For example, in the polynomial , and are like terms, since they have the same variables with the same corresponding exponents. This allows us to combine these two terms as follows: Note that even though and have the same variables, they are not like terms since in the first term we have and but in the second we have and so the corresponding exponents aren’t the same. Hence, is the simplified form of the polynomial.  There are four basic operations we can perform with polynomials: addition, subtraction, multiplication and division. Addition, subtraction, and multiplication follow the standard properties of real numbers after distributing or expanding all terms (for multiplication) and then collecting like terms again. Division, on the other hand, is a bit more complicated and will be discussed next.    Polynomial Long Division  We now turn our attention to polynomial long division. Dividing two polynomials follows the same algorithm, in principle, as dividing two natural numbers so we review that process first. Suppose we wished to divide by . The standard division tableau is given below.     In this case, is called the divisor , is called the dividend , is called the quotient and is called the remainder . We can check our answer by showing: or in this case, . We hope that the long division tableau evokes warm, fuzzy memories of your formative years as opposed to feelings of hopelessness and frustration. If you experience the latter, keep in mind that the Division Algorithm essentially is a two-step process, iterated over and over again. First, we guess the number of times the divisor goes into the dividend and then we subtract off our guess. We repeat those steps with what’s left over until what’s left over (the remainder) is less than what we started with (the divisor). That’s all there is to it!  The division algorithm for polynomials has the same basic two steps but when we subtract polynomials, we must take care to subtract like terms only. As a transition to polynomial division, let’s write out our previous division tableau in expanded form.     Written this way, we see that when we line up the digits we are really lining up the coefficients of the corresponding powers of - much like how we’ll have to keep the powers of lined up in the same columns. The big difference between polynomial division and the division of natural numbers is that the value of is an unknown quantity. So unlike using the known value of , when we subtract there can be no regrouping of coefficients as in our previous example. (The subtraction requires us to regroup or borrow from the tens digit, then the hundreds digit.) This actually makes polynomial division easier. In our opinion - you can judge for yourself. Before we dive into examples, we first state a theorem telling us when we can divide two polynomials, and what to expect when we do so.   Polynomial Division Let and be nonzero polynomials where the degree of is greater than or equal to the degree of . There exist two unique polynomials, and , such that where either or the degree of is strictly less than the degree of .  Essentially, Theorem tells us that we can divide polynomials whenever the degree of the divisor is less than or equal to the degree of the dividend. We know we’re done with the division when the polynomial left over (the remainder) has a degree strictly less than the divisor. It’s time to walk through a few examples to refresh your memory.      Perform the indicated division. Check your answer by showing    2                 2           .          To begin , we divide the first term in the dividend, namely , by the first term in the divisor, namely , and get . This then becomes the first term in the quotient. We proceed as in regular long division at this point: we multiply the entire divisor, , by this first term in the quotient to get . We then subtract this result from the dividend.   Now we bring down the next term of the quotient, namely , and repeat the process. We divide , and add this to the quotient polynomial, multiply it by the divisor (which yields ) and subtract.   Finally, we bring down the last term of the dividend, namely , and repeat the process. We divide , add this to the quotient, multiply it by the divisor (which yields ) and subtract.   In this case, we get a quotient of with a remainder of . To check our answer, we compute     To compute , we start as before. We find , so that becomes the first (and only) term in the quotient. We multiply the divisor by and get . We subtract this from the divided and get .   Our answer is with a remainder of . To check our answer, we compute     When we set-up the tableau for , we must first issue a placeholder for the missing  -term in the dividend, . We then proceed as before. Since , is the first term in our quotient. We multiply times and subtract it from the dividend. We bring down the , and repeat.   Our answer is with a remainder of . To check our answer, we compute:       For our last example, we need placeholders for both the divisor and the dividend . The first term in the quotient is , and when we multiply and subtract this from the dividend, we’re left with just .     Since the degree of (which is ) is less than the degree of the divisor (which is ), we are done. Since , we could proceed, write our quotient as , and move on…but even pedants have limits. Our answer is with a remainder of . To check, we compute:            Synthetic Division  Usually, when we want to divide polynomials, it is because we are trying to find all roots of a polynomial. This comes from the idea that if we have a polynomial and a value so that , then is a root of the polynomial. This means that is a factor of , so that we can write where is a polynomial with one lower degree than . We can find this by dividing which is why we need division to sort this out.  This means that we need to find the roots (or at least a root) to know what to divide by in order to start this process. The main theorem that can tell us where to start is the Rational Roots Theorem.   Rational Zeros Theorem Suppose is a polynomial of degree with , and , , … are integers. If is a rational zero of , then is of the form , where is a factor of the constant term , and is a factor of the leading coefficient .  The Rational Zeros Theorem gives us a list of numbers to try in our synthetic division and that is a lot nicer than simply guessing. If none of the numbers in the list are zeros, then either the polynomial has no real zeros at all, or all of the real zeros are irrational numbers.      Let . Use the Rational Zeros Theorem to list all of the possible rational zeros of .    To generate a complete list of rational zeros, we need to take each of the factors of constant term, , and divide them by each of the factors of the leading coefficient . The factors of are and . Since the Rational Zeros Theorem tacks on a anyway, for the moment, we consider only the positive factors and . The factors of are and , so the Rational Zeros Theorem gives the list or .    But this still doesn’t make the process easy or straight-forward for finding the roots. How can we take this list of options and easily figure out where the roots are, and what the remaining polynomial is?  We start by way of example: suppose we wish to determine the zeros of . Setting results in the polynomial equation . Despite all of the factoring techniques we learned (and forgot!), this equation foils pun intended us at every turn. Knowing that the zeros of correspond to -intercepts on the graph of , we use a graphing utility to produce the graph below on the left. The graph suggests that the function has three zeros, one of which appears to be and two others for whom we are provided what we assume to be decimal approximations: and . We can verify if these are zeros easily enough. We find , but and , While these last two values are probably by some measures, close to , they are not exactly equal to . The question becomes: is there a way to use the fact that is a zero to obtain the other two zeros? Based on our experience, if is a zero, it seems that there should be a factor of lurking around in the factorization of . In other words, we should expect that , where is some other polynomial. How could we find such a , if it even exists? The answer comes from our old friend, polynomial division. Below on the right, we perform the long division: and obtain .               Said differently, . Using this form of , we find the zeros by solving . Setting each factor equal to , we get (which gives us our known zero, ) as well as . The latter doesn’t factor nicely, so we apply the Quadratic Formula to get . Sure enough, and . We leave it to the reader to show and .  The point of this section is to generalize the technique applied here. First up is a friendly reminder of what we can expect when we divide polynomials.   Suppose and are nonzero polynomial functions where the degree of is greater than or equal to the degree of . There exist two unique polynomial functions, and , such that where either or the degree of is strictly less than the degree of .  As you may recall, all of the polynomials in Theorem have special names. The polynomial is called the dividend ; is the divisor ; is the quotient ; is the remainder . If then is called a factor of . The word unique here is critical in that it guarantees there is only one quotient and remainder for each division problem. Hence the use of the definite article the when speaking of the quotient and the remainder. The proof of Theorem is usually relegated to a course in Abstract Algebra, but we can still use the result to move forward with the rest of this section.  If we want to find all of the roots of a polynomial in a reasonable way, we had better find a more efficient way to divide polynomial functions by quantities of the form . Fortunately, people like Ruffini and Horner have already blazed this trail. Let’s take a closer look at the long division we performed at the beginning of the section and try to streamline it. First off, let’s change all of the subtractions into additions by distributing through the s.     Next, observe that the terms , and are the exact opposite of the terms above them. The algorithm we use ensures this is always the case, so we can omit them without losing any information. Also note that the terms we bring down (namely the and ) aren’t really necessary to recopy, so we omit them, too.     Let’s move terms up a bit and copy the into the last row.     Note that by arranging things in this manner, each term in the last row is obtained by adding the two terms above it. Notice also that the quotient polynomial can be obtained by dividing each of the first three terms in the last row by and adding the results. If you take the time to work back through the original division problem, you will find that this is exactly the way we determined the quotient polynomial. This means that we no longer need to write the quotient polynomial down, nor the in the divisor, to determine our answer.     We’ve streamlined things quite a bit so far, but we can still do more. Let’s take a moment to remind ourselves where the , and came from in the second row. Each of these terms was obtained by multiplying the terms in the quotient, , and , respectively, by the in , then by when we changed the subtraction to addition. Multiplying by then by is the same as multiplying by , so we replace the in the divisor by . Furthermore, the coefficients of the quotient polynomial match the coefficients of the first three terms in the last row, so we now take the plunge and write only the coefficients of the terms to get     We have constructed a synthetic division tableau for this polynomial division problem. Let’s re-work our division problem using this tableau to see how it greatly streamlines the division process. To divide by , we write in the place of the divisor and the coefficients of in for the dividend. Then bring down the first coefficient of the dividend.                Next, take the from the divisor and multiply by the that was brought down to get . Write this underneath the , then add to get .                Now take the from the divisor times the to get , and add it to the to get .                Finally, take the in the divisor times the to get , and add it to the to get .                The first three numbers in the last row of our tableau are the coefficients of the quotient polynomial. Remember, we started with a third degree polynomial and divided by a first degree polynomial, so the quotient is a second degree polynomial. Hence the quotient is . The number in the box is the remainder. Synthetic division is our tool of choice for dividing polynomials by divisors of the form . It is important to note that it works only for these kinds of divisors. You’ll need to use good old-fashioned polynomial long division for divisors of degree larger than 1. Also take note that when a polynomial (of degree at least ) is divided by , the result will be a polynomial of exactly one less degree. Finally, it is worth the time to trace each step in synthetic division back to its corresponding step in long division. While the authors have done their best to indicate where the algorithm comes from, there is no substitute for working through it yourself.      Use synthetic division to perform the following polynomial divisions. Identify the quotient and remainder.   3                          When setting up the synthetic division tableau, the coefficients of even missing terms need to be accounted for, so we enter for the coefficient of in the dividend.     Since the dividend was a third degree polynomial function, the quotient is a second degree (quadratic) polynomial function with coefficients , and : . The remainder is . According to Theorem , we have , which we leave to the reader to check.    To use synthetic division here, we rewrite as and proceed as before     We get the quotient and the remainder . Relating the dividend, quotient and remainder gives: , which is a specific instance of the sum of cubes formula some of you may recall.    To divide by , two things must be done. First, we write the dividend in descending powers of as . Second, since synthetic division works only for factors of the form , we factor as . Hence, we are dividing by two factors: and . Dividing first by , we obtain . Next, we divide by :     Hence, . However when it comes to writing the dividend, quotient and remainder in the form given in Theorem , we need to find and so that . Hence, starting with , we multiply back on both sides:     At this stage, we have written in the form  , so we identify the quotient as and the remainder is . But how can we be sure these are the same quotient and remainder polynomial functions we would have obtained if we had taken the time to do the long division in the first place? Because of the word unique in Theorem . The theorem states that there is only one way to decompose as . Since we have found such a way, we can be sure it is the only way. But it wouldn’t hurt to check, just this once.        The next example pulls together all of the concepts discussed in this section.      Let .     Find using The Remainder Theorem. Check your answer by substitution.    Verify is a zero of and use this information to all the real zeros of .          The Remainder Theorem states is the remainder when is divided by . We set up our synthetic division tableau below. We are careful to record the coefficient of as :     According to the Remainder Theorem, . We can check this by direct substitution into the formula for : .    We verify is a zero of by evaluating . To see if there are any more real zeros, we need to solve . From the Factor Theorem, we know since , we can factor as . To find , we use synthetic division:     As promised, our remainder is , and we get . Setting this form of equal to we get . We recover from setting but we also obtain from , courtesy of the Quadratic Formula.       Our next example demonstrates how we can extend the synthetic division tableau to accommodate zeros of multiplicity greater than .      Let . Show is a zero of multiplicity and find all of the remaining real zeros of .    While computing shows is a zero of , to prove it has multiplicity , we need to factor with ,. We set up for synthetic division, but instead of stopping after the first division, we continue the tableau downwards and divide directly into the quotient we obtained from the first division as follows:     We get: For those wanting more detail: the first division gives: . The second division gives: .  . Note if we let , then which proves is a zero of of multiplicity . To find the remaining zeros of , we set the quotient , so and extract square roots to get .    One last wrinkle in this process is complex roots, since it is possible for a polynomial (particularly a quadratic polynomial) to have complex numbers as roots. For a reminder of some more properties of complex numbers see . For this section in particular, we only need a few basic facts.  For us, it suffices to review the basic vocabulary.      The imaginary unit satisfies the two following properties          If is a real number with then        The complex numbers are the set of numbers     Given a complex number , the complex conjugate of , .     Note that every real number is a complex number, that is . To see this, take your favorite real number, say . We may write which puts in the form . Hence, we we speak of the complex zeros of a polynomial function, we are talking about not just the non-real, but also the real zeros.  Complex numbers, by their very definition, are two dimensional creatures. To see this, we may identify a complex number with the point in the Cartesian plane . The horizontal axis is called the real axis since points here have the form which corresponds to numbers of the form which are the real numbers. The vertical axis is called the imaginary axis since points here are of the form which correspond to numbers of the form , the so-called purely imaginary numbers. Below we plot some complex numbers on this so-called Complex Plane. Plotting a set of complex numbers this way is called an Argand Diagram , and opens up a wealth of opportunities to explore many algebraic properties of complex numbers geometrically. For example, complex conjugation amounts to a reflection about the real axis, and multiplication by amounts to a rotation. While we won’t have much use for the Complex Plane in this section, it is worth introducing this concept now, if, for no other reason, it gives the reader a sense of the vastness of the complex number system and the role of the real numbers in it.  Returning to zeros of polynomials, suppose we wish to find the zeros of . To solve the equation , we note that the quadratic doesn’t factor nicely, so we resort to the Quadratic Formula and obtain Two things are important to note. First, the zeros and are complex conjugates. If ever we obtain non-real zeros to a quadratic function with real number coefficients, the zeros will be a complex conjugate pair. (Do you see why?)  We could ask if all of the theory of polynomial division holds for non-real zeros, in particular the division algorithm and the Remainder and Factor Theorems. The answer is yes.      Indeed, the above shows which demonstrates both and are factors of . It is a good review of the algebra of complex numbers to start with , perform the indicated operations, and simplify the result to . See part 6 of Example .   But how do we know if a general polynomial has any complex zeros at all? We have many examples of polynomials with no real zeros. Can there be polynomials with no zeros whatsoever? The answer to that last question is No. and the theorem which provides that answer is The Fundamental Theorem of Algebra.   The Fundamental Theorem of Algebra Suppose is a polynomial function with complex number coefficients of degree , then has at least one complex zero.  The Fundamental Theorem of Algebra is an example of an existence theorem in Mathematics. Like the Intermediate Value Theorem, the Fundamental Theorem of Algebra guarantees the existence of at least one zero, but gives us no algorithm to use in finding it. In fact, as we mentioned previously, there are polynomials whose real zeros, though they exist, cannot be expressed using the usual combinations of arithmetic symbols, and must be approximated. It took mathematicians literally hundreds of years to prove the theorem in its full generality, So if its profound nature and beautiful subtlety escape you, no worries! and some of that history is recorded . Note that the Fundamental Theorem of Algebra applies to not only polynomial functions with real coefficients, but to those with complex number coefficients as well.  Suppose is a polynomial function of degree . The Fundamental Theorem of Algebra guarantees us at least one complex zero, . The Factor Theorem guarantees that factors as for a polynomial function , which has degree . If , then the Fundamental Theorem of Algebra guarantees a complex zero of as well, say , so then the Factor Theorem gives us , and hence . We can continue this process exactly times, at which point our quotient polynomial has degree so it’s a constant. This constant is none-other than the leading coefficient of which is carried down line by line each time we divide by factors of the form .   Complex Factorization Theorem Suppose is a polynomial function with complex number coefficients. If the degree of is and , then has exactly complex zeros, counting multiplicity. If , , …, are the distinct zeros of , with multiplicities , , …, , respectively, then .  Theorem says two important things: first, every polynomial is a product of linear factors; second, every polynomial function is completely determined by its zeros, their multiplicities, and its leading coefficient. We put this theorem to good use in the next example.      Let .     Find all of the complex zeros of and state their multiplicities.    Factor using Theorem           Since is a fifth degree polynomial, we know that we need to perform at least three successful divisions to get the quotient down to a quadratic function. At that point, we can find the remaining zeros using the Quadratic Formula, if necessary. Using the techniques of synthetic division:     Our quotient is , whose zeros we find to be . From Theorem , we know has exactly zeros, counting multiplicities, and as such we have the zero with multiplicity , and the zeros , and , each of multiplicity .    Applying Theorem , we are guaranteed that factors as          A true test of Theorem would be to take the factored form of in the previous example and multiply it out This is a good chance to test your algebraic mettle and see that all of this does actually work. to see that it really does reduce to . When factoring a polynomial using Theorem , we say that it is factored completely over the complex numbers , meaning that it is impossible to factor the polynomial any further using complex numbers. If we wanted to completely factor over the real numbers then we would have stopped short of finding the nonreal zeros of and factored using our work from the synthetic division to write , or . Since the zeros of are nonreal, we call an irreducible quadratic meaning it is impossible to break it down any further using real numbers.  The last two results of the section show us that, theoretically, the non-real zeros of polynomial functions with real number coefficients come exclusively from irreducible quadratics.   Conjugate Pairs Theorem If is a polynomial function with real number coefficients and is a complex zero of , then so is .  To prove the theorem, let be a polynomial function with real number coefficients. If is a zero of , then , which means . Next, we consider and apply Theorem below.     This shows that is a zero of . So, if is a polynomial function with real number coefficients, Theorem tells us that if is a nonreal zero of , then so is . In other words, nonreal zeros of come in conjugate pairs. The Factor Theorem kicks in to give us both and as factors of which means is an irreducible quadratic factor of . As a result, we have our last theorem of the section.   Real Factorization Theorem Suppose is a polynomial function with real number coefficients. Then can be factored into a product of linear factors corresponding to the real zeros of and irreducible quadratic factors which give the nonreal zeros of .      Let .     Use synthetic division to show that is a zero of .    Find the remaining complex zeros of .    Completely factor over the complex numbers.    Completely factor over the real numbers.          Remembering to insert the ’s in the synthetic division tableau we have       Since is a fourth degree polynomial, we need to make two successful divisions to get a quadratic quotient. Since is a zero, we know from Theorem that is also a zero. We continue our synthetic division tableau.     Our quotient polynomial is . Using the quadratic formula, we solve and find the remaining zeros are and .    Using Theorem , we get .    To find the irreducible quadratic factors of , we multiply the factors together which correspond to the conjugate pairs. We find , and , so .       We close this section with an example where we are asked to manufacture a polynomial function with certain characteristics.      Find a polynomial function of lowest degree that has integer coefficients and satisfies all of the following criteria:     the graph of touches and rebounds from the -axis at      is a zero of .    as ,     as ,          To solve this problem, we will need a good understanding of the relationship between the -intercepts of the graph of a function and the zeros of a function, the Factor Theorem, the role of multiplicity, complex conjugates, the Complex Factorization Theorem, and end behavior of polynomial functions. (In short, you’ll need most of the major concepts of this chapter.) Since the graph of touches the -axis at , we know is a zero of even multiplicity. Since we are after a polynomial of lowest degree, we need to have multiplicity exactly . The Factor Theorem now tells us is a factor of . Since is a zero and our final answer is to have integer (hence, real) coefficients, is also a zero. The Factor Theorem kicks in again to give us and as factors of . We are given no further information about zeros or intercepts so we conclude, by the Complex Factorization Theorem that for some real number . Expanding this, we get . In order to obtain integer coefficients, we know must be an integer multiple of . Our last concern is end behavior. Since the leading term of is , we need to get as . Hence, if we choose , we get . We can verify our handiwork using the techniques developed in this chapter.     "
},
{
  "id": "polynomial-long-division-10",
  "level": "2",
  "url": "sec-polys.html#polynomial-long-division-10",
  "type": "Example",
  "number": "7.1.1",
  "title": ".",
  "body": "    Perform the indicated division. Check your answer by showing    2                 2           .          To begin , we divide the first term in the dividend, namely , by the first term in the divisor, namely , and get . This then becomes the first term in the quotient. We proceed as in regular long division at this point: we multiply the entire divisor, , by this first term in the quotient to get . We then subtract this result from the dividend.   Now we bring down the next term of the quotient, namely , and repeat the process. We divide , and add this to the quotient polynomial, multiply it by the divisor (which yields ) and subtract.   Finally, we bring down the last term of the dividend, namely , and repeat the process. We divide , add this to the quotient, multiply it by the divisor (which yields ) and subtract.   In this case, we get a quotient of with a remainder of . To check our answer, we compute     To compute , we start as before. We find , so that becomes the first (and only) term in the quotient. We multiply the divisor by and get . We subtract this from the divided and get .   Our answer is with a remainder of . To check our answer, we compute     When we set-up the tableau for , we must first issue a placeholder for the missing  -term in the dividend, . We then proceed as before. Since , is the first term in our quotient. We multiply times and subtract it from the dividend. We bring down the , and repeat.   Our answer is with a remainder of . To check our answer, we compute:       For our last example, we need placeholders for both the divisor and the dividend . The first term in the quotient is , and when we multiply and subtract this from the dividend, we’re left with just .     Since the degree of (which is ) is less than the degree of the divisor (which is ), we are done. Since , we could proceed, write our quotient as , and move on…but even pedants have limits. Our answer is with a remainder of . To check, we compute:         "
},
{
  "id": "synthetic-division-6",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-6",
  "type": "Example",
  "number": "7.1.2",
  "title": ".",
  "body": "    Let . Use the Rational Zeros Theorem to list all of the possible rational zeros of .    To generate a complete list of rational zeros, we need to take each of the factors of constant term, , and divide them by each of the factors of the leading coefficient . The factors of are and . Since the Rational Zeros Theorem tacks on a anyway, for the moment, we consider only the positive factors and . The factors of are and , so the Rational Zeros Theorem gives the list or .   "
},
{
  "id": "synthetic-division-9",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-9",
  "type": "Table",
  "number": "7.1.3",
  "title": "",
  "body": "            "
},
{
  "id": "synthetic-division-25",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-25",
  "type": "Table",
  "number": "7.1.4",
  "title": "",
  "body": "            "
},
{
  "id": "synthetic-division-27",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-27",
  "type": "Table",
  "number": "7.1.5",
  "title": "",
  "body": "            "
},
{
  "id": "synthetic-division-29",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-29",
  "type": "Table",
  "number": "7.1.6",
  "title": "",
  "body": "            "
},
{
  "id": "synthetic-division-31",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-31",
  "type": "Table",
  "number": "7.1.7",
  "title": "",
  "body": "            "
},
{
  "id": "synthetic-division-33",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-33",
  "type": "Example",
  "number": "7.1.8",
  "title": ".",
  "body": "    Use synthetic division to perform the following polynomial divisions. Identify the quotient and remainder.   3                          When setting up the synthetic division tableau, the coefficients of even missing terms need to be accounted for, so we enter for the coefficient of in the dividend.     Since the dividend was a third degree polynomial function, the quotient is a second degree (quadratic) polynomial function with coefficients , and : . The remainder is . According to Theorem , we have , which we leave to the reader to check.    To use synthetic division here, we rewrite as and proceed as before     We get the quotient and the remainder . Relating the dividend, quotient and remainder gives: , which is a specific instance of the sum of cubes formula some of you may recall.    To divide by , two things must be done. First, we write the dividend in descending powers of as . Second, since synthetic division works only for factors of the form , we factor as . Hence, we are dividing by two factors: and . Dividing first by , we obtain . Next, we divide by :     Hence, . However when it comes to writing the dividend, quotient and remainder in the form given in Theorem , we need to find and so that . Hence, starting with , we multiply back on both sides:     At this stage, we have written in the form  , so we identify the quotient as and the remainder is . But how can we be sure these are the same quotient and remainder polynomial functions we would have obtained if we had taken the time to do the long division in the first place? Because of the word unique in Theorem . The theorem states that there is only one way to decompose as . Since we have found such a way, we can be sure it is the only way. But it wouldn’t hurt to check, just this once.       "
},
{
  "id": "synthetic-division-35",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-35",
  "type": "Example",
  "number": "7.1.9",
  "title": ".",
  "body": "    Let .     Find using The Remainder Theorem. Check your answer by substitution.    Verify is a zero of and use this information to all the real zeros of .          The Remainder Theorem states is the remainder when is divided by . We set up our synthetic division tableau below. We are careful to record the coefficient of as :     According to the Remainder Theorem, . We can check this by direct substitution into the formula for : .    We verify is a zero of by evaluating . To see if there are any more real zeros, we need to solve . From the Factor Theorem, we know since , we can factor as . To find , we use synthetic division:     As promised, our remainder is , and we get . Setting this form of equal to we get . We recover from setting but we also obtain from , courtesy of the Quadratic Formula.      "
},
{
  "id": "synthetic-division-37",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-37",
  "type": "Example",
  "number": "7.1.10",
  "title": ".",
  "body": "    Let . Show is a zero of multiplicity and find all of the remaining real zeros of .    While computing shows is a zero of , to prove it has multiplicity , we need to factor with ,. We set up for synthetic division, but instead of stopping after the first division, we continue the tableau downwards and divide directly into the quotient we obtained from the first division as follows:     We get: For those wanting more detail: the first division gives: . The second division gives: .  . Note if we let , then which proves is a zero of of multiplicity . To find the remaining zeros of , we set the quotient , so and extract square roots to get .   "
},
{
  "id": "synthetic-division-53",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-53",
  "type": "Example",
  "number": "7.1.11",
  "title": ".",
  "body": "    Let .     Find all of the complex zeros of and state their multiplicities.    Factor using Theorem           Since is a fifth degree polynomial, we know that we need to perform at least three successful divisions to get the quotient down to a quadratic function. At that point, we can find the remaining zeros using the Quadratic Formula, if necessary. Using the techniques of synthetic division:     Our quotient is , whose zeros we find to be . From Theorem , we know has exactly zeros, counting multiplicities, and as such we have the zero with multiplicity , and the zeros , and , each of multiplicity .    Applying Theorem , we are guaranteed that factors as         "
},
{
  "id": "synthetic-division-61",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-61",
  "type": "Example",
  "number": "7.1.12",
  "title": ".",
  "body": "    Let .     Use synthetic division to show that is a zero of .    Find the remaining complex zeros of .    Completely factor over the complex numbers.    Completely factor over the real numbers.          Remembering to insert the ’s in the synthetic division tableau we have       Since is a fourth degree polynomial, we need to make two successful divisions to get a quadratic quotient. Since is a zero, we know from Theorem that is also a zero. We continue our synthetic division tableau.     Our quotient polynomial is . Using the quadratic formula, we solve and find the remaining zeros are and .    Using Theorem , we get .    To find the irreducible quadratic factors of , we multiply the factors together which correspond to the conjugate pairs. We find , and , so .      "
},
{
  "id": "synthetic-division-63",
  "level": "2",
  "url": "sec-polys.html#synthetic-division-63",
  "type": "Example",
  "number": "7.1.13",
  "title": ".",
  "body": "    Find a polynomial function of lowest degree that has integer coefficients and satisfies all of the following criteria:     the graph of touches and rebounds from the -axis at      is a zero of .    as ,     as ,          To solve this problem, we will need a good understanding of the relationship between the -intercepts of the graph of a function and the zeros of a function, the Factor Theorem, the role of multiplicity, complex conjugates, the Complex Factorization Theorem, and end behavior of polynomial functions. (In short, you’ll need most of the major concepts of this chapter.) Since the graph of touches the -axis at , we know is a zero of even multiplicity. Since we are after a polynomial of lowest degree, we need to have multiplicity exactly . The Factor Theorem now tells us is a factor of . Since is a zero and our final answer is to have integer (hence, real) coefficients, is also a zero. The Factor Theorem kicks in again to give us and as factors of . We are given no further information about zeros or intercepts so we conclude, by the Complex Factorization Theorem that for some real number . Expanding this, we get . In order to obtain integer coefficients, we know must be an integer multiple of . Our last concern is end behavior. Since the leading term of is , we need to get as . Hence, if we choose , we get . We can verify our handiwork using the techniques developed in this chapter.   "
},
{
  "id": "sec-complexNums",
  "level": "1",
  "url": "sec-complexNums.html",
  "type": "Section",
  "number": "7.2",
  "title": "Complex Numbers",
  "body": " Complex Numbers  The equation has no real number solutions. However, it would have solutions if we could make sense of . The Complex Numbers do just that - they give us a mechanism for working with . As such, the set of complex numbers fill in an algebraic gap left by the set of real numbers.  Here’s the basic plan. There is no real number with , since for any real number . However, we could formally extract square roots and write . We build the complex numbers by relabeling the quantity as , the unfortunately misnamed imaginary unit . Some Technical Mathematics textbooks label it   . While it carries the adjective imaginary , these numbers have essential real-world implications. For example, every electronic device owes its existence to the study of imaginary numbers. The number , while not a real number, is defined so that it plays along well with real numbers and acts very much like any other radical expression. For instance, , , , and so forth. The key properties which distinguish from the real numbers are listed below.   The imaginary unit satisfies the two following properties:          If is a real number with then      Property 1 in the previous definition establishes that does act as a square root Note the use of the indefinite article a . Whatever beast is chosen to be , is the other square root of . of , and property 2 establishes what we mean by the principal square root of a negative real number. In property 2, it is important to remember the restriction on . For example, it is perfectly acceptable to say . However, , otherwise, we’d get which is unacceptable. The moral of this story is that the general properties of radicals do not apply for even roots of negative quantities. With Definition in place, we can define the set of complex numbers .  A complex number is a number of the form , where and are real numbers and is the imaginary unit. The set of complex numbers is denoted .  Complex numbers include things you’d normally expect, like and . However, don’t forget that or could be zero, which means numbers like and are also complex numbers. In other words, don’t forget that the complex numbers include the real numbers, In the language of set notation, . so and are both considered complex numbers. The arithmetic of complex numbers is as you would expect. The only things you need to remember are the two properties above. The next example should help recall how these animals behave.      Perform the indicated operations.   3                      3                          As mentioned earlier, we treat expressions involving as we would any other radical. We distribute and combine like terms: Technically, we’d have to rewrite our answer as to be (in the strictest sense) in the form . That being said, even pedants have their limits, so is good enough.    Using the Distributive Property (a.k.a. F.O.I.L.), we get     How in the world are we supposed to simplify ? Well, we deal with the denominator as we would any other denominator containing two terms, one of which is a square root. We multiply both numerator and denominator by , the (complex) conjugate of . Doing so produces     We use property 2 of Definition first, then apply the rules of radicals applicable to real numbers to get .    We adhere to the order of operations here and perform the multiplication before the radical to get .    We brute force multiply using the distributive property and find that        In the previous example, we used the conjugate idea from simplifying radical equations to divide two complex numbers. More generally, the complex conjugate of a complex number is the number . The notation commonly used for complex conjugation is a bar : . For example, and . To find , we note that , so . Similarly, , since . Note that , not , since . Here, the conjugation specified by the bar notation involves reversing the sign before , not before . The properties of the conjugate are summarized in the following theorem.   Properties of the Complex Conjugate Let and be complex numbers.                     , for any natural number      is a real number if and only if .     Theorem says in part that complex conjugation works well with addition, multiplication and powers. The proofs of these properties can best be achieved by writing out and for real numbers , , and . Next, we compute the left and right sides of each equation and verify that they are the same.  The proof of the first property is a very quick exercise. Trust us on this. To prove the second property, we compare with . We have . To find , we first compute so As such, we have established . The proof for multiplication works similarly. The proof that the conjugate works well with powers can be viewed as a repeated application of the product rule, and is best proved using a technique called Mathematical Induction. The last property is a characterization of real numbers. If is real, then , so . On the other hand, if , then which means so . Hence, and is real.  We now return to the business of solving quadratic equations. Consider . The discriminant is negative, so we know that there are no real solutions, since the Quadratic Formula would involve the term . Complex numbers, however, are built just for such situations, so we can go ahead and apply the Quadratic Formula to get:       Find the complex solutions to the following equations. Remember, all real numbers are complex numbers, so complex solutions means both real and non-real answers.    3                          Clearing fractions yields a quadratic equation so we then proceed via normal quadratic equation methods. From here, we apply the Quadratic Formula   We get two answers: and its conjugate . Checking both of these answers reviews all of the salient points about complex number arithmetic and is therefore strongly encouraged.    Since we have three terms, and the exponent on one term (   on ) is exactly twice the exponent on the other (   on ), we have a Quadratic in Disguise. We proceed accordingly. From we get , or . We extract square roots as follows: where we have rationalized the denominator per convention. From , we get . In total, we have four complex solutions - two real: and two non-real: .    To find the real solutions to , we can subtract the from both sides and extract cube roots: , so . It turns out there are two more non-real complex number solutions to this equation. To get at these, we factor: From , we get our real solution . From , we apply the Quadratic Formula to get: Thus we get three solutions to - one real: and two non-real: . As always, the reader is encouraged to test their algebraic mettle and check these solutions.       It is no coincidence that the non-real solutions to the equations in Example appear in complex conjugate pairs. Any time we use the Quadratic Formula to solve an equation with coefficients, the answers will form a complex conjugate pair owing to the in the Quadratic Formula.   Discriminant Theorem Given a Quadratic Equation , where , and are real numbers, let be the discriminant.     If , there are two distinct real number solutions to the equation.    If , there is one (repeated) real number solution.   Repeated here comes from the fact that both solutions reduce to .    If , there are two non-real solutions which form a complex conjugate pair.     "
},
{
  "id": "sec-complexNums-9",
  "level": "2",
  "url": "sec-complexNums.html#sec-complexNums-9",
  "type": "Example",
  "number": "7.2.1",
  "title": ".",
  "body": "    Perform the indicated operations.   3                      3                          As mentioned earlier, we treat expressions involving as we would any other radical. We distribute and combine like terms: Technically, we’d have to rewrite our answer as to be (in the strictest sense) in the form . That being said, even pedants have their limits, so is good enough.    Using the Distributive Property (a.k.a. F.O.I.L.), we get     How in the world are we supposed to simplify ? Well, we deal with the denominator as we would any other denominator containing two terms, one of which is a square root. We multiply both numerator and denominator by , the (complex) conjugate of . Doing so produces     We use property 2 of Definition first, then apply the rules of radicals applicable to real numbers to get .    We adhere to the order of operations here and perform the multiplication before the radical to get .    We brute force multiply using the distributive property and find that       "
},
{
  "id": "sec-complexNums-16",
  "level": "2",
  "url": "sec-complexNums.html#sec-complexNums-16",
  "type": "Example",
  "number": "7.2.2",
  "title": ".",
  "body": "    Find the complex solutions to the following equations. Remember, all real numbers are complex numbers, so complex solutions means both real and non-real answers.    3                          Clearing fractions yields a quadratic equation so we then proceed via normal quadratic equation methods. From here, we apply the Quadratic Formula   We get two answers: and its conjugate . Checking both of these answers reviews all of the salient points about complex number arithmetic and is therefore strongly encouraged.    Since we have three terms, and the exponent on one term (   on ) is exactly twice the exponent on the other (   on ), we have a Quadratic in Disguise. We proceed accordingly. From we get , or . We extract square roots as follows: where we have rationalized the denominator per convention. From , we get . In total, we have four complex solutions - two real: and two non-real: .    To find the real solutions to , we can subtract the from both sides and extract cube roots: , so . It turns out there are two more non-real complex number solutions to this equation. To get at these, we factor: From , we get our real solution . From , we apply the Quadratic Formula to get: Thus we get three solutions to - one real: and two non-real: . As always, the reader is encouraged to test their algebraic mettle and check these solutions.      "
},
{
  "id": "sec-derivInt",
  "level": "1",
  "url": "sec-derivInt.html",
  "type": "Section",
  "number": "7.3",
  "title": "Differentiation and Integration Techniques",
  "body": " Differentiation and Integration Techniques   In this section, we will cover some of the basic derivative and integral formulas that will be necessary for success in Differential Equations. In order to be able to deal with equations that involve derivatives, we need to be able to take derivatives as well as remove them.    Derivative and Integral Formulas  The following is a table of some of the basic derivative formulas covered in a Calculus 1 course.       Function  Derivative      any         constant                              Similarly, we have a table for some basic integral formulas. As integration is the inverse operation to differentiation, this table will look like the reverse version of the previous table.       Function  Integral    any                          or       Derivative Rules   The tables above only list a few simple functions for which we know how to compute the derivative and integral. However, there are some nice properties of derivatives and integrals that make this enough for our needs.    Linearity of the Derivative and Integral  The derivative and integral are both linear operators. This means that if we have two functions and , and two constants and , then That is, we can move constants and addition and subtractions out of the differentiation, reducing a complicated function down to simpler functions that we know how to differentiate.  The same is true for integration or antidifferentiation; if we have functions and and constants and , then       Compute the following derivatives and integrals using linearity and the table of known formulas.                            For this, we can use linearity and our formulas to write     This one gives     For this problem, we first want to simplify the expression algebraically, then integrate each term using linearity.     This problem uses standard linearity to get to the final answer.         Product and Quotient Rule  Linearity gives us a way to handle sums and differences of derivatives. What about products? It turns out that doesn’t work as simply, but there is still as nice formula to work it out. This gives us the Product Rule. If we have two functions and , then That is, the derivative has two terms, the first function times the derivative of the second, and the derivative of the first function times the second function. The product rule can also be used to compute the product of more than two functions; the general formula is that only one function is differentiated at a time and each function should be differentiated once. That is, for three functions, the formula is   The Quotient Rule gives us a way to do the same thing, but with quotients. The formula here is that This can also be derived using the product rule and the chain rule. It is important to get the order of the numerator correct, as there is a subtraction on top. For the product rule, the addition means that the order doesn’t matter, but if the order for the quotient rule is incorrect, there will be an additional minus sign in the answer.      Compute the following derivatives.               .        This is a direct application of the product rule.     This is a direct application of the quotient rule.     For this problem, we need to apply both the product rule and the quotient rule. Since the quotient rule is on the outside, we apply it first.         Chain Rule  The only type of function we haven’t discussed yet for differentiation is composite functions, and that is handled by the Chain Rule. For example, we don’t have a direct way (yet) to differentiate functions like or , and the Chain Rule lets us to do that. This rule tells us that, for functions and , we can compute the derivative of the composition or is This means that we differentiate the outside function , plug in the inside function, and then multiply this by the derivative of the inside function . It requires us to identify what the inner and outer functions are, and then the formula gives what the derivative should be. This can be done in a few different ways, either moving from outside in, or moving from inside out. These problems are conventionally written with as the inside function, but any letter can be used.      Compute the derivative of each of the following functions.                       For this problem, we take and , which gives that composing these functions gives the that we started with. Therefore, since and , we have that     For this case, the outside function is and the inner function is . Using the same process, we get that     Starting from the outside, we see that we can take . This makes , but we can’t differentiate this directly; it requires another iteration of the Chain Rule. Taking for , we can then compute the derivative of each of these functions, and our original function . We can extend the Chain Rule to apply to three functions by taking it one step at a time. The result of this process is that so you need to pull off one derivative at time to get to the correct computation. Thus, for this problem, we get that          Integration Techniques   Another main topic that will be needed throughout study of differential equations is various integration techniques. When trying to solve questions that involve derivatives, integration will be a very important step in that process.    Substitution  The substitution method for integration serves as the inverse operation to the Chain Rule for differentiation. Since the definition of the integral as an antiderivative gives that Integrals of this form can be computed using this formula, but it is often easier to think of this process in terms of changing variables. This means the following: If we have an integral that looks like then we can define the variable to represent the entire function . Then the differential is defined by Then we can substitute both and into the original expression to get that   The last component of this process is changing the limits of integration if a definite integral is being computed. The idea is that an integral in (denoted by ) has its limits also in terms of , where as the integral has endpoints given in terms of . The main way this comes up in problems is that because we know that is written in terms of as . Thus if we plug the endpoints into this function, we will be the new endpoints.      Compute the following integrals using substitution.                       For this situation we want to set , because then the integrand, once we make the change of variables, will be , which we know how to integrate. With this, we have , which we can rewrite as . Plugging all of this in gives that     For the same reason, we want to set to make the resulting integral . In this case, we have or . Plugging all of this in, we get     We can follow the same logic here as for the previous examples, but since we have a definite integral, we also need to switch the limits of integration. In this case, we want to pick , which gives . This gives the resulting integral as For the limits of integration, we take the function and plug in the original values of and . This gives the value and and the value at . Therefore, the result of this computation is       There can be some cases where these techniques will not work, because the term that you are looking for doesn’t quite appear in the expression you are trying to integrate. In cases like this, you may need to use some more complicated methods (like trigonometric substitution) or connect to inverse trigonometric integrals or other known formulas.    Integration by Parts  Integration by parts is the method used to handle integrals of a product of functions. Like the substitution method is the inverse of the Chain Rule, integration by parts is the inverse of the product rule. There are two main formulas that are used for this process. For two differentiable functions and , we have The other form is which matches the original form after setting and .  The most important part of this process is picking the appropriate functions for and in this formula. The general rule is given by the following list    Logarithmic functions    Inverse Functions    Algebraic or Polynomial Functions    Trigonometric Functions (sine and cosine)    Exponential Functions    and you want to make , the function that you are differentiating, the one that is higher on the list. The main reason for this list is that integration is much harder than differentiation, and so we generally want to integrate the part of the product that we have a formula for. This is why logarithms and inverses are on the top; we know how to differentiate them, but integration is difficult or impossible. Polynomials are good for both differentiation and integrals, but the benefit of differentiating them is that they eventually disappear, leaving us with an integral that we know how to solve. For example, becomes , and then differentiating a second time gives , which is just a constant and can be removed from the integral. Trigonometric and Exponential functions are interchangeable, they are easy to differentiate and integrate, and they don’t go away if we keep applying either operation.  This method can also be performed mutliple times by redefining and and applying the same process to the integral that remains on the right-hand side. When doing this, it is important not to reverse the roles of and , because then the process will just undo what was done in the first step. There are also some cases where circular reasoning is used, integrating by parts twice to get to the same expression on both sides of the equal sign, which can then be solved for. One of those will be shown in the examples below.      Compute the following integrals.                       Based on our list, we should choose , as it is a polynomial function. This means that . From this, we get that and we compute by integrating , which requires a substitution. This results in . Thus, the integration by parts formula gives This last integral we can compute directly, again requiring a substitution. Thus, the final answer is     By the same argument as the first example, we want to pick so then . We can then compute that and . Thus, integration by parts gives   This last integral is not something that we know how to compute. However, it looks like a product, so we should be able to work it out using integration by parts. We can set and . This is the same as before, which is good. If we had picked , we would have just gotten back to where we started. From these choices, we get that and . Integration by parts then gives that Now we can compute this last integral, which will give another factor of , resulting in Finally, we can combine this with our first integration by parts step to get that     For this example, we have both an exponential and a trigonometric function. We can pick either one to be and , and as long as we are consistent with that choice, we will get to the correct answer. For this, we will choose and . From these, we can compute that and . Thus, integration by parts tells us that This new integral is again a product, so we need to handle it using integration by parts. To do this, we are going to pick and . Note: If you pick and , the second integration by parts will just give that which does not help in solving the problem. With the correct choice of and , and , we have that and , so that integration by parts tells us that Combining this with our first integration by parts gives In this case, we can see that the integral on the left matches the integral on the right. If we combine these on the left side, we get which then allows us to solve for the answers as         Partial Fractions  Another integration technique that shows up frequently when dealing with rational functions is the method of partial fractions. This method works around decomposing a rational function into forms that we are able to integrate. For example, we do not have a formula or method to compute the integral since there is no simple function whose derivative is . What functions like this can we integrate?      Compute the following antiderivatives       This integral can be computed by a substitution ,     This integral is another substitution, but the goal here is arctangent, not a logarithm. We let , so that , and then     With an on top of the expression, we can now use a substitution to solve the integral.       So, we can handle these types of integrals, but that doesn’t necessarily help us with the initial one. Let’s take a look at another example.      Compute     This integral can be computed by splitting it into the two terms present. Each of those we know how to evaluate using the previous example. Thus, we have that     This is great! However, we can compute that, by adding fractions So this gives us a way to compute the original integral of this section, and we now know that   This gives an idea for how we may be able to evaluate integrals of rational functions. In the case of the integral above, we would need to figure out a way to convert between that is, we need to split the complicated fraction into the smaller, simpler that we can integrate. Based on our work in , we know that we can integrate functions that have a linear term in the denominator and a quadratic term in the denominator, and the process of putting these fractions together into a single term involves multiplying the individual denominators together. This gives the motivation for the method of partial fractions for integrating rational functions:    Factor the denominator of the function we need to integrate. Any polynomial can be factored into linear terms (terms like ) or irreducible quadratic terms (terms like or ).    Write an expression with unknown coefficients for each factor in the expression. If it is a linear term, it will need just a single constant, but if there is a quadratic term, it needs a numerator of the form .    Solve for the necessary constants (more on this later).    Integrate each of the resulting expressions, which are all forms where we know the antiderivative.    Combine the terms into a single expression.    The process is best shown through an example.      Compute     We start by factoring the denominator. We can factor an out of each term, and then the resulting quadratic can be factored. Since we want to figure out coefficients , , and so that where we have one term per factor of the denominator. In order to find these constants, our first trick is to multiply both sides of this equation by the entire denominator on the left. This gives where we have cancelled the appropriate terms from the top and bottom of each expression. One way to go from here to the constants is to expand out the right-hand side and recognize that for these two sides to be equal for all , the coefficient of , , and the constant term must match. This will result in solve a system of 3 equations.  An easier approach to doing this is to plug values for into each side, and to pick those values cleverly. One clever choice for is to set . If we do that, both the and terms will go away, because they are multiplied by zero. Thus, if we plug in zero, we get which implies that . For the next term, we can plug in to make the terms go away, resulting in so that . Plugging in gives so that . Therefore, we can write that Then, we can integrate both sides to get that     The same type of approach applies if there are irreducible quadratics in the expression.      Compute     The denominator can be factored as , which can be determined by grouping. This means that to do the partial fraction decomposition, we need to find coefficients , , and so that Note that the term has on top instead of just . This is because the term on the bottom is a quadratic, and there will always be a number of coefficients on top that matches the degree of the term in the denominator. By multiplying both sides by the denominator will give the equation where we need to find the appropriate constants. In this case, we can plug in to determine that or . However, there is no value we can plug in to make . We could use complex numbers here, but assuming we don’t want to do that, we can plug in any two numbers and go from there. Plugging in is nice because it makes the term go away, resulting in which we can solve to get . Finally, we can plug in any other number for to get an equation to solve for . Let’s use to give that which gives that . Therefore, we can write Therefore, we can write the integral we want to compute as     There are a few extra complications that can result from using this method.    If there is an irreducible quadratic like in the denominator, we will want to separate that out and complete the square before integrating. In this case, we have , so we will want to use when solving for coefficients (to make the u-substitution work better), and will get a slightly more complicated result.    If there are repeated factors, like in the denominator, we need to include one term in the partial fraction expansion for every power of that factor. For instance, the expansion should look like     If the rational function has an equal or higher degree in the numerator than in the denominator, we will need to do long division to remove a standard polynomial (which we know how to integrate) and a proper rational function that can be integrated using partial fractions.    Combining all of these techniques together will allow us to integrate pretty much any rational function that we need for a given application.    "
},
{
  "id": "derivative-and-integral-formulas-3",
  "level": "2",
  "url": "sec-derivInt.html#derivative-and-integral-formulas-3",
  "type": "Table",
  "number": "7.3.1",
  "title": "",
  "body": "    Function  Derivative      any         constant                             "
},
{
  "id": "derivative-and-integral-formulas-5",
  "level": "2",
  "url": "sec-derivInt.html#derivative-and-integral-formulas-5",
  "type": "Table",
  "number": "7.3.2",
  "title": "",
  "body": "    Function  Integral    any                          or    "
},
{
  "id": "linearity-of-the-derivative-and-integral-4",
  "level": "2",
  "url": "sec-derivInt.html#linearity-of-the-derivative-and-integral-4",
  "type": "Example",
  "number": "7.3.3",
  "title": ".",
  "body": "    Compute the following derivatives and integrals using linearity and the table of known formulas.                            For this, we can use linearity and our formulas to write     This one gives     For this problem, we first want to simplify the expression algebraically, then integrate each term using linearity.     This problem uses standard linearity to get to the final answer.      "
},
{
  "id": "product-and-quotient-rule-4",
  "level": "2",
  "url": "sec-derivInt.html#product-and-quotient-rule-4",
  "type": "Example",
  "number": "7.3.4",
  "title": ".",
  "body": "    Compute the following derivatives.               .        This is a direct application of the product rule.     This is a direct application of the quotient rule.     For this problem, we need to apply both the product rule and the quotient rule. Since the quotient rule is on the outside, we apply it first.      "
},
{
  "id": "chain-rule-3",
  "level": "2",
  "url": "sec-derivInt.html#chain-rule-3",
  "type": "Example",
  "number": "7.3.5",
  "title": ".",
  "body": "    Compute the derivative of each of the following functions.                       For this problem, we take and , which gives that composing these functions gives the that we started with. Therefore, since and , we have that     For this case, the outside function is and the inner function is . Using the same process, we get that     Starting from the outside, we see that we can take . This makes , but we can’t differentiate this directly; it requires another iteration of the Chain Rule. Taking for , we can then compute the derivative of each of these functions, and our original function . We can extend the Chain Rule to apply to three functions by taking it one step at a time. The result of this process is that so you need to pull off one derivative at time to get to the correct computation. Thus, for this problem, we get that      "
},
{
  "id": "substitution-4",
  "level": "2",
  "url": "sec-derivInt.html#substitution-4",
  "type": "Example",
  "number": "7.3.6",
  "title": ".",
  "body": "    Compute the following integrals using substitution.                       For this situation we want to set , because then the integrand, once we make the change of variables, will be , which we know how to integrate. With this, we have , which we can rewrite as . Plugging all of this in gives that     For the same reason, we want to set to make the resulting integral . In this case, we have or . Plugging all of this in, we get     We can follow the same logic here as for the previous examples, but since we have a definite integral, we also need to switch the limits of integration. In this case, we want to pick , which gives . This gives the resulting integral as For the limits of integration, we take the function and plug in the original values of and . This gives the value and and the value at . Therefore, the result of this computation is      "
},
{
  "id": "integration-by-parts-7",
  "level": "2",
  "url": "sec-derivInt.html#integration-by-parts-7",
  "type": "Example",
  "number": "7.3.7",
  "title": ".",
  "body": "    Compute the following integrals.                       Based on our list, we should choose , as it is a polynomial function. This means that . From this, we get that and we compute by integrating , which requires a substitution. This results in . Thus, the integration by parts formula gives This last integral we can compute directly, again requiring a substitution. Thus, the final answer is     By the same argument as the first example, we want to pick so then . We can then compute that and . Thus, integration by parts gives   This last integral is not something that we know how to compute. However, it looks like a product, so we should be able to work it out using integration by parts. We can set and . This is the same as before, which is good. If we had picked , we would have just gotten back to where we started. From these choices, we get that and . Integration by parts then gives that Now we can compute this last integral, which will give another factor of , resulting in Finally, we can combine this with our first integration by parts step to get that     For this example, we have both an exponential and a trigonometric function. We can pick either one to be and , and as long as we are consistent with that choice, we will get to the correct answer. For this, we will choose and . From these, we can compute that and . Thus, integration by parts tells us that This new integral is again a product, so we need to handle it using integration by parts. To do this, we are going to pick and . Note: If you pick and , the second integration by parts will just give that which does not help in solving the problem. With the correct choice of and , and , we have that and , so that integration by parts tells us that Combining this with our first integration by parts gives In this case, we can see that the integral on the left matches the integral on the right. If we combine these on the left side, we get which then allows us to solve for the answers as      "
},
{
  "id": "partial-fractions-3",
  "level": "2",
  "url": "sec-derivInt.html#partial-fractions-3",
  "type": "Example",
  "number": "7.3.8",
  "title": ".",
  "body": "    Compute the following antiderivatives       This integral can be computed by a substitution ,     This integral is another substitution, but the goal here is arctangent, not a logarithm. We let , so that , and then     With an on top of the expression, we can now use a substitution to solve the integral.      "
},
{
  "id": "partial-fractions-5",
  "level": "2",
  "url": "sec-derivInt.html#partial-fractions-5",
  "type": "Example",
  "number": "7.3.9",
  "title": ".",
  "body": "    Compute     This integral can be computed by splitting it into the two terms present. Each of those we know how to evaluate using the previous example. Thus, we have that    "
},
{
  "id": "partial-fractions-10",
  "level": "2",
  "url": "sec-derivInt.html#partial-fractions-10",
  "type": "Example",
  "number": "7.3.10",
  "title": ".",
  "body": "    Compute     We start by factoring the denominator. We can factor an out of each term, and then the resulting quadratic can be factored. Since we want to figure out coefficients , , and so that where we have one term per factor of the denominator. In order to find these constants, our first trick is to multiply both sides of this equation by the entire denominator on the left. This gives where we have cancelled the appropriate terms from the top and bottom of each expression. One way to go from here to the constants is to expand out the right-hand side and recognize that for these two sides to be equal for all , the coefficient of , , and the constant term must match. This will result in solve a system of 3 equations.  An easier approach to doing this is to plug values for into each side, and to pick those values cleverly. One clever choice for is to set . If we do that, both the and terms will go away, because they are multiplied by zero. Thus, if we plug in zero, we get which implies that . For the next term, we can plug in to make the terms go away, resulting in so that . Plugging in gives so that . Therefore, we can write that Then, we can integrate both sides to get that    "
},
{
  "id": "partial-fractions-12",
  "level": "2",
  "url": "sec-derivInt.html#partial-fractions-12",
  "type": "Example",
  "number": "7.3.11",
  "title": ".",
  "body": "    Compute     The denominator can be factored as , which can be determined by grouping. This means that to do the partial fraction decomposition, we need to find coefficients , , and so that Note that the term has on top instead of just . This is because the term on the bottom is a quadratic, and there will always be a number of coefficients on top that matches the degree of the term in the denominator. By multiplying both sides by the denominator will give the equation where we need to find the appropriate constants. In this case, we can plug in to determine that or . However, there is no value we can plug in to make . We could use complex numbers here, but assuming we don’t want to do that, we can plug in any two numbers and go from there. Plugging in is nice because it makes the term go away, resulting in which we can solve to get . Finally, we can plug in any other number for to get an equation to solve for . Let’s use to give that which gives that . Therefore, we can write Therefore, we can write the integral we want to compute as    "
},
{
  "id": "backmatter-2",
  "level": "1",
  "url": "backmatter-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt .  "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
