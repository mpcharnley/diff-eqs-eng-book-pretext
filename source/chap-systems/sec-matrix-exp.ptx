<?xml version="1.0" encoding="UTF-8"?>
<!-- Generated by Pandoc using pretext.lua -->


<section xml:id="sec-matexp">
	<title>Matrix exponentials</title>


	<subsection xml:id="definition">
		<title>Definition</title>

		<p> There is another way of finding a fundamental matrix solution of a system. Consider the
			constant coefficient equation <me>
				{\vec{x}}' = P \vec{x} .
			</me> If this would be just one equation (when <m>P</m> is a
			number or a <m>1
				\times 1</m> matrix), then the solution would be <me>
				\vec{x} = e^{Pt} .
			</me> That doesn’t make sense if <m>P</m> is a larger matrix, but
			essentially the same computation that led to the above works for matrices when we define <m>
			e^{Pt}</m> properly. First let us write down the Taylor series for <m>e^{at}</m> for
			some number <m>a</m>: <me>
				e^{at} = 1 + at
				+ \frac{{(at)}^2}{2}
				+ \frac{{(at)}^3}{6}
				+ \frac{{(at)}^4}{24}
				+ \cdots
				= \sum_{k=0}^\infty \frac{{(at)}^k}{k!} .
			</me>
			Recall <m>k! = 1 \cdot 2 \cdot 3 \cdots k</m> is the factorial, and <m>0! = 1</m>. We
			differentiate this series term by term <me>
				\frac{d}{dt} \left(e^{at} \right) =
				0
				+ a
				+ a^2 t
				+ \frac{a^3t^2}{2}
				+ \frac{a^4t^3}{6}
				+ \cdots
				= a \left(
				1
				+ a t
				+ \frac{{(at)}^2}{2}
				+ \frac{{(at)}^3}{6}
				+ \cdots \right)
				= a e^{at}.
			</me>
			Maybe we can try the same trick with matrices. </p>

		<!-- div attr= class="definition"-->
		<p> For an <m>n \times n</m> matrix <m>A</m> we define the <em></em> as <me>
				% \mybxbg{~~
				e^A \overset{\text{def}}{=} I + A + \frac{1}{2} A^2 +
				\frac{1}{6} A^3 + \cdots + \frac{1}{k!} A^k + \cdots
				% ~~}
			</me>

		</p><!--</div
		attr= class="definition">-->

		<p> Let us not worry about convergence. The series really does always converge. We usually
			write <m>Pt</m> as <m>tP</m> by convention when <m>P</m> is a matrix. With this small
			change and by the exact same calculation as above we have that <me>
				\frac{d}{dt} \left(e^{tP} \right) =
				P e^{tP} .
			</me> Now <m>P</m> and hence <m>
			e^{tP}</m> is an <m>n \times n</m> matrix. What we are looking for is a vector. In the <m>1
			\times 1</m> case we would at this point multiply by an arbitrary constant to get the
			general solution. In the matrix case we multiply by a column vector <m>\vec{c}</m>. </p>

		<!-- div attr= class="theorem1"-->
		<p> Let <m>P</m> be an <m>n \times n</m> matrix. Then the general solution to <m>{\vec{x}}'
			= P \vec{x}</m> is <me>
				\vec{x} = e^{tP} \vec{c} ,
			</me> where <m>\vec{c}</m> is an arbitrary constant
			vector. In fact, <m>\vec{x}(0) =
				\vec{c}</m>. </p><!--</div
		attr= class="theorem1">-->

		<p> Let us check: <me>
				\frac{d}{dt}
				\vec{x} =
				\frac{d}{dt} \left(
				e^{tP} \vec{c}\, \right)
				=
				P e^{tP} \vec{c} =
				P \vec{x}.
			</me>

		</p>

		<p> Hence <m>e^{tP}</m> is a of the homogeneous system. So if we can compute the matrix
			exponential, we have another method of solving constant coefficient homogeneous systems.
			It also makes it easy to solve for initial conditions. To solve <m>{\vec{x}}' = A
			\vec{x}</m>, <m>\vec{x}(0) = \vec{b}</m>, we take the solution <me>
				\vec{x} = e^{tA} \vec{b} .
			</me> This equation follows because <m>e^{0A} = I</m>, so <m>\vec{x}
			(0) = e^{0A} \vec{b} = \vec{b}</m>. </p>

		<p> We mention a drawback of matrix exponentials. In general <m>e^{A+B} \not= e^A e^B</m>.
			The trouble is that matrices do not commute, that is, in general <m>AB \not= BA</m>. If
			you try to prove <m>e^{A+B} \not= e^A e^B</m> using the Taylor series, you will see why
			the lack of commutativity becomes a problem. However, it is still true that if <m>AB =
			BA</m>, that is, if <m>A</m> and <m>B</m> commute, then <m>e^{A+B} = e^Ae^B</m>. We will
			find this fact useful. Let us restate this as a theorem to make a point. </p>

		<!-- div attr= class="theorem1"-->
		<p> If <m>AB = BA</m>, then <m>e^{A+B} = e^Ae^B</m>. Otherwise, <m>e^{A+B} \not= e^Ae^B</m>
			in general. </p><!--</div
		attr= class="theorem1">-->

	</subsection>

	<subsection xml:id="simple-cases">
		<title>Simple cases</title>

		<p> In some instances it may work to just plug into the series definition. Suppose the
			matrix is diagonal. For example, <m>D = \left[ \begin{smallmatrix} a &amp; 0 \\ 0 &amp;
			b \end{smallmatrix} \right]</m>. Then <me>
				D^k = \begin{bmatrix} a^k &amp; 0 \\ 0 &amp; b^k \end{bmatrix} ,
			</me> and <me>
			\begin{split}
				e^D &amp; =
				I + D + \frac{1}{2} D^2 +
				\frac{1}{6} D^3 + \cdots
				\\
				&amp;=
				\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} +
				\begin{bmatrix} a &amp; 0 \\ 0 &amp; b \end{bmatrix} +
				\frac{1}{2}
				\begin{bmatrix} a^2 &amp; 0 \\ 0 &amp; b^2 \end{bmatrix} +
				\frac{1}{6}
				\begin{bmatrix} a^3 &amp; 0 \\ 0 &amp; b^3 \end{bmatrix} + \cdots
				=
				\begin{bmatrix} e^a &amp; 0 \\ 0 &amp; e^b \end{bmatrix} .
				\end{split}
			</me>
			So by this rationale <me>
				e^I = \begin{bmatrix} e &amp; 0\\ 0 &amp; e \end{bmatrix}
				\qquad \text{and} \qquad
				e^{aI} = \begin{bmatrix} e^a &amp; 0\\ 0 &amp; e^a \end{bmatrix}.
			</me>

		</p>

		<p> This makes exponentials of certain other matrices easy to compute. For example, the
			matrix <m>A = \left[ \begin{smallmatrix} 5 &amp; 4 \\ -1 &amp; 1 \end{smallmatrix}
			\right]</m> can be written as <m>3I + B</m> where <m>B = \left[ \begin{smallmatrix} 2
			&amp; 4 \\ -1 &amp; -2 \end{smallmatrix} \right]</m>. Notice that <m>B^2 =
				\left[ \begin{smallmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{smallmatrix} \right]</m>. So <m>B^k
			= 0</m> for all <m>k \geq 2</m>. Therefore, <m>e^B = I + B</m>. Suppose we actually want
			to compute <m>e^{tA}</m>. The matrices <m>3tI</m> and <m>tB</m> commute (exercise: check
			this) and <m>e^{tB} = I + tB</m>, since <m>{(tB)}^2 = t^2 B^2 = 0</m>. We write <me>\begin{multline*}
			e^{tA} =
				e^{3tI + tB} = e^{3tI} e^{tB} =
				\begin{bmatrix} e^{3t} &amp; 0 \\ 0 &amp; e^{3t} \end{bmatrix}
				\left(
				I + tB
				\right)
				=
				\\
				=
				\begin{bmatrix} e^{3t} &amp; 0 \\ 0 &amp; e^{3t} \end{bmatrix}
				\begin{bmatrix} 1+2t &amp; 4t \\ -t &amp; 1-2t \end{bmatrix}
				=
				\begin{bmatrix} (1+2t)\,e^{3t} &amp; 4te^{3t} \\ -te^{3t} &amp; (1-2t)\,e^{3t}
			\end{bmatrix} .
				\end{multline*}</me> We found a fundamental matrix solution for the system <m>{\vec{x}}'
			= A \vec{x}</m>. Note that this matrix has a repeated eigenvalue with a defect; there is
			only one eigenvector for the eigenvalue 3. So we found a perhaps easier way to handle
			this case. In fact, if a matrix <m>A</m> is <m>2 \times 2</m> and has an eigenvalue <m>
			\lambda</m> of multiplicity 2, then either <m>A = \lambda I</m>, or <m>A = \lambda I + B</m>
			where <m>B^2 = 0</m>. This is a good exercise. </p>

		<exercise>
			<statement>
				<p> Suppose that <m>A</m> is <m>2 \times 2</m> and <m>\lambda</m> is the only
					eigenvalue. Show that <m>{(A - \lambda I)}^2 = 0</m>, and therefore that we can
					write <m>A = \lambda I + B</m>, where <m>B^2 = 0</m> (and possibly <m>B=0</m>).
					Hint: First write down what does it mean for the eigenvalue to be of
					multiplicity 2. You will get an equation for the entries. Now compute the square
					of <m>B</m>. </p>
			</statement>

			<answer>
				<p> Matrices <m>B</m> such that <m>B^k = 0</m> for some <m>k</m> are called <em></em>.
					Computation of the matrix exponential for nilpotent matrices is easy by just
					writing down the first <m>k</m> terms of the Taylor series. </p>
			</answer>
		</exercise>

	</subsection>

	<subsection xml:id="general-matrices">
		<title>General matrices</title>

		<p> In general, the exponential is not as easy to compute as above. We usually cannot write
			a matrix as a sum of commuting matrices where the exponential is simple for each one.
			But fear not, it is still not too difficult provided we can find enough eigenvectors.
			First we need the following interesting result about matrix exponentials. For two square
			matrices <m>A</m> and <m>B</m>, with <m>B</m> invertible, we have <me>
				e^{BAB^{-1}} = B e^A B^{-1} .
			</me> This can be seen by writing down the Taylor
			series. First <me>
				{(BAB^{-1})}^2 =
				BAB^{-1} BAB^{-1} =
				BAIAB^{-1} =
				BA^2B^{-1} .
			</me> And by the
			same reasoning <m>{(BAB^{-1})}^k = B A^k B^{-1}</m>. Now write the Taylor series for <m>
			e^{BAB^{-1}}</m>: <me>
				\begin{split}
				e^{BAB^{-1}} &amp; =
				I + {BAB^{-1}} + \frac{1}{2} {(BAB^{-1})}^2 +
				\frac{1}{6} {(BAB^{-1})}^3 + \cdots
				\\
				&amp; =
				BB^{-1} + {BAB^{-1}} + \frac{1}{2} BA^2B^{-1} +
				\frac{1}{6} BA^3B^{-1} + \cdots
				\\
				&amp; =
				B \bigl(
				I + A + \frac{1}{2} A^2 +
				\frac{1}{6} A^3 + \cdots \bigr) B^{-1} \\
				&amp; = B e^A B^{-1} .
				\end{split}
			</me>

		</p>

		<p> Given a square matrix <m>A</m>, we can usually write <m>A = E D E^{-1}</m>, where <m>D</m>
			is diagonal and <m>E</m> invertible. This procedure is called <em></em>. If we can do
			that, the computation of the exponential becomes easy as <m>e^D</m> is just taking the
			exponential of the entries on the diagonal. Adding <m>t</m> into the mix, we can then
			compute the exponential <me>
				e^{tA} = E e^{tD} E^{-1} .
			</me>

		</p>

		<p> To diagonalize <m>A</m> we need <m>n</m> linearly independent eigenvectors of <m>A</m>.
			Otherwise, this method of computing the exponential does not work and we need to be
			trickier, but we will not get into such details. Let <m>E</m> be the matrix with the
			eigenvectors as columns. Let <m>\lambda_1</m>, <m>\lambda_2</m>, …, <m>\lambda_n</m> be
			the eigenvalues and let <m>\vec{v}_1</m>, <m>\vec{v}_2</m>, …, <m>\vec{v}_n</m> be the
			eigenvectors, then <m>E = [\, \vec{v}_1 \quad \vec{v}_2 \quad \cdots \quad \vec{v}_n \,]</m>.
			Make a diagonal matrix <m>D</m> with the eigenvalues on the diagonal: <me>
				D =
				\begin{bmatrix}
				\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
				0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
				\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
				0 &amp; 0 &amp; \cdots &amp; \lambda_n
				\end{bmatrix} .
			</me>
			We compute <me>
				\begin{split}
				AE &amp; = A
				[\, \vec{v}_1 \quad \vec{v}_2 \quad \cdots \quad \vec{v}_n \,]
				\\
				&amp; =
				[\, A\vec{v}_1 \quad A\vec{v}_2 \quad \cdots \quad A\vec{v}_n \,]
				\\
				&amp; =
				[\, \lambda_1 \vec{v}_1 \quad \lambda_2 \vec{v}_2 \quad \cdots \quad
				\lambda_n \vec{v}_n \,]
				\\
				&amp; =
				[\, \vec{v}_1 \quad \vec{v}_2 \quad \cdots \quad \vec{v}_n \,] D
				\\
				&amp; =
				ED .
				\end{split}
			</me>
			The columns of <m>E</m> are linearly independent as these are linearly independent
			eigenvectors of <m>A</m>. Hence <m>E</m> is invertible. Since <m>AE = ED</m>, we
			multiply on the right by <m>E^{-1}</m> and we get <me>
				A = E D E^{-1}.
			</me> This means that <m>e^A = E e^D E^{-1}</m>. Multiplying the
			matrix by <m>t</m> we obtain <men xml:id="matexp-diagfundsol">
				\mybxbg{~~
				e^{tA} =
				Ee^{tD}E^{-1} =
				E
				\begin{bmatrix}
				e^{\lambda_1 t} &amp; 0 &amp; \cdots &amp; 0 \\
				0 &amp; e^{\lambda_2 t} &amp; \cdots &amp; 0 \\
				\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
				0 &amp; 0 &amp; \cdots &amp; e^{\lambda_n t}
				\end{bmatrix}
				E^{-1} .
				~~}
			</men>
			The formula <xref ref="matexp-diagfundsol" />, therefore, gives the formula for
			computing a fundamental matrix solution <m>e^{tA}</m> for the system <m>{\vec{x}}' = A
			\vec{x}</m>, in the case where we have <m>n</m> linearly independent eigenvectors. </p>

		<p> This computation still works when the eigenvalues and eigenvectors are complex, though
			then you have to compute with complex numbers. It is clear from the definition that if <m>
			A</m> is real, then <m>e^{tA}</m> is real. So you will only need complex numbers in the
			computation and not for the result. You may need to apply <xref ref="eulersformula" />
			to simplify the result. If simplified properly, the final matrix will not have any
			complex numbers in it. </p>


		<example>
			<title> </title>
			<statement>
				<p> Compute a fundamental matrix solution using the matrix exponential for the
					system <me>
						\begin{bmatrix}
						x \\ y
						\end{bmatrix} '
						=
						\begin{bmatrix}
						1 &amp; 2 \\
						2 &amp; 1
						\end{bmatrix}
						\begin{bmatrix}
						x \\ y
						\end{bmatrix} .
					</me>
					Then compute the particular solution for the initial conditions <m>x(0) = 4</m>
					and <m>y(0) = 2</m>. </p>

				<p> Let <m>A</m> be the coefficient matrix <m>\left[ \begin{smallmatrix}
						1 &amp; 2 \\
						2 &amp; 1
						\end{smallmatrix} \right]</m>. We first compute (exercise) that the
					eigenvalues are 3 and <m>-1</m> and corresponding eigenvectors are <m>\left[
					\begin{smallmatrix} 1 \\ 1 \end{smallmatrix} \right]</m> and <m>\left[
					\begin{smallmatrix} 1 \\ -1 \end{smallmatrix} \right]</m>. Hence the
					diagonalization of <m>A</m> is <me>
						\underbrace{
						\begin{bmatrix}
						1 &amp; 2 \\
						2 &amp; 1
						\end{bmatrix}
						}_{A}
						=
						\underbrace{
						\begin{bmatrix}
						1 &amp; 1 \\
						1 &amp; -1
						\end{bmatrix}
						}_{E}
						\underbrace{
						\begin{bmatrix}
						3 &amp; 0 \\
						0 &amp; -1
						\end{bmatrix}
						}_{D}
						\underbrace{
						\begin{bmatrix}
						1 &amp; 1 \\
						1 &amp; -1
						\end{bmatrix}^{-1}
						}_{E^{-1}} .
					</me>
					We write <me>
						\begin{split}
						e^{t A}
						=
						E e^{tD} E^{-1}
						&amp; =
						\begin{bmatrix}
						1 &amp; 1 \\
						1 &amp; -1
						\end{bmatrix}
						\begin{bmatrix}
						e^{3t} &amp; 0 \\
						0 &amp; e^{-t}
						\end{bmatrix}
						\begin{bmatrix}
						1 &amp; 1 \\
						1 &amp; -1
						\end{bmatrix}^{-1}
						\\
						&amp; =
						\begin{bmatrix}
						1 &amp; 1 \\
						1 &amp; -1
						\end{bmatrix}
						\begin{bmatrix}
						e^{3t} &amp; 0 \\
						0 &amp; e^{-t}
						\end{bmatrix}
						\frac{-1}{2}
						\begin{bmatrix}
						-1 &amp; -1 \\
						-1 &amp; 1
						\end{bmatrix}
						\\
						&amp; =
						\frac{-1}{2}
						\begin{bmatrix}
						e^{3t} &amp; e^{-t} \\
						e^{3t} &amp; -e^{-t}
						\end{bmatrix}
						\begin{bmatrix}
						-1 &amp; -1 \\
						-1 &amp; 1
						\end{bmatrix}
						\\
						&amp; =
						\frac{-1}{2}
						\begin{bmatrix}
						-e^{3t}-e^{-t} &amp; -e^{3t}+e^{-t} \\
						-e^{3t}+e^{-t} &amp; -e^{3t}-e^{-t}
						\end{bmatrix}
						=
						\begin{bmatrix}
						\frac{e^{3t}+e^{-t}}{2} &amp; \frac{e^{3t}-e^{-t}}{2} \\
					\frac{e^{3t}-e^{-t}}{2} &amp; \frac{e^{3t}+e^{-t}}{2}
						\end{bmatrix} .
						\end{split}
					</me>

				</p>

				<p> The initial conditions are <m>x(0) = 4</m> and <m>y(0) = 2</m>. Hence, by the
					property that <m>e^{0A} = I</m> we find that the particular solution we are
					looking for is <m>e^{tA} \vec{b}</m> where <m>\vec{b}</m> is <m>\left[
					\begin{smallmatrix} 4 \\ 2 \end{smallmatrix} \right]</m>. Then the particular
					solution we are looking for is <me>
						\begin{bmatrix}
						x \\ y
						\end{bmatrix}
						=
						\begin{bmatrix}
						\frac{e^{3t}+e^{-t}}{2} &amp; \frac{e^{3t}-e^{-t}}{2} \\
					\frac{e^{3t}-e^{-t}}{2} &amp; \frac{e^{3t}+e^{-t}}{2}
						\end{bmatrix}
						\begin{bmatrix}
						4 \\ 2
						\end{bmatrix}
						=
						\begin{bmatrix}
						2e^{3t}+2e^{-t} + e^{3t}-e^{-t} \\
						2e^{3t}-2e^{-t} + e^{3t}+e^{-t}
						\end{bmatrix}
						=
						\begin{bmatrix}
						3e^{3t}+e^{-t} \\
						3e^{3t}-e^{-t}
						\end{bmatrix} .
					</me>

				</p>
			</statement>
		</example>
	</subsection>

	<subsection xml:id="fundamental-matrix-solutions">
		<title>Fundamental matrix solutions</title>

		<p> We note that if you can compute a fundamental matrix solution in a different way, you
			can use this to find the matrix exponential <m>e^{tA}</m>. A fundamental matrix solution
			of a system of ODEs is not unique. The exponential is the fundamental matrix solution
			with the property that for <m>t=0</m> we get the identity matrix. So we must find the
			right fundamental matrix solution. Let <m>X</m> be any fundamental matrix solution to <m>{\vec{x}}'
			= A \vec{x}</m>. Then we claim <me>
				e^{tA} = X(t) \left[ X(0) \right]^{-1} .
			</me> Clearly, if we plug <m>t=0</m> into <m>X(t)
			\left[ X(0) \right]^{-1}</m> we get the identity. We can multiply a fundamental matrix
			solution on the right by any constant invertible matrix and we still get a fundamental
			matrix solution. All we are doing is changing what are the arbitrary constants in the
			general solution <m>\vec{x}(t) = X(t)\, \vec{c}</m>. </p>

	</subsection>

	<subsection xml:id="approximations">
		<title>Approximations</title>

		<p> If you think about it, the computation of any fundamental matrix solution <m>X</m> using
			the eigenvalue method is just as difficult as the computation of <m>e^{tA}</m>. So
			perhaps we did not gain much by this new tool. However, the Taylor series expansion
			actually gives us a way to approximate solutions, which the eigenvalue method did not. </p>

		<p> The simplest thing we can do is to just compute the series up to a certain number of
			terms. There are better ways to approximate the exponential <fn>
				 C. Moler and C.F. Van Loan, <em>Nineteen Dubious Ways to Compute the Exponential
			of a Matrix, Twenty-Five Years Later</em>, SIAM Review 45 (1), 2003, 3–49 
			</fn>.
			In many cases however, few terms of the Taylor series give a reasonable approximation
			for the exponential and may suffice for the application. For example, let us compute the
			first 4 terms of the series for the matrix <m>A =
				\left[ \begin{smallmatrix}
				1 &amp; 2 \\
				2 &amp; 1
				\end{smallmatrix} \right]</m>. <me>\begin{multline*}
				e^{tA}
				\approx
				I + tA + \frac{t^2}{2}A^2 + \frac{t^3}{6}A^3
				=
				I + t
				\begin{bmatrix}
				1 &amp; 2 \\
				\noalign{\smallskip}
				2 &amp; 1
				\end{bmatrix}
				+ t^2
				\begin{bmatrix}
				\frac{5}{2} &amp; 2 \\
				\noalign{\smallskip}
				2 &amp; \frac{5}{2}
				\end{bmatrix}
				+ t^3
				\begin{bmatrix}
				\frac{13}{6} &amp; \frac{7}{3} \\
				\noalign{\smallskip}
				\frac{7}{3} &amp; \frac{13}{6}
				\end{bmatrix}
				=
				\\
				=
				\begin{bmatrix}
				1 + t + \frac{5}{2}\, t^2 + \frac{13}{6}\, t^3 &amp;
				2\,t + 2\, t^2 + \frac{7}{3}\, t^3 \\
				\noalign{\smallskip}
				2\,t + 2\, t^2 + \frac{7}{3}\, t^3 &amp;
				1 + t + \frac{5}{2}\, t^2 + \frac{13}{6}\, t^3
				\end{bmatrix} .
				\end{multline*}</me> Just like the scalar version of the Taylor series
			approximation, the approximation will be better for small <m>t</m> and worse for larger <m>
			t</m>. For larger <m>t</m>, we will generally have to compute more terms. Let us see how
			we stack up against the real solution with <m>t=0.1</m>. The approximate solution is
			approximately (rounded to 8 decimal places) <me>
				e^{0.1\,A} \approx
				I + 0.1\,A + \frac{0.1^2}{2}A^2 + \frac{0.1^3}{6}A^3
				=
				\begin{bmatrix}
				1.12716667 &amp; 0.22233333 \\
				0.22233333 &amp; 1.12716667 \\
				\end{bmatrix} .
			</me>
			And plugging <m>t=0.1</m> into the real solution (rounded to 8 decimal places) we get <me>
			e^{0.1\,A} =
				\begin{bmatrix}
				1.12734811 &amp; 0.22251069 \\
				0.22251069 &amp; 1.12734811
				\end{bmatrix} .
			</me>
			Not bad at all! Although if we take the same approximation for <m>t=1</m> we get <me>
				I + A + \frac{1}{2}A^2 + \frac{1}{6}A^3
				=
				\begin{bmatrix}
				6.66666667 &amp; 6.33333333 \\
				6.33333333 &amp; 6.66666667
				\end{bmatrix} ,
			</me>
			while the real value is (again rounded to 8 decimal places) <me>
				e^{A} =
				\begin{bmatrix}
				10.22670818 &amp; \phantom{0}9.85882874 \\
				\phantom{0}9.85882874 &amp; 10.22670818
				\end{bmatrix} .
			</me>
			So the approximation is not very good once we get up to <m>t=1</m>. To get a good
			approximation at <m>t=1</m> (say up to 2 decimal places) we would need to go up to the <m>
			{11}^{\text{th}}</m> power (exercise). </p>

	</subsection>

	<subsection xml:id="non-homogeneous-systems">
		<title>Non-Homogeneous Systems</title>


		<subsubsection xml:id="integrating-factor">
			<title>Integrating factor</title>

			<p> Now that we have matrix exponentials, we can try to use them to help us solve
				non-homogeneous systems of differential equations. First, let’s recall what we did
				for first order equations. If we have an equation of the form <me>
					x'(t) + p x(t) = f(t)
				</me> where will assume that <m>p</m> is constant (even
				though it doesn’t have to be). We would go about solving this problem by multiplying
				both sides of the equation by <m>e^{pt}</m>, writing the left-hand side as a product
				rule, integrating both sides, and solving. </p>

			<p> With matrix exponentials, we can do exactly the same thing with first order systems.
				Let us focus on the nonhomogeneous first order equation <me>
					{\vec{x}}'(t) = A\vec{x}(t) + \vec{f}(t) ,
				</me> where <m>A</m> is a constant
				matrix. The method we look at here is the <em>integrating factor method</em>. For
				simplicity we rewrite the equation as <me>
					{\vec{x}}'(t) + P \vec{x}(t) = \vec{f}(t) ,
				</me> where <m>P = -A</m>. We
				multiply both sides of the equation by <m>e^{tP}</m> (being mindful that we are
				dealing with matrices that may not commute) to obtain <me>
					e^{tP}{\vec{x}}'(t) + e^{tP}P\vec{x}(t) = e^{tP}\vec{f}(t) .
				</me> We notice that <m>P
				e^{tP} = e^{tP} P</m>. This fact follows by writing down the series definition of <m>
				e^{tP}</m>: <me>
					\begin{split}
					P e^{tP} &amp; =
					P \left(
					I + tP + \frac{1}{2} {(tP)}^2 + \cdots \right)
					=
					P + tP^2 + \frac{1}{2} t^2P^3 + \cdots
					=
					\\
					&amp; =
					\left(
					I + tP + \frac{1}{2} {(tP)}^2 + \cdots \right) P
					= e^{tP} P .
					\end{split}
				</me>
				So <m>\frac{d}{dt} \left( e^{tP} \right) = P e^{tP} = e^{tP} P</m>. The product rule
				says <me>
					\frac{d}{dt}
					\Bigl( e^{tP} \vec{x}(t) \Bigr) =
					e^{tP}{\vec{x}}'(t) + e^{tP}P\vec{x}(t),
				</me>
				and so <me>
					\frac{d}{dt}
					\Bigl( e^{tP} \vec{x}(t) \Bigr) = e^{tP}\vec{f}(t) .
				</me> We can
				now integrate. That is, we integrate each component of the vector separately <me>
				e^{tP} \vec{x}(t) = \int e^{tP}\vec{f}(t) \, dt + \vec{c} .
				</me> In , you will
				compute and verify that <m>{(e^{tP})}^{-1} = e^{-tP}</m>. Therefore, we obtain <me>
				\vec{x}(t) = e^{-tP} \int e^{tP}\vec{f}(t) \, dt + e^{-tP} \vec{c} .
				</me>

			</p>

			<p> Perhaps it is better understood as a definite integral. In this case it will be easy
				to also solve for the initial conditions. Consider the equation with initial
				conditions <me>
					{\vec{x}}'(t) + P\vec{x}(t) = \vec{f}(t) ,
					\qquad \vec{x}(0) = \vec{b} .
				</me>
				The solution can then be written as <men xml:id="nhsys-intfacsoleq">
					\mybxbg{~~
					\vec{x}(t) = e^{-tP} \int_0^t e^{sP}\vec{f}(s) \, ds + e^{-tP} \vec{b} .
					~~}
				</men>
				Again, the integration means that each component of the vector <m>e^{sP}\vec{f}(s)</m>
				is integrated separately. It is not hard to see that <xref ref="nhsys-intfacsoleq" />
				really does satisfy the initial condition <m>\vec{x}(0) = \vec{b}</m>. <me>
				\vec{x}(0) = e^{-0P} \int_0^0 e^{sP}\vec{f}(s) \, ds + e^{-0P} \vec{b}
					= I \vec{b} = \vec{b} .
				</me>

			</p>


			<example>
				<title> </title>
				<statement>
					<p> Suppose that we have the system <me>\begin{align*}
							x_1' + 5x_1 - 3x_2 &amp;= e^t , \\
							x_2' + 3x_1 - x_2 &amp;= 0 ,
							\end{align*}</me> with initial conditions <m>x_1(0) = 1, x_2(0) = 0</m>. </p>
				</statement>

				<solution>
					<p> Let us write the system as <me>
							{\vec{x}}' +
							\begin{bmatrix} 5 &amp; -3 \\ 3 &amp; -1 \end{bmatrix}
							\vec{x} =
							\begin{bmatrix} e^t \\ 0 \end{bmatrix} ,
							\qquad
							\vec{x}(0) =
							\begin{bmatrix} 1 \\ 0 \end{bmatrix} .
						</me>
						The matrix <m>P = \left[
							\begin{smallmatrix} 5 &amp; -3 \\ 3 &amp; -1 \end{smallmatrix} \right]</m>
						has a doubled eigenvalue 2 with defect 1, and we leave it as an exercise to
						double check we computed <m>e^{tP}</m> correctly. Once we have <m>e^{tP}</m>,
						we find <m>e^{-tP}</m>, simply by negating <m>t</m>. <me>
							e^{tP} =
							\begin{bmatrix}
							(1+3t)\,e^{2t} &amp; -3te^{2t} \\
							3te^{2t} &amp; (1-3t)\,e^{2t}
							\end{bmatrix}
							, \qquad
							e^{-tP} =
							\begin{bmatrix}
							(1-3t)\,e^{-2t} &amp; 3te^{-2t} \\
							-3te^{-2t} &amp; (1+3t)\,e^{-2t}
							\end{bmatrix}
							.
						</me>
						Instead of computing the whole formula at once, let us do it in stages.
						First <me>
							\begin{split}
							\int_0^t e^{sP}\vec{f}(s) \, ds &amp; =
							\int_0^t
							\begin{bmatrix}
							(1+3s)\,e^{2s} &amp; -3se^{2s} \\
							3se^{2s} &amp; (1-3s)\,e^{2s}
							\end{bmatrix}
							\begin{bmatrix} e^{s} \\ 0 \end{bmatrix}
							\, ds
							\\
							&amp; =
							\int_0^t
							\begin{bmatrix}
							(1+3s)\,e^{3s} \\
							3se^{3s}
							\end{bmatrix}
							\, ds
							\\
							&amp;=
							\begin{bmatrix}
							\int_0^t (1+3s)\,e^{3s} \,ds \\
							\int_0^t 3se^{3s} \,ds
							\end{bmatrix}
							\\
							&amp; =
							\begin{bmatrix}
							t e^{3t} \\
							\frac{(3t-1) \,e^{3t} + 1}{3}
							\end{bmatrix} %.
							\qquad \qquad \text{(used integration by parts).}
							\end{split}
						</me>
						Then <me>
							\begin{split}
							\vec{x}(t)
							&amp; = e^{-tP} \int_0^t e^{sP}\vec{f}(s) \, ds + e^{-tP} \vec{b} \\
						&amp; =
							\begin{bmatrix}
							(1-3t)\,e^{-2t} &amp; 3te^{-2t} \\
							-3te^{-2t} &amp; (1+3t)\,e^{-2t}
							\end{bmatrix}
							\begin{bmatrix}
							t e^{3t} \\
							\frac{(3t-1) \,e^{3t} + 1}{3}
							\end{bmatrix}
							+
							\begin{bmatrix}
							(1-3t)\,e^{-2t} &amp; 3te^{-2t} \\
							-3te^{-2t} &amp; (1+3t)\,e^{-2t}
							\end{bmatrix}
							\begin{bmatrix} 1 \\ 0 \end{bmatrix} \\
							&amp; =
							\begin{bmatrix}
							te^{-2t} \\
							-\frac{e^t}{3}+\left( \frac{1}{3} + t \right) \, e^{-2t}
							\end{bmatrix}
							+
							\begin{bmatrix}
							(1-3t)\,e^{-2t} \\
							-3te^{-2t}
							\end{bmatrix} \\
							&amp; =
							\begin{bmatrix}
							(1-2t)\,e^{-2t} \\
							-\frac{e^t}{3}+\left( \frac{1}{3} -2 t \right) \, e^{-2t}
							\end{bmatrix} .
							\end{split}
						</me>
						Phew! </p>

					<p> Let us check that this really works. <me>
							x_1' + 5 x_1 - 3x_2 = (4te^{-2t} - 4 e^{-2t}) + 5
							(1-2t)\,e^{-2t}
							+e^t-( 1 -6 t ) \, e^{-2t} = e^t .
						</me>
						Similarly (exercise) <m>x_2' + 3 x_1 - x_2 = 0</m>. The initial conditions
						are also satisfied (exercise). </p>
				</solution>
			</example>
			<p> For systems, the integrating factor method only works if <m>P</m> does not depend on <m>
				t</m>, that is, <m>P</m> is constant. The problem is that in general <me>
				\frac{d}{dt} \left[ e^{\int P(t)\,dt} \right] \not= P(t) \, e^{\int P(t)\,dt} ,
				</me>
				because matrix multiplication is not commutative. </p>

		</subsubsection>
	</subsection>

	<exercises>
		<title>Exercises</title>

		<exercise>
			<statement>
				<p> Using the matrix exponential, find a fundamental matrix solution for the system <m>x'
					= 3x+y</m>, <m>y' = x+3y</m>. </p>
			</statement>

			<answer>
				<p>
					<m>e^{tA} = \left[\begin{smallmatrix} \frac{1}{2}e^{2t} + \frac{1}{2}e^{4t}
						&amp; \frac{1}{2}e^{4t} - \frac{1}{2}e^{2t} \\ -\frac{1}{2}e^{2t} +
						\frac{1}{2}e^{4t} &amp; \frac{1}{2}e^{2t} + \frac{1}{2}e^{4t}
						\end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Find <m>e^{tA}</m> for the matrix <m>A =
						\left[ \begin{smallmatrix}
						2 &amp; 3 \\
						0 &amp; 2
						\end{smallmatrix} \right]</m>. </p>
			</statement>

			<answer>
				<p>
					<m>e^{tA} = \left[\begin{smallmatrix} e^{2t} &amp; 3te^{2t} \\ 0 &amp; e^{2t}
						\end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Compute <m>e^{tA}</m> where <m>A=\left[ \begin{smallmatrix}
						1 &amp; -2 \\
						-2 &amp; 1
						\end{smallmatrix}\right]</m>. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Compute <m>e^{tA}</m> where <m>A=\left[ \begin{smallmatrix}
						1 &amp; -3 &amp; 2 \\
						-2 &amp; 1 &amp; 2 \\
						-1 &amp; -3 &amp; 4
						\end{smallmatrix}\right]</m>. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<!-- div attr= class="tasks"-->
				<p> (2) Compute <m>e^{tA}</m> where <m>A=\left[ \begin{smallmatrix}
						3 &amp; -1 \\
						1 &amp; 1
						\end{smallmatrix}\right]</m>. Solve <m>\vec{x}\,' = A \vec{x}</m> for <m>\vec{x}(0)
					=
						\left[ \begin{smallmatrix}
						1 \\ 2
						\end{smallmatrix}\right]</m>. </p><!--</div
				attr= class="tasks">-->
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Find a fundamental matrix solution for the system <m>x_1' = 7x_1+4x_2+ 12x_3</m>
					, <m>x_2' = x_1+2x_2+x_3</m>, <m>x_3' = -3x_1-2x_2- 5x_3</m>. Then find the
					solution that satisfies <m>\vec{x}(0) =
						\left[ \begin{smallmatrix} 0 \\ 1 \\ -2 \end{smallmatrix} \right]</m>. </p>
			</statement>

			<answer>
				<p>
					<m>\frac{1}{6}\left[\begin{smallmatrix} 10e^{3t} + 12e^t - 16 &amp; 8e^{3t} - 8
					&amp; 16e^{3t} + 24e^t - 40 \\%
						5e^{3t} - 9e^t + 4 &amp; 4e^{3t} + 2 &amp; 8e^{3t} - 18e^t + 10 \\%
						-5e^{3t} - 3e^t + 8 &amp; -4e^{3t} + 4 &amp; -8e^{3t} - 6e^t + 20
					\end{smallmatrix}\right]</m>, <m>\vec{x}(t) =
					\frac{1}{6}\left[\begin{smallmatrix} 10e^{3t} + 12e^t - 16 &amp; 8e^{3t} - 8
					&amp; 16e^{3t} + 24e^t - 40 \\%
						5e^{3t} - 9e^t + 4 &amp; 4e^{3t} + 2 &amp; 8e^{3t} - 18e^t + 10 \\%
						-5e^{3t} - 3e^t + 8 &amp; -4e^{3t} + 4 &amp; -8e^{3t} - 6e^t + 20
					\end{smallmatrix}\right] \left[\begin{smallmatrix} 0 \\ 1 \\ 2
					\end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Compute the matrix exponential <m>e^A</m> for <m>A = \left[ \begin{smallmatrix}
					1 &amp; 2 \\ 0 &amp; 1 \end{smallmatrix} \right]</m>. </p>
			</statement>

			<answer>
				<p>
					<m>\left[\begin{smallmatrix} e^t &amp; (1+2t)e^t \\ 0 &amp; e^t
						\end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Suppose <m>AB = BA</m>. Show that under this assumption, <m>e^{A+B} = e^A e^B</m>
					.
			</p>
			</statement>

			<answer>
				<p> Hint: Consider the equation <m>X' = (A+B)X</m>. Show that both of the above
					solve this equation using that if <m>AB=BA</m> then <m>A</m> commutes with <m>
					e^B</m> and vice versa. </p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Use to show that <m>{(e^{A})}^{-1} = e^{-A}</m>. In particular this means that <m>
					e^A</m> is invertible even if <m>A</m> is not. </p>
			</statement>

			<answer>
				<p> Hint: <m>A</m> commutes with <m>-A</m>. </p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Let <m>A</m> be a <m>2 \times 2</m> matrix with eigenvalues <m>-1</m>, <m>1</m>,
					and corresponding eigenvectors <m>\left[ \begin{smallmatrix}
						1 \\
						1
						\end{smallmatrix} \right]</m>, <m>\left[ \begin{smallmatrix}
						0 \\
						1
						\end{smallmatrix} \right]</m>. </p>

				<!-- div attr= class="tasks"-->
				<p> Find matrix <m>A</m> with these properties. Find a fundamental matrix solution
					to <m>{\vec{x}}' = A \vec{x}</m>. Solve the system in with initial conditions <m>\vec{x}(0)
					=
						\left[ \begin{smallmatrix}
						2 \\
						3
						\end{smallmatrix} \right]</m> . </p><!--</div
				attr= class="tasks">-->
			</statement>

			<answer>
				<p> a)  <m>\left[\begin{smallmatrix} -1 &amp; 0 \\ -2 &amp; 1
					\end{smallmatrix}\right]</m> b)  <m>\left[\begin{smallmatrix} e^{-t} &amp; 0 \\
					e^{-t} - e^t &amp; e^t \end{smallmatrix}\right]</m> c) <m>\left[\begin{smallmatrix}
					2e^{-t} \\ 2e^{-t} + e^t \end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Suppose that <m>A</m> is an <m>n \times n</m> matrix with a repeated eigenvalue <m>
					\lambda</m> of multiplicity <m>n</m>. Suppose that there are <m>n</m> linearly
					independent eigenvectors. Show that the matrix is diagonal, in particular <m>A =
					\lambda I</m>. Hint: Use diagonalization and the fact that the identity matrix
					commutes with every other matrix. </p>
			</statement>

			<answer>
				<p> Hint: If there are <m>n</m> linearly independent eigenvectors, then it can be
					diagonalized. What does <m>D</m> look like? </p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Let <m>A = \left[ \begin{smallmatrix}
						-1 &amp; -1 \\
						1 &amp; -3
						\end{smallmatrix} \right]</m>. </p>

				<!-- div attr= class="tasks"-->
				<p> (2) Find <m>e^{tA}</m>. Solve <m>{\vec{x}}' = A \vec{x}</m>, <m>\vec{x}(0) =
					\left[ \begin{smallmatrix}
						1 \\
						-2
						\end{smallmatrix} \right]</m>. </p><!--</div
				attr= class="tasks">-->
			</statement>

			<answer>
				<p> a)  <m>\left[\begin{smallmatrix} (1+t)e^{-2t} &amp; -te^{-2t} \\ te^{-2t} &amp;
					(1-t)e^{-2t} \end{smallmatrix}\right]</m> b) <m>\left[\begin{smallmatrix}
					(1+3t)e^{-2t} \\(-2 + 3t)e^{-2t} \end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Let <m>A = \left[ \begin{smallmatrix}
						1 &amp; 2 \\
						3 &amp; 4
						\end{smallmatrix} \right]</m>. Approximate <m>e^{tA}</m> by expanding the
					power series up to the third order. </p>
			</statement>

			<answer>
				<p>
					<m>\left[\begin{smallmatrix} 1 + t + \frac{7}{2}t^2 + \frac{37}{6}t^3 &amp; 2t +
						5t^2 + 9t^3 \\ 3t + \frac{15}{2}t^2 + \frac{79}{6}t^3 &amp; 1 + 4t + 11t^2 +
						18t^3 \end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Compute the first 3 terms (up to the second degree) of the Taylor expansion of <m>
					e^{tA}</m> where <m>A=\left[ \begin{smallmatrix}
						2 &amp; 3 \\
						2 &amp; 2
						\end{smallmatrix}\right]</m> (Write as a single matrix). Then use it to
					approximate <m>e^{0.1A}</m>. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> For any positive integer <m>n</m>, find a formula (or a recipe) for <m>A^n</m>
					for the following matrices: </p>

				<!-- div attr= class="tasks"-->
				<p> (4) <m>\begin{bmatrix}
						3 &amp; 0 \\ 0 &amp; 9
						\end{bmatrix}</m> <m>\begin{bmatrix}
						5 &amp; 2 \\ 4 &amp; 7
						\end{bmatrix}</m> <m>\begin{bmatrix}
						0 &amp; 1 \\ 0 &amp; 0
						\end{bmatrix}</m> <m>\begin{bmatrix}
						2 &amp; 1 \\ 0 &amp; 2
						\end{bmatrix}</m>
				</p><!--</div
				attr= class="tasks">-->
			</statement>

			<answer>
				<p> a) <m>\left[\begin{smallmatrix} 3^n &amp; 0 \\ 0 &amp; 9^n
					\end{smallmatrix}\right]</m> b)  <m>3^{n-1}\left[\begin{smallmatrix} 2 + 3^n
					&amp; -1 + 3^n \\ -2 + 2\cdot3^n &amp; 1 + 2\cdot 3^n \end{smallmatrix}\right]</m>
					c)  <m>A^0 = I</m>, <m>A^1 = A</m>, <m>A^n = 0</m> for all <m>n \geq 2</m> d) <m>\left[\begin{smallmatrix}
					2^n &amp; n2^{n-1} \\ 0 &amp; 2^n \end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> For any positive integer <m>n</m>, find a formula (or a recipe) for <m>A^n</m>
					for the following matrices: </p>

				<!-- div attr= class="tasks"-->
				<p> (3) <m>\begin{bmatrix}
						7 &amp; 4 \\ -5 &amp; -2
						\end{bmatrix}</m> <m>\begin{bmatrix}
						-3 &amp; 4 \\ -6 &amp; 7
						\end{bmatrix}</m> <m>\begin{bmatrix}
						0 &amp; 1 \\ 1 &amp; 0
						\end{bmatrix}</m>
				</p><!--</div
				attr= class="tasks">-->
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Solve the initial value problem <me>{\vec{x}}' = \begin{bmatrix} -4 &amp; 2 \\
					-9 &amp; 5 \end{bmatrix}\vec{x} + \begin{bmatrix} e^{3t} \\ e^t - 1
					\end{bmatrix} \qquad \vec{x}(0) = \begin{bmatrix} 0 \\ 2 \end{bmatrix}</me>
					using matrix exponentials. </p>
			</statement>

			<answer>
				<p>
					<m>\vec{x}(t) = \left[\begin{smallmatrix} -\frac{1}{2}e^{3t} - e^t + 1 \\
						-\frac{9}{4}e^{3t} - \frac{5}{2}e^t + 2 \end{smallmatrix}\right] +
						\frac{8}{3}\left[\begin{smallmatrix} 1 \\ 3 \end{smallmatrix}\right]e^{2t} -
						\frac{13}{12}\left[\begin{smallmatrix} 2 \\ 3 \end{smallmatrix}\right]e^{-t}</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Solve the initial value problem <me>{\vec{x}}' = \begin{bmatrix} 3 &amp; 2 \\ 0
					&amp; 4 \end{bmatrix}\vec{x} + \begin{bmatrix} e^{4t} \\ e^{3t} - t
					\end{bmatrix} \qquad \vec{x}(0) = \begin{bmatrix} 2 \\ -1 \end{bmatrix}</me>
					using matrix exponentials. </p>
			</statement>

			<answer>
				<p>
					<m>\vec{x}(t) = \left[\begin{smallmatrix} -2t + \frac{88}{72} \\ -1
						\end{smallmatrix}\right]e^{3t} + \left[\begin{smallmatrix} -\frac{1}{6}t -
						\frac{7}{72} \\ \frac{t}{4} + \frac{1}{16} \end{smallmatrix}\right] +
						\left[\begin{smallmatrix} \frac{7}{8} \\-\frac{1}{16}
						\end{smallmatrix}\right]e^{4t}</m>
				</p>
			</answer>
		</exercise>
	</exercises>

</section>



