<?xml version="1.0" encoding="UTF-8"?>
<!-- Generated by Pandoc using pretext.lua -->


<section xml:id="elim-section">
	<title>Elimination</title>


	<subsection xml:id="linear-systems-of-equations">
		<title>Linear systems of equations</title>

		<p> One application of matrices is to solve systems of linear equations<fn>
				Although perhaps we have this backwards, quite often we solve a linear system of
			equations to find out something about matrices, rather than vice versa.
			</fn>.
			Consider the following system of linear equations <men xml:id="linalg-elim-eq">
			\begin{aligned}
				2 x_1 + 2 x_2 + 2 x_3 &amp; = 2 , \\
				\phantom{9} x_1 + \phantom{9} x_2 + 3 x_3 &amp; = 5 , \\
				\phantom{9} x_1 + 4 x_2 + \phantom{9} x_3 &amp; = 10 .
				\end{aligned}
			</men>
		</p>

		<p> There is a systematic procedure called <em></em> to solve such a system. In this
			procedure, we attempt to eliminate each variable from all but one equation. We want to
			end up with equations such as <m>x_3 = 2</m>, where we can just read off the answer. </p>

		<p> We write a system of linear equations as a matrix equation: <me>
				A \vec{x} = \vec{b} .
			</me> The system <xref ref="linalg-elim-eq" /> is written as <me>
			\underbrace{
				\begin{bmatrix}
				2 &amp; 2 &amp; 2 \\
				1 &amp; 1 &amp; 3 \\
				1 &amp; 4 &amp; 1
				\end{bmatrix}
				}_{A}
				\underbrace{
				\begin{bmatrix}
				x_1 \\
				x_2 \\
				x_3
				\end{bmatrix}
				}_{\vec{x}}
				=
				\underbrace{
				\begin{bmatrix}
				2 \\
				5 \\
				10
				\end{bmatrix}
				}_{\vec{b}} .
			</me>
			If we knew the inverse of <m>A</m>, then we would be done; we would simply solve the
			equation: <me>
				\vec{x} = A^{-1} A \vec{x} = A^{-1} \vec{b} .
			</me> Well, but that is part of the
			problem, we do not know how to compute the inverse for matrices bigger than <m>2 \times
			2</m>. We will see later that to compute the inverse we are really solving <m>A \vec{x}
			= \vec{b}</m> for several different <m>\vec{b}</m>. In other words, we will need to do
			elimination to find <m>A^{-1}</m>. In addition, we may wish to solve <m>A \vec{x} =
			\vec{b}</m> even if <m>A</m> is not invertible, or perhaps not even square. </p>

		<p> Let us return to the equations themselves and see how we can manipulate them. There are
			a few operations we can perform on the equations that do not change the solution. First,
			perhaps an operation that may seem stupid, we can swap two equations in <xref
				ref="linalg-elim-eq" />: <me>
				\begin{aligned}
				\phantom{9} x_1 + \phantom{9} x_2 + 3 x_3 &amp; = 5 , \\
				2 x_1 + 2 x_2 + 2 x_3 &amp; = 2 , \\
				\phantom{9} x_1 + 4 x_2 + \phantom{9} x_3 &amp; = 10 .
				\end{aligned}
			</me>
			Clearly these new equations have the same solutions <m>x_1,x_2,x_3</m>. A second
			operation is that we can multiply an equation by a nonzero number. For example, we
			multiply the third equation in <xref ref="linalg-elim-eq" /> by 3: <me>
				\begin{aligned}
				2 x_1 + \phantom{9} 2 x_2 + 2 x_3 &amp; = 2 , \\
				\phantom{9} x_1 + \phantom{99} x_2 + 3 x_3 &amp; = 5 , \\
				3 x_1 + 12 x_2 + 3 x_3 &amp; = 30 .
				\end{aligned}
			</me>
			Finally we can add a multiple of one equation to another equation. For example, we add 3
			times the third equation in <xref ref="linalg-elim-eq" /> to the second equation: <me>
			\begin{aligned}
				\phantom{(1+3)} 2 x_1 + \phantom{(1+12)} 2 x_2 + \phantom{(3+3)} 2 x_3 &amp; = 2 ,
			\\
				\phantom{2} (1+3) x_1 + \phantom{2}(1+12) x_2 + \phantom{2} (3+3) x_3 &amp; = 5+30 ,
			\\
				\phantom{2 (1+3)} x_1 + \phantom{(1+12)} 4 x_2 + \phantom{(3+3) 2} x_3 &amp; = 10 .
			\end{aligned}
			</me>
			The same <m>x_1,x_2,x_3</m> should still be solutions to the new equations. These were
			just examples; we did not get any closer to the solution. We must to do these three
			operations in some more logical manner, but it turns out these three operations suffice
			to solve every linear equation. </p>

		<p> The first thing is to write the equations in a more compact manner. Given <me>
				A \vec{x} = \vec{b} ,
			</me> we write down the so-called <em></em> 
<me>
				[ A ~|~ \vec{b} ] ,
			</me> where the vertical line is just a marker for us to know
			where the of the equation starts. For example, for the system <xref ref="linalg-elim-eq" />
			the augmented matrix is <me>
				\left[
				\begin{array}{ccc|c}
				2 &amp; 2 &amp; 2 &amp; 2 \\
				1 &amp; 1 &amp; 3 &amp; 5 \\
				1 &amp; 4 &amp; 1 &amp; 10
				\end{array}
				\right] .
			</me>
			The entire process of elimination, which we will describe, is often applied to any sort
			of matrix, not just an augmented matrix. Simply think of the matrix as the <m>3 \times 4</m>
			matrix <me>
				\begin{bmatrix}
				2 &amp; 2 &amp; 2 &amp; 2 \\
				1 &amp; 1 &amp; 3 &amp; 5 \\
				1 &amp; 4 &amp; 1 &amp; 10
				\end{bmatrix} .
			</me>

		</p>

	</subsection>

	<subsection xml:id="row-echelon-form-and-elementary-operations">
		<title>Row echelon form and elementary operations</title>

		<p> We apply the three operations above to the matrix. We call these the <em></em> or <em></em>
			.
			</p>

		<!-- div attr= class="definition"-->
		<p>
			The elementary row operations on a matrix are:
		</p>

		<p>
			<ol>
				<li>
					<p>
						Swap two rows.
					</p>
				</li>

				<li>
					<p>
						Multiply a row by a nonzero number.
					</p>
				</li>

				<li>
					<p>
						Add a multiple of one row to another row.
					</p>
				</li>

			</ol>
		</p><!--</div
		attr= class="definition">-->

		<p>
			Note that these are the same three operations that we could do with equations to try to
			solve them earliner in this section. We run these operations until we get into a state
			where it is easy to read off the answer, or until we get into a contradiction indicating
			no solution.
		</p>

		<p> More specifically, we run the operations until we obtain the so-called <em></em>. Let us
			call the first (from the left) nonzero entry in each row the <em></em>. A matrix is in <em>row
			echelon form</em> if the following conditions are satisfied: </p>

		<p>
			<ol>
				<li>
					<p>
						The leading entry in any row is strictly to the right of the leading entry
						of the row above.
					</p>
				</li>

				<li>
					<p>
						Any zero rows are below all the nonzero rows.
					</p>
				</li>

				<li>
					<p> All leading entries are 1.<fn>
							
								Some books do not require this and allow the entries to be any
						non-zero number, putting this as a requirement for reduced row echelon form.
						I like leaving this here because it makes the process of row reduction seem
						more defined and algorithmic. They are equivalent though and with or without
						the 1 requirement can be used to answer the same questions.
							
						</fn>
					</p>
				</li>

			</ol>
		</p>

		<p> A matrix is in <em></em> if furthermore the following condition is satisfied. </p>

		<p>
			<ol>
				<li>
					<p>
						All the entries above a leading entry are zero.
					</p>
				</li>

			</ol>
		</p>


		<example>
		<title> </title>
		<statement>
			<p> The following matrices are in row echelon form. The leading entries are marked: <me>
				\begin{bmatrix}
					\mybxsm{1} &amp; 2 &amp; 9 &amp; 3 \\
					0 &amp; 0 &amp; \mybxsm{1} &amp; 5 \\
					0 &amp; 0 &amp; 0 &amp; \mybxsm{1}
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					\mybxsm{1} &amp; -1 &amp; -3 \\
					0 &amp; \mybxsm{1} &amp; 5 \\
					0 &amp; 0 &amp; \mybxsm{1}
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					\mybxsm{1} &amp; 2 &amp; 1 \\
					0 &amp; \mybxsm{1} &amp; 2 \\
					0 &amp; 0 &amp; 0
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					0 &amp; \mybxsm{1} &amp; -5 &amp; 2 \\
					0 &amp; 0 &amp; 0 &amp; \mybxsm{1} \\
					0 &amp; 0 &amp; 0 &amp; 0
					\end{bmatrix}
				</me>
				Note that the definition applies to matrices of any size. None of the matrices above
				are in <em>reduced</em> row echelon form. For example, in the first matrix none of
				the entries above the second and third leading entries are zero; they are 9, 3, and
				5. </p>

			<p> The following matrices are in reduced row echelon form. The leading entries are
				marked: <me>
					\begin{bmatrix}
					\mybxsm{1} &amp; 3 &amp; 0 &amp; 8 \\
					0 &amp; 0 &amp; \mybxsm{1} &amp; 6 \\
					0 &amp; 0 &amp; 0 &amp; 0
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					\mybxsm{1} &amp; 0 &amp; 2 &amp; 0 \\
					0 &amp; \mybxsm{1} &amp; 3 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; \mybxsm{1}
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					\mybxsm{1} &amp; 0 &amp; 3 \\
					0 &amp; \mybxsm{1} &amp; -2 \\
					0 &amp; 0 &amp; 0
					\end{bmatrix}
					\qquad
					\begin{bmatrix}
					0 &amp; \mybxsm{1} &amp; 2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; \mybxsm{1} \\
					0 &amp; 0 &amp; 0 &amp; 0
					\end{bmatrix}
				</me>

			</p>
		</statement>
	</example>
		<p> The procedure we will describe to find a reduced row echelon form of a matrix is called <em></em>.
			The first part of it, which obtains a row echelon form, is called <em></em> or <em></em>.
			For some problems, a row echelon form is sufficient, and it is a bit less work to only
			do this first part. </p>

		<p> To attain the row echelon form we work <em>systematically</em>. We go column by column,
			starting at the first column. We find topmost entry in the first column that is not
			zero, and we call it the <em></em>. If there is no nonzero entry we move to the next
			column. We swap rows to put the row with the pivot as the first row. We divide the first
			row by the pivot to make the pivot entry be a 1. Now look at all the rows below and
			subtract the correct multiple of the pivot row so that all the entries below the pivot
			become zero. </p>

		<p>
			After this procedure we forget that we had a first row (it is now fixed), and we forget
			about the column with the pivot and all the preceding zero columns. Below the pivot row,
			all the entries in these columns are just zero. Then we focus on the smaller matrix and
			we repeat the steps above.
		</p>

		<p> It is best shown by example, so let us go back to the example from the beginning of the
			section. We keep the vertical line in the matrix, even though the procedure works on any
			matrix, not just an augmented matrix. We start with the first column and we locate the
			pivot, in this case the first entry of the first column. <me>
				\left[
				\begin{array}{ccc|c}
				\mybxsm{2} &amp; 2 &amp; 2 &amp; 2 \\
				1 &amp; 1 &amp; 3 &amp; 5 \\
				1 &amp; 4 &amp; 1 &amp; 10
				\end{array}
				\right]
			</me>
			We multiply the first row by <m>\nicefrac{1}{2}</m>. <me>
				\left[
				\begin{array}{ccc|c}
				\mybxsm{1} &amp; 1 &amp; 1 &amp; 1 \\
				1 &amp; 1 &amp; 3 &amp; 5 \\
				1 &amp; 4 &amp; 1 &amp; 10
				\end{array}
				\right]
			</me>
			We subtract the first row from the second and third row (two elementary operations). <me>
			\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; 0 &amp; 2 &amp; 4 \\
				0 &amp; 3 &amp; 0 &amp; 9
				\end{array}
				\right]
			</me>
			We are done with the first column and the first row for now. We almost pretend the
			matrix doesn’t have the first column and the first row. <me>
				\left[
				\begin{array}{ccc|c}
				* &amp; * &amp; * &amp; * \\
				* &amp; 0 &amp; 2 &amp; 4 \\
				* &amp; 3 &amp; 0 &amp; 9
				\end{array}
				\right]
			</me>

		</p>

		<p> OK, look at the second column, and notice that now the pivot is in the third row. <me>
			\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; 0 &amp; 2 &amp; 4 \\
				0 &amp; \mybxsm{3} &amp; 0 &amp; 9
				\end{array}
				\right]
			</me>
			We swap rows. <me>
				\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; \mybxsm{3} &amp; 0 &amp; 9 \\
				0 &amp; 0 &amp; 2 &amp; 4
				\end{array}
				\right]
			</me>
			And we divide the pivot row by 3. <me>
				\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; \mybxsm{1} &amp; 0 &amp; 3 \\
				0 &amp; 0 &amp; 2 &amp; 4
				\end{array}
				\right]
			</me>
			We do not need to subtract anything as everything below the pivot is already zero. We
			move on, we again start ignoring the second row and second column and focus on <me>
			\left[
				\begin{array}{ccc|c}
				* &amp; * &amp; * &amp; * \\
				* &amp; * &amp; * &amp; * \\
				* &amp; * &amp; 2 &amp; 4
				\end{array}
				\right] .
			</me>
			We find the pivot, then divide that row by 2: <me>
				\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; 1 &amp; 0 &amp; 3 \\
				0 &amp; 0 &amp; \mybxsm{2} &amp; 4
				\end{array}
				\right]
				\qquad \to \qquad
				\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 1 &amp; 1 \\
				0 &amp; 1 &amp; 0 &amp; 3 \\
				0 &amp; 0 &amp; 1 &amp; 2
				\end{array}
				\right] .
			</me>
			The matrix is now in row echelon form. </p>

		<p> The equation corresponding to the last row is <m>x_3 = 2</m>. We know <m>x_3</m> and we
			could substitute it into the first two equations to get equations for <m>x_1</m> and <m>
			x_2</m>. Then we could do the same thing with <m>x_2</m>, until we solve for all 3
			variables. This procedure is called <em></em> and we can achieve it via elementary
			operations. We start from the lowest pivot (leading entry in the row echelon form) and
			subtract the right multiple from the row above to make all the entries above this pivot
			zero. Then we move to the next pivot and so on. After we are done, we will have a matrix
			in reduced row echelon form. </p>

		<p> We continue our example. Subtract the last row from the first to get <me>
				\left[
				\begin{array}{ccc|c}
				1 &amp; 1 &amp; 0 &amp; -1 \\
				0 &amp; 1 &amp; 0 &amp; 3 \\
				0 &amp; 0 &amp; 1 &amp; 2
				\end{array}
				\right] .
			</me>
			The entries above the pivot in the third row is already zero. So we move onto the next
			pivot, the one in the second row. We subtract this row from the top row to get <me>
			\left[
				\begin{array}{ccc|c}
				1 &amp; 0 &amp; 0 &amp; -4 \\
				0 &amp; 1 &amp; 0 &amp; 3 \\
				0 &amp; 0 &amp; 1 &amp; 2
				\end{array}
				\right] .
			</me>
			The matrix is in reduced row echelon form. </p>

		<p> If we now write down the equations for <m>x_1,x_2,x_3</m>, we find <me>
				x_1 = -4, \qquad x_2 = 3, \qquad x_3 = 2 .
			</me> In other words, we have solved the
			system. </p>


		<example>
			<title> </title>
			<statement>
				<p> Solve the following system of equations using row reduction: <me>
						\begin{split}
						\phantom{9} -x_1 + x_2 + 3x_3 &amp;= 7 \\
						-3x_1 \phantom{+x_2} + \phantom{9} x_3 &amp;= -5 \\
						-2x_1 - x_2 &amp;= -4
						\end{split}
					</me>

				</p>
			</statement>

			<solution>
				<p> In order to solve this problem, we need to set up the augmented matrix for this
					system, which is <me>
						\left[
						\begin{array}{ccc|c}
						-1 &amp; 1 &amp; 3 &amp; 7 \\
						-3 &amp; 0 &amp; 1 &amp; -5 \\
						-2 &amp; -1 &amp; 0 &amp; -4
						\end{array}
						\right]
					</me>

				</p>

				<p> To carry out the process, we need to get a 1 in the top left corner, then work
					from there. We multiply the first row by -1 to get <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -7 \\
						-3 &amp; 0 &amp; 1 &amp; -5 \\
						-2 &amp; -1 &amp; 0 &amp; -4
						\end{array}
						\right].
					</me>

				</p>

				<p> Next, we want to use row 1 to cancel out the <m>-3</m> and <m>-2</m> in column
					1. To do this, we add three copies of row 1 to row 2, and two copies of row 1 to
					row 3 to get the augmented matrix <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -7 \\
						0 &amp; -3 &amp; -8 &amp; -26 \\
						0 &amp; -3 &amp; -6 &amp; -18
						\end{array}
						\right].
					</me>

				</p>

				<p> Normally, the next step would be to divide the second row by <m>-3</m> in order
					to put a <m>1</m> in that pivot spot. However, since both the second and third
					rows have a <m>-3</m> in the second column, we can combine these two rows
					directly without dividing by <m>-3</m> first. We subtract row 2 from row 3 to
					get <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -7 \\
						0 &amp; -3 &amp; -8 &amp; -26 \\
						0 &amp; 0 &amp; 2 &amp; 8
						\end{array}
						\right]
					</me>
					and we can now use this to solve the system. The bottom row says that <m>2x_3 =
					8</m>, so that <m>x_3 = 4</m>. The second row says that <m>-3x_2 - 8x_3 = -26</m>,
					since <m>x_3 = 4</m>, we have that <m>-3x_2 = -26 + 32 = 6</m>, so <m>x_2 = -2</m>.
					Finally, the first row of the augmented matrix says that <m>x_1 - x_2 - 3x_3 =
					-7</m>. Plugging in our values for <m>x_2</m> and <m>x_3</m> gives <m>x_1 = -7 -
					2 + 12 = 3</m>. Therefore, the solution is <me>
						x_1 = 3 \quad x_2 = -2 \quad x_3 = 4.
					</me>

				</p>
			</solution>
		</example>
	</subsection>

	<subsection xml:id="non-unique-solutions-and-inconsistent-systems">
		<title>Non-unique solutions and inconsistent systems</title>

		<p> It is possible that the solution of a linear system of equations is not unique, or that
			no solution exists. Suppose for a moment that the row echelon form we found was <me>
			\left[
				\begin{array}{ccc|c}
				1 &amp; 2 &amp; 3 &amp; 4 \\
				0 &amp; 0 &amp; 1 &amp; 3 \\
				0 &amp; 0 &amp; 0 &amp; 1
				\end{array}
				\right] .
			</me>
			Then the last row gives the equation <m>0x_1 + 0x_2 + 0x_3 = 1</m>, or <m>0=1</m>. That
			is impossible and the equations are <em></em>. There is no solution to <m>A \vec{x} =
			\vec{b}</m>. </p>

		<p> On the other hand, if we find a row echelon form of <me>
				\left[
				\begin{array}{ccc|c}
				1 &amp; 2 &amp; 3 &amp; 4 \\
				0 &amp; 0 &amp; 1 &amp; 3 \\
				0 &amp; 0 &amp; 0 &amp; 0
				\end{array}
				\right] ,
			</me>
			then there is no issue with finding solutions. In fact, we will find way too many. Let
			us continue with backsubstitution (subtracting 3 times the second row from the first) to
			find the reduced row echelon form and let’s mark the pivots. <me>
				\left[
				\begin{array}{ccc|c}
				\mybxsm{1} &amp; 2 &amp; 0 &amp; -5 \\
				0 &amp; 0 &amp; \mybxsm{1} &amp; 3 \\
				0 &amp; 0 &amp; 0 &amp; 0
				\end{array}
				\right]
			</me>
			The last row is all zeros; it just says <m>0=0</m> and we ignore it. The two remaining
			equations are <me>
				x_1 + 2 x_2 = -5 , \qquad
				x_3 = 3 .
			</me> Let us solve for the variables that
			corresponded to the pivots, that is <m>x_1</m> and <m>x_3</m> as there was a pivot in
			the first column and in the third column: <me>\begin{align*}
				&amp; x_1 = - 2 x_2 -5 , \\
				&amp; x_3 = 3 .
				\end{align*}</me> The variable <m>x_2</m> can be anything you wish and we still get
			a solution. The <m>x_2</m> is called a <em></em>. There are infinitely many solutions,
			one for every choice of <m>x_2</m>. For example, if we pick <m>x_2=0</m>, then <m>x_1 =
			-5</m>, and <m>x_3 = 3</m> give a solution. But we also get a solution by picking say <m>x_2
			= 1</m>, in which case <m>x_1 = -7</m> and <m>x_3 = 3</m>, or by picking <m>x_2 = -5</m>
			in which case <m>x_1 = 5</m> and <m>x_3 = 3</m>. </p>

		<p> The general idea is that if any row has all zeros in the columns corresponding to the
			variables, but a nonzero entry in the column corresponding to the right-hand side <m>
			\vec{b}</m>, then the system is inconsistent and has no solutions. In other words, the
			system is inconsistent if you find a pivot on the right side of the vertical line drawn
			in the augmented matrix. Otherwise, the system is consistent, and at least one solution
			exists. </p>

		<p>
			If the system is consistent:
		</p>

		<p>
			<ol>
				<li>
					<p>
						If every column corresponding to a variable has a pivot element, then the
						solution is unique.
					</p>
				</li>

				<li>
					<p> If there are columns corresponding to variables with no pivot, then those
						are <em>free variables</em> that can be chosen arbitrarily, and there are
						infinitely many solutions. </p>
				</li>

			</ol>
		</p>

		<p> Another way to interpret this idea of free variables is that at the beginning, before
			you look at the system of equations, all of the variables can be anything, and there are
			no constraints on them. The equations then give us constraints on these variables,
			because they give us rules that the variables must satisfy. When we have a row of the
			augmented matrix that becomes all zeros, it means that the equation that was there is
			redundant and doesn’t add any constraints to the equations. This may result in an <em></em>
			system, which will likely have free variables. </p>


		<example>
			<title> </title>
			<statement>
				<p>
					Solve the following two systems of equations, or determine that no solution
					exists, using row reduction:
				</p>

				<!-- div attr= class="minipage"-->
				<p>

					<me>
						\begin{split}
						x_1 - \phantom{9} x_2 - 3x_3 &amp; = -3 \\
						-x_1 - 2x_2 + 4x_3 &amp;= 6 \\
						x_1 + 5x_2 - 5x_3 &amp;= -9
						\end{split}
					</me>

				</p><!--</div
				attr= class="minipage">-->

				<!-- div attr= class="minipage"-->
				<p>

					<me>
						\begin{split}
						x_1 - \phantom{9} x_2 - 3x_3 &amp; = -3 \\
						-x_1 - 2x_2 + 4x_3 &amp;= 6 \\
						x_1 + 5x_2 - 5x_3 &amp;= 1
						\end{split}
					</me>

				</p><!--</div
				attr= class="minipage">-->
			</statement>

			<solution>
				<p> For the first of these systems, we will set up the augmented matrix and proceed
					through the process like normal. The augmented matrix is <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -3 \\
						-1 &amp; -2 &amp; 4 &amp; 6 \\
						1 &amp; 5 &amp; -5 &amp; -9
						\end{array}
						\right].
					</me>
					Since we already have a <m>1</m> in the top-left corner of this matrix, we can
					use it to cancel the entries in the rest of column <m>1</m>. We add one copy of
					row 1 to row 2, and subtract row 1 from row 3 to get the next augmented form
					matrix as <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -3 \\
						0 &amp; -3 &amp; 1 &amp; 3 \\
						0 &amp; 6 &amp; -2 &amp; -6
						\end{array}
						\right].
					</me>
					Looking at the matrix here, we see that row 3 is <m>-2</m> times row 2.
					Therefore, if we add two copies of row 2 to row 3, we get the augmented matrix <me>
					\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -3 \\
						0 &amp; -3 &amp; 1 &amp; 3 \\
						0 &amp; 0 &amp; 0 &amp; 0
						\end{array}
						\right].
					</me>
					Therefore, we have a situation where there are only two pivot columns, and the
					last row is all zeros. Since there are three variables and column 3 is not a
					pivot column, we can take <m>x_3</m> as a free variable. If we do that, the
					second equation tells us that <m>-3x_2 + x_3 = 3</m>, or, since we are taking <m>
					x_3</m> as a free variable, we can write <m>x_2 = -1 + \nicefrac{1}{3}x_3</m>.
					We can then take the first equation, which says that <m>x_1 - x_2 - 3x_3 = -3</m>
					or, by rearranging <me>
						x_1 = -3 + x_2 + 3x_3 = -3 + \left(-1 + \frac{1}{3}x_3\right) + 3x_3 = -4 +
					\frac{10}{3}x_3.
					</me>
					This means that for any value of <m>t</m>, our solution is determined by <me>
					\begin{split}
						x_1 &amp;= -4 + \frac{10}{3}t \\
						x_2 &amp;= -1 + \frac{1}{3}t \\
						x_3 &amp;= t
						\end{split}.
					</me>
					The use of <m>t</m> here is just to separate it from the variable <m>x_3</m>.
					For example, we could pick <m>t=3</m>, in which case we would get <m>x_1 = 6</m>
					, <m>x_2 = 0</m>, <m>x_3 = 3</m>. </p>

				<p> For the second version of the problem, we again set up the augmented matrix <me>
					\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -3 \\
						-1 &amp; -2 &amp; 4 &amp; 6 \\
						1 &amp; 5 &amp; -5 &amp; 1
						\end{array}
						\right].
					</me>
					Since the left side matrix part is the same as the previous version, the process
					of row reducing the matrix is identical to what was done previously. When we
					carry out this process we get the augmented matrix <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; -1 &amp; -3 &amp; -3 \\
						0 &amp; -3 &amp; 1 &amp; 3 \\
						0 &amp; 0 &amp; 0 &amp; 10
						\end{array}
						\right].
					</me>
					In this case, we see that the last row corresponds to the equation <m>0 = 10</m>
					so these equations are inconsistent and do not have a solution. </p>
			</solution>
		</example>
		<p>
			The point of the above example is to illustrate the fact that whether or not a system is
			inconsistent or has free variables in the solution depends on the right-hand side of the
			equation, even if the left-hand side has the same coefficients. We’ll see more about why
			this is in .
		</p>

		<p> When <m>\vec{b} = \vec{0}</m>, we have a so-called <em></em> 
<me>
				A \vec{x} = \vec{0} .
			</me> There is no need to write an augmented matrix in this
			case. As the elementary operations do not do anything to a zero column, it always stays
			a zero column. Moreover, <m>A \vec{x} = \vec{0}</m> always has at least one solution,
			namely <m>\vec{x} = \vec{0}</m>. Such a system is always consistent. It may have other
			solutions: If you find any free variables, then you get infinitely many solutions. As
			mentioned in the last section, this is directly connected to linear independence of the
			columns of <m>A</m>. If there are other solutions, then there are other linear
			combinations that give <m>\vec{0}</m>, and so the columns of <m>A</m> are linearly
			dependent. Otherwise, if there are no such solutions outside of <m>\vec{x} = \vec{0}</m>,
			then the columns of <m>A</m> are linearly independent. </p>

		<p> How would we determine this fact? We don’t need to include the zero column on the far
			right, but we can apply the same operations to the matrix <m>A</m> alone. In this case,
			we either get a pivot column in every column for the row echelon form, in which case the
			only solution is <m>\vec{x} = \vec{0}</m>, or we get at least one non-pivot column,
			which means that there are free variables, implying that non-zero solutions exist. This
			leads to a first equivalence statement we can make about the solution to homogeneous
			matrix equations. </p>

		<!-- div attr= class="theorem"-->
		<p> Let <m>A</m> be a matrix. The following statements are equivalent (meaning if any one of
			them is true, so are all of the other ones): </p>

		<p>
			<ol>
				<li>
					<p> The only solution to the matrix equation <m>A\vec{x} = \vec{0}</m> is <m>\vec{x}
						= \vec{0}</m>. </p>
				</li>

				<li>
					<p> The row echelon form of <m>A</m> has a pivot element in every column. </p>
				</li>

				<li>
					<p> The reduced row echelon form of <m>A</m> is an identity matrix, potentially
						with rows of zero on the bottom. </p>
				</li>

				<li>
					<p> The columns of <m>A</m> are linearly independent. </p>
				</li>

			</ol>
		</p><!--</div
		attr= class="theorem">-->

		<p> The set of solutions of <m>A \vec{x} = \vec{0}</m> comes up quite often so people give
			it a name. It is called the <em></em> or the <em></em> of <m>A</m>. One place where the
			kernel comes up is invertibility of a square matrix <m>A</m>. If the kernel of <m>A</m>
			contains a nonzero vector, then it contains infinitely many vectors (there was a free
			variable). But then it is impossible to invert <m>\vec{0}</m>, since infinitely many
			vectors go to <m>\vec{0}</m>, so there is no unique vector that <m>A</m> takes to <m>
			\vec{0}</m>. So if the kernel is nontrivial, that is, if there are any nonzero vectors,
			in other words, if there are any free variables, or in yet other words, if the row
			echelon form of <m>A</m> has columns without pivots, then <m>A</m> is not invertible. We
			will return to this idea later. </p>

	</subsection>

	<exercises>
		<title>Exercises</title>

		<!-- div attr= class="samepage"-->
		<exercise>
			<statement>
				<p>
					Compute the reduced row echelon form for the following matrices:
				</p>

				<!-- div attr= class="tasks"-->
				<p> (4) <m>\begin{bmatrix}
						1 &amp; 3 &amp; 1 \\
						0 &amp; 1 &amp; 1
						\end{bmatrix}</m> <m>\begin{bmatrix}
						3 &amp; 3 \\
						6 &amp; -3
						\end{bmatrix}</m> <m>\begin{bmatrix}
						3 &amp; 6 \\
						-2 &amp; -3
						\end{bmatrix}</m> <m>\begin{bmatrix}
						6 &amp; 6 &amp; 7 &amp; 7 \\
						1 &amp; 1 &amp; 0 &amp; 1
						\end{bmatrix}</m> <m>\begin{bmatrix}
						9 &amp; 3 &amp; 0 &amp; 2 \\
						8 &amp; 6 &amp; 3 &amp; 6 \\
						7 &amp; 9 &amp; 7 &amp; 9
						\end{bmatrix}</m> <m>\begin{bmatrix}
						2 &amp; 1 &amp; 3 &amp; -3 \\
						6 &amp; 0 &amp; 0 &amp; -1 \\
						-2 &amp; 4 &amp; 4 &amp; 3
						\end{bmatrix}</m> <m>\begin{bmatrix}
						6 &amp; 6 &amp; 5 \\
						0 &amp; -2 &amp; 2 \\
						6 &amp; 5 &amp; 6
						\end{bmatrix}</m> <m>\begin{bmatrix}
						0 &amp; 2 &amp; 0 &amp; -1 \\
						6 &amp; 6 &amp; -3 &amp; 3 \\
						6 &amp; 2 &amp; -3 &amp; 5
						\end{bmatrix}</m>
				</p><!--</div
				attr= class="tasks">--><!--</div
				attr= class="samepage">-->
			</statement>

			<answer>
				<p> a) <m>\left[\begin{smallmatrix} 1 &amp; 0 &amp; -2 \\ 0 &amp; 1 &amp; 1
					\end{smallmatrix}\right]</m> b) <m>\left[\begin{smallmatrix} 1 &amp; 0 \\ 0
					&amp; 1 \end{smallmatrix}\right]</m> c) <m>\left[\begin{smallmatrix} 1 &amp; 0
					\\ 0 &amp; 1 \end{smallmatrix}\right]</m> d) <m>\left[\begin{smallmatrix} 1
					&amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 1/7 \end{smallmatrix}\right]</m><!--
					linebreak -->
					e) <m>\left[\begin{smallmatrix} 1 &amp; 0 &amp; 0 &amp; -1/2 \\ 0 &amp; 1 &amp;
					0 &amp; 13/6 \\ 0 &amp; 0 &amp; 1 &amp; -1 \end{smallmatrix}\right]</m> f) <m>\left[\begin{smallmatrix}
					1 &amp; 0 &amp; 0 &amp; -1/6 \\ 0 &amp; 1 &amp; 0 &amp; 7/3 \\ 0 &amp; 0 &amp; 1
					&amp; -5/3 \end{smallmatrix}\right]</m> g) <m>\left[\begin{smallmatrix} 1 &amp;
					0 &amp; 11/6 \\ 0 &amp; 1 &amp; -1 \\ 0 &amp; 0 &amp; 0 \end{smallmatrix}\right]</m>
					h) <m>\left[\begin{smallmatrix} 1 &amp; 0 &amp; -1/2 &amp; 1 \\ 0 &amp; 1 &amp;
					0 &amp; -1/2 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{smallmatrix}\right]</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p>
					Compute the reduced row echelon form for the following matrices:
				</p>

				<!-- div attr= class="tasks"-->
				<p> (4) <m>\begin{bmatrix}
						1 &amp; 0 &amp; 1 \\
						0 &amp; 1 &amp; 0
						\end{bmatrix}</m> <m>\begin{bmatrix}
						1 &amp; 2 \\
						3 &amp; 4
						\end{bmatrix}</m> <m>\begin{bmatrix}
						1 &amp; 1 \\
						-2 &amp; -2
						\end{bmatrix}</m> <m>\begin{bmatrix}
						1 &amp; -3 &amp; 1 \\
						4 &amp; 6 &amp; -2 \\
						-2 &amp; 6 &amp; -2
						\end{bmatrix}</m> <m>\begin{bmatrix}
						2 &amp; 2 &amp; 5 &amp; 2 \\
						1 &amp; -2 &amp; 4 &amp; -1 \\
						0 &amp; 3 &amp; 1 &amp; -2
						\end{bmatrix}</m> <m>\begin{bmatrix}
						-2 &amp; 6 &amp; 4 &amp; 3 \\
						6 &amp; 0 &amp; -3 &amp; 0 \\
						4 &amp; 2 &amp; -1 &amp; 1
						\end{bmatrix}</m> <m>\begin{bmatrix}
						0 &amp; 0 &amp; 0 &amp; 0 \\
						0 &amp; 0 &amp; 0 &amp; 0
						\end{bmatrix}</m> <m>\begin{bmatrix}
						1 &amp; 2 &amp; 3 &amp; 3 \\
						1 &amp; 2 &amp; 3 &amp; 5
						\end{bmatrix}</m>
				</p><!--</div
				attr= class="tasks">-->
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p>
					Solve (find all solutions), or show no solution exists
				</p>

				<!-- div attr= class="tasks"-->
				<p> (2) <m>\begin{aligned}
						4x_1+3x_2 &amp; = -2 \\
						-x_1+\phantom{3} x_2 &amp; = 4
						\end{aligned}</m> <m>\begin{aligned}
						x_1+5x_2+3x_3 &amp; = 7 \\
						8x_1+7x_2+8x_3 &amp; = 8 \\
						4x_1+8x_2+6x_3 &amp; = 4
						\end{aligned}</m> <m>\begin{aligned}
						4x_1+8x_2+2x_3 &amp; = 3 \\
						-x_1-2x_2+3x_3 &amp; = 1 \\
						4x_1+8x_2 \phantom{{}+3x_3} &amp; = 2
						\end{aligned}</m> <m>\begin{aligned}
						x+2y+3z &amp; = 4 \\
						2 x-\phantom{2} y+3z &amp; = 1 \\
						3 x+\phantom{2} y+6z &amp; = 6
						\end{aligned}</m>
				</p><!--</div
				attr= class="tasks">-->
			</statement>

			<answer>
				<p> a) <m>x_1 = -2</m>, <m>x_2 = 2</m> b)  <m>x_1 = -4</m>, <m>x_2 = -16</m>. <m>x_3
					= 36</m><!-- linebreak -->c) <m>x_1 = \frac{1}{2} - 2t</m>, <m>x_2 = t</m>, <m>x_3 = \frac{1}{2}</m>,
					any real <m>t</m> d)  No solution </p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p>
					Solve (find all solutions), or show no solution exists
				</p>

				<!-- div attr= class="tasks"-->
				<p> (2) <m>\begin{aligned}
						4x_1+3x_2 &amp; = -1 \\
						5x_1+6x_2 &amp; = 4
						\end{aligned}</m> <m>\begin{aligned}
						5x+6y+5z &amp; = 7 \\
						6x+8y+6z &amp; = -1 \\
						5x+2y+5z &amp; = 2
						\end{aligned}</m> <m>\begin{aligned}
						a+\phantom{5}b+\phantom{6}c &amp; = -1 \\
						a+5b+6c &amp; = -1 \\
						-2a+5b+6c &amp; = 8
						\end{aligned}</m> <m>\begin{aligned}
						-2 x_1+2x_2+8x_3 &amp; = 6 \\
						x_2+\phantom{8}x_3 &amp; = 2 \\
						x_1+4x_2+\phantom{8}x_3 &amp; = 7
						\end{aligned}</m>
				</p><!--</div
				attr= class="tasks">-->
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Solve the system of equations <me>
						\begin{split}
						-4x_2 + x_3 + 2x_4 &amp;= 16 \\
						2x_1 + 2x_2 - 4x_3 - 3x_4 &amp;= 1 \\
						x_1 + x_2 + 2x_3 + 3x_4 &amp;= 6 \\
						2x_1 - 2x_3 + 4x_4 &amp;= 24
						\end{split}
					</me>
					or determine that no solution exists. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Solve the system of equations <me>
						\begin{split}
						3x_2 + 3x_3 + 2x_4 &amp;= 4 \\
						4x_1 + 4x_2 + 2x_3 - 4x_4 &amp;= -26 \\
						x_1 - 3x_2 -2x_3 + 2x_4 &amp;= 1 \\
						3x_1 + 3x_2 + 3x_3 - x_4 &amp;= -14
						\end{split}
					</me>
					or determine that no solution exists. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Solve the system of equations <me>
						\begin{split}
						2x_1 + x_2 - x_3 + 4x_4 &amp;= 11 \\
						x_1 + 4x_2 - 4x_3 - x_4 &amp;= -7 \\
						-2x_1 - 3x_2 + 2x_3 + x_4 &amp;= 11 \\
						3x_1 + x_3 + 4x_4 &amp;= 3
						\end{split}
					</me>
					or determine that no solution exists. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Solve the system of equations <me>
						\begin{split}
						x_1 - x_3 - 4x_4 &amp;= -3 \\
						x_1 + x_2 + x_4 &amp;= 0\\
						x_1 + 3x_2 + 3x_3 - 4x_4 &amp;= -28 \\
						6x_1 + 3x_2 - 4x_3 + 6x_4 &amp;= 25
						\end{split}
					</me>
					or determine that no solution exists. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Assume that you are solving a three component linear system of equations via row
					reduction of an augmented matrix and reach the matrix <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; 0 &amp; 3 &amp; 4 \\
						0 &amp; 0 &amp; 1 &amp; 3 \\
						0 &amp; 0 &amp; 0 &amp; 1
						\end{array}
						\right].
					</me>
					What does this mean about the solution to this system of equations? </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Assume that you are solving a three component linear system of equations via row
					reduction of an augmented matrix and reach the matrix <me>
						\left[
						\begin{array}{ccc|c}
						1 &amp; 1 &amp; 3 &amp; 6 \\
						0 &amp; 1 &amp; 2 &amp; 4 \\
						0 &amp; 0 &amp; 0 &amp; 0
						\end{array}
						\right].
					</me>
					What does this mean about the solution to this system of equations? </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Assume that you are solving a four component linear system of equations via row
					reduction of an augmented matrix and reach the matrix <me>
						\left[
						\begin{array}{cccc|c}
						1 &amp; 2 &amp; 3 &amp; 5 &amp; 1 \\
						0 &amp; 2 &amp; 1 &amp; 4 &amp; 2 \\
						0 &amp; 1 &amp; 0 &amp; 3 &amp; 0 \\
						0 &amp; 3 &amp; 2 &amp; -1 &amp; 1
						\end{array}
						\right].
					</me>
					What is the next step in reducing this matrix? Carry out the rest of this
					problem to solve the corresponding system of equations. </p>
			</statement>

			<answer>
				<p> Swap rows 2 and 3, then cancel down. <m>x_1 = -\frac{15}{2}</m>, <m>x_2 =
					-\frac{3}{2}</m>, <m>x_3 = 3</m>, <m>x_4 = \frac{1}{2}</m>
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Assume that someone else has provided you the solution to an augmented matrix
					reduction for solving a system of equations given below <me>
						\begin{bmatrix}
						1 &amp; 1 &amp; 2 &amp; 4 \\
						0 &amp; 1 &amp; 3 &amp; 5 \\
						1 &amp; 2 &amp; 4 &amp; -1
						\end{bmatrix} \ \rightarrow \ \begin{bmatrix} 1 &amp; 1 &amp; 2 &amp; 4 \\ 0
					&amp; 1 &amp; 3 &amp; 5 \\ 0 &amp; 1 &amp; 2 &amp; -5 \end{bmatrix} \
					\rightarrow \ \begin{bmatrix} 1 &amp; 1 &amp; 2 &amp; 4 \\ 0 &amp; 0 &amp; 1
					&amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; -9 \end{bmatrix}.
					</me>
					Is this work correct? If so, what does this say about the solution(s) to the
					system? If not, correct the work to solve the system. </p>
			</statement>

		</exercise>
		<exercise>
			<statement>
				<p> Find the row echelon form of the matrix <m>A</m> given below. What does this
					tell you about the solutions to the equation <m>A\vec{x} = \vec{0}</m>? <me>
						A = \begin{bmatrix} 1 &amp; 2 &amp; 4 \\ -2 &amp; -3 &amp; -6 \\ 1 &amp; 1
					&amp; 2 \end{bmatrix}
					</me>

				</p>
			</statement>

			<answer>
				<p>
					There are infinitely many solutions.
				</p>
			</answer>
		</exercise>

		<exercise>
			<statement>
				<p> Find the row echelon form of the matrix <m>A</m> given below. What does this
					tell you about the solutions to the equation <m>A\vec{x} = \vec{0}</m>? <me>
						A = \begin{bmatrix} 1 &amp; -1 &amp; 4 &amp; 1 \\ 2 &amp; -3 &amp; 10 &amp;
					2 \\ -3 &amp; 4 &amp; -15 &amp; -4 \\ 3 &amp; -5 &amp; 17 &amp; 3 \end{bmatrix}
					</me>

				</p>
			</statement>

			<answer>
				<p> There is only one solution, <m>\vec{x} = \vec{0}</m>. </p>
			</answer>
		</exercise>
	</exercises>

</section>



